<doc id="3107" url="https://en.wikipedia.org/wiki?curid=3107" title="Asymptote">
Asymptote

In analytic geometry, an asymptote () of a curve is a line such that the distance between the curve and the line approaches zero as they tend to infinity. Some sources include the requirement that the curve may not cross the line infinitely often, but this is unusual for modern authors. In some contexts, such as algebraic geometry, an asymptote is defined as a line which is tangent to a curve at infinity.
The word asymptote is derived from the Greek ἀσύμπτωτος ("asumptōtos") which means "not falling together", from ἀ priv. + σύν "together" + πτωτ-ός "fallen". The term was introduced by Apollonius of Perga in his work on conic sections, but in contrast to its modern meaning, he used it to mean any line that does not intersect the given curve.
There are potentially three kinds of asymptotes: "horizontal", "vertical" and "oblique" asymptotes. For curves given by the graph of a function , horizontal asymptotes are horizontal lines that the graph of the function approaches as "x" tends to Vertical asymptotes are vertical lines near which the function grows without bound.
More generally, one curve is a "curvilinear asymptote" of another (as opposed to a "linear asymptote") if the distance between the two curves tends to zero as they tend to infinity, although the term "asymptote" by itself is usually reserved for linear asymptotes.
Asymptotes convey information about the behavior of curves "in the large", and determining the asymptotes of a function is an important step in sketching its graph. The study of asymptotes of functions, construed in a broad sense, forms a part of the subject of asymptotic analysis.
Introduction.
The idea that a curve may come arbitrarily close to a line without actually becoming the same may seem to counter everyday experience. The representations of a line and a curve as marks on a piece of paper or as pixels on a computer screen have a positive width. So if they were to be extended far enough they would seem to merge, at least as far as the eye could discern. But these are physical representations of the corresponding mathematical entities; the line and the curve are idealized concepts whose width is 0 (see Line). Therefore the understanding of the idea of an asymptote requires an effort of reason rather than experience.
Consider the graph of the function formula_1 shown to the right. The coordinates of the points on the curve are of the form formula_2 where x is a number other than 0. For example, the graph contains the points (1, 1), (2, 0.5), (5, 0.2), (10, 0.1), ... As the values of formula_3 become larger and larger, say 100, 1000, 10,000 ..., putting them far to the right of the illustration, the corresponding values of formula_4, .01, .001, .0001, ..., become infinitesimal relative to the scale shown. But no matter how large formula_3 becomes, its reciprocal formula_6 is never 0, so the curve never actually touches the "x"-axis. Similarly, as the values of formula_3 become smaller and smaller, say .01, .001, .0001, ..., making them infinitesimal relative to the scale shown, the corresponding values of formula_4, 100, 1000, 10,000 ..., become larger and larger. So the curve extends farther and farther upward as it comes closer and closer to the "y"-axis. Thus, both the "x" and "y"-axes are asymptotes of the curve. These ideas are part of the basis of concept of a limit in mathematics, and this connection is explained more fully below.
Asymptotes of functions.
The asymptotes most commonly encountered in the study of calculus are of curves of the form . These can be computed using limits and classified into "horizontal", "vertical" and "oblique" asymptotes depending on its orientation. Horizontal asymptotes are horizontal lines that the graph of the function approaches as "x" tends to +∞ or −∞. As the name indicate they are parallel to the "x"-axis. Vertical asymptotes are vertical lines (perpendicular to the "x"-axis) near which the function grows without bound. Oblique asymptotes are diagonal lines so that the difference between the curve and the line approaches 0 as "x" tends to +∞ or −∞. More general type of asymptotes can be defined in this case. Only open curves that have some infinite branch, can have an asymptote. No closed curve can have an asymptote.
Vertical asymptotes.
The line "x" = "a" is a "vertical asymptote" of the graph of the function if at least one of the following statements is true:
The function "ƒ"("x") may or may not be defined at "a", and its precise value at the point "x" = "a" does not affect the asymptote. For example, for the function
has a limit of +∞ as , "ƒ"("x") has the vertical asymptote , even though "ƒ"(0) = 5. The graph of this function does intersect the vertical asymptote once, at (0,5). It is impossible for the graph of a function to intersect a vertical asymptote (or a vertical line in general) in more than one point. Moreover, if a function is continuous at each point where it is defined, it is impossible that its graph does intersect any vertical asymptote.
A common example of a vertical asymptote is the case of a rational function at a point x such that the denominator is zero and the numerator is non-zero.
Horizontal asymptotes.
"Horizontal asymptotes" are horizontal lines that the graph of the function approaches as . The horizontal line "y" = "c" is a horizontal asymptote of the function "y" = "ƒ"("x") if
In the first case, "ƒ"("x") has "y" = "c" as asymptote when "x" tends to −∞, and in the second that "ƒ"("x") has "y" = "c" as an asymptote as "x" tends to +∞
For example the arctangent function satisfies
So the line is a horizontal tangent for the arctangent when "x" tends to −∞, and is a horizontal tangent for the arctangent when "x" tends to +∞.
Functions may lack horizontal asymptotes on either or both sides, or may have one horizontal asymptote that is the same in both directions. For example, the function has a horizontal asymptote at "y" = 0 when "x" tends both to −∞ and +∞ because, respectively,
Oblique asymptotes.
When a linear asymptote is not parallel to the "x"- or "y"-axis, it is called an "oblique asymptote" or "slant asymptote". A function "f"("x") is asymptotic to the straight line ("m" ≠ 0) if
formula_17
In the first case the line is an oblique asymptote of "ƒ"("x") when "x" tends to +∞, and in the second case the line is an oblique asymptote of "ƒ(x)" when "x" tends to −∞
An example is ƒ("x") = "x" + 1/"x", which has the oblique asymptote "y" = "x" (that is "m" = 1, "n" = 0) as seen in the limits
Elementary methods for identifying asymptotes.
The asymptotes of many elementary functions can be found without the explicit use of limits (although the derivations of such methods typically use limits).
General computation of oblique asymptotes for functions.
The oblique asymptote, for the function "f"("x"), will be given by the equation "y"="mx"+"n". The value for "m" is computed first and is given by
where "a" is either formula_22 or formula_23 depending on the case being studied. It is good practice to treat the two cases separately. If this limit doesn't exist then there is no oblique asymptote in that direction.
Having "m" then the value for "n" can be computed by
where "a" should be the same value used before. If this limit fails to exist then there is no oblique asymptote in that direction, even should the limit defining "m" exist. Otherwise is the oblique asymptote of "ƒ"("x") as "x" tends to "a".
For example, the function has
so that is the asymptote of "ƒ"("x") when "x" tends to +∞.
The function has
So does not have an asymptote when "x" tends to +∞.
Asymptotes for rational functions.
A rational function has at most one horizontal asymptote or oblique (slant) asymptote, and possibly many vertical asymptotes.
The degree of the numerator and degree of the denominator determine whether or not there are any horizontal or oblique asymptotes. The cases are tabulated below, where deg(numerator) is the degree of the numerator, and deg(denominator) is the degree of the denominator.
The vertical asymptotes occur only when the denominator is zero (If both the numerator and denominator are zero, the multiplicities of the zero are compared). For example, the following function has vertical asymptotes at "x" = 0, and "x" = 1, but not at "x" = 2.
Oblique asymptotes of rational functions.
When the numerator of a rational function has degree exactly one greater than the denominator, the function has an oblique (slant) asymptote. The asymptote is the polynomial term after dividing the numerator and denominator. This phenomenon occurs because when dividing the fraction, there will be a linear term, and a remainder. For example, consider the function 
shown to the right. As the value of "x" increases, "f" approaches the asymptote "y" = "x". This is because the other term, "y" = 1/("x"+1) becomes smaller.
If the degree of the numerator is more than 1 larger than the degree of the denominator, and the denominator does not divide the numerator, there will be a nonzero remainder that goes to zero as "x" increases, but the quotient will not be linear, and the function does not have an oblique asymptote.
Transformations of known functions.
If a known function has an asymptote (such as "y"=0 for "f"(x)="e"), then the translations of it also have an asymptote.
If a known function has an asymptote, then the scaling of the function also have an asymptote.
For example, "f"("x")="e"+2 has horizontal asymptote "y"=0+2=2, and no vertical or oblique asymptotes.
General definition.
Let be a parametric plane curve, in coordinates "A"("t") = ("x"("t"),"y"("t")). Suppose that the curve tends to infinity, that is: 
A line ℓ is an asymptote of "A" if the distance from the point "A"("t") to ℓ tends to zero as "t" → "b".
For example, the upper right branch of the curve "y" = 1/"x" can be defined parametrically as "x" = "t", "y" = 1/"t" (where "t">0). First, "x" → ∞ as "t" → ∞ and the distance from the curve to the "x"-axis is 1/"t" which approaches 0 as "t" → ∞. Therefore the "x"-axis is an asymptote of the curve. Also, "y" → ∞ as "t" → 0 from the right, and the distance between the curve and the "y"-axis is "t" which approaches 0 as "t" → 0. So the "y"-axis is also an asymptote. A similar argument shows that the lower left branch of the curve also has the same two lines as asymptotes.
Although the definition here uses a parameterization of the curve, the notion of asymptote does not depend on the parameterization. In fact, if the equation of the line is formula_32 then the distance from the point "A"("t") = ("x"("t"),"y"("t")) to the line is given by
if γ("t") is a change of parameterization then the distance becomes
which tends to zero simultaneously as the previous expression.
An important case is when the curve is the graph of a real function (a function of one real variable and returning real values). The graph of the function "y" = "ƒ"("x") is the set of points of the plane with coordinates ("x","ƒ"("x")). For this, a parameterization is
This parameterization is to be considered over the open intervals ("a","b"), where "a" can be −∞ and "b" can be +∞.
An asymptote can be either vertical or non-vertical (oblique or horizontal). In the first case its equation is "x" = "c", for some real number "c". The non-vertical case has equation , where "m" and formula_36 are real numbers. All three types of asymptotes can be present at the same time in specific examples. Unlike asymptotes for curves that are graphs of functions, a general curve may have more than two non-vertical asymptotes, and may cross its vertical asymptotes more than once.
Curvilinear asymptotes.
Let be a parametric plane curve, in coordinates "A"("t") = ("x"("t"),"y"("t")), and "B" be another (unparameterized) curve. Suppose, as before, that the curve "A" tends to infinity. The curve "B" is a curvilinear asymptote of "A" if the shortest of the distance from the point "A"("t") to a point on "B" tends to zero as "t" → "b". Sometimes "B" is simply referred to as an asymptote of "A", when there is no risk of confusion with linear asymptotes.
For example, the function
has a curvilinear asymptote , which is known as a "parabolic asymptote" because it is a parabola rather than a straight line.
Asymptotes and curve sketching.
Asymptotes are used in procedures of curve sketching. An asymptote serves as a guide line to show the behavior of the curve towards infinity. In order to get better approximations of the curve, curvilinear asymptotes have also been used although the term asymptotic curve seems to be preferred.
Algebraic curves.
The asymptotes of an algebraic curve in the affine plane are the lines that are tangent to the projectivized curve through a point at infinity. For example, one may identify the asymptotes to the unit hyperbola in this manner. Asymptotes are often considered only for real curves, although they also make sense when defined in this way for curves over an arbitrary field.
A plane curve of degree "n" intersects its asymptote at most at "n"−2 other points, by Bézout's theorem, as the intersection at infinity is of multiplicity at least two. For a conic, there are a pair of lines that do not intersect the conic at any complex point: these are the two asymptotes of the conic.
A plane algebraic curve is defined by an equation of the form "P"("x","y") = 0 where "P" is a polynomial of degree "n"
where "P" is homogeneous of degree "k". Vanishing of the linear factors of the highest degree term "P" defines the asymptotes of the curve: setting , if , then the line
is an asymptote if formula_40 and formula_41 are not both zero. If formula_42 and formula_43, there is no asymptote, but the curve has a branch that looks like a branch of parabola. Such a branch is called a parabolic branch, even when it does not have any parabola that is a curvilinear asymptote. If formula_44 the curve has a singular point at infinity which may have several asymptotes or parabolic branches.
Over the complex numbers, "P" splits into linear factors, each of which defines an asymptote (or several for multiple factors). 0ver the reals, "P" splits in factors that are linear or quadratic factors. Only the linear factors correspond to infinite (real) branches of the curve, but if a linear factor has multiplicity greater than one, the curve may have several asymptotes or parabolic branches. It may also occur that such a multiple linear factor corresponds to two complex conjugate branches, and does not corresponds to any infinite branch of the real curve. For example, the curve has no real points outside the square formula_45, but its highest order term gives the linear factor "x" with multiplicity 4, leading to the unique asymptote "x"=0.
Asymptotic cone.
The hyperbola
has the two asymptotes 
The equation for the union of these two lines is
Similarly, the hyperboloid
is said to have the asymptotic cone
The distance between the hyperboloid and cone approaches 0 as the distance from the origin approaches infinity.
More generally, let us consider a surface that has an implicit equation 
formula_51
where the formula_52 are homogeneous polynomials of degree formula_53 and formula_54. Then the equation formula_55 defines a cone which is centered at the origin. It is called an asymptotic cone, because the distance to the cone of a point of the surface tends to zero when the point on the surface tends to infinity.

</doc>
<doc id="3110" url="https://en.wikipedia.org/wiki?curid=3110" title="Andrew S. Tanenbaum">
Andrew S. Tanenbaum

Andrew Stuart "Andy" Tanenbaum (sometimes referred to by the handle ast) (born March 16, 1944) is an American computer scientist and professor emeritus of computer science at the Vrije Universiteit, Amsterdam in the Netherlands.
He is best known as the author of MINIX, a free Unix-like operating system for teaching purposes, and for his computer science textbooks, regarded as standard texts in the field. He regards his teaching job as his most important work. Since 2004 he has operated Electoral-vote.com, a website dedicated to analysis of polling data in federal elections in the United States.
Biography.
Tanenbaum was born in New York City and grew up in suburban White Plains, New York.
He received his bachelor of Science degree in Physics from MIT in 1965 and his Ph.D. degree in physics from the University of California, Berkeley in 1971. Tanenbaum also served as a lobbyist for the Sierra Club.
He moved to the Netherlands to live with his wife, who is Dutch, but he retains his United States citizenship. He teaches courses about Computer Organization and Operating Systems and supervises the work of Ph.D. candidates at the VU University Amsterdam.
On , he announced his retirement.
Teaching.
Books.
Tanenbaum is well recognized for his textbooks on computer science. They include:
His book, "Operating Systems: Design and Implementation" and MINIX were Linus Torvalds' inspiration for the Linux kernel. In his autobiography "Just for Fun", Torvalds describes it as "the book that launched me to new heights".
His books have been translated into many languages including Arabic, Basque, Bulgarian, Chinese, Dutch, French, German, Greek, Hebrew, Hungarian, Italian, Japanese, Korean, Macedonian, Mexican Spanish, Persian, Polish, Portuguese, Romanian, Russian, Serbian, and Spanish. They have appeared in over 175 editions and are used at universities around the world.
Doctoral students.
Tanenbaum has had a number of Ph.D. students who themselves have gone on to become widely known computer science researchers.
These include:
Dean of the Advanced School for Computing and Imaging.
In the early 1990s, the Dutch government began setting up a number of thematically oriented research schools that spanned multiple universities. These schools were intended to bring professors and Ph.D. students from different Dutch (and later, foreign) universities together to help them cooperate and enhance their research.
Tanenbaum was one of the cofounders and first Dean of the Advanced School for Computing and Imaging (ASCI). This school initially consisted of nearly 200 faculty members and Ph.D. students from the Vrije Universiteit, University of Amsterdam, Delft University of Technology, and Leiden University. They were especially working on problems in advanced computer systems such as parallel computing and image analysis and processing.
Tanenbaum remained dean for 12 years, until 2005, when he was awarded an Academy Professorship by the Royal Netherlands Academy of Arts and Sciences, at which time he became a full-time research professor. ASCI has since grown to include researchers from nearly a dozen universities in The Netherlands, Belgium, and France. ASCI offers Ph.D. level courses, has an annual conference, and runs various workshops every year.
Projects.
Amsterdam Compiler Kit.
The Amsterdam Compiler Kit is a toolkit for producing portable compilers. It was started sometime before 1981 and Andrew Tanenbaum was the architect from the start until version 5.5.
MINIX.
In 1987, Tanenbaum wrote a clone of UNIX, called MINIX (MINi-unIX), for the IBM PC. It was targeted at students and others who wanted to learn how an operating system worked. Consequently, he wrote a book that listed the source code in an appendix and described it in detail in the text. The source code itself was available on a set of floppy disks. Within three months, a Usenet newsgroup, comp.os.minix, had sprung up with over 40,000 subscribers discussing and improving the system. One of these subscribers was a Finnish student named Linus Torvalds who began adding new features to MINIX and tailoring it to his own needs. On October 5, 1991, Torvalds announced his own (POSIX like) kernel, called Linux, which originally used the MINIX file system, but it is not based on MINIX code.
Although MINIX and Linux have diverged, MINIX continues to be developed, now as a production system as well as an educational one. The focus is on building a highly modular, reliable, and secure, operating system. The system is based on a microkernel, with only 5000 lines of code running in kernel mode. The rest of the operating system runs as a number of independent processes in user mode, including processes for the file system, process manager, and each device driver. The system continuously monitors each of these processes, and when a failure is detected is often capable of automatically replacing the failed process without a reboot, without disturbing running programs, and without the user even noticing. MINIX 3, as the current version is called, is available under the BSD license for free.
Research projects.
Tanenbaum has also been involved in numerous other research projects in the areas of operating systems, distributed systems, and ubiquitous computing, often as supervisor of Ph.D. students or a postdoctoral researcher. These projects include:
Electoral-vote.com.
In 2004, Tanenbaum created Electoral-vote.com, a web site analyzing opinion polls for the 2004 U.S. Presidential Election, using them to project the outcome in the Electoral College. He stated that he created the site as an American who "knows first hand what the world thinks of America and it is not a pretty picture at the moment. I want people to think of America as the land of freedom and democracy, not the land of arrogance and blind revenge. I want to be proud of America again." The site provided a color-coded map, updated each day with projections for each state's electoral votes. Through most of the campaign period Tanenbaum kept his identity secret, referring to himself as "the Votemaster" and acknowledging only that he personally preferred John Kerry. A libertarian who supports the Democrats, he revealed his identity on November 1, 2004, the day before the election, also stating his reasons and qualifications for running the website.
Through the site he also covered the 2006 midterm elections, correctly predicting the winner of all 33 Senate races that year.
For the 2008 elections, he got every state right except for Indiana, which he said McCain would win by 2% (Obama won by 1%) and Missouri, which he said was too close to call (McCain won by 0.1%). He correctly predicted all the winners in the Senate except for Minnesota, where he predicted a 1% win by Norm Coleman over Al Franken. After 7 months of legal battling and recounts, Franken won by 312 votes (0.01%).
In 2010, he correctly projected 35 out of 37 Senate races in the Midterm elections on the website. The exceptions were Colorado and Nevada.
Tanenbaum–Torvalds debate.
The Tanenbaum–Torvalds debate was a famous debate between Tanenbaum and Linus Torvalds regarding kernel design on Usenet in 1992.
Keynote talks.
Tanenbaum has been keynote speaker at numerous conferences, most recently

</doc>
<doc id="3111" url="https://en.wikipedia.org/wiki?curid=3111" title="Ariane 5">
Ariane 5

Ariane 5 is a European heavy lift launch vehicle that is part of the Ariane rocket family, an expendable launch system used to deliver payloads into geostationary transfer orbit (GTO) or low Earth orbit (LEO). Ariane 5 rockets are manufactured under the authority of the European Space Agency (ESA) and the Centre National d'Etudes Spatiales. Airbus Defence and Space is the prime contractor for the vehicles, leading a consortium of sub-contractors. Ariane 5 is operated and marketed by Arianespace as part of the "Ariane" programme. Astrium builds the rockets in Europe and Arianespace launches them from the Guiana Space Centre in French Guiana.
Ariane 5 succeeded Ariane 4, but was not derived from it directly. Ariane 5 has been refined since the first launch in successive versions, "G", "G+", "GS", "ECA", and most recently, "ES". ESA originally designed Ariane 5 to launch the Hermes spaceplane, and thus intended it to be human rated from the beginning.
Two satellites can be mounted using a SYLDA carrier ("SYstème de Lancement Double Ariane"). Three main satellites are possible depending on size using SPELTRA ("Structure Porteuse Externe Lancement TRiple Ariane"). Up to eight secondary payloads, usually small experiment packages or minisatellites, can be carried with an ASAP ("Ariane Structure for Auxiliary Payloads") platform.
Vehicle description.
Cryogenic main stage.
Ariane 5’s cryogenic H173 main stage (H158 for Ariane 5 G, G+, and GS) is called the EPC ("Étage Principal Cryotechnique"—Cryotechnic Main Stage). It consists of a large tank 30.5 metres high with two compartments, one for liquid oxygen and one for liquid hydrogen, and a Vulcain 2 engine at the base with a vacuum thrust of . The H173 EPC weighs about 189 tonnes, including 175 tonnes of propellant. After the main cryogenic stage runs out of fuel, it can re-enter the atmosphere for an ocean splashdown.
Solid boosters.
Attached to the sides are two P241 (P238 for Ariane 5 G and G+) solid rocket boosters (SRBs or EAPs from the French "Étages d’Accélération à Poudre"), each weighing about 277 tonnes full and delivering a thrust of about . They are fueled by a mix of ammonium perchlorate (68%) and aluminum fuel (18%) and polybutadiene (14%). They each burn for 130 seconds before being dropped into the ocean. The SRBs are usually allowed to sink to the bottom of the ocean, but like the Space Shuttle Solid Rocket Boosters they can be recovered with parachutes, and this has occasionally been done for post-flight analysis. (Unlike Space Shuttle SRBs Ariane 5 boosters are not reused.) The most recent attempt was for the first Ariane 5 ECA mission. One of the two boosters was successfully recovered and returned to the Guiana Space Center for analysis. Prior to that mission, the last such recovery and testing was done in 2003.
The French M51 SLBM shares a substantial amount of technology with these boosters.
In February 2000 the suspected nose cone of an Ariane 5 booster washed ashore on the South Texas coast, and was recovered by beachcombers before the government could get to it.
Second stage.
The second stage is on top of the main stage and below the payload. The Ariane 5G used the EPS ("Étage à Propergols Stockables"—Storable Propellant Stage), which is fueled by monomethylhydrazine (MMH) and nitrogen tetroxide. It also has 10 tons of storable propellants. The EPS was improved for use on the Ariane 5 G+, GS, and ES. Ariane 5 ECA uses the ESC ("Étage Supérieur Cryotechnique"—Cryogenic Upper Stage), which is fueled by liquid hydrogen and liquid oxygen.
The EPS upper stage is capable of multiple ignitions, first demonstrated during flight V26 which was launched on 5 October 2007. This was purely to test the engine, and occurred after the payloads had been deployed. The first operational use of restart capability as part of a mission came on 9 March 2008, when two burns were made to deploy the first Automated Transfer Vehicle into a circular parking orbit, followed by a third burn after ATV deployment to de-orbit the stage. This procedure was repeated for all subsequent ATV flights.
Fairing.
The payload and all upper stages are covered at launch by a fairing, which is jettisoned once sufficient altitude has been reached (typically above 100 km). The Fairing is also used for aerodynamic stability and protection from re-entry heating.
Launch pricing and market competition.
, the Ariane 5 commercial launch price for launching a "midsize satellite in the lower position" is approximately , competing for commercial launches in an increasingly competitive market, mainly due to SpaceX.
The heavier satellite launched in the upper position on a typical dual-satellite Ariane 5 launch is priced higher.
Total launch price is on the order of 150 million euros.
Future developments.
Ariane 5 ME.
The Ariane 5 ME (Mid-life Evolution) was in development until 2015 and seen as a stopgap between / and the new Ariane 6. With first flight planned for 2018, it would have become ESA's principal launcher until the arrival of the new Ariane 6 version.
The Ariane 5 ME uses a new upper stage, with increased propellant volume, powered by the new Vinci engine. Unlike the HM-7B engine, it can restart several times, allowing for complex orbital maneuvers such as insertion of two satellites into different orbits, direct insertion into geosynchronous orbit, planetary exploration missions, and guaranteed upper stage deorbiting or insertion into graveyard orbit.
The new launcher also includes a lengthened fairing up to 20m and a new dual launch system to accommodate larger satellites. Compared to an Ariane 5 ECA model, the payload to GTO increases by 15% to 11.5 tonnes and the cost-per-kilogram of each launch is projected to decline by 20%.
Development.
Originally known as the Ariane 5 ECB, was to have its first flight in 2006. However, the failure of the first ECA flight in 2002, combined with a deteriorating satellite industry, caused ESA to cancel development in 2003. Development of the Vinci engine continued, though at a lower pace. The ESA Council of Ministers agreed to fund development of the new upper stage in November 2008.
In 2009, EADS Astrium was awarded a €200 million contract, and on April 10, 2012 received another €112 million contract to continue development of the Ariane 5 ME with total development effort expected to cost €1 billion ($1.35 billion).
On 21 November 2012, ESA agreed to continue with the Ariane 5 ME to meet the challenge of lower priced competitors. It was agreed the Vinci upper stage would also be used as the second stage of a new Ariane 6, and further commonality would be sought. Ariane 5 ME qualification flight is scheduled for mid-2018, followed by gradual introduction into service.
On 2 December 2014, ESA decided to stop funding the development of Ariane 5 ME and instead focus on Ariane 6 which should have a lower cost per launch and allow more flexibility in the payloads (using two or four P120C solid boosters depending on total payload mass).
Solid propellant stage.
Work on the Ariane 5 EAP motors have been continued in the Vega programme. The Vega 1st stage engine—the P80 engine—is a shorter derivation of the EAP. The P80 booster casing is made of filament wound graphite epoxy, much lighter than the current stainless steel casing. A new composite steerable nozzle has been developed while new thermal insulation material and a narrower throat improve the expansion ratio and subsequently the overall performance. Additionally, the nozzle now has electromechanical actuators which have replaced the heavier hydraulic ones used for thrust vector control.
These developments will probably later make their way back into the Ariane programme. The incorporation of the ESC-B with the improvements to the solid motor casing and an uprated Vulcain engine would deliver to LEO. This would be developed for any lunar missions but the performance of such a design may not be possible if the higher Max-Q for the launch of this rocket poses a constraint on the mass delivered to orbit.
Ariane 6.
The design brief of the next generation rocket called for a smaller rocket capable of launching a single satellite of up to 6.5 tonnes to GTO. However, after several permutations the finalized design was nearly identical in performance to the Ariane 5.
Development is projected to cost €4 billion. Its first test launch is set for 2021.
Ariane 6 is planned to be launched for about €70 million ($96 million) per flight or about half of the Ariane 5 rocket's current price.
Notable launches.
Ariane 5's first test flight (Ariane 5 Flight 501) on 4 June 1996 failed, with the rocket self-destructing 37 seconds after launch because of a malfunction in the control software. A data conversion from 64-bit floating point value to 16-bit signed integer value to be stored in a variable representing horizontal bias caused a processor trap (operand error) because the floating point value was too large to be represented by a 16-bit signed integer. The software was originally written for the Ariane 4 where efficiency considerations (the computer running the software had an 80% maximum workload requirement) led to four variables being protected with a handler while three others, including the horizontal bias variable, were left unprotected because it was thought that they were "physically limited or that there was a large margin of error". The software, written in Ada, was included in the Ariane 5 through the reuse of an entire Ariane 4 subsystem despite the fact that the particular software containing the bug, which was just a part of the subsystem, was not required by the Ariane 5 because it has a different preparation sequence than the Ariane 4.
The second test flight (L502, on 30 October 1997) was a partial failure. The Vulcain nozzle caused a roll problem, leading to premature shutdown of the core stage. The upper stage operated successfully, but it could not reach the intended orbit.
A subsequent test flight (L503, on 21 October 1998) proved successful and the first commercial launch (L504) occurred on 10 December 1999 with the launch of the XMM-Newton X-ray observatory satellite.
Another partial failure occurred on 12 July 2001, with the delivery of two satellites into an incorrect orbit, at only half the height of the intended GTO. The ESA Artemis telecommunications satellite was able to reach its intended orbit on 31 January 2003, through the use of its experimental ion propulsion system.
The next launch did not occur until 1 March 2002, when the Envisat environmental satellite successfully reached an orbit above the Earth in the 11th launch. At , it was the heaviest single payload until the launch of the first ATV on March 9, 2008 (19,360 kg).
The first launch of the ECA variant on 11 December 2002 ended in failure when a main booster problem caused the rocket to veer off-course, forcing its self-destruction three minutes into the flight. Its payload of two communications satellites (Stentor and Hot Bird 7), valued at about EUR 630 million, was lost in the ocean. The fault was determined to have been caused by a leak in coolant pipes allowing the nozzle to overheat. After this failure, Arianespace SA delayed the expected January 2003 launch for the Rosetta mission to 26 February 2004, but this was again delayed to early March 2004 due to a minor fault in the foam that protects the cryogenic tanks on the Ariane 5. As of April 2014, the failure of the first ECA launch was the last failure of an Ariane 5; since then, all subsequent launches have been successful, with 69 consecutive successes that stretch back to 9 April 2003 with the launch of INSAT-3A and Galaxy 12 satellites.
On 27 September 2003 the last Ariane 5 G boosted three satellites (including the first European lunar probe, SMART-1), in Flight 162. On 18 July 2004 an Ariane 5 G+ boosted what was at the time the heaviest telecommunication satellite ever, Anik F2, weighing almost .
The first successful launch of the Ariane 5 ECA took place on 12 February 2005. The payload consisted of the XTAR-EUR military communications satellite, a 'SLOSHSAT' small scientific satellite and a MaqSat B2 payload simulator. The launch had been originally scheduled for October 2004, but additional testing and the military requiring a launch at that time (of a Helios 2A observation satellite) delayed the attempt.
On 11 August 2005, the first Ariane 5GS (featuring the Ariane 5 ECA's improved solid motors) boosted Thaïcom-4/iPStar-1, the heaviest telecommunications satellite to date at , into orbit.
On 16 November 2005, the third Ariane 5 ECA launch (the second successful ECA launch) took place. It carried a dual payload consisting of Spaceway-F2 for DirecTV and Telkom-2 for PT Telekomunikasi of Indonesia. This was the rocket's heaviest dual payload to date, at more than .
On 27 May 2006, an Ariane 5 ECA rocket set a new commercial payload lifting record of 8.2 tonnes. The dual-payload consisted of the Thaicom 5 and Satmex 6 satellites.
On 4 May 2007 the Ariane 5 ECA set another new commercial record, lifting into transfer orbit the Astra 1L and Galaxy 17 communication satellites with a combined weight of 8.6 tonnes, and a total payload weight of 9.4 tonnes. This record was again broken by another Ariane 5 ECA, launching the Skynet 5B and Star One C1 satellites, on 11 November 2007. The total payload weight for this launch was .
On 9 March 2008, the first Ariane 5 ES-ATV was launched to deliver the first ATV called "Jules Verne" to the International Space Station. The ATV was the heaviest payload ever launched by a European rocket, providing supplies to the space station with necessary propellant, water, air and dry cargo. This was the first operational Ariane mission which involved an engine restart in the upper stage. (The ES-ATV Aestus EPS upper stage was restartable while the ECA HM7-B engine was not.)
On 1 July 2009, an Ariane 5 ECA launched TerreStar-1, the largest commercial telecommunication satellite ever built.
On 28 October 2010, an Ariane 5 ECA launched Eutelsat's W3B (part of its W Series of satellites) and Broadcasting Satellite System Corporation (B-SAT)'s BSAT-3b satellites into orbit. However, the W3B satellite failed to operate shortly after the successful launch and was written off as a total loss due to an oxidizer leak in the satellite's main propulsion system. The BSAT-3b satellite, however, is operating normally.
On 22 April 2011, the Ariane 5 ECA flight VA-201 broke a commercial record, lifting Yahsat 1A and Intelsat New Dawn with a total payload weight of 10,064 kg to transfer orbit. This record was later broken again during the launch of Ariane 5 ECA flight VA-208 on 2 August 2012, lifting a total of 10,182 kg into the planned geosynchronous transfer orbit, which was broken again 6 months later on flight VA-212 with 10,317 kg sent towards geosynchronous transfer orbit.
Launch history.
Scheduled Flights.
Timezone in Kourou: UTC−3. 
For 2016, Arianespace is planning 8 launches using an Ariane 5 rocket.

</doc>
<doc id="3112" url="https://en.wikipedia.org/wiki?curid=3112" title="Arianespace">
Arianespace

Arianespace SA is a French multinational company founded in 1980 as the world's first commercial launch service provider. It undertakes the production, operation, and marketing of the Ariane programme. The main launch vehicles offered by the company are the Ariane 5, the Soyuz-2 as a medium-lift alternative, and the Vega as a lighter one.
, more than 240 commercial launches have occurred since May 22, 1984. Arianespace states that the total number of launch contracts signed since Ariane launches commenced operations in 1984 is 285. Arianespace uses the Centre Spatial Guyanais in French Guiana as a launch site. It has its headquarters in Courcouronnes, Essonne, France, near Évry.
On 21 October 2011 Arianespace launched the first Soyuz rocket ever from outside former Soviet territory. The payload was two Galileo navigation satellites.
The company and its infrastructure.
Arianespace primary shareholders are its suppliers, in the various nations of the European Union. 
Arianespace currently has 20 shareholders:
Arianespace shareholding is currently being restructured with the creation of an Airbus-Safran joint venture that will develop and manufacture the Ariane 6 launcher. Their subsidiaries shareholdings will be pooled along with the purchase of the French governments CNES stake. Airbus-Safran once the restructure is complete will have a 76% shareholding while the remaining 24% will be spread across ten countries.
Competition and pricing.
In 2004, Arianespace held more than 50 percent of the world market for boosting satellites to geostationary transfer orbit (GTO).
The disruptive force represented in new sector entrant SpaceX, forced Arianespace to cut workforce, and focus on cost-cutting, to decrease costs to remain competitive against the new low-cost entrant in the launch sector. According to one Arianespace managing director, ""It's quite clear there's a very significant challenge coming from SpaceX," he said. "Therefore things have to change … and the whole European industry is being restructured, consolidated, rationalised and streamlined."
In the midst of pricing pressure from U.S. company SpaceX, Arianespace made a November 2013 announcement of pricing flexibility for the "lighter satellites" it carries to Geostationary orbits aboard its Ariane 5.
In early 2014, Arianespace requested additional subsidies from European governments to face the competition from SpaceX and unfavorable changes in the Euro-Dollar exchange rate. Reducing pricing allowed Arianespace to sign four additional contracts in September 2014 for a lower slots on an Ariane 5 SYLDA dispenser for the satellites that otherwise could be flown on SpaceX launch vehicle. Overall Arianespace signed 11 contracts in 2014 until September with two additional being in a late stage of negotiations. Arianespace has a backlog of launches worth billion with 38 satellites to be launched on Ariane 5, 7 on Soyuz and 9 on Vega, claiming 60% of global satellite launch market.
By November 2014, SpaceX had "already begun to take market share" from Arianespace, and Eutelsat CEO Michel de Rosen—a major customer of Arianespace—said that "Each year that passes will see SpaceX advance, gain market share and further reduce its costs through economies of scale."
Launch Vehicles.
Currently Arianespace operates 3 launch vehicles, including two versions of Ariane 5:
Additionally Arianespace offers optional back-up launch service on H-IIA through Launch Services Alliance.
Ariane launch vehicles.
Since the first launch in 1979, there have been several versions of the Ariane launch vehicle:
Ariane's Cup.
The Ariane's Cup is a sailing competition organized on behalf of the Industrials participating in the Ariane programme.

</doc>
<doc id="3114" url="https://en.wikipedia.org/wiki?curid=3114" title="Amiga 500 Plus">
Amiga 500 Plus

The Commodore Amiga 500 Plus (often A500 Plus or simply A500+) is an enhanced version of the original Amiga 500 computer. It was notable for introducing new versions of Kickstart and Workbench, and for some minor improvements in the custom chips, known as the Enhanced Chip Set (or ECS).
Introduction.
The A500+ was released in several markets (including many European countries), but was never sold officially in the U.S.
Although officially introduced in 1992, some Amiga 500 Plus units had already been sold (masquerading as Amiga 500 models, and with no prior announcement) during late 1991. It has been speculated that Commodore had already sold out the remaining stocks of Amiga 500s, before the run up to the profitable Christmas sales period. In order to make enough A500s before Christmas, Commodore used stocks of the new 8A revision motherboards destined for the A500+. Many users were unaware that they were purchasing anything other than a standard Amiga 500. Although the Amiga 500+ was an improvement to the Amiga 500, it was minor. It was discontinued and replaced by the Amiga 600 in summer 1992, making it the shortest lived Amiga model.
Reason for design.
Commodore created the A500+ for a couple of reasons. The first was cost reduction; minor changes were made to the motherboard to make it cheaper to produce. It was also so that Commodore could introduce the new version of the Amiga Operating system, 2.04.
Compatibility problems.
Due to the new Kickstart, quite a few popular games (such as Treasure Island Dizzy, SWIV, and Lotus Esprit Turbo Challenge) failed to work on the Amiga 500+, and some people took them back to dealers demanding an original Kickstart 1.3 Amiga 500. This problem was solved by third parties who produced Kickstart ROM switching boards, that could allow the Amiga 500+ to be downgraded to Kickstart 1.2 or 1.3. It also encouraged game developers to use better programming habits, which was important since Commodore already had plans for the introduction of the next-generation Amiga 1200 computer. A program, Relokick, was also released (and included with an issue of CU Amiga) which loaded a Kickstart 1.3 ROM image into memory and booted the machine into Kickstart 1.3, allowing incompatible software to run. In some cases, updated compatible versions of games were later released, such as budget versions of Lotus 1 and SWIV.

</doc>
<doc id="3116" url="https://en.wikipedia.org/wiki?curid=3116" title="Accumulator (computing)">
Accumulator (computing)

In a computer's central processing unit (CPU), an accumulator is a register in which intermediate arithmetic and logic results are stored. 
Without a register like an accumulator, it would be necessary to write the result of each calculation (addition, multiplication, shift, etc.) to main memory, perhaps only to be read right back again for use in the next operation. Access to main memory is slower than access to a register like the accumulator because the technology used for the large main memory is slower (but cheaper) than that used for a register. Early electronic computer systems were often split into two groups, those with accumulators and those without.
Modern computer systems often have multiple general purpose registers that operate as accumulators, and the term is no longer as common as it once was. However, a number of special-purpose processors still use a single accumulator for their work, in order to simplify their design.
Basic concept.
Mathematical operations often take place in a stepwise fashion, using the results from one operation as the input to the next. For instance, a manual calculation of a worker's weekly payroll might look something like:
A computer program carrying out the same task would follow the same basic sequence of operations, although the values being looked up would all be stored in computer memory. In early computers the number of hours would likely be held on a punch card and the pay rate in some other form of memory, perhaps a magnetic drum. Once the multiplication is complete, the result needs to be placed somewhere. On a "drum machine" this would likely be back to the drum, an operation that takes considerable time. And then the very next operation has to read that value back in, which introduces another considerable delay.
Accumulators dramatically improve performance in systems like these by providing a scratchpad area where the results of one operation can be fed to the next one for little or no performance penalty. In the example above, the basic weekly pay would be calculated and placed in the accumulator, which could then immediately be used by the income tax calculation. This removes one save and one read operation from the sequence, operations that generally took tens to hundreds of times as long as the multiplication itself.
Accumulator machines.
An accumulator machine, also called a 1-operand machine, or a CPU with "accumulator-based architecture", is a kind of CPU where, although it may have several registers, the CPU mostly stores the results of calculations in one special register, typically called "the accumulator". Almost all early computers were accumulator machines with only the high-performance "supercomputers" having multiple registers. Then as mainframe systems gave way to microcomputers, accumulator architectures were again popular with the MOS 6502 being a notable example. Many 8-bit microcontrollers that are still popular as of 2014, such as the PICmicro and 8051, are accumulator-based machines.
Modern CPUs are typically 2-operand or 3-operand machines. The additional operands specify which one of many general purpose registers (also called "general purpose accumulators") are used as the source and destination for calculations. These CPUs are not considered "accumulator machines".
The characteristic which distinguishes one register as being the accumulator of a computer architecture is that the accumulator (if the architecture were to have one) would be used as an "implicit" operand for arithmetic instructions. For instance, a CPU might have an instruction like: codice_1 that adds the value read from memory location "memaddress" to the value in the accumulator, placing the result back in the accumulator. The accumulator is not identified in the instruction by a register number; it is implicit in the instruction and no other register can be specified in the instruction. Some architectures use a particular register as an accumulator in some instructions, but other instructions use register numbers for explicit operand specification.
History of the computer accumulator.
Any system that uses a single "memory" to store the result of multiple operations can be considered an accumulator. J. Presper Eckert refers to even the earliest adding machines of Gottfried Leibniz and Blaise Pascal as accumulator-based systems.
Historical convention dedicates a register to "the accumulator", an "arithmetic organ" that literally accumulates its number during a sequence of arithmetic operations:
Just a few of the instructions are, for example (with some modern interpretation):
No convention exists regarding the names for operations from registers to accumulator and from accumulator to registers. Tradition (e.g. Donald Knuth's (1973) hypothetical MIX computer), for example, uses two instructions called "load accumulator" from register/memory (e.g. "LDA r") and "store accumulator" to register/memory (e.g. "STA r"). Knuth's model has many other instructions as well.
Notable accumulator-based computers.
Most of IBM's early binary "scientific" computers, beginning with the vacuum tube IBM 701 in 1952, used a single 36-bit accumulator, along with a separate multiplier/quotient register to handle operations with longer results. The IBM 650, a decimal machine, had one 10 digit accumulator; the IBM 7070, a later, transistorized decimal machine had three accumulators.
The 12-bit PDP-8 was one of the first minicomputers to use accumulators, and inspired many later machines. The PDP-8 had but one accumulator. The HP 2100 and Data General Nova had 2 and 4 accumulators. The Nova was created when this follow-on to the PDP-8 was rejected in favor of what would become the PDP-11. The Nova provided four accumulators, AC0-AC3, although AC2 and AC3 could also be used to provide offset addresses, tending towards more generality of usage for the registers. The PDP-11 introduced a more contemporary model of general registers, numbered R0-R7 or more, adopted by most later CISC and RISC machines.
Early 4-bit and 8-bit microprocessors such as the 4004, 8008 and numerous others, typically had single accumulators. The 8051 microcontroller has two, a primary accumulator and a secondary accumulator, where the second is used by instructions only when multiplying (MUL AB) or dividing (DIV AB); the former splits the 16-bit result between the two 8-bit accumulators, whereas the latter stores the quotient on the primary accumulator A and the remainder in the secondary accumulator B. As a direct descendent of the 8008, the 8080, and the 8086, the modern ubiquitous Intel x86 processors still uses the primary accumulator EAX and the secondary accumulator EDX for multiplication and division of large numbers. For instance, MUL ECX will multiply the 32-bit registers ECX and EAX and split the 64-bit result between EAX and EDX. However, MUL and DIV are special cases, other arithmetic-logical instructions (ADD, SUB, CMP, AND, OR, XOR, TEST) may specify any of the eight registers EAX, ECX, EDX, EBX, ESP, EBP, ESI, EDI as the accumulator (i.e. left operand and destination); this is also supported for multiply if the upper half of the result is not required. x86 is thus a fairly general register architecture, despite being based on an accumulator model. The 64-bit extension of x86, x86-64, has been further generalized to 16 instead of 8 general registers.

</doc>
<doc id="3117" url="https://en.wikipedia.org/wiki?curid=3117" title="Abu Zubaydah">
Abu Zubaydah

Abu Zubaydah ( ; , "Abū Zubaydah"; born March 12, 1971 as Zayn al-Abidin Muhammad Husayn) is a Saudi Arabian citizen currently held by the U.S. in the Guantanamo Bay detention camps, in Cuba. He is held under the authority of Authorization for Use of Military Force Against Terrorists (AUMF).
Zubaydah was arrested in Pakistan in March 2002 and has been in United States custody for more than twelve years, four-and-a-half of them in the secret prison network of the Central Intelligence Agency (CIA). He was transferred among prisons in various countries as part of United States rendition program. During the time in CIA custody Zubaydah was extensively interrogated; he was water-boarded 83 times and subjected to numerous other torture techniques including forced nudity, sleep deprivation, confinement in small dark boxes, deprivation of solid food, stress positions, and physical assaults. While in CIA custody, Zubaydah lost his left eye. Videotapes of some of Zubaydah's interrogations are amongst those destroyed by the CIA in 2005.
It was not until September 2006 that Zubaydah, together with ten other "high-value detainees" were transferred to Guantanamo. He and other former CIA detainees are held in Camp 7, where conditions are the most isolating. At his Combatant Status Review Tribunal in 2007, Zubaydah said he was told that the CIA realized he was not significant.
On July 24, 2014 the European Court of Human Rights (ECHR) ordered the Polish government to pay Zubaydah 100,000 euros in damages. It also awarded him 30,000 euros to cover his costs. Poland cooperated with US allowing the CIA to hold and torture Zubaydah on its territory in 2002–2003. Abu Zubaydah said through his US lawyer that he would be donating the full €100,000 in damages to victims of torture. Joseph Marguiles was a lawyer for Zubaydah.
Biography and early activities.
According to his younger brother Hesham, they had eight siblings. Hesham remembers his older brother "as a happy-go-lucky guy, and something of a womanizer." Born in Saudi Arabia, Zubaydah moved to the West Bank as a teenager, where he joined in Palestinian demonstrations against the Israelis. Zubaydah is reported to have studied computer science in Pune, India prior to his travel to Afghanistan/Pakistan at the age of 20 in 1991. He joined the mujahideen in the Afghan civil war, perhaps serving under Mohamad Kamal Elzahabi. In 1992, Zubaydah was injured in a mortar shell blast, which left shrapnel in his head and caused severe memory loss, as well as the loss of the ability to speak for over one year.
Zubaydah eventually became involved in the jihad training site known as the Khalden training camp, where he oversaw the flow of recruits and obtained passports and paperwork for men transferring out of Khalden. He may also have worked as an instructor there. Although originally described as an Al Qaeda training camp, this alleged connection, which has been used as justification for holding Zubaydah and others as enemy combatants, has recently come under scrutiny from multiple sources,<ref name="9/11CommissionReport">"9/11 Commission Report: Final Report of the National Commission on Terrorist Attacks Upon the United States", July 22, 2006</ref> and the camp may have shuttered its doors in 2001 in response to an ideological division with Al Qaeda.
By 1999, the United States government was attempting to surveil Zubaydah. By March 2000, United States officials were reporting that Zubaydah was a "senior Bin Laden official," the "former head of Egypt-based Islamic Jihad," a "trusted aide" to Bin Laden with "growing power," who had "played a key role in the East Africa embassy attacks." Zubaydah was convicted "in absentia" in Jordan and sentenced to death by a Jordanian court for his role in plots to bomb U.S. and Israeli targets there. A senior Middle East security official said Zubaydah had directed the Jordanian cell and was part of "Bin Laden's inner circle."
In August 2001, the classified FBI report, "Bin Laden Determined To Strike in US", said that the foiled millennium bomber, Ahmed Ressam, had confessed that Zubaydah had encouraged him to blow up the Los Angeles airport and facilitated his mission. The report said that Zubaydah was also planning his own attack on the U.S. However, when Ressam was tried in December 2001, federal prosecutors did not try to connect him to Zubaydah or refer to any of this supposed evidence in its case. After the trial, Ressam recanted his confession, saying he had been coerced into giving it.
According to a psychological evaluation conducted upon his capture, Zubaydah allegedly served as Osama Bin Laden's senior lieutenant and counter-intelligence officer (i.e. third or fourth highest-ranking member of al Qaeda), managed a network of training camps, was involved in every major terrorist operation carried out by al Qaeda (including the planning of 9/11), and was engaged in planning future terrorist attacks against U.S. interests. These statements were widely echoed by members of the Bush administration and other US officials. Zubaydah's perceived "value" as a detainee would later be used by President Bush to justify the use of "enhanced interrogation techniques" and Zubaydah's detention in secret CIA prisons around the world. However, Zubaydah's connection to Al Qaeda is now often said to have been overstated, and in response to his habeas corpus petition, the U.S. Government stated in 2009 that they did not contend that Zubaydah had any involvement with the 9/11 attacks or that he had even been a member of Al Qaeda.
Capture.
On March 28, 2002, CIA and FBI agents, in conjunction with Pakistani intelligence services, raided several safe houses in Pakistan searching for Zubaydah. Zubaydah was apprehended from one of the targeted safe houses in Faisalabad, Pakistan. The Pakistani intelligence service had paid a small amount for a tip on his whereabouts. The United States paid far more to Pakistan for its assistance; a CIA source later said, "We paid $10 million for Zubaydah." The Pakistan ISI built a new headquarters on 35 acres outside Islamabad with the money and also bought a helicopter.
During the raid, Zubaydah was shot in the thigh, the testicle, and the stomach with rounds from an AK-47 assault rifle. Not recognised at first, he was piled into a pick-up truck along with other prisoners by the Pakistani forces, until a senior FBI agent identified him. He was taken by the FBI to a Pakistani hospital nearby and treated for his wounds. The attending doctor told John Kiriakou, the co-leader of the CIA group who apprehended Zubaydah, that he had never before seen a patient survive such severe wounds. The FBI and CIA flew in a doctor from Johns Hopkins University to ensure Zubaydah would survive during transit out of Pakistan.
His pocket litter supposedly contained two bank cards which showed he had access to Saudi and Kuwaiti bank accounts; most al-Qaeda members used the preferred, untraceable hawala banking. According to James Risen, "It is not clear whether an investigation of the cards simply fell through the cracks, or whether they were ignored because no one wanted to know the answers about connections between al Qaeda and important figures in the Middle East – particularly in Saudi Arabia." One of Risen's sources chalks up the failure to investigate the cards to incompetence rather than foul play: "The cards were sent back to Washington and were never fully exploited. I think nobody ever looked at them because of incompetence."
When Americans investigated the cards, they worked with "a Muslim financier with a questionable past, and with connections to the Afghan Taliban, al Qaeda, and Saudi intelligence." Risen wrote, "Saudi intelligence officials had seized all of the records related to the card from the Saudi financial institution in question; the records then disappeared. There was no longer any way to trace the money that had gone into the account."
A search of the safehouse turned up Zubaydah's personal 10,000-page diaries, in which he recorded his thoughts as a young boy, old man, and at his current age. What appears to be split personalities is how Zubaydah was piecing his memories together after his 1992 shrapnel head wound. As part of his therapy to regain his memories, he began recording the diary that detailed his life, emotions, and what people were telling him. He split information into categories, such as what he knew about himself and what people told him, and listed them under different names to distinguish one set from the other. This was later incorrectly interpreted by some analysts reviewing the diary as symptoms of split personality disorder.
Zubaydah was turned over to the CIA. Reports later alleged that he was transferred to secret CIA-operated prisons, known as black sites, in Pakistan, Thailand, Afghanistan, Poland, Northern Africa, and Diego Garcia. Historically, renditions of prisoners to countries which commit torture have been illegal. A memo written by John Yoo and signed by Jay Bybee of the Office of the Legal Counsel, DOJ, days before Zubaydah's capture, provided a legal opinion providing for CIA renditions of detainees to places such as Thailand. In March 2009, the U.S. Senate Intelligence Committee launched a year-long study on how the CIA operated the secret prisons, or black sites, around the world.
Top U.S. officials approved torture techniques.
In the Spring of 2002, immediately following the capture of Zubaydah, top Bush administration officials, Vice President Dick Cheney, Secretary of State Colin Powell, CIA Director George Tenet, National Security Adviser Condoleezza Rice, Secretary of Defense Donald Rumsfeld, and US Attorney General John Ashcroft discussed at length whether or not the CIA could legally use harsh techniques against him. Condoleezza Rice specifically mentioned the SERE program during the meeting, saying, "I recall being told that U.S. military personnel were subjected to training to certain physical and psychological interrogation techniques..."
In addition, in 2002 and 2003, the administration briefed several Democratic Congressional leaders on the proposed "enhanced interrogation techniques." These congressional leaders included Nancy Pelosi, the future Speaker of the House, and Representative Jane Harman. Congressional officials have stated that the attitude in the briefings ranged from "quiet acquiescence, if not downright support." The documents show that top U.S. Officials were intimately involved in the discussion and approval of the harsher interrogation techniques used on Zubaydah. Condoleezza Rice ultimately told the CIA the harsher interrogation tactics were acceptable, and Dick Cheney stated, "I signed off on it; so did others." During the discussions, US Attorney General John Ashcroft is reported as saying, "Why are we talking about this in the White House? History will not judge this kindly."
Interrogation of Zubaydah.
Zubaydah was interrogated by two separate interrogation teams: the first from the FBI and one from the CIA. Ali Soufan, one of the FBI interrogators, later testified in 2009 on these issues to the Senate Committee that was investigating detainee treatment. Soufan, who witnessed part of the CIA interrogation of Zubaydah, described his treatment under the CIA as torture. The International Committee of the Red Cross and others later reached the same conclusion. While in CIA custody, Zubaydah lost his left eye.
Because of the urgency felt about the interrogation of Zubaydah, the CIA had consulted with the president about how to proceed. The General Counsel of the CIA asked for a legal opinion from the Office of Legal Counsel, Department of Justice about what was permissible during interrogation.
August 1, 2002 memo.
It was later discovered that in August 2002, the Office of Legal Counsel, Jay Bybee and his assistant John Yoo drafted what became known as the first Torture Memo. Addressed to CIA acting General Counsel John A. Rizzo at his request, the purpose of the memo was to describe and authorize specific enhanced interrogation techniques to be used on Zubaydah.
Journalists including Jane Mayer, Joby Warrick and Peter Finn, and Alex Koppelman have reported the CIA was already using these harsh tactics before the memo authorizing their use was written, and that it was used to provide after-the-fact legal support for harsh interrogation techniques. A Department of Justice 2009 report regarding prisoner abuses reportedly stated the memos were prepared one month after Zubaydah had already been subjected to the specific techniques authorized in August 1, 2002, memo. John Kiriakou stated in July 2009 that Zubaydah was waterboarded in the early summer of 2002, months before August 1, 2002 memo was written.
The memo described ten techniques which the interrogators wanted to use: "(1) attention grasp, (2) walling, (3) facial hold, (4) facial slap (insult slap), (5) cramped confinement, (6) wall standing, (7) stress positions, (8) sleep deprivation, (9) insects placed in a confinement box, and (10) the waterboard." Many of the techniques were, until then, generally considered illegal. Many other techniques developed by the CIA were held to constitute inhumane and degrading treatment and torture under the United Nations Convention against Torture and Article 3 of the European Convention on Human Rights.
As reported later, many of these interrogation techniques were previously considered illegal under U.S. and international law and treaties at the time of Zubaydah's capture. For instance, the United States had prosecuted Japanese military officials after World War II and American soldiers after the Vietnam War for waterboarding. Since 1930, the United States had defined sleep deprivation as an illegal form of torture. Many other techniques developed by the CIA constitute inhuman and degrading treatment and torture under the United Nations Convention against Torture, and Article 3 of the European Convention on Human Rights.
Ensuing interrogation.
The CIA subjected Zubaydah to various forms of increasingly harsh interrogation techniques, including temperature extremes, music played at debilitating volumes, and sexual humiliation. Zubaydah was also subjected to beatings, isolation, waterboarding, long-time standing, continuous cramped confinement, and sleep deprivation.
During Zubaydah's interrogation, President Bush learned he was on painkillers for his wounds and was proving resistant. He said to the CIA director George Tenet, "Who authorized putting him on pain medication?" It was later reported that Zubaydah was denied painkillers during his interrogation.
Waterboarding.
Zubaydah was one of three or more high-value detainees to be waterboarded. The Bush administration in 2007 said that Zubaydah had been waterboarded once. John Kiriakou, a CIA officer who had seen the cables regarding Zubaydah's interrogation, publicly said in 2009 that Zubaydah was waterboarded once for 35 seconds before he started talking.
Intelligence sources claimed as early as 2008 that Zubaydah had been waterboarded no less than ten times in the span of one week. Zubaydah was waterboarded 83 times within the month of August 2002, the month the CIA was authorized to use this enhanced interrogation techniques for him. In January 2010, Kiriakou, in a memoir, said, "Now we know that Zubaydah was waterboarded eighty-three times in a single month, raising questions about how much useful information he actually supplied."
2003 transfer to Guantanamo.
In August 2010 the Associated Press reported that the CIA, having concluded its agents had gotten most of the information from Zubaydah, in September 2003 transferred him and three other high-value detainees to Guantanamo. They were held at what was informally known as "Strawberry Fields," a secret camp within the complex built especially for former CIA detainees. Concerned that a pending Supreme Court decision, "Rasul v. Bush" (2004), might go against the Bush administration and require providing the prisoners with counsel and having to reveal data about them, on March 27, 2004 the CIA took the four men back into custody and transported them out of Guantanamo to one of their secret sites. At the time, the moves were all kept secret.
International Committee of the Red Cross report.
In February 2007, the International Committee of the Red Cross concluded a report on the treatment of "14 high-value detainees," who had been held by the CIA and, after September 2006, by the military at Guantanamo. The ICRC described the twelve enhanced interrogation techniques covered in the OLC memos to the CIA: suffocation by water (which is described as "torture" by numerous US officials), prolonged stress standing position, beatings by use of a collar, beating and kicking, confinement in a box, prolonged nudity, sleep deprivation, exposure to cold temperature, prolonged shackling, threats of ill-treatment, forced shaving, and deprivation/restricted provision of solid food. Zubaydah was the only detainee of the 14 interviewed who had been subjected to all 12 of these interrogation techniques. He was also the only one of the 14 detainees to be put into close confinement.
May 30, 2005 memo.
The final memo mentioned Zubaydah several times. It claimed that due to the enhanced interrogation techniques, Zubaydah "provided significant information on two operatives, ncludin José Padilla who planned to build and detonate a 'dirty bomb' in the Washington DC area." This claim is strongly disputed by Ali Soufan, the FBI interrogator who first interrogated Zubaydah following his capture, by traditional means. He said the most valuable information was gained before torture was used. Other intelligence officers have also disputed that claim. Soufan, when asked in 2009 by Senator Sheldon Whitehouse during a Congressional hearing if the memo was incorrect, testified that it was. The memo noted that not all of the waterboarding sessions were necessary for Zubaydah, since the on-scene interrogation team determined he had stopped producing actionable intelligence. The memo reads:
This is not to say that the interrogation program has worked perfectly. According to the IG Report, the CIA, at least initially, could not always distinguish detainees who had information but were successfully resisting interrogation from those who did not actually have the information. See IG Report at 83–85. On at least one occasion, this may have resulted in what might be deemed in retrospect to have been the unnecessary use of enhanced techniques. On that occasion, although the on-scene interrogation team judged Zubaydah to be compliant, elements within CIA Headquarters still believed he was withholding information. See id at 84. At the direction of CIA Headquarters, interrogators therefore used the waterboard one more time on Zubaydah.
John McLaughlin, former acting CIA director, stated in 2006, "I totally disagree with the view that the capture of Zubaydah was unimportant. Zubaydah was woven through all of the intelligence prior to 9/11 that signaled a major attack was coming, and his capture yielded a great deal of important information."
In his 2007 memoir, former CIA Director George Tenet writes:
A published report in 2006 contended that Zubaydah was mentally unstable and that the administration had overstated his importance. Baloney. Zubaydah had been at the crossroads of many al-Qa'ida operations and was in position to – and did – share critical information with his interrogators. Apparently, the source of the rumor that Zubaydah was unbalanced was his personal diary, in which he adopted various personas. From that shaky perch, some junior Freudians leapt to the conclusion that Zubaydah had multiple personalities. In fact, Agency psychiatrists eventually determined that in his diary he was using a sophisticated literary device to express himself. And, boy, did he express himself.
Intelligence obtained from Zubaydah and its aftereffects.
Zubaydah's capture was touted as the biggest of the War on Terror until that of Khalid Sheikh Mohammed.<ref name="9/11MastermindNabbed">"Alleged 9-11 Mastermind Nabbed" CBS News, March 1, 2003</ref> The director of the FBI stated Zubaydah's capture would help deter future attacks.
In a speech in 2006, President Bush claimed that Zubaydah revealed useful intelligence when enhanced interrogation was used, including identification of two important suspects and information that allegedly helped foil a terrorist attack on American soil. These claims directly conflict with the reports of the F.B.I. agents who first interrogated Zubaydah. He gave them the names before torture was used, and the third piece of information came from other sources who had been receiving crucial pieces of information from him without the use of harsher techniques, as well as other government officials.
Iraq War (2003).
The Bush administration relied on some of Zubaydah's claims in justifying the invasion of Iraq. U.S. officials stated that the allegations that Iraq and al-Qaeda were linked in the training of people on chemical weapons came from Zubaydah. The officials noted there was no independent verification of his claims.
The U.S. Government included statements made by Zubaydah in regards to al Qaeda's ability to obtain a dirty bomb to show a link between Iraq and al Qaeda. According to a Senate Intelligence Committee report of 2004, Zubaydah said that "he had heard that an important al Qaeda associate, Abu Musab al Zarqawi, and others had good relationships with Iraqi intelligence." But the year before in June 2003, Zubaydah and Khalid Sheikh Mohammed were reported as saying there was no link between Saddam Hussein and al Qaeda.
In the Senate Armed Services Committee 2008 report on the abuses of detainees, the Bush administration was described as having applied pressure to interrogators to find a link between Iraq and Al-Qaeda prior to the Iraq War. Major Paul Burney, a psychiatrist with the United States Army, said to the committee, "while we were t Guantanam a large part of the time we were focused on trying to establish a link between Al Qaeda and Iraq and we were not being successful." He said that higher-ups were "frustrated" and applied "more and more pressure to resort to measures that might produce more immediate results."
Colonel Lawrence B. Wilkerson, the former chief of staff for former Secretary of State Colin Powell said:
Likewise, what I have learned is that as the administration authorized harsh interrogation in April and May of 2002—well before the Justice Department had rendered any legal opinion—its principal priority for intelligence was not aimed at pre-empting another terrorist attack on the U.S. but discovering a smoking gun linking Iraq and al-Qa'ida.
So furious was this effort that on one particular detainee, even when the interrogation team had reported to Cheney's office that their detainee "was compliant" (meaning the team recommended no more torture), the VP's office ordered them to continue the enhanced methods. The detainee had not revealed any al-Qa'ida-Baghdad contacts yet. This ceased only after Ibn al-Shaykh al-Libi, under waterboarding in Egypt, "revealed" such contacts. Of course, later we learned that al-Libi revealed these contacts only to get the torture to stop.
Concerns.
In 2004 media coverage of Abu Zubaydah began listing him as a "disappeared" prisoner," claiming he had no access to the International Red Cross. In February 2005, the CIA was reported as uncomfortable keeping Zubaydah in indefinite custody. Less than 18 months later, Zubaydah and the thirteen other high-value detainees who had been in secret CIA custody were transferred to the Guantanamo Bay detention camp.
After his transfer, the CIA denied access to Zubaydah. In 2008, the Office of the Inspector General, Department of Justice, complained that it had been prevented from seeing him, although it was conducting a study of the US treatment of its detainees.
Zubaydah's mental health.
Some people are concerned about Zubaydah's mental stability and how that has affected information he has given to interrogators. Ron Suskind noted in his book, "The One Percent Doctrine: Deep Inside America's Pursuit of Its Enemies Since 9/11" (2006), that Zubaydah was mentally ill or disabled due to a severe head injury. He described Zubaydah as keeping a diary "in the voice of three people: Hani 1, Hani 2, and Hani 3"—a boy, a young man and a middle-aged alter ego. Zubaydah's diaries spanned ten years and recorded in numbing detail "what he ate, or wore, or trifling things eopl said." Dan Coleman, then the FBI's top al-Qaeda analyst, told a senior bureau official, "This guy is insane, certifiable, split personality." According to Suskind, this judgment was "echoed at the top of CIA and was briefed to the President and Vice President." Coleman stated Zubaydah was a "safehouse keeper" with mental problems, who "claimed to know more about al-Qaeda and its inner workings than he really did."
Joseph Margulies, Zubaydah's co-counsel, wrote in an OpEd in the "Los Angeles Times":
Partly as a result of injuries he suffered while he was fighting the communists in Afghanistan, partly as a result of how those injuries were exacerbated by the CIA and partly as a result of his extended isolation, Zubaydah's mental grasp is slipping away. Today, he suffers blinding headaches and has permanent brain damage. He has an excruciating sensitivity to sounds, hearing what others do not. The slightest noise drives him nearly insane. In the last two years alone, he has experienced about 200 seizures. Already, he cannot picture his mother's face or recall his father's name. Gradually, his past, like his future, eludes him.
Legal status.
President Bush referred to Zubaydah in a speech to Congress September 2006 requesting a bill to authorize military commissions, following the US Supreme Court ruling in "Hamdan v. Rumsfeld" (2006) that held the tribunals as formulated by the executive branch were unconstitutional. Congress rapidly passed legislation that was signed by the president.
Less than one month after Zubaydah's capture, Justice Department officials said Zubaydah was "a near-ideal candidate for a tribunal trial." Several months later in 2002, US officials said there was "no rush" to try Zubaydah via military commission.
At his Combatant Status Review Tribunal in 2007, Zubaydah said he was told that the CIA realized he was not significant.
"They told me, 'Sorry, we discover that you are not Number 3, not a partner, not even a fighter,' "said Zubaydah, speaking in broken English, according to the new transcript of a Combatant Status Review Tribunal held at the U.S. military prison in Guantanamo Bay, Cuba."
Abu Zubaydah's lawyers filed a lawsuit in July 2008 challenging his detention at Guantanamo Bay detention camps after the "Boumediene v. Bush" ruling. As of 2015, the judge overseeing the case, Richard W. Roberts, has failed to rule on any motions related to the case, even the preliminary ones. This has led Zubaydah's lawyers to file motion asking Judge Roberts to recuse himself for "nonfeasance" in January 2015.
The judge's failure to act for nearly seven years may be related to the revelation in the Senate Intelligence Committee report on CIA torture that Zubaydah's CIA interrogators wanted him to "remain in isolation and incommunicado for the remainder of his life."
The U.S. Government has not officially charged Zubaydah with any crimes.
Joint Review Task Force.
When he assumed office in January 2009 President Barack Obama made a number of promises about the future of Guantanamo.
He promised the use of torture would cease at the camp. He promised to institute a new review system. That new review system was composed of officials from six departments, where the OARDEC reviews were conducted entirely by the Department of Defense. When it reported back, a year later, the Joint Review Task Force classified some individuals as too dangerous to be transferred from Guantanamo, even though there was no evidence to justify laying charges against them. On April 9, 2013, that document was made public after a Freedom of Information Act request.
Zayn al-lbidin Muhammed Husayn was one of the 71 individuals deemed too innocent to charge, but too dangerous to release. Although Obama promised that those deemed too innocent to charge, but too dangerous to release would start to receive reviews from a Periodic Review Board less than a quarter of men have received a review.
European Court of Human Rights decision.
On July 24, 2014 the European Court of Human Rights (ECHR) ruled that Poland had violated the European Convention on Human Rights when it cooperated with US allowing the CIA to hold and torture Zubaydah and Abd al-Rahim al-Nashiri on its territory in 2002–2003. The court ordered the Polish government to pay each of the men 100,000 euros in damages. It also awarded Zubaydah 30,000 euros to cover his costs.

</doc>
<doc id="3118" url="https://en.wikipedia.org/wiki?curid=3118" title="Arithmetic">
Arithmetic

Arithmetic or arithmetics (from the Greek ἀριθμός "arithmos", "number") is the oldest and most elementary branch of mathematics. It consists of the study of numbers, especially the properties of the traditional operations between them—addition, subtraction, multiplication and division. Arithmetic is an elementary part of number theory, and number theory is considered to be one of the top-level divisions of modern mathematics, along with algebra, geometry, and analysis. The terms "arithmetic" and "higher arithmetic" were used until the beginning of the 20th century as synonyms for "number theory" and are sometimes still used to refer to a wider part of number theory.
History.
The prehistory of arithmetic is limited to a small number of artifacts which may indicate the conception of addition and subtraction, the best-known being the Ishango bone from central Africa, dating from somewhere between 20,000 and 18,000 BC, although its interpretation is disputed.
The earliest written records indicate the Egyptians and Babylonians used all the elementary arithmetic operations as early as 2000 BC. These artifacts do not always reveal the specific process used for solving problems, but the characteristics of the particular numeral system strongly influence the complexity of the methods. The hieroglyphic system for Egyptian numerals, like the later Roman numerals, descended from tally marks used for counting. In both cases, this origin resulted in values that used a decimal base but did not include positional notation. Complex calculations with Roman numerals required the assistance of a counting board or the Roman abacus to obtain the results.
Early number systems that included positional notation were not decimal, including the sexagesimal (base 60) system for Babylonian numerals and the vigesimal (base 20) system that defined Maya numerals. Because of this place-value concept, the ability to reuse the same digits for different values contributed to simpler and more efficient methods of calculation.
The continuous historical development of modern arithmetic starts with the Hellenistic civilization of ancient Greece, although it originated much later than the Babylonian and Egyptian examples. Prior to the works of Euclid around 300 BC, Greek studies in mathematics overlapped with philosophical and mystical beliefs. For example, Nicomachus summarized the viewpoint of the earlier Pythagorean approach to numbers, and their relationships to each other, in his "Introduction to Arithmetic".
Greek numerals were used by Archimedes, Diophantus and others in a positional notation not very different from ours. Because the ancient Greeks lacked a symbol for zero (until the Hellenistic period), they used three separate sets of symbols. One set for the unit's place, one for the ten's place, and one for the hundred's. Then for the thousand's place they would reuse the symbols for the unit's place, and so on. Their addition algorithm was identical to ours, and their multiplication algorithm was only very slightly different. Their long division algorithm was the same, and the square root algorithm that was once taught in school was known to Archimedes, who may have invented it. He preferred it to Hero's method of successive approximation because, once computed, a digit doesn't change, and the square roots of perfect squares, such as 7485696, terminate immediately as 2736. For numbers with a fractional part, such as 546.934, they used negative powers of 60 instead of negative powers of 10 for the fractional part 0.934. The ancient Chinese used a similar positional notation. Because they also lacked a symbol for zero, they had one set of symbols for the unit's place, and a second set for the ten's place. For the hundred's place they then reused the symbols for the unit's place, and so on. Their symbols were based on the ancient counting rods. It is a complicated question to determine exactly when the Chinese started calculating with positional representation, but it was definitely before 400 BC. The Bishop of Syria, Severus Sebokht (650 AD), "Indians possess a method of calculation that no word can praise enough. Their rational system of mathematics, or of their method of calculation. I mean the system using nine symbols."
Leonardo of Pisa (Fibonacci) in 1200 AD wrote in "Liber Abaci" "The method of the Indians (Modus Indoram) surpasses any known method to compute. It's a marvelous method. They do their computations using nine figures and symbol zero".
The gradual development of Hindu–Arabic numerals independently devised the place-value concept and positional notation, which combined the simpler methods for computations with a decimal base and the use of a digit representing 0. This allowed the system to consistently represent both large and small integers. This approach eventually replaced all other systems. In the early the Indian mathematician Aryabhata incorporated an existing version of this system in his work, and experimented with different notations. In the 7th century, Brahmagupta established the use of 0 as a separate number and determined the results for multiplication, division, addition and subtraction of zero and all other numbers, except for the result of division by 0. His contemporary, the Syriac bishop Severus Sebokht described the excellence of this system as "... valuable methods of calculation which surpass description". The Arabs also learned this new method and called it "hesab".
Although the Codex Vigilanus described an early form of Arabic numerals (omitting 0) by 976 AD, Fibonacci was primarily responsible for spreading their use throughout Europe after the publication of his book "Liber Abaci" in 1202. He considered the significance of this "new" representation of numbers, which he styled the "Method of the Indians" (Latin "Modus Indorum"), so fundamental that all related mathematical foundations, including the results of Pythagoras and the algorism describing the methods for performing actual calculations, were "almost a mistake" in comparison.
In the Middle Ages, arithmetic was one of the seven liberal arts taught in universities.
The flourishing of algebra in the medieval Islamic world and in Renaissance Europe was an outgrowth of the enormous simplification of computation through decimal notation.
Various types of tools exist to assist in numeric calculations. Examples include slide rules (for multiplication, division, and trigonometry) and nomographs in addition to the electrical calculator.
Arithmetic operations.
The basic arithmetic operations are addition, subtraction, multiplication and division, although this subject also includes more advanced operations, such as manipulations of percentages, square roots, exponentiation, and logarithmic functions. Arithmetic is performed according to an order of operations. Any set of objects upon which all four arithmetic operations (except division by 0) can be performed, and where these four operations obey the usual laws, is called a field.
Addition (+).
Addition is the basic operation of arithmetic. In its simplest form, addition combines two numbers, the "addends" or "terms", into a single number, the "sum" of the numbers (Such as or ).
Adding more than two numbers can be viewed as repeated addition; this procedure is known as summation and includes ways to add infinitely many numbers in an infinite series; repeated addition of the number 1 is the most basic form of counting.
Addition is commutative and associative so the order the terms are added in does not matter. The identity element of addition (the additive identity) is 0, that is, adding 0 to any number yields that same number. Also, the inverse element of addition (the additive inverse) is the opposite of any number, that is, adding the opposite of any number to the number itself yields the additive identity, 0. For example, the opposite of 7 is −7, so .
Addition can be given geometrically as in the following example:
Subtraction (−).
Subtraction is the inverse of addition. Subtraction finds the "difference" between two numbers, the "minuend" minus the "subtrahend". If the minuend is larger than the subtrahend, the difference is positive; if the minuend is smaller than the subtrahend, the difference is negative; if they are equal, the difference is 0.
Subtraction is neither commutative nor associative. For that reason, it is often helpful to look at subtraction as addition of the minuend and the opposite of the subtrahend, that is . When written as a sum, all the properties of addition hold.
There are several methods for calculating results, some of which are particularly advantageous to machine calculation. For example, digital computers employ the method of two's complement. Of great importance is the counting up method by which change is made. Suppose an amount "P" is given to pay the required amount "Q", with "P" greater than "Q". Rather than performing the subtraction and counting out that amount in change, money is counted out starting at "Q" and continuing until reaching "P". Although the amount counted out must equal the result of the subtraction , the subtraction was never really done and the value of might still be unknown to the change-maker.
Multiplication (× or · or *).
Multiplication is the second basic operation of arithmetic. Multiplication also combines two numbers into a single number, the "product". The two original numbers are called the "multiplier" and the "multiplicand", sometimes both simply called "factors".
Multiplication may be viewed as a scaling operation. If the numbers are imagined as lying in a line, multiplication by a number, say "x", greater than 1 is the same as stretching everything away from 0 uniformly, in such a way that the number 1 itself is stretched to where "x" was. Similarly, multiplying by a number less than 1 can be imagined as squeezing towards 0. (Again, in such a way that 1 goes to the multiplicand.)
Multiplication is commutative and associative; further it is distributive over addition and subtraction. The multiplicative identity is 1, that is, multiplying any number by 1 yields that same number. Also, the multiplicative inverse is the reciprocal of any number (except 0; 0 is the only number without a multiplicative inverse), that is, multiplying the reciprocal of any number by the number itself yields the multiplicative identity.
The product of "a" and "b" is written as or . When "a" or "b" are expressions not written simply with digits, it is also written by simple juxtaposition: "ab". In computer programming languages and software packages in which one can only use characters normally found on a keyboard, it is often written with an asterisk: 
Division (÷ or /).
Division is essentially the inverse of multiplication. Division finds the "quotient" of two numbers, the "dividend" divided by the "divisor". Any dividend divided by 0 is undefined. For distinct positive numbers, if the dividend is larger than the divisor, the quotient is greater than 1, otherwise it is less than 1 (a similar rule applies for negative numbers). The quotient multiplied by the divisor always yields the dividend.
Division is neither commutative nor associative. As it is helpful to look at subtraction as addition, it is helpful to look at division as multiplication of the dividend times the reciprocal of the divisor, that is When written as a product, it obeys all the properties of multiplication.
Decimal arithmetic.
Decimal representation refers exclusively, in common use, to the written numeral system employing arabic numerals as the digits for a radix 10 ("decimal") positional notation; however, any numeral system based on powers of 10, e.g., Greek, Cyrillic, Roman, or Chinese numerals may conceptually be described as "decimal notation" or "decimal representation".
Modern methods for four fundamental operations (addition, subtraction, multiplication and division) were first devised by Brahmagupta of India. This was known during medieval Europe as "Modus Indoram" or Method of the Indians. Positional notation (also known as "place-value notation") refers to the representation or encoding of numbers using the same symbol for the different orders of magnitude (e.g., the "ones place", "tens place", "hundreds place") and, with a radix point, using those same symbols to represent fractions (e.g., the "tenths place", "hundredths place"). For example, 507.36 denotes 5 hundreds (10), plus 0 tens (10), plus 7 units (10), plus 3 tenths (10) plus 6 hundredths (10).
The concept of 0 as a number comparable to the other basic digits is essential to this notation, as is the concept of 0's use as a placeholder, and as is the definition of multiplication and addition with 0. The use of 0 as a placeholder and, therefore, the use of a positional notation is first attested to in the Jain text from India entitled the "Lokavibhâga", dated 458 AD and it was only in the early 13th century that these concepts, transmitted via the scholarship of the Arabic world, were introduced into Europe by Fibonacci using the Hindu–Arabic numeral system.
Algorism comprises all of the rules for performing arithmetic computations using this type of written numeral. For example, addition produces the sum of two arbitrary numbers. The result is calculated by the repeated addition of single digits from each number that occupies the same position, proceeding from right to left. An addition table with ten rows and ten columns displays all possible values for each sum. If an individual sum exceeds the value 9, the result is represented with two digits. The rightmost digit is the value for the current position, and the result for the subsequent addition of the digits to the left increases by the value of the second (leftmost) digit, which is always one. This adjustment is termed a "carry" of the value 1.
The process for multiplying two arbitrary numbers is similar to the process for addition. A multiplication table with ten rows and ten columns lists the results for each pair of digits. If an individual product of a pair of digits exceeds 9, the "carry" adjustment increases the result of any subsequent multiplication from digits to the left by a value equal to the second (leftmost) digit, which is any value from (). Additional steps define the final result.
Similar techniques exist for subtraction and division.
The creation of a correct process for multiplication relies on the relationship between values of adjacent digits. The value for any single digit in a numeral depends on its position. Also, each position to the left represents a value ten times larger than the position to the right. In mathematical terms, the exponent for the radix (base) of 10 increases by 1 (to the left) or decreases by 1 (to the right). Therefore, the value for any arbitrary digit is multiplied by a value of the form 10 with integer "n". The list of values corresponding to all possible positions for a single digit is written 
Repeated multiplication of any value in this list by 10 produces another value in the list. In mathematical terminology, this characteristic is defined as closure, and the previous list is described as closed under multiplication. It is the basis for correctly finding the results of multiplication using the previous technique. This outcome is one example of the uses of number theory.
Compound unit arithmetic.
Compound unit arithmetic is the application of arithmetic operations to mixed radix quantities such as feet and inches, gallons and pints, pounds shillings and pence, and so on. Prior to the use of decimal-based systems of money and units of measure, the use of compound unit arithmetic formed a significant part of commerce and industry.
Basic arithmetic operations.
The techniques used for compound unit arithmetic were developed over many centuries and are well-documented in many textbooks in many different languages. In addition to the basic arithmetic functions encountered in decimal arithmetic, compound unit arithmetic employs three more functions:
Knowledge of the relationship between the various units of measure, their multiples and their submultiples forms an essential part of compound unit arithmetic.
Principles of compound unit arithmetic.
There are two basic approaches to compound unit arithmetic:
Operations in practice.
During the 19th and 20th centuries various aids were developed to aid the manipulation of compound units, particularly in commercial applications. The most common aids were mechanical tills which were adapted in countries such as the United Kingdom to accommodate pounds, shillings, pennies and farthings and "Ready Reckoners" – books aimed at traders that catalogued the results of various routine calculations such as the percentages or multiples of various sums of money. One typical booklet that ran to 150 pages tabulated multiples "from one to ten thousand at the various prices from one farthing to one pound".
The cumbersome nature of compound unit arithmetic has been recognized for many years – in 1586, the Flemish mathematician Simon Stevin published a small pamphlet called "De Thiende" ("the tenth") in which he declared that the universal introduction of decimal coinage, measures, and weights to be merely a question of time while in the modern era, many conversion programs, such as that embedded in the calculator supplied as a standard part of the Microsoft Windows 7 operating system display compound units in a reduced decimal format rather than using an expanded format (i.e. "2.5 ft" is displayed rather than ).
Number theory.
Until the 19th century, "number theory" was a synonym of "arithmetic". The addressed problems were directly related to the basic operations and concerned primality, divisibility, and the solution of equations in integers, such as Fermat's last theorem. It appeared that most of these problems, although very elementary to state, are very difficult and may not be solved without very deep mathematics involving concepts and methods from many other branches of mathematics. This led to new branches of number theory such as analytic number theory, algebraic number theory, Diophantine geometry and arithmetic algebraic geometry. Wiles' proof of Fermat's Last Theorem is a typical example of the necessity of sophistical methods, which go far beyond the classical methods of arithmetic, for solving problems that can be stated in elementary arithmetic.
Arithmetic in education.
Primary education in mathematics often places a strong focus on algorithms for the arithmetic of natural numbers, integers, fractions, and decimals (using the decimal place-value system). This study is sometimes known as algorism.
The difficulty and unmotivated appearance of these algorithms has long led educators to question this curriculum, advocating the early teaching of more central and intuitive mathematical ideas. One notable movement in this direction was the New Math of the 1960s and 1970s, which attempted to teach arithmetic in the spirit of axiomatic development from set theory, an echo of the prevailing trend in higher mathematics.
Also, arithmetic was used by Islamic Scholars in order to teach application of the rulings related to Zakat and Irth. This was done in a book entitled "The Best of Arithmetic" by Abd-al-Fattah-al-Dumyati.
The book begins with the foundations of mathematics and proceeds to its application in the later chapters.

</doc>
<doc id="3120" url="https://en.wikipedia.org/wiki?curid=3120" title="Andersonville, Georgia">
Andersonville, Georgia

Andersonville is a city in Sumter County, Georgia, United States. As of the 2010 census, the city had a population of 255. It is located in the southwest part of the state, about southwest of Macon, Georgia on the Central of Georgia railroad. During the American Civil War, it was the site of a prisoner-of-war camp which is now Andersonville National Historic Site.
Andersonville is part of the Americus Micropolitan Statistical Area.
History.
The little hamlet of Anderson was named for John Anderson, a director of the South Western Railroad in 1853 when it was extended from Oglethorpe to Americus. It was known as Anderson Station until the US post office was established in November 1855. The government changed the name of the station from “Anderson” to “Andersonville” in order to avoid confusion with the post office in Anderson, South Carolina.
During the Civil War, the Confederate army established Camp Sumter at Andersonville to house incoming Union prisoners of war. The town served as a supply depot during the war period. It included a post office, a depot, a blacksmith shop and stable, a couple of general stores, two saloons, a school, a Methodist church, and about a dozen houses. (Ben Dykes, who owned the land on which the prison was built, was both depot agent and postmaster.)
Until the establishment of the prison, the area was entirely dependent on agriculture. After the close of the prison and end of the war, the town continued economically dependent on agriculture, primarily the cultivation of cotton as a commodity crop. The town changed very little over the years.
It was not until 1968, when the large-scale mining of kaolin, bauxitic kaolin, and bauxite was begun by Mulcoa, Mullite Company of America, that the town was dramatically altered. This operation exploited of scrub oak wilderness into a massive mining and refining operation. The company now ships more than 2000 tons of refined ore from Andersonville each week.
In 1974, long-time mayor Lewis Easterlin and a group of concerned citizens decided to promote tourism in the town; they stressed its history, redeveloping Main Street to look much as it did during the American Civil War. The city of Andersonville and the Andersonville National Historic Site, location of the prison camp, welcomes tourists from all over the world. They come for the history, museums, and to step back in time.
Demographics.
As of the census of 2000, there were 331 people, 124 households, and 86 families residing in the city. The population density was 254.1 people per square mile (98.3/km²). There were 142 housing units at an average density of 109.0 per square mile (42.2/km²). The racial makeup of the city was 65.26% white and 34.74% African American. 1.21% of the population were Hispanic or Latino.
There were 124 households out of which 34.7% had children under the age of 18 living with them, 46.0% were married couples living together, 17.7% had a female householder with no husband present, and 30.6% were non-families. 26.6% of all households were made up of individuals and 10.5% had someone living alone who was 65 years of age or older. The average household size was 2.67 and the average family size was 3.21.
In the city the population was spread out with 27.8% under the age of 18, 9.4% from 18 to 24, 31.4% from 25 to 44, 19.3% from 45 to 64, and 12.1% who were 65 years of age or older. The median age was 36 years. For every 100 females there were 105.6 males. For every 100 females age 18 and over, there were 97.5 males.
The median income for a household in the city was $29,107, and the median income for a family was $30,972. Males had a median income of $26,591 versus $20,000 for females. The per capita income for the city was $15,168. About 19.8% of families and 23.0% of the population were below the poverty line, including 29.3% of those under age 18 and 13.5% of those age 65 or over.

</doc>
<doc id="3121" url="https://en.wikipedia.org/wiki?curid=3121" title="Andersonville">
Andersonville

Andersonville may refer to:

</doc>
<doc id="3122" url="https://en.wikipedia.org/wiki?curid=3122" title="Agra Canal">
Agra Canal

The Agra Canal is an important Indian irrigation work which starts from Okhla in Delhi. The Agra canal originates from Okhla barrage, downstream of Nizamuddin bridge. It opened in 1874.
In the beginning, it was available for navigation, in Delhi, erstwhile Gurgaon, Mathura and Agra Districts, and Bharatpur State. Later, navigation was stopped in 1904 and the canal has since then, been exclusively used for irrigation purposes only. At present the canal does not flow in district Gurgaon, but only in Faridabad, which was earlier a part of Gurgaon.
The Canal receives its water from the Yamuna River at Okhla, about 10 km to the south of New Delhi. The weir across the Yamuna was the first attempted in Upper India upon a foundation of fine sand; it is about 800-yard long, and rises seven-feet above the summer level of the river.
From Okhla the canal follows the high land between the Khari-Nadi and the Yamuna and finally joins the Banganga river about below Agra. Navigable branches connect the canal with Mathura and Agra.
the canal irrigates about 1.5 lakh hectares in Agra, and Mathura in Uttar Pradesh, Faridabad in Haryana, Bharatpur in Rajasthan and also some parts of Delhi
References.
The Agra Canal also has many places to visit along its coast.

</doc>
<doc id="3123" url="https://en.wikipedia.org/wiki?curid=3123" title="Amakusa">
Amakusa

Amakusa (天草), which means "Heaven's Grass," is a series of islands belonging to Japan, off the west coast of Kyushu, the southernmost of the four main islands of Japan. The largest island of the Amakusa group is Shimoshima, which is 26.5 miles long and 13.5 miles in extreme width (). It is situated at 32°20'N, 130°E, separated from the rest of Kumamoto Prefecture by the Yatsushiro Sea.
It has no high mountains, but its surface is very hilly—four of the peaks rise to a height of over . The population resorts to the terrace system of cultivation to cope with the lack of flat arable land.
Amakusa, along with the neighboring Shimabara Peninsula, became the site of a Christian rebellion in the 17th century. Following the rebellion, those Christians who survived continued to practice their faith in secret, despite persecution.
Amakusa produces a little coal and pottery stone, both being used by the potters of Hirado and Satsuma Province. Many kilns remain on the islands today, and pottery and pottery stone are still exported. Hidenoshin Koyama, who built Thomas Blake Glover's House in Glover Garden, came from this island.
At present, the islands are organized as Amakusa District, Amakusa City, and Kami-amakusa City, all of which are under the administration of Kumamoto Prefecture.
Transport.
The islands are served by Amakusa Airfield, located on the north end of Shimoshima. The islands are connected to the mainland by the Five Bridges of Amakusa and by ferry from Hondo and Matsushima.
There are also ferries between the islands and the neighboring prefectures of Kagoshima Prefecture and Nagasaki Prefecture. The ferry from Oniike on the north Shimoshima to Kuchinotsu, at the southern tip of the Shimabara Peninsula, is run by the Shimabara Railway and operates hourly each day. The ferry boat from Tomioka Port in Reihoku, sailing north to Mogi in Nagasaki Prefecture, is operated by Yasuda Sangyo Kisen Co. Ltd.
Two ferries from Shinwa and Ushibuka, in the south of Shimoshima, connect Amakusa to Nagashima in Kagoshima Prefecture.

</doc>
<doc id="3124" url="https://en.wikipedia.org/wiki?curid=3124" title="Afterglow">
Afterglow

An afterglow is a broad high arch of whitish or rosy light appearing in the sky due to very fine particles of dust suspended in the high regions of the atmosphere. An afterglow may appear above the highest clouds in the hour of deepening twilight, or reflected from the high snowfields in mountain regions long after sunset. The particles produce a scattering effect upon the component parts of white light. The true alpenglow, which occurs long after sunset or long before sunrise, is caused by the backscattering of red sunlight by aerosols and fine dust particles low in the atmosphere. It is an afterglow caused by direct illumination of atmospheric particles by sunlight as it refracts and gets scattered through the earth's atmosphere. The high-energy and high-frequency light is scattered out the most and the remaining low-energy, low-frequency reaches the observer in the horizon at twilight. The backscattering of this light further turns it pinkish-red. This period of time is referred to as the blue hour and is widely treasured by photographers and painters as it offers breathtaking imagery.
The afterglow persists till the earth's shadow (terminator line) takes over the sky of the observer as nightfall and the stars appear, with planet Venus being the brightest star visible in the night sky just opposite to the Belt of Venus at the anti-solar point.
After the eruption of the volcano Krakatoa in 1883, a remarkable series of red sunsets appeared worldwide. These were due to an enormous amount of exceedingly fine dust blown to a great height by the volcano's explosion, and then globally diffused by the high atmospheric currents. Edvard Munch's painting "The Scream" possibly depicts an afterglow during this period.

</doc>
<doc id="3125" url="https://en.wikipedia.org/wiki?curid=3125" title="Ammonius Grammaticus">
Ammonius Grammaticus

Ammonius Grammaticus was a 4th-century Egyptian priest who, after the destruction of the pagan temple at Alexandria (389), fled to Constantinople, where he became the tutor of the ecclesiastical historian Socrates.
Life.
Ammonius was formerly identified as the author of a treatise titled "Peri homoíōn kai diaphórōn léxeōn" (περὶ ὁμοίων καὶ διαφόρων λέξεων, "On the Differences of Synonymous Expressions").
But it seems more probable that the real author was Herennius Philo of Byblus, who was born during the reign of Nero and lived till the reign of Hadrian, and that the treatise in its present form is a revision prepared by a later Byzantine editor, whose name may have been Ammonius.

</doc>
<doc id="3129" url="https://en.wikipedia.org/wiki?curid=3129" title="Algebraic closure">
Algebraic closure

In mathematics, particularly abstract algebra, an algebraic closure of a field "K" is an algebraic extension of "K" that is algebraically closed. It is one of many closures in mathematics.
Using Zorn's lemma, it can be shown that every field has an algebraic closure, and that the algebraic closure of a field "K" is unique up to an isomorphism that fixes every member of "K". Because of this essential uniqueness, we often speak of "the" algebraic closure of "K", rather than "an" algebraic closure of "K".
The algebraic closure of a field "K" can be thought of as the largest algebraic extension of "K".
To see this, note that if "L" is any algebraic extension of "K", then the algebraic closure of "L" is also an algebraic closure of "K", and so "L" is contained within the algebraic closure of "K".
The algebraic closure of "K" is also the smallest algebraically closed field containing "K",
because if "M" is any algebraically closed field containing "K", then the elements of "M" that are algebraic over "K" form an algebraic closure of "K".
The algebraic closure of a field "K" has the same cardinality as "K" if "K" is infinite, and is countably infinite if "K" is finite.
Existence of an algebraic closure and splitting fields.
Let formula_1 be the set of all monic irreducible polynomials in "K"'x'.
For each formula_2, introduce new variables formula_3 where formula_4.
Let "R" be the polynomial ring over "K" generated by formula_5 for all formula_6 and all formula_7. Write
with formula_9.
Let "I" be the ideal in "R" generated by the formula_10. Since "I" is strictly smaller than "R",
Zorn's lemma implies that there exists a maximal ideal "M" in "R" that contains "I".
Now the field "R"/"M" is an algebraic closure of "K": every polynomial formula_11 splits as the
product of the formula_12.
The same proof also shows that for any subset "S" of "K"'x', there exists a splitting field of "S" over "K".
Separable closure.
An algebraic closure "K" of "K" contains a unique separable extension "K" of "K" containing all (algebraic) separable extensions of "K" within "K". This subextension is called a separable closure of "K". Since a separable extension of a separable extension is again separable, there are no finite separable extensions of "K", of degree > 1. Saying this another way, "K" is contained in a "separably-closed" algebraic extension field. It is unique (up to isomorphism).
The separable closure is the full algebraic closure if and only if "K" is a perfect field. For example, if "K" is a field of characteristic "p" and if "X" is transcendental over "K", formula_13 is a non-separable algebraic field extension.
In general, the absolute Galois group of "K" is the Galois group of "K" over "K".

</doc>
<doc id="3130" url="https://en.wikipedia.org/wiki?curid=3130" title="Advanced Power Management">
Advanced Power Management

Advanced power management (APM) is an API developed by Intel and Microsoft and released in 1992 which enables an operating system running an IBM-compatible personal computer to work with the BIOS (part of the computer's firmware) to achieve power management.
Revision 1.2 was the last version of the APM specification, released in 1996. ACPI is intended as the successor to APM. Microsoft dropped support for APM in Windows Vista. The Linux kernel still mostly supports APM, with the last fully functional APM support shipping in 3.3.
Overview.
APM uses a layered approach to manage devices. APM-aware applications (which include device drivers) talk to an OS-specific APM driver. This driver communicates to the APM-aware BIOS, which controls the hardware. There is the ability to opt out of APM control on a device-by-device basis, which can be used if a driver wants to communicate directly with a hardware device.
Communication occurs both ways; power management events are sent from the BIOS to the APM driver, and the APM driver sends information and requests to the BIOS via function calls. In this way the APM driver is an intermediary between the BIOS and the operating system.
Power management happens in two ways; through the above-mentioned function calls from the APM driver to the BIOS requesting power state changes, and automatically based on device activity.
Power management events.
There are 12 power events (such as standby, suspend and resume requests, and low battery notifications), plus OEM-defined events, that can be sent from the APM BIOS to the operating system. The APM driver regularly polls for event change notifications.
Power Management Events:
Power management functions:
APM functions.
There are 21 APM function calls defined that the APM driver can use to query power management statuses, or request power state transitions. Example function calls include letting the BIOS know about current CPU usage (the BIOS may respond to such a call by placing the CPU in a low-power state, or returning it to its full-power state), retrieving the current power state of a device, or requesting a power state change.
Power states.
The APM specification defines system power states and device power states.
System power states.
APM defines five power states for the computer system:
Device power states.
APM also defines power states that APM-aware hardware can implement. There is no requirement that an APM-aware device implement all states.
The four states are:
CPU.
The CPU core (defined in APM as the CPU clock, cache, system bus and system timers) is treated specially in APM, as it is the last device to be powered down, and the first device to be powered back up. The CPU core is always controlled through the APM BIOS (there is no option to control it through a driver). Drivers can use APM function calls to notify the BIOS about CPU usage, but it is up to the BIOS to act on this information; a driver cannot directly tell the CPU to go into a power saving state.

</doc>
<doc id="3132" url="https://en.wikipedia.org/wiki?curid=3132" title="Adolphe Sax">
Adolphe Sax

Antoine-Joseph "Adolphe" Sax (6 November 1814 – c. 7 February 1894) was a Belgian inventor and musician who invented the saxophone in 1846. He played the flute and clarinet, and his other inventions are the saxotromba, saxhorn and saxtuba. 
Early life.
Antoine-Joseph Sax was born on 6 November 1814, in Dinant, Belgium, to Charles-Joseph Sax and his wife. While his first name was Antoine, he was referred to as Adolphe from childhood. His father and mother were instrument designers themselves, who made several changes to the design of the horn. Adolphe began to make his own instruments at an early age, entering two of his flutes and a clarinet into a competition at the age of 15. He subsequently studied performance on those two instruments as well as voice at the Royal Conservatory of Brussels.
According to the biography of Adolphe Sax, published on the city of Dinant's website, Sax faced many near-death experiences. Over the course of his childhood, he:
Also according to the biography, his mother once said that "He's a child condemned to misfortune; he won't live". His neighbors called him "little Sax, the ghost".
Career.
After leaving the Royal Conservatory of Brussels, Sax began to experiment with new instrument designs, while his parents continued to make conventional instruments to bring in money. Adolphe's first important invention was an improvement of the bass clarinet design, which he patented at the age of 24. Sax relocated permanently to Paris in 1841 and began working on a new set of instruments exhibited there in 1844. These were valved bugles, and although he had not invented the instrument itself, his examples were much more successful than those of his rivals and became known as saxhorns. They came in approximately seven different sizes, and paved the path to the creation of the flugelhorn. Today, saxhorns are sometimes used in concert bands and orchestras. The saxhorn also laid the groundwork for the modern euphonium.
Sax also developed the "saxotromba" family, valved brass instruments with narrower bore than the saxhorns, in 1845, though they survived only briefly.
Saxhorn instruments spread rapidly. The saxhorn valves were accepted as state-of-the-art and are largely unchanged today. The advances made by Adolphe Sax were soon followed by the British brass band movement which exclusively adopted the saxhorn range. The Jedforest Instrumental Band formed in 1854 and The Hawick Saxhorn Band formed in 1855, within the Scottish Borders, a decade after saxhorn models became available.
The period around 1840 saw Sax inventing the "clarinette-bourdon", an early unsuccessful design of contrabass clarinet. Around this time he also developed the instrument for which he is best known, the saxophone, patented on 28 June 1846. The saxophone was invented for use in both orchestras and concert bands. Composer Hector Berlioz wrote approvingly of the new instrument in 1842. By 1846 Sax had designed, on paper, a full range of saxophones (from sopranino to subcontrabass). Although they never became standard orchestral instruments, the saxophones made his reputation and secured him a job, teaching at the Paris Conservatoire in 1857.
Sax continued to make instruments later in life and presided over the new saxophone class at the Paris Conservatoire. Rival instrument makers attacked the legitimacy of his patents and mounted a long campaign of litigation against Sax and his company. He was driven into bankruptcy in 1856 and again in 1873.
Sax suffered from lip cancer between 1853 and 1858 but made a full recovery. In 1894 Sax died in complete poverty in Paris and was interred in section 5 (Avenue de Montebello) at the Cimetière de Montmartre in Paris.

</doc>
<doc id="3134" url="https://en.wikipedia.org/wiki?curid=3134" title="Aspirated consonant">
Aspirated consonant

In phonetics, aspiration is the strong burst of breath that accompanies either the release or, in the case of preaspiration, the closure of some obstruents. In English, aspirated consonants are allophones in complementary distribution with their unaspirated counterparts, but in some other languages, notably most Indian and East Asian languages, the difference is contrastive.
To feel or see the difference between aspirated and unaspirated sounds, one can put a hand or a lit candle in front of one's mouth, and say "pin" and then "spin" . One should either feel a puff of air or see a flicker of the candle flame with "pin" that one does not get with "spin". In most dialects of English, the initial consonant is aspirated in "pin" and unaspirated in "spin".
Transcription.
In the International Phonetic Alphabet (IPA), aspirated consonants are written using the symbols for voiceless consonants followed by the aspiration modifier letter , a superscript form of the symbol for the voiceless glottal fricative . For instance, represents the voiceless bilabial stop, and represents the aspirated bilabial stop.
Voiced consonants are seldom actually aspirated. Symbols for voiced consonants followed by , such as , typically represent consonants with breathy voiced release (see below). In the grammatical tradition of Sanskrit, aspirated consonants are called voiceless aspirated, and breathy-voiced consonants are called voiced aspirated.
There are no dedicated IPA symbols for degrees of aspiration and typically only two degrees are marked: unaspirated and aspirated . An old symbol for light aspiration was , but this is now obsolete. The aspiration modifier letter may be doubled to indicate especially strong or long aspiration. Hence, the two degrees of aspiration in Korean stops are sometimes transcribed or and , but they are usually transcribed and , with the details of voice-onset time given numerically.
Preaspirated consonants are marked by placing the aspiration modifier letter before the consonant symbol: represents the preaspirated bilabial stop.
Unaspirated or tenuis consonants are occasionally marked with the modifier letter for unaspiration , a superscript equal sign: . Usually, however, unaspirated consonants are left unmarked: .
Phonetics.
Voiceless consonants are produced with the vocal folds open (spread) and not vibrating, and voiced consonants are produced when the vocal folds are fractionally closed and vibrating (modal voice). Voiceless aspiration occurs when the vocal cords remain open after a consonant is released. An easy way to measure this is by noting the consonant's voice-onset time, as the voicing of a following vowel cannot begin until the vocal cords close.
Phonetically in some languages, such as Navajo, aspiration of stops tends to be realised as voiceless velar airflow; aspiration of affricates is realised as an extended length of the frication.
Aspirated consonants are not always followed by vowels or other voiced sounds. For example, in Eastern Armenian, aspiration is contrastive even word-finally, and aspirated consonants occur in consonant clusters. In Wahgi, consonants are aspirated only in final position.
Degree.
The degree of aspiration varies: the voice-onset time of aspirated stops is longer or shorter depending on the language or the place of articulation.
Armenian and Cantonese have aspiration that lasts about as long as English aspirated stops, in addition to unaspirated stops. Korean has lightly aspirated stops that fall between the Armenian and Cantonese unaspirated and aspirated stops as well as strongly aspirated stops whose aspiration lasts longer than that of Armenian or Cantonese. (See voice-onset time.)
Aspiration varies with place of articulation. The Spanish voiceless stops have voice-onset times (VOTs) of about 5, 10, and 30 milliseconds, whereas English aspirated have VOTs of about 60, 70, and 80 ms. Voice-onset time in Korean has been measured at 20, 25, and 50 ms for and 90, 95, and 125 for .
Doubling.
When aspirated consonants are doubled or geminated, the stop is held longer and then has an aspirated release. An aspirated affricate consists of a stop, fricative, and aspirated release. A doubled aspirated affricate has a longer hold in the stop portion and then has a release consisting of the fricative and aspiration.
Preaspiration.
Icelandic and Faroese have preaspirated ; some scholars interpret these as consonant clusters as well. In Icelandic, preaspirated stops contrast with double stops and single stops:
Preaspirated stops also occur in most Sami languages; for example, in North Sami, the unvoiced stop and affricate phonemes , , , , are pronounced preaspirated (, , , ) when they occur in medial or final position.
Fricative.
Although most aspirated obstruents in the world's language are stops and affricates, aspirated fricatives such as , or have been documented in Korean, in a few Tibeto-Burman languages, in some Oto-Manguean languages, and in the Siouan language Ofo. Some languages, such as Choni Tibetan, have up to four contrastive aspirated fricatives , and .
Voiced consonants with voiceless aspiration.
True aspirated voiced consonants, as opposed to murmured (breathy-voice) consonants such as the that are common in the languages of India, are extremely rare. They have been documented in Kelabit Taa, and the Kx'a languages. Reported aspirated voiced stops, affricates and clicks are .
Phonology.
Aspiration has varying significance in different languages. It is either allophonic or phonemic, and may be analyzed as an underlying consonant cluster.
Allophonic.
In some languages, such as English, aspiration is allophonic. Stops are distinguished primarily by voicing, and voiceless stops are sometimes aspirated, while voiced stops are usually unaspirated.
English voiceless stops are aspirated for most native speakers when they are word-initial or begin a stressed syllable, as in "pill", "till", "kill".
They are unaspirated for almost all speakers when immediately following word-initial s, as in "spill", "still", "skill". After an "s" elsewhere in a word they are normally unaspirated as well, except sometimes in compound words. When the consonants in a cluster like "st" are analyzed as belonging to different morphemes (heteromorphemic) the stop is aspirated, but when they are analyzed as belonging to one morpheme the stop is unaspirated. For instance, "distend" has unaspirated since it is not analyzed as two morphemes, but "distaste" has an aspirated middle because it is analyzed as "dis-" + "taste" and the word "taste" has an aspirated initial "t".
Word-final voiceless stops are sometimes aspirated.
Phonemic.
In many languages, such as Armenian, Korean, Thai, Indo-Aryan languages, Dravidian languages, Icelandic, Ancient Greek, and the varieties of Chinese, tenuis and aspirated consonants are phonemic. Unaspirated consonants like and aspirated consonants like are separate phonemes, and words are distinguished by whether they have one or the other.
Consonant cluster.
Alemannic German dialects have unaspirated as well as aspirated ; the latter series are usually viewed as consonant clusters.
Tenseness.
In Danish and most southern varieties of German, the "lenis" consonants transcribed for historical reasons as are distinguished from their fortis counterparts , mainly in their lack of aspiration.
Absence.
French, Standard Dutch, Tamil, Italian, Russian, Spanish, Modern Greek, and Latvian are languages that do not have aspirated consonants.
Examples.
Chinese.
Standard Chinese (Mandarin) has stops and affricates distinguished by aspiration: for instance, , . In pinyin, tenuis stops are written with letters that represent voiced consonants in English, and aspirated stops with letters that represent voiceless consonants. Thus "d" represents , and "t" represents .
Wu Chinese has a three-way distinction in stops and affricates: . In addition to aspirated and unaspirated consonants, there is a series of "muddy consonants", like . These are pronounced with slack or breathy voice: that is, they are weakly voiced. Muddy consonants as initial cause a syllable to be pronounced with low pitch or "light" (陽 "yáng") tone.
Indian languages.
Many Indo-Aryan languages have aspirated stops. Sanskrit, Hindi, Bengali, Marathi, and Gujarati have a four-way distinction in stops: voiceless, aspirated, voiced, and breathy-voiced or voiced aspirated, such as . Punjabi has lost breathy-voiced consonants, which resulted in a tone system, and therefore has a distinction between voiceless, aspirated, and voiced: .
Some of the Dravidian languages, such as Telugu, Tamil, Malayalam, and Kannada, have a distinction between voiced and voiceless, aspirated and unaspirated only in loanwords from Indo-Aryan languages. In native Dravidian words, there is no distinction between these categories and stops are underspecified for voicing and aspiration.
Armenian.
Most dialects of Armenian have aspirated stops, and some have breathy-voiced stops.
Classical and Eastern Armenian have a three-way distinction between voiceless, aspirated, and voiced, such as .
Western Armenian has a two-way distinction between aspirated and voiced: . Western Armenian aspirated corresponds to Eastern Armenian aspirated and voiced , and Western voiced corresponds to Eastern voiceless .
Greek.
Some forms of Greek before the Koine Greek period are reconstructed as having aspirated stops. The Classical Attic dialect of Ancient Greek had a three-way distinction in stops like Eastern Armenian: . These stops were called "thin, thick, middle" by Koine Greek grammarians.
There were aspirated stops at three places of articulation: labial, coronal, and velar . Earlier Greek, represented by Mycenaean Greek, likely had a labialized velar aspirated stop , which later became labial, coronal, or velar depending on dialect and phonetic environment.
The other Ancient Greek dialects, Ionic, Doric, Aeolic, and Arcadocypriot, likely had the same three-way distinction at one point, but Doric seems to have had a fricative in place of in the Classical period, and the Ionic and Aeolic dialects sometimes lost aspiration (psilosis).
Later, during the Koine Greek period, the aspirated and voiceless stops of Attic Greek lenited to voiceless and voiced fricatives, yielding in Medieval and Modern Greek.
Other uses.
Debuccalization.
The term "aspiration" sometimes refers to the sound change of debuccalization, in which a consonant is lenited (weakened) to become a glottal stop or fricative .
Breathy-voiced release.
So-called voiced aspirated consonants are nearly always pronounced instead with breathy voice, a type of phonation or vibration of the vocal folds. The modifier letter after a voiced consonant actually represents a breathy-voiced or murmured dental stop, as with the "voiced aspirated" bilabial stop in the Indo-Aryan languages. This consonant is therefore more accurately transcribed as , with the diacritic for breathy voice, or with the modifier letter , a superscript form of the symbol for the voiced glottal fricative .
Some linguists restrict the double-dot subscript to murmured sonorants, such as vowels and nasals, which are murmured throughout their duration, and use the superscript hook-aitch for the breathy-voiced release of obstruents.

</doc>
<doc id="3135" url="https://en.wikipedia.org/wiki?curid=3135" title="Arteriovenous malformation">
Arteriovenous malformation

Arteriovenous malformation (AVM) is an abnormal connection between arteries and veins, bypassing the capillary system. This vascular anomaly is widely known because of its occurrence in the central nervous system, but can appear in any location. Although many AVMs are asymptomatic, they can cause intense pain or bleeding or lead to other serious medical problems.
AVMs are usually congenital and belong to the RASopathies.
The genetic transmission patterns of AVM, if any, are unknown. AVM is not generally thought to be an inherited disorder, unless in the context of a specific hereditary syndrome.
Signs and symptoms.
Symptoms of AVM vary according to the location of the malformation. Roughly 88% of people affected with AVM are asymptomatic; often the malformation is discovered as part of an autopsy or during treatment of an unrelated disorder (called in medicine "an incidental finding"); in rare cases its expansion or a micro-bleed from an AVM in the brain can cause epilepsy, neurological deficit or pain.
The most general symptoms of a cerebral AVM include headache and epilepsy, with more specific symptoms occurring that normally depend on the location of the malformation and the individual. Such possible symptoms include:
Cerebral AVMs may present in a number of ways
Pulmonary arteriovenous malformations.
In the lungs, pulmonary arteriovenous malformations have no symptoms in up to 29% of cases.
Genetics.
Can occur due to autosomal dominant diseases, such as Hereditary Hemorrhagic Telangiectasia.
Pathophysiology.
In a normal functioning human body, arteries carry blood away from the heart to the lungs or the rest of the body, where the blood passes through capillaries, and veins return the blood to heart. An AVM interferes with this process by forming a direct connection of the arteries and veins. AVMs can cause intense pain and lead to serious medical problems. Although AVMs are often associated with the brain and spinal cord, they can develop in any part of the body.
Arteries and veins are part of the human cardiovascular system. Normally, the arteries in the vascular system carry oxygen-rich blood, except in the case of the pulmonary artery. Structurally, arteries divide and sub-divide repeatedly, eventually forming a sponge-like capillary bed. Blood moves through the capillaries, giving up oxygen and taking up waste products, including , from the surrounding cells. Capillaries in turn successively join together to form veins that carry blood away. The heart acts to pump blood through arteries and uptake the venous blood.
An AVM lacks the dampening effect of capillaries on the blood flow, which means that the AVM can get progressively larger over time as the amount of blood flowing through it increases, forcing the heart to work harder to keep up with the extra blood flow. It also causes the surrounding area to be deprived of the functions of the capillaries — removal of and delivery of nutrients to the cells. The resulting tangle of blood vessels, often called a "nidus" (Latin for "nest"), has no capillaries. It can be extremely fragile and prone to bleeding because of the abnormally direct connections between high-pressure arteries and low-pressure veins. The resultant sign, audible via stethoscope, is a rhythmic, whooshing sound caused by excessively rapid blood flow through the arteries and veins. It has been given the term "bruit", French for noise. On some occasions a patient with a brain AVM may become aware of the noise, which can compromise hearing and interfere with sleep in addition to causing psychological distress.
Diagnosis.
AVMs are diagnosed primarily by the following methods:
AVMs can occur in various parts of the body:
AVMs may occur in isolation or as a part of another disease (for example, Von Hippel-Lindau disease or hereditary hemorrhagic telangiectasia).
AVMs have been shown to be associated with aortic stenosis.
Bleeding from an AVM can be relatively mild or devastating. It can cause severe and less often fatal strokes. If a cerebral AVM is detected before a stroke occurs, usually the arteries feeding blood into the nidus can be closed off to avert the danger. However, interventional therapy may also be relatively risky. 
Treatment.
Treatment for brain AVMs can be symptomatic, and patients should be followed by a neurologist for any seizures, headaches or focal deficits. AVM-specific treatment may also involve endovascular embolization, neurosurgery or radiosurgery.
Embolization, that is, cutting off the blood supply to the AVM with coils or particles or glue introduced by a radiographically guided catheter, may be used in addition to neurosurgery or radiosurgery, but is rarely successful in isolation except in smaller AVMs. Gamma knife may also be used.
The Spetzler-Martin grading system developed at the Barrow Neurological Institute is utilized by neurosurgeons to determine operative versus nonoperative management of AVMs.
Epidemiology.
The estimated detection rate of AVM in the US general population is 1.4/100,000 per year. This is approximately one fifth to one seventh the incidence of intracranial aneurysms. An estimated 300,000 Americans have AVMs, of whom 12% (approximately 36,000) will exhibit symptoms of greatly varying severity.
History.
Emmanuel, Luschka and Virchow first described arteriovenous malformations in the mid-1800s. Olivecrona performed the first surgical excision of an intracranial AVM in 1932.
Research directions.
Despite many years of research, the central question of whether to treat AVMs has not been answered. All treatments, whether involving surgery, radiation, or drugs, have risks and side-effects. Therefore, it might be better in some cases to avoid treatment altogether and simply accept a small risk of coming to harm from the AVM itself. This question is currently being addressed in clinical trials.

</doc>
<doc id="3138" url="https://en.wikipedia.org/wiki?curid=3138" title="Atlanta">
Atlanta

Atlanta is the capital of and the most populous city in the U.S. state of Georgia, with an estimated 2013 population of 447,841. Atlanta is the cultural and economic center of the Atlanta metropolitan area, home to 5,522,942 people and the ninth largest metropolitan area in the United States. Atlanta is the county seat of Fulton County, and a small portion of the city extends eastward into DeKalb County.
Atlanta was established in 1837 at the intersection of two railroad lines, and the city rose from the ashes of the American Civil War to become a national center of commerce. In the decades following the Civil Rights Movement, during which the city earned a reputation as "too busy to hate" for the progressive views of its citizens and leaders, Atlanta attained international prominence. Atlanta is the primary transportation hub of the Southeastern United States, via highway, railroad, and air, with Hartsfield–Jackson Atlanta International Airport being the world's busiest airport since 1998.
Atlanta is considered an "alpha-" or "world city", ranking 36th among world cities and 8th in the nation with a gross domestic product of $270 billion. Atlanta's economy is considered diverse, with dominant sectors including logistics, professional and business services, media operations, and information technology. Topographically, Atlanta is marked by rolling hills and dense tree coverage. Revitalization of Atlanta's neighborhoods, initially spurred by the 1996 Olympics, has intensified in the 21st century, altering the city's demographics, politics, and culture.
History.
Prior to the arrival of European settlers in north Georgia, Creek and Cherokee Indians inhabited the area. Standing Peachtree, a Creek village located where Peachtree Creek flows into the Chattahoochee River, was the closest Indian settlement to what is now Atlanta. As part of the systematic removal of Native Americans from northern Georgia from 1802 to 1825, the Creek ceded the area in 1821, and white settlers arrived the following year.
In 1836, the Georgia General Assembly voted to build the Western and Atlantic Railroad in order to provide a link between the port of Savannah and the Midwest. The initial route was to run southward from Chattanooga to a terminus east of the Chattahoochee River, which would then be linked to Savannah. After engineers surveyed various possible locations for the terminus, the "zero milepost" was driven into the ground in what is now Five Points. A year later, the area around the milepost had developed into a settlement, first known as "Terminus", and later as "Thrasherville" after a local merchant who built homes and a general store in the area. By 1842, the town had six buildings and 30 residents, and was renamed "Marthasville" to honor the Governor's daughter. J. Edgar Thomson, Chief Engineer of the Georgia Railroad, suggested the town be renamed "Atlantica-Pacifica," which was shortened to "Atlanta". The residents approved, and the town was incorporated as Atlanta on December 29, 1847.
By 1860, Atlanta's population had grown to 9,554. During the Civil War, the nexus of multiple railroads in Atlanta made the city a hub for the distribution of military supplies. In 1864, following the capture of Chattanooga, the Union Army moved southward and began its invasion of north Georgia. The region surrounding Atlanta was the location of several major army battles, culminating with the Battle of Atlanta and a four-month-long siege of the city by the Union Army under the command of General William Tecumseh Sherman. On September 1, 1864, Confederate General John Bell Hood made the decision to retreat from Atlanta, ordering all public buildings and possible assets to the Union Army destroyed. On the next day, Mayor James Calhoun surrendered Atlanta to the Union Army, and on September 7, General Sherman ordered the city's civilian population to evacuate. On November 11, 1864, in preparation of the Union Army's march to Savannah, Sherman ordered Atlanta to be burned to the ground, sparing only the city's churches and hospitals.
After the Civil War ended in 1865, Atlanta was gradually rebuilt. Due to the city's superior rail transportation network, the state capital was moved to Atlanta from Milledgeville in 1868. In the 1880 Census, Atlanta surpassed Savannah as Georgia's largest city.
Beginning in the 1880s, Henry W. Grady, the editor of the "Atlanta Constitution" newspaper, promoted Atlanta to potential investors as a city of the "New South" that would be based upon a modern economy and less reliant on agriculture. By 1885, the founding of the Georgia School of Technology (now Georgia Tech) and the city's black colleges had established the city as a center for higher education. In 1895, Atlanta hosted the Cotton States and International Exposition, which attracted nearly 800,000 attendees and successfully promoted the New South's development to the world.
During the first decades of the 20th century, Atlanta experienced a period of unprecedented growth. In three decades' time, Atlanta's population tripled as the city limits expanded to include nearby streetcar suburbs; the city's skyline emerged with the construction of the Equitable, Flatiron, Empire, and Candler buildings; and Sweet Auburn emerged as a center of black commerce. However, the period was also marked by strife and tragedy. Increased racial tensions led to the Atlanta Race Riot of 1906, which left at least 27 people dead and over 70 injured. In 1915, Leo Frank, a Jewish-American factory superintendent, convicted of murder, was hanged by a lynch mob, drawing attention to antisemitism in the United States. On May 21, 1917, the Great Atlanta Fire destroyed 1,938 buildings in what is now the Old Fourth Ward, resulting in one fatality and the displacement of 10,000 people.
On December 15, 1939, Atlanta hosted the film premiere of "Gone with the Wind", the epic film based on the best-selling novel by Atlanta's Margaret Mitchell. The film's legendary producer, David O. Selznick, as well as the film's stars Clark Gable, Vivien Leigh, and Olivia de Havilland attended the gala event at Loew's Grand Theatre, but Oscar winner Hattie McDaniel, an African American, was barred from the event due to racial segregation laws and policies.
Atlanta played a vital role in the Allied effort during World War II due the city's war-related manufacturing companies, railroad network, and military bases, leading to rapid growth in the city's population and economy. In the 1950s, the city's newly constructed freeway system allowed middle class Atlantans the ability to relocate to the suburbs. As a result, the city began to make up an ever smaller proportion of the metropolitan area's population.
During the 1960s, Atlanta was a major organizing center of the Civil Rights Movement, with Dr. Martin Luther King, Jr., Ralph David Abernathy, and students from Atlanta's historically black colleges and universities playing major roles in the movement's leadership. While minimal compared to other cities, Atlanta was not completely free of racial strife. In 1961, the city attempted to thwart blockbusting by erecting road barriers in Cascade Heights, countering the efforts of civic and business leaders to foster Atlanta as the "city too busy to hate". Desegregation of the public sphere came in stages, with public transportation desegregated by 1959, the restaurant at Rich's department store by 1961, movie theaters by 1963, and public schools by 1973.
In 1960, whites comprised 61.7% of the city's population. By 1970, African Americans were a majority of the city's population and exercised new-found political influence by electing Atlanta's first black mayor, Maynard Jackson, in 1973. Under Mayor Jackson's tenure, Atlanta's airport was modernized, solidifying the city's role as a transportation center. The opening of the Georgia World Congress Center in 1976 heralded Atlanta's rise as a convention city. Construction of the city's subway system began in 1975, with rail service commencing in 1979. However, despite these improvements, Atlanta lost over 100,000 residents between 1970 and 1990, over 20% of its population.
In 1990, Atlanta was selected as the site for the 1996 Summer Olympic Games. Following the announcement, the city government undertook several major construction projects to improve Atlanta's parks, sporting venues, and transportation infrastructure. While the games themselves were marred by numerous organizational inefficiencies, as well as the Centennial Olympic Park bombing, they were a watershed event in Atlanta's history, initiating a fundamental transformation of the city in the decade that followed.
During the 2000s, Atlanta underwent a profound transformation demographically, physically, and culturally. Suburbanization, a booming economy, and new migrants decreased the city's black percentage from a high of 67% in 1990 to 54% in 2010. From 2000 to 2010, Atlanta gained 22,763 white residents, 5,142 Asian residents, and 3,095 Hispanic residents, while the city's black population decreased by 31,678. Much of the city's demographic change during the decade was driven by young, college-educated professionals: from 2000 to 2009, the three-mile radius surrounding Downtown Atlanta gained 9,722 residents aged 25 to 34 holding at least a four-year degree, an increase of 61%. Between the mid-1990s and 2010, stimulated by funding from the HOPE VI program, Atlanta demolished nearly all of its public housing, a total of 17,000 units and about 10% of all housing units in the city. In 2005, the $2.8 billion BeltLine project was adopted, with the stated goals of converting a disused 22-mile freight railroad loop that surrounds the central city into an art-filled multi-use trail and increasing the city's park space by 40%. Lastly, Atlanta's cultural offerings expanded during the 2000s: the High Museum of Art doubled in size; the Alliance Theatre won a Tony Award; and numerous art galleries were established on the once-industrial Westside.
Geography.
Atlanta encompasses , of which is land and is water. The city is situated among the foothills of the Appalachian Mountains, and at above mean sea level, Atlanta has the highest elevation of major cities east of the Mississippi River. Atlanta straddles the Eastern Continental Divide, such that rainwater that falls on the south and east side of the divide flows into the Atlantic Ocean, while rainwater on the north and west side of the divide flows into the Gulf of Mexico. Atlanta sits atop a ridge south of the Chattahoochee River, which is part of the ACF River Basin. Located at the far northwestern edge of the city, much of the river's natural habitat is preserved, in part by the Chattahoochee River National Recreation Area.
Cityscape.
Most of Atlanta was burned during the Civil War, depleting the city of a large stock of its historic architecture. Yet architecturally, the city had never been particularly "southern"—because Atlanta originated as a railroad town, rather than a patrician southern seaport like Savannah or Charleston, many of the city's landmarks could have easily been erected in the Northeast or Midwest.
During the Cold War era, Atlanta embraced global modernist trends, especially regarding commercial and institutional architecture. Examples of modernist architecture include the Westin Peachtree Plaza (1976), Georgia-Pacific Tower (1982), the State of Georgia Building (1966), and the Atlanta Marriott Marquis (1985). In the latter half of the 1980s, Atlanta became one of the early adopters of postmodern designs that reintroduced classical elements to the cityscape. Many of Atlanta's tallest skyscrapers were built in the late 1980s and early 1990s, with most displaying tapering spires or otherwise ornamented crowns, such as One Atlantic Center (1987), 191 Peachtree Tower (1991), and the Four Seasons Hotel Atlanta (1992). Also completed during the era is Atlanta's tallest skyscraper, the Bank of America Plaza (1992), which, at , is the 61st-tallest building in the world and the 9th-tallest building in the United States. The Bank of America Plaza is the tallest building outside of New York City and Chicago, and was the last building built in the United States to be in the top 10 tallest buildings in the world until One World Trade Center was completed externally on May 2013. The city's embrace of modern architecture, however, translated into an ambivalent approach toward historic preservation, leading to the destruction of notable architectural landmarks, including the Equitable Building (1892–1971), Terminal Station (1905–1972), and the Carnegie Library (1902–1977). The Fox Theatre (1929)—Atlanta's cultural icon—would have met the same fate had it not been for a grassroots effort to save it in the mid-1970s.
Atlanta is divided into 242 officially defined neighborhoods. The city contains three major high-rise districts, which form a north-south axis along Peachtree: Downtown, Midtown, and Buckhead. Surrounding these high-density districts are leafy, low-density neighborhoods, most of which are dominated by single-family homes.
Downtown Atlanta contains the most office space in the metro area, much of it occupied by government entities. Downtown is also home to the city's sporting venues and many of its tourist attractions. Midtown Atlanta is the city's second-largest business district, containing the offices of many of the region's law firms. Midtown is also known for its art institutions, cultural attractions, institutions of higher education, and dense form. Buckhead, the city's uptown district, is eight miles (13 km) north of Downtown and the city's third-largest business district. The district is marked by an urbanized core along Peachtree Road, surrounded by suburban single-family neighborhoods situated among dense forests and rolling hills.
Surrounding Atlanta's three high-rise districts are the city's low- and medium-density neighborhoods, where the craftsman bungalow single-family home is dominant. The eastside is marked by historic streetcar suburbs built from the 1890s-1930s as havens for the upper middle class. These neighborhoods, many of which contain their own villages encircled by shaded, architecturally-distinct residential streets, include the Victorian Inman Park, Bohemian East Atlanta, and eclectic Old Fourth Ward. On the westside, former warehouses and factories have been converted into housing, retail space, and art galleries, transforming the once-industrial West Midtown into a model neighborhood for smart growth, historic rehabilitation, and infill construction. In southwest Atlanta, neighborhoods closer to downtown originated as streetcar suburbs, including the historic West End, while those farther from downtown retain a postwar suburban layout, including Collier Heights and Cascade Heights, home to much of the city's affluent African American population. Northwest Atlanta contains the areas of the city to west of Marietta Boulevard and to the north of Martin Luther King, Jr. Drive, including those neighborhoods remote to downtown, such as Riverside, Bolton and Whittier Mill, which is one of Atlanta's designated Landmark Historical Neighborhoods. Vine City, though technically Northwest, adjoins the city's Downtown area and has recently been the target of community outreach programs and economic development initiatives.
Gentrification of the city's neighborhoods is one of the more controversial and transformative forces shaping contemporary Atlanta. The gentrification of Atlanta has its origins in the 1970s, after many of Atlanta's neighborhoods had undergone the urban decay that affected other major American cities in the mid-20th century. When neighborhood opposition successfully prevented two freeways from being built through city's the east side in 1975, the area became the starting point for Atlanta's gentrification. After Atlanta was awarded the Olympic games in 1990, gentrification expanded into other parts of the city, stimulated by infrastructure improvements undertaken in preparation for the games. Gentrification was also aided by the Atlanta Housing Authority's eradication of the city's public housing.
Climate.
Under the Köppen classification, Atlanta has a humid subtropical climate ("Cfa") with four distinct seasons and generous precipitation year-round, typical for the inland South. Summers are hot and humid, with temperatures somewhat moderated by the city's elevation. Winters are cool but variable, with an average of 48 freezing days per year and temperatures dropping to on rare occasions. Warm air from the Gulf of Mexico can bring spring-like highs while strong Arctic air masses can push lows into the teens (≤ −7 °C).
July averages , with high temperatures reaching on an average 44 days per year, though readings are not seen most years. January averages , with temperatures in the suburbs slightly cooler due largely to the urban heat island effect. Lows at or below freezing can be expected 40 nights annually, but extended stretches with daily high temperatures below are very rare, with a recent exception in January 2014. Extremes range from on February 13, 1899 to on June 30, 2012. Dewpoints in the summer range from in June to in July.
Typical of the southeastern U.S., Atlanta receives abundant rainfall that is relatively evenly distributed throughout the year, though spring and early fall are markedly drier. The average annual rainfall is , while snowfall is typically light at around per year. The heaviest single snowfall occurred on January 23, 1940, with around of snow. However, ice storms usually cause more problems than snowfall does, the most severe occurring on January 7, 1973. Tornadoes are rare in the city itself, but the March 15, 2008 EF2 tornado damaged prominent structures in downtown Atlanta.
Demographics.
The 2010 United States Census reported that Atlanta had a population of 420,003. The population density was 3,154 per square mile (1232/km). The racial makeup and population of Atlanta was 54.0% Black or African American, 38.4% White, 3.1% Asian and 0.2% Native American. Those from some other race made up 2.2% of the city's population, while those from two or more races made up 2.0%. Hispanics of any race made up 5.2% of the city's population. The median income for a household in the city was $45,171. The per capita income for the city was $35,453. 22.6% percent of the population was living below the poverty line. However, compared to the rest of the country, Atlanta's cost of living is 6.00% lower than the U.S. average. Atlanta has one of the highest LGBT populations per capita, ranking third among major American cities, behind San Francisco and slightly behind Seattle, with 12.8% of the city's total population recognizing themselves as gay, lesbian, or bisexual. 7.3% of Atlantans were born abroad.
In the 2010 Census, Atlanta was recorded as the nation's fourth largest majority black city, and the city has long been known as a center of African American political power, education, and culture, often called a black mecca. However, African American Atlantans have rapidly suburbanized in recent decades, and from 2000 to 2010, the city's black population decreased by 31,678 people, shrinking from 61.4% of the city's population in 2000 to 54.0% in 2010.
Atlanta has recently undergone a drastic demographic increase in its white population. Between 2000 and 2010, the proportion of whites in the city's population grew faster than that of any other U.S. city. In that decade, Atlanta's white population grew from 31% to 38% of the city's population, an absolute increase of 22,753 people, more than triple the increase that occurred between 1990 and 2000.
Out of the total population five years and older, 83.3% spoke only English at home, while 8.8% spoke Spanish, 3.9% another Indo-European language and 2.8% an Asian language. Atlanta's dialect has traditionally been a variation of Southern American English. The Chattahoochee River long formed a border between the Coastal Southern and Southern Appalachian dialects. However, by 2003, "Atlanta" magazine concluded that Atlanta had become significantly "de-Southernized", with a Southern accent considered a handicap in some circumstances. In general, Southern accents are less prevalent among residents of the city and inner suburbs and among younger people, while they are more common in the outer suburbs and among older people; this pattern coexists alongside Southern variations of African American Vernacular English.
Religion in Atlanta, while historically centered on Protestant Christianity, now involves many faiths as a result of the city and metro area's increasingly international population. While Protestant Christianity still maintains a strong presence in the city (63%), in recent decades Catholicism has gained a strong foothold due to migration patterns. Metro Atlanta also has a considerable number of ethnic Christian congregations, including Korean and Indian churches. Large non-Christian faiths are present in the form of Judaism, Islam and Hinduism. Overall, there are over 1,000 places of worship within Atlanta.
Economy.
Encompassing $304 billion, the Atlanta metropolitan area is the eighth-largest economy in the country and 17th-largest in the world. Corporate operations comprise a large portion of the Atlanta's economy, with the city serving as the regional, national, or global headquarters for many corporations. Atlanta contains the country's third largest concentration of Fortune 500 companies, and the city is the global headquarters of corporations such as The Coca-Cola Company, The Home Depot, Delta Air Lines, AT&T Mobility, Chick-fil-A, UPS, and Newell-Rubbermaid. Over 75 percent of Fortune 1000 companies conduct business operations in the Atlanta metropolitan area, and the region hosts offices of about 1,250 multinational corporations. Many corporations are drawn to Atlanta on account of the city's educated workforce; as of 2010, nearly 43% of adults in the city of Atlanta have college degrees, compared to 27% in the nation as a whole.
Atlanta began as a railroad town and logistics has remained a major component of the city's economy to this day. Atlanta is an important rail junction and contains major classification yards for Norfolk Southern and CSX. Since its construction in the 1950s, Hartsfield-Jackson Atlanta International Airport has served as a key engine of Atlanta's economic growth. Delta Air Lines, the city's largest employer and the metro area's third largest, operates the world's largest airline hub at Hartsfield-Jackson and has helped make it the world's busiest airport, both in terms of passenger traffic and aircraft operations. Partly due to the airport, Atlanta has become a hub for diplomatic missions; as of 2012, the city contains 25 general consulates, the seventh-highest concentration of diplomatic missions in the United States.
Media is also an important aspect of Atlanta's economy. The city is a major cable television programming center. Ted Turner established the headquarters of both the Cable News Network (CNN) and the Turner Broadcasting System (TBS) in Atlanta. Cox Enterprises, the country's third-largest cable television service and the publisher of over a dozen major American newspapers, is headquartered in the city. The Weather Channel, owned by NBCUniversal, Bain Capital, and The Blackstone Group, is headquartered just outside Atlanta in Cobb County.
Information technology, an economic sector that includes publishing, software development, entertainment and data processing has garnered a larger percentage of Atlanta's economic output. Indeed, Atlanta has been nicknamed the Silicon peach due to its burgeoning technology sector. As of 2013, Atlanta contains the fourth-largest concentration of information technology jobs in the United States, numbering 85,000. Atlanta also ranks as the sixth fastest-growing city for information technology jobs, with an employment growth of 4.8% in 2012 and a three-year growth near 9%, or 16,000 jobs. Information technology companies are drawn to Atlanta's lower costs and educated workforce.
Largely due to a statewide tax incentive enacted in 2005, the Georgia Entertainment Industry Investment Act, which awards qualified productions a transferable income tax credit of 20% of all in-state costs for film and television investments of $500,000 or more, Atlanta has become a center for film and television production. Film and television production facilities in Atlanta include Turner Studios, Pinewood Studios (Pinewood Atlanta), Tyler Perry Studios, Williams Street Productions, and the EUE/Screen Gems soundstages. Film and television production injected $1 billion into Georgia's economy in 2010, with Atlanta garnering most of the projects. Atlanta has gained recognition as a center of production of horror and zombie-related productions, with "Atlanta" magazine dubbing the city the "Zombie Capital of the World".
Compared to other American cities, Atlanta's economy has been disproportionately affected by the 2008 financial crisis and subsequent recession, with the city's economy earning a ranking of 68 among 100 American cities in a September 2014 report due to an elevated unemployment rate, declining real income levels, and a depressed housing market. From 2010–2011, Atlanta saw a 0.9% contraction in employment and only a 0.4% rise in income. Though unemployment had dropped to 7% by late 2014, this was still higher than the national unemployment rate of 5.8% Atlanta's housing market has also struggled, with home prices falling by 2.1% in January 2012, reaching levels not seen since 1996. Compared with a year earlier, the average home price in Atlanta fell 17.3% in February 2012, the largest annual drop in the history of the index for any city. Atlanta home values average $85,000 as of January 2012, second-lowest among major metropolitan areas, ranking slightly behind Detroit. The collapse in home prices has led some economists to deem Atlanta the worst housing market in the country. Nevertheless, in August 2013, Atlanta appeared on "Forbes" magazine's list of the Best Places for Business and Careers.
Culture.
Atlanta, while located in the South, has a culture that is no longer strictly Southern. This is due to a large population of migrants from other parts of the U.S., in addition to many recent immigrants to the U.S. who have made the metropolitan area their home, establishing Atlanta as the cultural and economic hub of an increasingly multi-cultural metropolitan area. Thus, although traditional Southern culture is part of Atlanta's cultural fabric, it is mostly the backdrop to one of the nation's most cosmopolitan cities. This unique cultural combination reveals itself in the arts district of Midtown, the quirky neighborhoods on the city's eastside, and the multi-ethnic enclaves found along Buford Highway.
Arts and theater.
Atlanta is one of few United States cities with permanent, professional, resident companies in all major performing arts disciplines: opera (Atlanta Opera), ballet (Atlanta Ballet), orchestral music (Atlanta Symphony Orchestra), and theater (the Alliance Theatre). Atlanta also attracts many touring Broadway acts, concerts, shows, and exhibitions catering to a variety of interests. Atlanta's performing arts district is concentrated in Midtown Atlanta at the Woodruff Arts Center, which is home to the Atlanta Symphony Orchestra and the Alliance Theatre. The city also frequently hosts touring Broadway acts, especially at The Fox Theatre, a historic landmark that is among the highest grossing theatres of its size.
As a national center for the arts, Atlanta is home to significant art museums and institutions. The renowned High Museum of Art is arguably the South's leading art museum and among the most-visited art museums in the world. The Museum of Design Atlanta (MODA), a design museum, is the only such museum in the Southeast. Contemporary art museums include the Atlanta Contemporary Art Center and the Museum of Contemporary Art of Georgia. Institutions of higher education also contribute to Atlanta's art scene, with the Savannah College of Art and Design's Atlanta campus providing the city's arts community with a steady stream of curators, and Emory University's Michael C. Carlos Museum containing the largest collection of ancient art in the Southeast.
Music.
Atlanta has played a major or contributing role in the development of various genres of American music at different points in the city's history. Beginning as early as the 1920s, Atlanta emerged as a center for country music, which was brought to the city by migrants from Appalachia. During the countercultural 1960s, Atlanta hosted the Atlanta International Pop Festival, with the 1969 festival taking place more than a month before Woodstock and featuring many of the same bands. The city was also a center for Southern rock during its 1970s heyday: the Allman Brothers Band's hit instrumental "Hot 'Lanta" is an ode to the city, while Lynyrd Skynyrd's famous live rendition of "Free Bird" was recorded at the Fox Theatre in 1976, with lead singer Ronnie Van Zant directing the band to "play it pretty for Atlanta". During the 1980s, Atlanta had an active Punk rock scene that was centered on two of the city's music venues, 688 Club and the Metroplex, and Atlanta famously played host to the Sex Pistols first U.S. show, which was performed at the Great Southeastern Music Hall. The 1990s saw the birth of Atlanta hip hop, a subgenre that gained relevance following the success of home-grown duo OutKast; however, it was not until the 2000s that Atlanta moved "from the margins to becoming hip-hop's center of gravity, part of a larger shift in hip-hop innovation to the South". Also in the 2000s, Atlanta was recognized by the Brooklyn-based "Vice" magazine for its impressive yet under-appreciated Indie rock scene, which revolves around the various live music venues found on the city's alternative eastside.
Tourism.
As of 2010, Atlanta is the seventh-most visited city in the United States, with over 35 million visitors per year. Although the most popular attraction among visitors to Atlanta is the Georgia Aquarium, the world's largest indoor aquarium, Atlanta's tourism industry mostly driven by the city's history museums and outdoor attractions. Atlanta contains a notable amount of historical museums and sites, including the Martin Luther King, Jr. National Historic Site, which includes the preserved childhood home of Dr. Martin Luther King, Jr., as well as his final resting place; the Atlanta Cyclorama & Civil War Museum, which houses a massive painting and diorama in-the-round, with a rotating central audience platform, depicting the Battle of Atlanta in the Civil War; the World of Coca-Cola, featuring the history of the world famous soft drink brand and its well-known advertising; the College Football Hall of Fame which honors college football and its athletes; the National Center for Civil and Human Rights, which explores the American Civil Rights Movement and its connection to contemporary human rights movements throughout the world; the Carter Center and Presidential Library, housing U.S. President Jimmy Carter's papers and other material relating to the Carter administration and the Carter family's life; and the Margaret Mitchell House and Museum, site of the writing of the best-selling novel Gone with the Wind.
Atlanta also contains various outdoor attractions. The Atlanta Botanical Garden, adjacent to Piedmont Park, is home to the Kendeda Canopy Walk, a skywalk that allows visitors to tour one of the city's last remaining urban forests from . The Canopy Walk is considered the only canopy-level pathway of its kind in the United States. Zoo Atlanta, located in Grant Park, accommodates over 1,300 animals representing more than 220 species. Home to the nation's largest collections of gorillas and orangutans, the Zoo is also one of only four zoos in the U.S. to house giant pandas. Festivals showcasing arts and crafts, film, and music, including the Atlanta Dogwood Festival, the Atlanta Film Festival, and Music Midtown, respectively, are also popular with tourists.
Tourists are also drawn to the city's culinary scene, which comprises a mix of urban establishments garnering national attention, ethnic restaurants serving cuisine from every corner of the world, and traditional eateries specializing in Southern dining. Since the turn of the 21st century, Atlanta has emerged as a sophisticated restaurant town. Many restaurants opened in the city's gentrifying neighborhoods have received praise at the national level, including Bocado, Bacchanalia, and Miller Union in West Midtown, Empire State South in Midtown, and Two Urban Licks and Rathbun's on the east side. In 2011, the "New York Times" characterized Empire State South and Miller Union as reflecting "a new kind of sophisticated Southern sensibility centered on the farm but experienced in the city." Visitors seeking to sample international Atlanta are directed to Buford Highway, the city's international corridor. There, the million-plus immigrants that make Atlanta home have established various authentic ethnic restaurants representing virtually every nationality on the globe. For traditional Southern fare, one of the city's most famous establishments is The Varsity, a long-lived fast food chain and the world's largest drive-in restaurant. Mary Mac's Tea Room and Paschal's are more formal destinations for Southern food.
Sports.
Atlanta is home to professional franchises for three major team sports: the Atlanta Braves of Major League Baseball, the Atlanta Hawks of the National Basketball Association, and the Atlanta Falcons of the National Football League. The Braves, who moved to Atlanta in 1966, were established as the Boston Red Stockings in 1871 and are the oldest continually operating professional sports franchise in the United States. The Braves won the World Series in 1995, and had an unprecedented run of 14 straight divisional championships from 1991 to 2005.
The Atlanta Falcons have played in Atlanta since their inception in 1966. The Falcons have won the division title five times (1980, 1998, 2004, 2010, 2012) and the conference championship once, when they finished as the runner-up to the Denver Broncos in Super Bowl XXXIII in 1999. The Atlanta Hawks began in 1946 as the Tri-Cities Blackhawks, playing in Moline, Illinois. The team moved to Atlanta in 1968, and they currently play their games in Philips Arena. The Atlanta Dream is the city's Women's National Basketball Association franchise.
Atlanta has also had its own professional ice hockey and soccer franchises. The National Hockey League (NHL) has had two Atlanta franchises: the Atlanta Flames began play in 1972 before moving to Calgary in 1980, while the Atlanta Thrashers began play in 1999 before moving to Winnipeg in 2011. The Atlanta Chiefs was the city's professional soccer team from 1967 to 1972, and the team won a national championship in 1968. In 1998 another professional soccer team was formed, the Atlanta Silverbacks of the North American Soccer League. In April 2014, a Major League Soccer team, Atlanta United FC, was formed as an expansion team to begin play in 2017.
Atlanta has been the host city for various international, professional and collegiate sporting events. Most famously, Atlanta hosted the Centennial 1996 Summer Olympics. Atlanta has also hosted Super Bowl XXVIII in 1994 and Super Bowl XXXIV in 2000. In professional golf, The Tour Championship, the final PGA Tour event of the season, is played annually at East Lake Golf Club. In 2001 and 2011, Atlanta hosted the PGA Championship, one of the four major championships in men's professional golf, at the Atlanta Athletic Club. In professional ice hockey, the city hosted the 56th NHL All-Star Game in 2008, three years before the Thrashers moved. In 2011, Atlanta hosted professional wrestling's annual WrestleMania. The city has hosted the NCAA Final Four Men's Basketball Championship four times, most recently in 2013. In college football, Atlanta hosts the Chick-fil-A Kickoff Game, the SEC Championship Game, and the Chick-fil-A Peach Bowl.
Parks and recreation.
Atlanta's 343 parks, nature preserves, and gardens cover , which amounts to only 5.6% of the city's total acreage, compared to the national average of just over 10%. However, 64% of Atlantans live within a 10-minute walk of a park, a percentage equal to the national average. Furthermore, in its 2013 ParkScore ranking, the The Trust for Public Land, a national land conservation organization, reported that among the park systems of the 50 most populous U.S. cities, Atlanta's park system received a ranking of 31. Piedmont Park, located in Midtown is Atlanta's most iconic green space. The park, which has undergone a major renovation and expansion in recent years, attracts visitors from across the region and hosts cultural events throughout the year. Other notable city parks include Centennial Olympic Park, a legacy of the 1996 Summer Olympics that forms the centerpiece of the city's tourist district; Woodruff Park, which anchors the campus of Georgia State University; Grant Park, home to both Zoo Atlanta and the Atlanta Cyclorama & Civil War Museum; and Chastain Park, which houses an amphitheater used for live music concerts. The Chattahoochee River National Recreation Area, located in the northwestern corner of the city, preserves a stretch of the river for public recreation opportunities. The Atlanta Botanical Garden, adjacent to Piedmont Park, contains formal gardens, including a Japanese garden and a rose garden, woodland areas, and a conservatory that includes indoor exhibits of plants from tropical rainforests and deserts. The BeltLine, a former rail corridor that forms a loop around Atlanta's core, will eventually be transformed into a series of parks, connected by a multi-use trail, increasing Atlanta's park space by 40%.
Atlanta offers resources and opportunities for amateur and participatory sports and recreation. Jogging is a particularly popular local sport. The Peachtree Road Race, the world's largest race, is held annually on Independence Day. The Georgia Marathon, which begins and ends at Centennial Olympic Park, routes through the city's historic east side neighborhoods. Golf and tennis are also popular in Atlanta, and the city contains six public golf courses and 182 tennis courts. Facilities located along the Chattahoochee River cater to watersports enthusiasts, providing the opportunity for kayaking, canoeing, fishing, boating, or tubing. The city's only skate park, a facility that offers bowls, curbs, and smooth-rolling concrete mounds, is located at Historic Fourth Ward Park.
Government and politics.
Atlanta is governed by a mayor and the Atlanta City Council. The city council consists of 15 representatives—one from each of the city's 12 districts and three at-large positions. The mayor may veto a bill passed by the council, but the council can override the veto with a two-thirds majority. The mayor of Atlanta is Kasim Reed, a Democrat elected on a nonpartisan ballot whose first term in office expired at the end of 2013. Reed was elected to a second term on November 5, 2013.
Every mayor elected since 1973 has been black. In 2001, Shirley Franklin became the first woman to be elected Mayor of Atlanta, and the first African-American woman to serve as mayor of a major southern city. Atlanta city politics suffered from a notorious reputation for corruption during the 1990s administration of Bill Campbell, who was convicted by a federal jury in 2006 on three counts of tax evasion in connection with gambling income he received while Mayor during trips he took with city contractors.
As the state capital, Atlanta is the site of most of Georgia's state government. The Georgia State Capitol building, located downtown, houses the offices of the governor, lieutenant governor and secretary of state, as well as the General Assembly. The Governor's Mansion is located in a residential section of Buckhead. Atlanta serves as the regional hub for many arms of the federal bureaucracy, including the Federal Reserve Bank of Atlanta and the Centers for Disease Control and Prevention. Atlanta also plays an important role in federal judiciary system, containing the United States Court of Appeals for the Eleventh Circuit and of the United States District Court for the Northern District of Georgia.
Historically, Atlanta has been a stronghold for the Democratic Party. Although municipal elections are officially nonpartisan, nearly all of the city's elected officials are registered Democrats. The city is split among 14 state house districts and four state senate districts, all held by Democrats. At the federal level, Atlanta is split between two congressional districts. The northern three-fourths of the city is located in the 5th district, represented by Democrat John Lewis. The southern fourth is in the 13th district, represented by Democrat David Scott.
The city is served by the Atlanta Police Department, which numbers 2,000 officers and oversaw a 40% decrease in the city's crime rate between 2001 and 2009. Specifically, homicide decreased by 57%, rape by 72%, and violent crime overall by 55%. Crime is down across the country, but Atlanta's improvement has occurred at more than twice the national rate. Nevertheless, Forbes ranked Atlanta as the sixth most dangerous city in the United States in 2012.
Education.
Due to the more than 30 colleges and universities located in the city, Atlanta is considered a center for higher education. Among the most prominent public universities in Atlanta is the Georgia Institute of Technology, a research university located in Midtown that has been consistently ranked among the nation's top ten public universities for its degree programs in engineering, computing, management, the sciences, architecture, and liberal arts. Georgia State University, a public research university located in Downtown Atlanta, is the largest of the 29 public colleges and universities in the University System of Georgia and a major contributor to the revitalization of the city's central business district. Atlanta is also home to nationally renowned private colleges and universities, most notably Emory University, a leading liberal arts and research institution that ranks among the top 20 schools in the United States and operates Emory Healthcare, the largest health care system in Georgia.
Atlanta Public Schools enrolls 55,000 students in 106 schools, some of which are operated as charter schools. The district has been plagued by a widely publicized cheating scandal exposed in 2009. Atlanta is also served by many private schools, including parochial Roman Catholic schools operated by the Archdiocese of Atlanta.
Media.
The primary network-affiliated television stations in Atlanta are WXIA-TV (NBC), WGCL-TV (CBS), WSB-TV (ABC), and WAGA-TV (FOX). The Atlanta metropolitan area is served by two public television stations and one public radio station. WGTV is the flagship station of the statewide Georgia Public Television network and is a PBS member station, while WPBA is owned by Atlanta Public Schools. Georgia Public Radio is listener-funded and comprises one NPR member station, WABE, a classical music station operated by Atlanta Public Schools.
Atlanta is served by the "Atlanta Journal-Constitution", its only major daily newspaper with wide distribution. The "Atlanta Journal-Constitution" is the result of a 1950 merger between "The Atlanta Journal" and "The Atlanta Constitution", with staff consolidation occurring in 1982 and separate publication of the morning "Constitution" and afternoon "Journal" ceasing in 2001. Alternative weekly newspapers include "Creative Loafing", which has a weekly print circulation of 80,000. "Atlanta" magazine is an award-winning, monthly general-interest magazine based in and covering Atlanta.
Transportation.
Atlanta's transportation infrastructure comprises a complex network that includes a heavy rail line, a streetcar line, multiple interstate highways, the world's busiest airport, and over of bike paths.
With a network of freeways that radiate out from the city, automobiles are the dominant mode of transportation in the region. Three major interstate highways converge in Atlanta: I-20 (east-west), I-75 (northwest-southeast), and I-85 (northeast-southwest). The latter two combine in the middle of the city to form the Downtown Connector (I-75/85), which carries more than 340,000 vehicles per day and is one of the most congested segments of interstate highway in the United States. Atlanta is mostly encircled by Interstate 285, a beltway locally known as "the Perimeter" that has come to mark the boundary between "Inside the Perimeter" (ITP), the city and close-in suburbs, and "Outside the Perimeter" (OTP), the outer suburbs and exurbs. The heavy reliance on automobiles for transportation in Atlanta has resulted in traffic, commute, and air pollution rates that rank among the worst in the country.
The Metropolitan Atlanta Rapid Transit Authority (MARTA) provides public transportation in the form of buses and heavy rail. Notwithstanding heavy automotive usage in Atlanta, the city's subway system is the eighth busiest in the country. MARTA rail lines connect many key destinations, such as the airport, Downtown, Midtown, Buckhead, and Perimeter Center. However, significant destinations, such as Emory University and Cumberland, remain unserved. As a result, a 2012 Brookings Institution study placed Atlanta 87th of 100 metro areas for transit accessibility. Emory University operates its Cliff shuttle buses with 200,000 boardings per month, while private minibuses ply Buford Highway. Amtrak, the national rail passenger system, provides service to Atlanta via the "Crescent train" (New York–New Orleans), which stops at Peachtree Station. In 2014, the Atlanta Streetcar opened to the public. The streetcar's line, which is also known as the Downtown Loop, runs 2.7 miles around the downtown tourist areas of Peachtree Center, Centennial Olympic Park, the Martin Luther King, Jr. National Historic Site, and Sweet Auburn. The Atlanta Streetcar line is also being expanded on in the coming years to include a wider range of Atlanta's neighborhoods and important places of interest, with a total of 66 miles of track being laid in the near future.
Hartsfield-Jackson Atlanta International Airport, the world's busiest airport as measured by passenger traffic and aircraft traffic, offers air service to over 150 U.S. destinations and more than 80 international destinations in 52 countries, with over 2,700 arrivals and departures daily. Delta Air Lines maintains its largest hub at the airport. Situated () south of downtown, the airport covers most of the land inside a wedge formed by Interstate 75, Interstate 85, and Interstate 285.
Cycling is a growing mode of transportation in Atlanta, more than doubling since 2009, when it comprised 1.1% of all commutes (up from 0.3% in 2000). Although Atlanta's lack of bike lanes and hilly topography may deter many residents from cycling, the city's transportation plan calls for the construction of of bike lanes by 2020, with the BeltLine helping to achieve this goal. In 2012, Atlanta's first "bike track" was constructed on 10th Street in Midtown. The two lane bike track runs from Monroe Drive west to Charles Allen Drive, with connections to the Beltline and Piedmont Park.
Tree canopy.
Atlanta has a reputation as a "city in a forest" due to an abundance of trees that is rare among major cities. The city's main street is named after a tree, and beyond the Downtown, Midtown, and Buckhead business districts, the skyline gives way to a dense canopy of woods that spreads into the suburbs. The city is home to the Atlanta Dogwood Festival, an annual arts and crafts festival held one weekend during early April, when the native dogwoods are in bloom. However, the nickname is also factually accurate, as the city's tree coverage percentage is at 36%, the highest out of all major American cities, and above the national average of 27%. Atlanta's tree coverage does not go unnoticed—it was the main reason cited by "National Geographic" in naming Atlanta a "Place of a Lifetime".
The city's lush tree canopy, which filters out pollutants and cools sidewalks and buildings, has increasingly been under assault from man and nature due to heavy rains, drought, aged forests, new pests, and urban construction. A 2001 study found that Atlanta's heavy tree cover declined from 48% in 1974 to 38% in 1996. However, the problem is being addressed by community organizations and city government: Trees Atlanta, a non-profit organization founded in 1985, has planted and distributed over 75,000 shade trees in the city, while Atlanta's government has awarded $130,000 in grants to neighborhood groups to plant trees.
Sister cities.
Atlanta has 18 sister cities, as designated by Sister Cities International, Inc. (SCI):

</doc>
<doc id="3143" url="https://en.wikipedia.org/wiki?curid=3143" title="Axiology">
Axiology

Axiology (from Greek , "axiā", "value, worth"; and , "-logos") is the philosophical study of value. It is either the collective term for ethics and aesthetics—philosophical fields that depend crucially on notions of worth—or the foundation for these fields, and thus similar to value theory and meta-ethics. The term was first used by Paul Lapie, in 1902, and Eduard von Hartmann, in 1908.
Axiology studies mainly two kinds of values: ethics and aesthetics. Ethics investigates the concepts of "right" and "good" in individual and social conduct. Aesthetics studies the concepts of "beauty" and "harmony." Formal axiology, the attempt to lay out principles regarding value with mathematical rigor, is exemplified by Robert S. Hartman's Science of Value.
History.
Between the 5th and 6th century BC, it was important in Greece to be knowledgeable if you were to be successful. Philosophers began to recognize that differences existed between the laws and morality of society. Socrates held the belief that knowledge had a vital connection to virtue, making morality and democracy closely intertwined. Socrates' student, Plato furthered the belief by establishing virtues which should be followed by all. With the fall of the government, values became individual, causing skeptic schools of thought to flourish, ultimately shaping a pagan philosophy that is thought to have influenced and shaped Christianity. During these medieval times, Thomas Aquinas argued for a separation between natural and religious virtues. This concept led philosophers to distinguish between judgments based on fact and judgments based on values, creating division between science and philosophy.
Axiological issues in communication studies.
Communication theorists seek to contribute to mutual intelligence about the anatomy and operation of human communication. The axiological issues that are significant for the evolution of communication theory are whether research can be truly free of value and whether the end for the administered research should be designed to expand knowledge or to change society. For communication theorists, a primary interest is with the philosophical establishment of the research approach. A continuing value debate occurs between scholars who comply with a conventional scientific approach and those who take an interpretivist approach to communication development.
Those who take a conventional scientific approach believe that research must be free of values in order to be valid. Therefore, it is necessary for the scientist to approach their research in a neutral and objective manner. In contrast, the interpretivists argue that it is impossible for research to be completely free of personal values, as research is always biased towards the values of the researcher. According to interpretivists, these biases are sometimes so entrenched in the researcher's culture that they will most likely go unnoticed during research. Since no one can truly be unbiased, some groups are more knowledgeable about certain things than other groups due to their positions in society, and they can be considered more qualified to perform research on certain topics as a result.
References.
Julian, M.(1967).History of philosophy.Dover publications, Inc. New York.

</doc>
<doc id="3144" url="https://en.wikipedia.org/wiki?curid=3144" title="A Doll's House">
A Doll's House

A Doll's House (; also translated as "A Doll House") is a three-act play in prose by Henrik Ibsen. It premiered at the Royal Theatre in Copenhagen, Denmark, on 21 December 1879, having been published earlier that month.
The play is significant for its critical attitude toward 19th-century marriage norms. It aroused great controversy at the time, as it concludes with the protagonist, Nora, leaving her husband and children because she wants to discover herself. Ibsen was inspired by the belief that "a woman cannot be herself in modern society," since it is "an exclusively male society, with laws made by men and with prosecutors and judges who assess feminine conduct from a masculine standpoint." Its ideas can also be seen as having a wider application: Michael Meyer argued that the play's theme is not women's rights, but rather "the need of every individual to find out the kind of person he or she really is and to strive to become that person." In a speech given to the Norwegian Association for Women's Rights in 1898, Ibsen insisted that he "must disclaim the honor of having consciously worked for the women's rights movement," since he wrote "without any conscious thought of making propaganda," his task having been "the "description of humanity"."
In 2006, the centennial of Ibsen's death, "A Doll's House" held the distinction of being the world's most performed play for that year. UNESCO has inscribed Ibsen's autographed manuscripts of "A Doll's House" on the Memory of the World Register in 2001, in recognition of their historical value.
Title.
The title of the play is most commonly translated as "A Doll's House", though some scholars use "A Doll House". John Simon argues that the only significance in the alternative translation is the difference in the way the toy is named in Britain and the United States. Egil Törnqvist argues that the alternative "simply sounds more idiomatic to Americans."
Synopsis.
Act one.
The play opens at Christmas time as Nora Helmer enters her home carrying a number of packages. Nora's husband Torvald is working in his study when she arrives. He playfully rebukes her for spending so much money on Christmas gifts, calling her his "little squirrel". He teases her about how she spent weeks making gifts and ornaments by hand last year because money was scarce. This year Torvald is due a promotion at the bank where he works, so Nora feels that they can let themselves go a little. The maid announces two visitors: Mrs. Kristine Linde, an old friend of Nora's, who has come seeking employment, and Dr. Rank, a close friend of the family, who is let into the study. Kristine has had a difficult few years, ever since her husband died leaving her with no money or children. Nora explains that things have not been easy for them either: Torvald became sick and they had to travel to Italy so he could recover. Kristine further explains that when her mother was ill, she had to take care of her brothers, but now that they are grown she feels her life is "unspeakably empty". Nora promises to talk to Torvald about finding her a job. Kristine gently tells Nora that she is like a child. Nora is offended, so she reveals that she borrowed money from "some admirer", so they could travel to Italy to improve Torvald's health. She told Torvald that her father gave her the money, but in fact she managed to illegally borrow it without his knowledge. Over the years, she has been secretly working and saving up to pay it off.
Krogstad, a lower-level employee at Torvald's bank, arrives and goes into the study. Nora is clearly uneasy when she sees him. Dr. Rank leaves the study and mentions that he feels wretched, though, like everyone, he wants to go on living. In contrast to his physical illness, he says that the man in the study, Krogstad, is "morally diseased".
After the meeting with Krogstad, Torvald comes out of the study. Nora asks him if he can give Kristine a position at the bank and Torvald is very positive, saying that this is a fortunate moment, as a position has just become available. Torvald, Kristine, and Dr. Rank leave the house, leaving Nora alone. The nanny returns with the children and Nora plays with them for a while until Krogstad creeps into the living room and surprises her. Krogstad tells Nora that Torvald intends to fire him at the bank and asks her to intercede with Torvald to allow him to keep his job. She refuses and Krogstad threatens to blackmail her about the loan she took out for the trip to Italy; he knows that she obtained this loan by forging her father's signature. Krogstad leaves and when Torvald returns, she tries to convince him not to fire Krogstad. Torvald refuses to hear her pleas, explaining that Krogstad is a liar and a hypocrite and that he committed a terrible crime: he forged someone's name. Torvald feels physically ill in the presence of a man "poisoning his own children with lies and dissimulation".
Act two.
Kristine arrives to help Nora repair a dress for a costume function that Torvald and she plan to attend the next day. Torvald returns from the bank, and Nora pleads with him to reinstate Krogstad, claiming she is worried Krogstad will publish libelous articles about Torvald and ruin his career. Torvald dismisses her fears and explains that, although Krogstad is a good worker and seems to have turned his life around, he must be fired because he is not deferential enough to Torvald in front of other bank personnel. Torvald then retires to his study to work.
Dr. Rank, the family friend, arrives. Nora asks him for a favour, but Rank responds by revealing that he has entered the terminal stage of tuberculosis of the spine and that he has always been secretly in love with her. Nora tries to deny the first revelation and make light of it, but is more disturbed by his declaration of love. She tries clumsily to tell him that she is not in love with him, but that she loves him dearly as a friend.
Desperate after being fired by Torvald, Krogstad arrives at the house. Nora convinces Dr. Rank to go into Torvald's study so he will not see Krogstad. When Krogstad confronts Nora, he declares that he no longer cares about the remaining balance of Nora's loan, but that he will instead preserve the associated bond to blackmail Torvald into not only keeping him employed, but also promoting him. Nora explains that she has done her best to persuade her husband, but he refuses to change his mind. Krogstad informs Nora that he has written a letter detailing her crime (forging her father's signature of surety on the bond) and put it in Torvald's mailbox, which is locked.
Nora tells Kristine of her difficult situation. Having had a relationship in the past before her marriage, Kristine says that Krogstad and she are still in love and promises to try to convince him to relent.
Torvald enters and tries to retrieve his mail, but Nora distracts him by begging him to help her with the dance she has been rehearsing for the costume party, feigning anxiety about performing. She dances so badly and acts so childishly that Torvald agrees to spend the whole evening coaching her. When the others go to dinner, Nora stays behind for a few minutes and contemplates killing herself to save her husband from the shame of the revelation of her crime and (more importantly) to pre-empt any gallant gesture on his part to save her reputation.
Act Three.
Kristine tells Krogstad that she only married her husband because she had no other means to support her sick mother and young siblings and that she has returned to offer him her love again. She believes that he would not have stooped to unethical behavior if he had not been devastated by her abandonment and been in dire financial straits. Krogstad is moved and offers to take back his letter to Torvald. However, Kristine decides that Torvald should know the truth for the sake of his and Nora's marriage.
After literally dragging Nora home from the party, Torvald goes to check his mail, but is interrupted by Dr. Rank, who has followed them. Dr. Rank chats for a while, conveying obliquely to Nora that this is a final goodbye, as he has determined that his death is near. Dr. Rank leaves, and Torvald retrieves his letters. As he reads them, Nora steels herself to take her life. Torvald confronts her with Krogstad's letter. Enraged, he declares that he is now completely in Krogstad's power – he must yield to Krogstad's demands and keep quiet about the whole affair. He berates Nora, calling her a dishonest and immoral woman and telling her that she is unfit to raise their children. He says that from now on their marriage will be only a matter of appearances.
A maid enters, delivering a letter to Nora. The letter is from Krogstad, yet Torvald demands to read the letter, taking it from Nora. Torvald exults that he is saved, as Krogstad has returned the incriminating bond, which Torvald immediately burns along with Krogstad's letters. He takes back his harsh words to his wife and tells her that he forgives her. Nora realizes that her husband is not the strong and gallant man she thought he was, and that he truly loves himself more than he does her.
Torvald explains that, when a man has forgiven his wife, it makes him love her all the more, since it reminds him that she is totally dependent on him, like a child. He dismisses the fact that Nora had to make the agonizing choice between her conscience and his health, and ignores her years of secret efforts to free them from the ensuing obligations and the danger of loss of reputation. He preserves his peace of mind by thinking of the incident as a mere mistake that she made owing to her dumbness, one of her most endearing feminine traits.
Nora tells Torvald that she is leaving him to live alone so that she can find out who she is and what she believes and decide what to do with her life. She says that she has been treated like a doll to play with for her whole life, first by her father and then by him. Concerned for the family reputation, Torvald insists that she fulfill her duty as a wife and mother, but Nora says that her first duties are to herself and that she cannot be a good mother or wife without learning to be more than a plaything. She reveals that she had expected that he would want to sacrifice his reputation for hers and that she had planned to kill herself to prevent him from doing so. She now realizes that Torvald is not at all the kind of person she had believed him to be and that their marriage has been based on mutual fantasies and misunderstanding.
Torvald is unable to comprehend Nora's point of view, since it contradicts all that he has been taught about the female mind throughout his life. Furthermore, he is so narcissistic that it is impossible for him to understand how he appears to her, as selfish, hypocritical, and more concerned with public reputation than with actual morality. Nora leaves her keys and wedding ring, and as Torvald breaks down and begins to cry, baffled by what has happened, Nora leaves the house, slamming the door behind herself. Whether or not she ever comes back is never made clear.
Alternative ending.
Ibsen's German agent felt that the original ending would not play well in German theatres; therefore, for it to be considered acceptable, Ibsen was forced to write an alternative ending for the German premiere. In this ending, Nora is led to her children after having argued with Torvald. Seeing them, she collapses, and the curtain is brought down. Ibsen later called the ending a disgrace to the original play and referred to it as a 'barbaric outrage'.
Composition and publication.
Real-life inspiration.
"A Doll's House" was based on the life of Laura Kieler (maiden name Laura Smith Petersen), a good friend of Ibsen. Much that happened between Nora and Torvald happened to Laura and her husband, Victor. Much like the play, Laura signs the illegal loan to save her husband. She wants the money to find a cure for her husband's tuberculosis. She wrote to Ibsen, asking for his recommendation of her work to his publisher, thinking that the sales of her book would repay her debt. At his refusal, she forged a cheque for the money. At this point she was found out. In real life, when Victor discovered about Laura's secret loan, he divorced her and had her committed to an asylum. Two years later, she returned to her husband and children at his urging, and she went on to become a well-known Danish author, living to the age of 83.
Ibsen wrote "A Doll's House" at the point when Laura Kieler had been committed to the asylum, and the fate of this friend of the family shook him deeply, perhaps also because Laura had asked him to intervene at a crucial point in the scandal, which he did not feel able or willing to do. Instead, he turned this life situation into an aesthetically shaped, successful drama. In the play, Nora leaves Torvald with head held high, though facing an uncertain future given the limitations single women faced in the society of the time.
Kieler eventually rebounded from the shame of the scandal and had her own successful writing career while remaining discontented with sole recognition as "Ibsen's Nora" years afterwards.
Composition.
Ibsen started thinking about the play around May 1878, although he did not begin its first draft until a year later, having reflected on the themes and characters in the intervening period (he visualised its protagonist, Nora, for instance, as having approached him one day wearing "a blue woolen dress"). He outlined his conception of the play as a "modern tragedy" in a note written in Rome on 19 October 1878. "A woman cannot be herself in modern society," he argues, since it is "an exclusively male society, with laws made by men and with prosecutors and judges who assess feminine conduct from a masculine standpoint."
Publication.
Ibsen sent a fair copy of the completed play to his publisher on 15 September 1879. It was first published in Copenhagen on 4 December 1879, in an edition of 8,000 copies that sold out within a month; a second edition of 3,000 copies followed on 4 January 1880, and a third edition of 2,500 was issued on 8 March.
Production history.
"A Doll's House" received its world premiere on 21 December 1879 at the Royal Theatre in Copenhagen, with Betty Hennings as Nora, Emil Poulsen as Torvald, and Peter Jerndorff as Dr. Rank. Writing for the Norwegian newspaper "Folkets Avis", the critic Erik Bøgh admired Ibsen's originality and technical mastery: "Not a single declamatory phrase, no high dramatics, no drop of blood, not even a tear." Every performance of its run was sold out. Another production opened at the Royal Theatre in Stockholm, on 8 January 1880, while productions in Christiania (with Johanne Juell as Nora and Arnoldus Reimers as Torvald) and Bergen followed shortly after.
In Germany, the actress Hedwig Niemann-Raabe refused to perform the play as written, declaring, ""I" would never leave "my" children!" Since the playwright's wishes were not protected by copyright, Ibsen decided to avoid the danger of being rewritten by a lesser dramatist by committing what he called a "barbaric outrage" on his play himself and giving it an alternative ending in which Nora did not leave. A production of this version opened in Flensburg in February 1880. This version was also played in Hamburg, Dresden, Hanover, and Berlin, although, in the wake of protests and a lack of success, Niemann-Raabe eventually restored the original ending. Another production of the original version, some rehearsals of which Ibsen attended, opened on 3 March 1880 at the Residenz Theatre in Munich.
In Great Britain, the only way in which the play was initially allowed to be given in London was in an adaptation by Henry Arthur Jones and Henry Herman called "Breaking a Butterfly". This adaptation was produced at the Princess Theatre, 3 March 1884. The first British production of the play in its regular form opened on 7 June 1889 at the Novelty Theatre, starring Janet Achurch as Nora and Charles Charrington as Torvald. Achurch played Nora again for a 7-day run in 1897. Soon after its London premiere, Achurch brought the play to Australia in 1889.
The play was first seen in America when, during 1883, in Louisville, Kentucky, Helena Modjeska acted Nora. The play made its Broadway premiere at the Palmer's Theatre on 21 December 1889, starring Beatrice Cameron as Nora Helmer. It was first performed in France in 1894.
Other productions in the United States include one in 1902 starring Minnie Maddern Fiske, a 1937 adaptation with acting script by Thornton Wilder and starring Ruth Gordon, and a 1971 production starring Claire Bloom.
A new translation by Zinnie Harris at the Donmar Warehouse, starring Gillian Anderson, Toby Stephens, Anton Lesser, Tara FitzGerald and Christopher Eccleston opened in May 2009. In August 2013, Young Vic, London, Great Britain, produced a new adaptation of "A Doll's House" directed by Carrie Cracknell based on the English language version by Simon Stephens.
In September 2014, in partnership with Brisbane Festival, La Boite located in Brisbane, Australia, hosted an adaptation of "A Doll's House" written by Lally Katz and directed by Stephen Mitchell Wright.
In June 2015, Space Arts Centre in London staged an adaptation of A Doll's House featuring the discarded alternate ending.
Criticism.
"A Doll's House" questions the traditional roles of men and women in 19th-century marriage. To many 19th-century Europeans, this was scandalous. The Swedish playwright August Strindberg attacked the play in his volume of short stories "Getting Married" (1884). The covenant of marriage was considered holy, and to portray it as Ibsen did was controversial; However, other critics such as the Irish playwright George Bernard Shaw found Ibsen's willingness to examine society without prejudice exhilarating.
In Germany, the production's lead actress refused to play the part of Nora unless Ibsen changed the ending, which, under pressure, he eventually did. In the alternative ending, Nora gives her husband another chance after he reminds her of her responsibility to their children. This ending proved unpopular and Ibsen later regretted his decision on the matter. Virtually all productions today use the original ending, as do nearly all of the film versions of this play, including Dariush Mehrjui's "Sara" (the Argentine version, made in 1943 and starring Delia Garcés, does not; it also modernizes the story, setting it in the early 1940s). Because of the departure from traditional behavior and theatrical convention involved in Nora's leaving home, her act of slamming the door as she leaves has come to represent the play itself. One critic noted, "That slammed door reverberated across the roof of the world."
Adaptations.
Film.
"A Doll's House" has been adapted for the cinema on many occasions, including:
Television.
There have been several television versions, including:

</doc>
<doc id="3146" url="https://en.wikipedia.org/wiki?curid=3146" title="AIM-7 Sparrow">
AIM-7 Sparrow

The AIM-7 Sparrow is an American, medium-range semi-active radar homing air-to-air missile operated by the United States Air Force, United States Navy and United States Marine Corps, as well as other various air forces and navies. Sparrow and its derivatives were the West's principal beyond visual range (BVR) air-to-air missile from the late 1950s until the 1990s. It remains in service, although it is being phased out in aviation applications in favor of the more advanced AIM-120 AMRAAM. The Self-Defence Forces of Japan also employ the Sparrow missile, though it is being phased out and replaced by the Mitsubishi AAM-4. NATO pilots use the brevity code Fox One in radio communication to signal launch of a Semi-Active Radar Homing Missile such as the Sparrow.
The Sparrow was used as the basis for a surface-to-air missile, the RIM-7 Sea Sparrow, which is used by a number of navies for air defense of their ships. Fired at low altitude and flying directly at its target though the lower atmosphere, the range of the missile in this role is greatly reduced. With the retirement of the Sparrow in the air-to-air role, a new version of the Sea Sparrow was produced to address this concern, producing the much larger and more capable RIM-162 ESSM.
Development.
Sparrow I.
 from a late-1940s United States Navy program to develop a guided rocket weapon for air-to-air use. In 1947 the Navy contracted Sperry to build a beam riding version of a standard HVAR, the standard unguided aerial rocket, under Project Hotshot. The weapon was initially dubbed KAS-1, then AAM-2, and, from 1948 on, AAM-N-2. The airframe was developed by Douglas Aircraft Company. The diameter of the HVAR proved to be inadequate for the electronics, leading Douglas to expand the missile's airframe to diameter. The prototype weapon began unpowered flight-tests in 1947, and made its first aerial interception in 1952.
After a protracted development cycle the initial AAM-N-2 "Sparrow" entered limited operational service in 1954 with specially modified Skyknights all weather carrier night fighters. And in 1956, they were carried by the F3H-2M Demon and F7U Cutlass fighter aircraft. Compared to the modern versions, the Sparrow I was more streamlined and featured a bullet-shaped airframe with a long pointed nose.
Sparrow I was a limited and rather primitive weapon. The limitations of beam-riding guidance (which was slaved to an optical sight on single seater fighters and a radar with night fighters) restricted the missile to attacks against targets flying a straight course and made it essentially useless against a maneuvering target. Only about 2,000 rounds were produced to this standard.
Sparrow II.
As early as 1950 Douglas examined equipping the Sparrow with an active radar seeker, initially known as XAAM-N-2a "Sparrow II, the original retroactively becoming Sparrow I". In 1952 it was given the new code AAM-N-3. The active radar made the Sparrow II a "fire and forget" weapon, allowing several to be fired at separate targets at the same time.
By 1955 Douglas proposed going ahead with development, intending it to be the primary weapon for the F5D Skylancer interceptor. It was later selected, with some controversy, to be the primary weapon for the Canadian Avro Arrow supersonic interceptor, along with the new Astra fire-control system. For Canadian use and as a second source for US missiles, Canadair was selected to build the missiles in Quebec.
The small size of the missile forebody and the K-band AN/APQ-64-radar limited performance, and it was never able to work in testing. After considerable development and test firings in the U.S. and Canada, Douglas abandoned development in 1956. Canadair continued development until the Arrow was cancelled in 1959.
Sparrow X.
A subvariant of the Sparrow I armed with the same nuclear warhead as the MB-1 Genie was proposed in 1958, but was cancelled shortly thereafter.
Sparrow III.
Concurrently with the development of the Sparrow I, in 1951, Raytheon began work on the semi-active radar homing version of Sparrow family of missiles, the AAM-N-6 "Sparrow III". The first of these weapons entered United States Navy service in 1958.
The AAM-N-6a was similar to the -6, but used a new Thiokol liquid-fuel rocket engine for improved performance. It also included changes to the guidance electronics to make it effective at higher closing speeds. The -6a was also selected to arm the Air Force's "F-110A Spectre" (F-4 Phantom) fighters in 1962, known to them as the AIM-101. It entered production in 1959, with 7500 being built.
Another upgrade reverted to a Rocketdyne solid-fuel motor for the AAM-N-6b, which started production in 1963. The new motor significantly increased maximum range to for head-on attacks.
During this year the Navy and Air Force agreed on standardized naming conventions for their missiles. The Sparrows became the AIM-7 series. The original Sparrow I and aborted Sparrow II became the AIM-7A and AIM-7B, despite both being out of service. The -6, -6a and -6B became the AIM-7C, AIM-7D and AIM-7E respectively.
25,000 AIM-7Es were produced, and saw extensive use during the Vietnam War, where its performance was generally considered disappointing. The mixed results were a combination of reliability problems (exacerbated by the tropical climate), limited pilot training in fighter-to-fighter combat, and restrictive rules of engagement that generally prohibited BVR (beyond visual range) engagements. The P (kill probability) of the AIM-7E was less than 10%; US fighter pilots shot down 59 aircraft out of the 612 Sparrows fired. Of the 612 AIM-7D/E/E-2 missiles fired, 97 (or 15.8%) hit their targets, resulting in 56 (or 9.2%) kills. Two kills were obtained beyond visual range.
In 1969 an improved version, the E-2, was introduced with clipped wings and various changes to the fuzing. Considered a "dogfight Sparrow", the AIM-7E-2 was intended to be used at shorter ranges where the missile was still travelling at high speeds, and in the head-on aspect, making it much more useful in the visual limitations imposed on the engagements. Even so, its kill rate was only 13% in combat, leading to a practice of ripple-firing all four at once in hopes of increasing kill probability. Its worst tendency was that of detonating prematurely, approximately a thousand feet in front of the launching aircraft, but it also had many motor failures, erratic flights, and fuzing problems. An E-3 version included additional changes to the fuzing, and an E-4 featured a modified seeker for use with the F-14 Tomcat.
U.S. AIM-7 Sparrow Aerial Combat Victories in the Vietnam War 1965–1973.
Improved versions of the AIM-7 were developed in the 1970s in an attempt to address the weapon's limitations. The AIM-7F, which entered service in 1976, had a dual-stage rocket motor for longer range, solid-state electronics for greatly improved reliability, and a larger warhead. Even this version had room for improvement, leading British Aerospace and the Italian firm Alenia to develop advanced versions of Sparrow with better performance and improved electronics as the BAe Skyflash and Alenia Aspide, respectively.
The most common version of the Sparrow today, the AIM-7M, entered service in 1982 and featured a new inverse monopulse seeker (matching the capabilities of Skyflash), active radar fuse, digital controls, improved ECM resistance, and better low-altitude performance. It was used to good advantage in the 1991 Gulf War, where it scored many USAF air-to-air kills. Of 44 missiles fired, 30 (68.2%) hit their intended targets resulting in 24/26 (54.5%/59.1%) kills. 19 kills were obtained beyond visual range.
The AIM-7P is similar in most ways to the M versions, and was primarily an upgrade program for existing M-series missiles. The main changes were to the software, improving low-level performance. A follow-on Block II upgrade added a new rear receiver allowing the missile to receive mid-course correction from the launching aircraft. Plans initially called for all M versions to be upgraded, but currently P's are being issued as required to replace M's lost or removed from the inventory.
The final version of the missile was to have been the AIM-7R, which added an infrared homing seeker to an otherwise unchanged AIM-7P Block II. A general wind-down of the budget led to it being cancelled in 1997.
Sparrow is now being phased out with the availability of the active-radar AIM-120 AMRAAM, but is likely to remain in service for several years.
Foreign versions.
Canada.
As part of the Avro Arrow program, Canadair partnered with Douglas in the development of the Sparrow II (AIM-7B). After Douglas dropped out of this program, Canadair continued on with it until the termination of the Arrow. Canadair had completed five missiles based on airframes from Douglas, and built two models from scratch, when the program was cancelled with the cancellation of the Arrow.
Greece.
Skyguard I is an anti-aircraft system, utilizing ground based AIM-7 Sparrow launchers.
Italy.
The Italian company Finmeccanica, Alenia Difesa licensed the AIM-7E Sparrow technology from the US, and produced its own improved version called Aspide.
UK.
British Aerospace (BAe) licensed the AIM-7E2 technology in the 1970s, producing the Skyflash missile. Skyflash used a Marconi XJ521 monopulse Semi-Active seeker together with improvements to the electronics. It was powered by the Aerojet Mk52 mod 2 rocket engine (later by the Rocketdyne Mk38 mod 4). Skyflash entered service with the Royal Air Force (RAF) on their Phantom FG.1/FGR.2 in 1978, and later on the Tornado F3. Skyflash was also exported to Sweden for use on their Viggen fighters.
An upgraded version with active radar seeker, called Active Sky Flash was proposed by BAe and Thomson-CSF, but did not receive funding because the RAF opted for other missiles.
People's Republic of China.
The LY-60/FD-60/PL-10 is a family of PRC missiles developed by the Shanghai Academy of Science and Technology, largely based on the Italian Aspide missile - a version of the Sparrow. There are four versions of the basic design, three of which are surface-to-air and one air-to-air.
Design.
The Sparrow has four major sections: guidance section, warhead, control, and rocket motor (currently the Hercules MK-58 solid-propellant rocket motor). It has a cylindrical body with four wings at mid-body and four tail fins. Although the external dimensions of the Sparrow remained relatively unchanged from model to model, the internal components of newer missiles represent major improvements, with vastly increased capabilities. The warhead is of the continuous-rod type.
As with other semi-active radar guided missiles, the missile does not generate radar signals, but instead homes in on reflected continuous-wave signals from the launch platform's radar. The receiver also senses the guidance radar to enable comparisons that enhance the missile's resistance to passive jamming.
Principle of guidance (semi-active version).
The launching aircraft will illuminate the target with its radar. In radars of the 1950s these were single target tracking devices using a nutating horn as part of the antenna. This caused the beam to be swept in a small cone. Signal processing would be applied to determine the direction of maximum illumination and so develop a signal to steer the antenna toward the target. The missile detects the reflected signal from the target with a high gain antenna in a similar fashion and steers the entire missile toward closure with the target. The missile guidance also samples a portion of the illuminating signal via rearward pointing waveguides. The comparison of these two signals enabled logic circuits to determine the true target reflection signal, even if the target were to eject radar-reflecting chaff.

</doc>
<doc id="3147" url="https://en.wikipedia.org/wiki?curid=3147" title="AIM-120 AMRAAM">
AIM-120 AMRAAM

The AIM-120 Advanced Medium-Range Air-to-Air Missile, or AMRAAM (pronounced "am-ram"), is a modern beyond-visual-range air-to-air missile (BVRAAM) capable of all-weather day-and-night operations. Designed with 7" diameter instead of 8" diameter form-and-fit factors, and employing active transmit-receive radar guidance instead of semi-active receive-only radar guidance, it is a fire-and-forget upgrade to the previous generation Sparrow missiles. When an AMRAAM missile is being launched, NATO pilots use the brevity code Fox Three.
Origins.
AIM-7 Sparrow MRM.
The AIM-7 Sparrow medium range missile (MRM) was purchased by the US Navy from original developer Howard Hughes in the 1950s as its first operational air-to-air missile with "beyond visual range" (BVR) capability. With an effective range of about , it was introduced as a radar beam-riding missile and then it was improved to a semiactive radar guided missile which would home in on reflections from a target illuminated by the radar of the launching aircraft. It was effective at visual to beyond visual range. The early beam riding versions of the Sparrow missiles were integrated onto the F3H Demon and F7U Cutlass, but the definitive AIM-7 Sparrow was the primary weapon for the all-weather F-4 Phantom II fighter/interceptor, which lacked an internal gun in its U.S. Navy, U.S. Marine Corps, and early U.S. Air Force versions. The F-4 carried up to four AIM-7s in built-in recesses under its belly.
Although designed for use against non-maneuvering targets such as bombers, because of poor performance against fighters over North Vietnam, these missiles were progressively improved until they proved highly effective in dogfights. Together with the short-range, infrared-guided AIM-9 Sidewinder, they replaced the AIM-4 Falcon IR and radar guided series for use in air combat by the USAF as well. A disadvantage to semi-active homing was that only one target could be illuminated by the launching fighter plane at a time. Also, the launching aircraft had to remain pointed in the direction of the target (within the azimuth and elevation of its own radar set) which could be difficult or dangerous in air-to-air combat.
An active-radar variant called the Sparrow II was developed to address these drawbacks, but the U.S. Navy pulled out of the project in 1956. The Royal Canadian Air Force, which took over development in the hopes of using the missile to arm their prospective CF-105 Arrow interceptor, soon followed in 1958. The electronics of the time simply could not be miniaturized enough to make Sparrow II a viable working weapon. It would take decades, and a new generation of digital electronics, to produce an effective active-radar air-to-air missile as compact as the Sparrow.
AIM-54 Phoenix LRM.
The US Navy later developed the AIM-54 Phoenix long-range missile (LRM) for the fleet air defense mission. It was a large , Mach 5 missile designed to counter cruise missiles and the bombers that launched them. Originally intended for the straight-wing Douglas F6D Missileer and then the navalized version of the F-111B, it finally saw service with the Grumman F-14 Tomcat, the only fighter capable of carrying such a heavy missile. Phoenix was the first US fire-and-forget, multiple-launch, radar-guided missile: one which used its own active guidance system to guide itself without help from the launch aircraft when it closed on its target. This, in theory, gave a Tomcat with a six-Phoenix load the unprecedented capability of tracking and destroying up to six targets beyond visual range, as far as away—the only US fighter with such capability.
A full load of six Phoenix missiles and its dedicated launcher exceeded a typical Vietnam-era bomb load. Its service in the US Navy was primarily as a deterrent, as its use was hampered by restrictive rules of engagement in conflicts such as Operations Desert Storm, Southern Watch, and Iraqi Freedom. The US Navy retired the Phoenix in 2004 in light of availability of the AIM-120 AMRAAM on the F/A-18 Hornet and the pending retirement of the F-14 Tomcat from active service in late 2006.
ACEVAL/AIMVAL.
The Department of Defense conducted an extensive evaluation of air combat tactics and missile technology from 1974 to 1978 at Nellis AFB using the F-14 Tomcat and F-15 Eagle equipped with Sparrow and Sidewinder missiles as the blue force and aggressor F-5E aircraft equipped with AIM-9L all-aspect Sidewinders as the red force. This joint test and evaluation (JT&E) was designated Air Combat Evaluation/Air Intercept Missile Evaluation (ACEVAL/AIMVAL). A principal finding was that the necessity to produce illumination for the Sparrow until impact resulted in the red force's being able to launch their all-aspect Sidewinders before impact, resulting in mutual kills. What was needed was Phoenix-type multiple-launch and terminal active capability in a Sparrow-size airframe. This led to a memorandum of agreement (MOA) with European allies (principally the UK and Germany for development) for the US to develop an advanced, medium-range, air-to-air missile with the USAF as lead service. The MOA also assigned responsibility for development of an advanced, short-range, air-to-air missile to the European team; this would become the British ASRAAM.
Requirements.
By the 1990s, the reliability of the Sparrow had improved so much from the dismal days of Vietnam that it accounted for the largest number of aerial targets destroyed in Desert Storm. But while the USAF had passed on the Phoenix and their own similar AIM-47/YF-12 to optimize dogfight performance, they still needed a multiple-launch fire-and-forget capability for the F-15 and F-16. AMRAAM would need to be fitted on fighters as small as the F-16, and fit in the same spaces that were designed to fit the Sparrow on the F-4 Phantom. The European partners needed AMRAAM to be integrated on aircraft as small as the Sea Harrier. The US Navy needed AMRAAM to be carried on the F/A-18 Hornet and wanted capability for two to be carried on a launcher that normally carried one Sparrow to allow for more air-to-ground weapons.
The AMRAAM became one of the primary air-to-air weapons of the new F-22 Raptor fighter, which needed to place all of its weapons into internal weapons bays in order to help achieve an extremely low radar cross-section.
Development.
AMRAAM was developed as the result of an agreement (the Family of Weapons MOA, no longer in effect by 1990), among the United States and several other NATO nations to develop air-to-air missiles and to share production technology. Under this agreement the U.S. was to develop the next generation medium range missile (AMRAAM) and Europe would develop the next generation short range missile (ASRAAM). Although Europe initially adopted the AMRAAM, an effort to develop the Meteor (missile), a competitor to AMRAAM, was begun in Great Britain. Eventually the ASRAAM was developed solely by the British, but using another source for its infrared seeker. After protracted development, the deployment of AMRAAM (AIM-120A) began in September 1991 in US Air Force F-15 Eagle fighter squadrons. The US Navy soon followed (in 1993) in its F/A-18 Hornet squadrons.
The eastern counterpart of AMRAAM is the somewhat similar Russian Air Force AA-12 "Adder", sometimes referred to in the West as the "AMRAAMski." Likewise, France began its own air-to-air missile development with the MICA concept that used a common airframe for separate radar-guided and infrared-guided versions.
Operational features summary.
AMRAAM has an all-weather, beyond-visual-range (BVR) capability. It improves the aerial combat capabilities of US and allied aircraft to meet the threat of enemy air-to-air weapons as they existed in 1991. AMRAAM serves as a follow-on to the AIM-7 Sparrow missile series. The new missile is faster, smaller, and lighter, and has improved capabilities against low-altitude targets. It also incorporates a datalink to guide the missile to a point where its active radar turns on and makes terminal intercept of the target. An inertial reference unit and micro-computer system makes the missile less dependent upon the fire-control system of the aircraft.
Once the missile closes in on the target, its active radar guides it to intercept. This feature, known as "fire-and-forget", frees the aircrew from the need to further provide guidance, enabling the aircrew to aim and fire several missiles simultaneously at multiple targets and perform evasive maneuvers while the missiles guide themselves to the targets.
The missile also features the ability to "Home on Jamming," giving it the ability to switch over from active radar homing to passive homing – homing on jamming signals from the target aircraft. Software on board the missile allows it to detect if it is being jammed, and guide on its target using the proper guidance system.
Guidance system overview.
Interception course stage.
AMRAAM uses two-stage guidance when fired at long range. The aircraft passes data to the missile just before launch, giving it information about the location of the target aircraft from the launch point and its direction and speed. The missile uses this information to fly on an interception course to the target using its built in inertial navigation system (INS). This information is generally obtained using the launching aircraft's radar, although it could come from an Infra-red search and track system, from a data link from another fighter aircraft, or from an AWACS aircraft.
After launch, if the firing aircraft or surrogate continues to track the target, periodic updates—such as changes in the target's direction and speed—are sent from the launch aircraft to the missile, allowing the missile to adjust its course, via actuation of the rear fins, so that it is able to close to a self-homing distance where it will be close enough to "catch" the target aircraft in the "basket" (the missile's radar field of view in which it will be able to lock onto the target aircraft, unassisted by the launch aircraft).
Not all armed services using the AMRAAM have elected to purchase the mid-course update option, which limits AMRAAM's effectiveness in some scenarios. The RAF initially opted not to use mid-course update for its Tornado F3 force, only to discover that without it, testing proved the AMRAAM was less effective in beyond visual range (BVR) engagements than the older semi-active radar homing BAE Skyflash weapon—the AIM-120's own radar is necessarily of limited range and power compared to that of the launch aircraft.
Terminal stage and impact.
Once the missile closes to self-homing distance, it turns on its active radar seeker and searches for the target aircraft. If the target is in or near the expected location, the missile will find it and guide itself to the target from this point. If the missile is fired at short range, within visual range (WVR) or the near BVR, it can use its active seeker just after launch, making the missile truly "fire and forget". 
Boresight mode.
Apart from the slave mode, there is a free guidance mode, called boresight. This mode is radar guidance-free, the missile just fires and locks the first thing it sees. This mode can be used for defensive shot, i.e. when the enemy has numerical superiority.
Kill probability and tactics.
General considerations.
The kill probability (P) is determined by several factors, including aspect (head-on interception, side-on or tail-chase), altitude, the speed of the missile and the target, and how hard the target can turn. Typically, if the missile has sufficient energy during the terminal phase, which comes from being launched at close range to the target from an aircraft with an altitude and speed advantage, it will have a good chance of success. This chance drops as the missile is fired at longer ranges as it runs out of overtake speed at long ranges, and if the target can force the missile to turn it might bleed off enough speed that it can no longer chase the target. Operationally, the missile, which was designed for beyond visual range combat, has a P of 59% (17 missiles for 10 kills). The targets included six MiG-29s, a MiG-25, a MiG-23, a Galeb and a US Army Blackhawk that was targeted by mistake.
Variants and upgrades.
Air-to-air missile versions.
There are currently four main variants of AMRAAM, all in service with the United States Air Force, United States Navy, and the United States Marine Corps. The AIM-120A is no longer in production and shares the enlarged wings and fins with the successor AIM-120B. The AIM-120C has smaller "clipped" aerosurfaces to enable internal carriage on the USAF F-22 Raptor. AIM-120B deliveries began in 1994.
The AIM-120C deliveries began in 1996. The C-variant has been steadily upgraded since it was introduced. The AIM-120C-6 contained an improved fuse (Target Detection Device) compared to its predecessor. The AIM-120C-7 development began in 1998 and included improvements in homing and greater range (actual amount of improvement unspecified). It was successfully tested in 2003 and is currently being produced for both domestic and foreign customers. It helped the U.S. Navy replace the F-14 Tomcats with F/A-18E/F Super Hornets – the loss of the F-14's long-range AIM-54 Phoenix missiles (already retired) is offset with a longer-range AMRAAM-D. The lighter weight of the advanced AMRAAM enables an F/A-18E/F pilot greater bring-back weight upon carrier landings.
The AIM-120D is an upgraded version of the AMRAAM with improvements in almost all areas, including 50% greater range (than the already-extended range AIM-120C-7) and better guidance over its entire flight envelope yielding an improved kill probability (P). Raytheon began testing the D model on August 5, 2008, the company reported that an AIM-120D launched from an F/A-18F Super Hornet passed within lethal distance of a QF-4 target drone at the White Sands Missile Range.
The AIM-120D (P3I Phase 4, formerly known as AIM-120C-8) is a development of the AIM-120C with a two-way data link, more accurate navigation using a GPS-enhanced IMU, an expanded no-escape envelope, improved HOBS (High-Angle Off-Boresight) capability, and a 50% increase in range. The AIM-120D is a joint USAF/USN project, and is currently in the testing phase. The USN was scheduled to field it from 2014, and AIM-120D will be carried by all Pacific carrier groups by 2020, although the 2013 sequestration cuts could push back this later date to 2022.
There are also plans for Raytheon to develop a ramjet-powered derivative of the AMRAAM, the Future Medium Range Air-Air Missile (FMRAAM). It is not known whether the FMRAAM will be produced since the target market, the British Ministry of Defence, has chosen the Meteor missile over the FMRAAM for a BVR missile for the Eurofighter Typhoon aircraft.
Raytheon is also working with the Missile Defense Agency to develop the Network Centric Airborne Defense Element (NCADE), an anti-ballistic missile derived from the AIM-120. This weapon will be equipped with a Ramjet engine and an infrared homing seeker derived from the Sidewinder missile. In place of a proximity-fused warhead, the NCADE will use a kinetic energy hit-to-kill vehicle based on the one used in the Navy's RIM-161 Standard Missile 3.
The −120A and −120B models are currently nearing the end of their service life while the −120D variant has just entered full production. AMRAAM was due to be replaced by the USAF, the U.S. Navy, and the U.S. Marine Corps after 2020 by the Joint Dual Role Air Dominance Missile (Next Generation Missile). This was unexpectedly terminated in the 2013 budget plan, and so the future replacement is uncertain.
Ground-launched systems.
Raytheon successfully tested launching AMRAAM missiles from a five-missile carrier on a M1097 Humvee. This system will be known as the SLAMRAAM (Surface Launched (SL) and AMRAAM). They receive their initial guidance information from a radar not mounted on the vehicle. Since the missile is launched without the benefit of an aircraft's speed or high altitude, its range is considerably shorter. Raytheon is currently marketing an SL-AMRAAM EX, purported to be an extended range AMRAAM and bearing a resemblance to the RIM-162 ESSM.
The Norwegian Advanced Surface-to-Air Missile System (NASAMS), developed by Kongsberg Defence & Aerospace, consists of a number of vehicle-pulled launch batteries (containing six AMRAAMs each) along with separate radar trucks and control station vehicles. A more recent version of the program is the "High Mobility Launcher", made in cooperation with Raytheon (Kongsberg Defence & Aerospace was allready a subcontractor on the SLAMRAAM system), where the launch-vehicle is a Humvee (M1152A1 HMMWV), containing four AMRAAMs each.
While still under evaluation for replacement of current US Army assets, the SL-AMRAAM has been deployed in several nations' military forces. The United Arab Emirates (UAE) has requested the purchasing of SL-AMRAAM as part of a larger 7 billion dollar foreign military sales package. The sale would include 288 AMRAAM C-7 missiles.
The US Army has test fired the SL-AMRAAM from a HIMARS artillery rocket launcher as a common launcher, as part of a move to switch to a larger and more survivable launch platform.
The National Guard Association of the United States has sent a letter asking for the United States Senate to stop the Army's plan to drop the SLAMRAAM program because without it there would be no path to modernize the Guard's AN/TWQ-1 Avenger Battalions.
On January 6, 2011, Secretary of Defense Robert Gates announced that the U.S. Army has decided to terminate acquisition of the SLAMRAAM as part of a budget-cutting effort.
On February 22, 2015 Raytheon announced an Extended Range upgrade to NASAMS-launched AMRAAM, calling it AMRAAM-ER.
Operational history.
The AMRAAM was used for the first time on December 27, 1992, when a USAF F-16D shot down an Iraqi MiG-25 that violated the southern no-fly-zone. Interestingly, this missile had been returned from the flight line as defective a day earlier. AMRAAM gained a second victory in January 1993 when an Iraqi MiG-23 was shot down by a USAF F-16C.
The third combat use of the AMRAAM was in 1994, when a Republika Srpska Air Force J-21 Jastreb aircraft was shot down by a USAF F-16C that was patrolling the UN-imposed no-fly zone over Bosnia. In that engagement, at least three other Serbian aircraft were shot down by USAF F-16C fighters using AIM-9 missiles (see Banja Luka incident for more details). At that point, three launches in combat had resulted in three kills, resulting in the AMRAAM's being informally named "slammer" in the second half of the 1990s.
In 1998 and 1999 AMRAAMs were again fired by USAF F-15 fighters at Iraqi aircraft violating the No-Fly-Zone, but this time they failed to hit their targets. During the spring of 1999, AMRAAMs saw their main combat action during Operation Allied Force, the Kosovo bombing campaign. Six Serbian MiG-29 were shot down by NATO (4 USAF F-15C, 1 USAF F-16C, 1 Dutch F-16A MLU), all of them using AIM-120 missiles (the kill by the F-16C may have happened due to friendly fire, from SA-7 MANPAD fired by Serbian infantry).
As of mid 2008, the AIM-120 AMRAAM has shot down nine aircraft (six MiG-29s, one MiG-25, one MiG-23, and one Soko J-21 Jastreb). An AMRAAM was also involved in a friendly fire incident in 1994 when F-15 fighters patrolling Iraq's Northern No-Fly Zone inadvertently shot down a pair of U.S. Army Black Hawk helicopters.
Since 2007 Raytheon has continued to slip on AMRAAM deliveries, leading the USAF to withhold $621 million in 2012 on account of 193 missiles not delivered.
On 23 March 2014, a Turkish Air Force F-16 shot down a Syrian Air Force Mig-23 that was violating air space.
Foreign sales.
Canadair, now Bombardier, had largely helped with the development of the AIM-7 Sparrow and Sparrow II, and assisted to a less extent in the AIM-120 development. Canada had placed an order for 256 AIM-120's, but cancelled half of them after engine ignition problems due to cold weather conditions. The AIM-9X & AIM-7 were ordered as replacements.
In early 1995 South Korea ordered 88 AIM-120A missiles for its KF-16 fleet. In 1997 South Korea ordered additional 737 AIM-120B missiles.
In 2006 Poland received AIM-120C-5 missiles to arm its new F-16C/D Block 52+ fighters.
In early 2006, the Pakistan Air Force (PAF) ordered 500 AIM-120C-5 AMRAAM missiles as part of a $650 million F-16 ammunition deal to equip its F-16C/D Block 50/52+ and F-16A/B Block 15 MLU fighters. The PAF got the first three F-16C/D Block 50/52+ aircraft on July 3, 2010 and first batch of AMRAAMs on July 26, 2010.
In 2007, the United States government agreed to sell 218 AIM-120C-7 missiles to Taiwan as part of a large arms sales package that also included 235 AGM-65G-2 Maverick missiles. Total value of the package, including launchers, maintenance, spare parts, support and training rounds, was estimated at around US$421 million. This supplemented an earlier Taiwanese purchase of 120 AIM-120C-5 missiles a few years ago.
2008 has brought announcements of new or additional sales to Singapore, Finland, Morocco and South Korea; in December 2010 the Swiss government requested 150 AIM-120C-7 missiles. Sales to Finland have stalled, because the manufacturer has not been able to fix a mysterious bug that causes the rocket motors of the missile to fail in cold tests.
Cold weather malfunctions.
Finnish Defence Forces reported on September 3, 2012 that the United States had not delivered any of the AMRAAM anti-aircraft missiles they had ordered due to a mysterious engine malfunction in cold weather. The manufacturer, Raytheon, has not been able to determine the cause of the problem. Colonel Kari Renko, an engineer at the Finnish Air Force, was quoted by Helsingin Sanomat as saying, "The problem involves the rocket engines which have been in use for decades" and that Finland first was told of the problems by the Americans about two years ago. The reason for the malfunction has been determined to be a change in the chemical formula of the rocket propellant to comply with new environmental regulations. The change caused the supplier of AMRAAM rocket motors, Alliant Techsystems, to produce motors that were unreliable, especially in cold conditions where aircraft carrying them would fly. ATK has been unable to find a solution, and no new AMRAAM missiles had been delivered to the USAF since 2010 as a result. In late 2012, Raytheon solved the problem by selecting Norwegian ammunition manufacturer Nammo Raufoss to be their new supplier of AMRAAM rocket motors.

</doc>
<doc id="3149" url="https://en.wikipedia.org/wiki?curid=3149" title="AGM-88 HARM">
AGM-88 HARM

The AGM-88 High-speed Anti-Radiation Missile (HARM) is a tactical, air-to-surface missile designed to home in on electronic transmissions coming from surface-to-air radar systems. It was originally developed by Texas Instruments as a replacement for the AGM-45 Shrike and AGM-78 Standard ARM system. Production was later taken over by Raytheon Corporation when it purchased the defense production business of Texas Instruments.
Description.
The AGM-88 can detect, attack and destroy a radar antenna or transmitter with minimal aircrew input. The proportional guidance system that homes in on enemy radar emissions has a fixed antenna and seeker head in the missile's nose. A smokeless, solid-propellant, booster-sustainer rocket motor propels the missile at speeds over Mach 2. HARM, a U.S. Navy-led program, was initially integrated onto the A-6E, A-7 and F/A-18 and later onto the EA-6B. RDT&E for use on the F-14 was begun, but not completed. The USAF introduced HARM on the F-4G Wild Weasel and later on specialized F-16s equipped with the HARM Targeting System (HTS).
History.
Deployment.
The HARM missile was approved for full production in March 1983, obtained initial operating capability (IOC) on the A-7E Corsair II in late 1983 and then deployed in late 1985 with VA-72 and VA-46 aboard the aircraft carrier USS "America". In 1986 the first successful firing of the HARM from an EA-6B was performed by VAQ-131. It was soon used in combat—in March 1986 against a Libyan SA-5 site in the Gulf of Sidra, and then Operation Eldorado Canyon in April. HARM was used extensively by the United States Navy and the United States Air Force for Operation Desert Storm during the Gulf War of 1991.
During the Gulf War, the HARM was involved in a friendly fire incident when the pilot of an F-4G Wild Weasel escorting a B-52 bomber mistook the latter's tail gun radar for an Iraqi AAA site. (This was after the tail gunner of the B-52 had targeted the F-4G, mistaking it for an Iraqi MiG.) The F-4 pilot launched the missile and then saw that the target was the B-52, which was hit. It survived with shrapnel damage to the tail and no casualties. The B-52 was subsequently renamed "In HARM's Way".
"Magnum" is spoken over the radio to announce the launch of an AGM-88. During the Gulf War, if an aircraft was illuminated by enemy radar a bogus "Magnum" call on the radio was often enough to convince the operators to power down.
This technique would also be employed in Serbia during air operations in 1999.
In 2013 President Obama offered the AGM-88 to Israel for the first time.
AGM-88E AARGM.
The newest upgrade, the "AGM-88E Advanced Anti-Radiation Guided Missile (AARGM)," features the latest software, enhanced capabilities intended to counter radar shutdown and passive radar using an additional active millimeter wave seeker. It was released in November 2010 and is a joint venture by the US Department of Defense and the Italian Ministry of Defense and is produced by Alliant Techsystems.
In November 2005, the Italian Ministry of Defense and the US Department of Defense signed a Memorandum of Agreement on the joint development of the AGM-88E AARGM missile. Italy was providing $20 million of developmental funding as well as several millions worth of material, equipment and related services. The Italian Air Force was expected to procure up to 250 missiles for its Tornado ECR aircraft. Thus flight test program was set to integrate the AARGM onto Tornado ECR's weapon system.<br>
The Navy demonstrated the AARGM's capability during Initial Operational Test and Evaluation (IOT&E) in spring 2012 with live firing of 12 missiles. Aircrew and maintenance training with live missiles was completed in June.<br>
Lot 1<br>
"ATK Defense Electronics Systems in Woodland Hills, CA receives a $70.6 million firm-fixed-price contract for AARGM Full Rate Production Lot 1. ATK will convert 53 AGM-88B HARM missiles provided by the US government, turning them into 49 AGM-88E AARGM All-Up Rounds for the US Navy, and 4 missiles for Italy. ATK will also provide 23 AGM-88E Captive Air Training Missile systems for the US Navy, which have seekers but no rocket motors, along with all related supplies and services.<br>
Work will be performed in Woodland Hills, CA (90%); various locations in Italy (8.1%); Ridgecrest, CA (1.7%), and Clearwater, FL (0.2%), and is expected to be complete in December 2012. This contract was not competitively procured pursuant to FAR 6.302-1. This contract combines purchases for the Navy ($65.0M / 92.06%) and the Government of Italy ($5.6M / 7.94%). US Naval Air Systems Command, Patuxent River, MD manages the contract (N00019-12-C-0113)"<br>
Lot 2<br>
The Navy authorized Full-Rate Production (FRP) of the AARGM in August 2012, with 72 missiles for the Navy and nine for the Italian Air Force to be delivered in 2013. A U.S. Marine Corps F/A-18 Hornet squadron will be the first forward-deployed unit with the AGM-88E.<br>
Lot 4<br>
In September 2013, ATK delivered the 100th AARGM to the U.S. Navy. The AGM-88E program is on schedule and on budget, with Full Operational Capability (FOC) planned for September 2014.
On September 3, 2015 U.S. Department of Defence noticed order to Alliant Techsystems Operations LLC, Defense Electronic Systems, California, for a $118,724,146 firm-fixed-price contract, to Full Rate Production Lot 4 procurement of the Advanced Anti-Radiation Guided Missile (AARGM) services for the U.S. Navy and the Governments of Australia and Italy, to include conversion of AGM-88B High-Speed Anti-Radiation Missiles to 142 AGM-88E All-Up-Rounds and 12 Captive Air Training Missiles, to include related supplies.
It will be initially integrated onto the F/A-18C/D, F/A-18E/F, EA-18G, and Tornado ECR aircraft and later on the F-35.
The Navy's FY 2016 budget included funding for an extended range AARGM-ER that utilizes the existing guidance system and warhead of the AGM-88E with a solid integrated rocket-ramjet for double the range. Development funding will last to 2020.
In September 2015, the AGM-88E successfully hit a mobile ship target in a live-fire test, demonstrating the missile's ability to use anti-radiation homing and millimeter wave radar to detect, identify, locate, and engage moving targets.

</doc>
<doc id="3151" url="https://en.wikipedia.org/wiki?curid=3151" title="AGM-65 Maverick">
AGM-65 Maverick

The AGM-65 Maverick is an air-to-ground tactical missile (AGM) designed for close air support. The most widely produced precision-guided missile in the Western world, it is effective against a wide range of tactical targets, including armor, air defenses, ships, ground transportation and fuel storage facilities. Originally designed and built by Hughes Missile Systems, development of the AGM-65 spanned from 1966 to 1972, after which it entered service with the United States Air Force in August 1972. Since then, it has been exported to more than 30 countries and is certified on 25 aircraft. The Maverick served during the Vietnam, Yom Kippur, Iran–Iraq and Gulf Wars, along with other smaller conflicts, destroying enemy forces and installations with varying degrees of success.
Since its introduction into service, numerous Maverick versions had been designed and produced, using electro-optical, laser, charge-coupled device and infra-red guidance systems. The AGM-65 has two types of warhead: one has a contact fuze in the nose, the other has a heavyweight warhead fitted with a delayed-action fuze, which penetrates the target with its kinetic energy before detonating. The Maverick shares the same configuration as Hughes's AIM-4 Falcon and AIM-54 Phoenix, and measures more than in length and in diameter.
Development.
The Maverick's development history began in 1965, when the United States Air Force (USAF) began a program to develop a replacement to the AGM-12 Bullpup. With a range of , the radio-guided Bullpup was introduced in 1959 and was considered a "silver bullet" by operators. However, the launch aircraft was required to fly straight towards the target during the missile's flight instead of performing evasive maneuvers, thus risking the crew. Even when it hit, the small warhead was only useful against small targets like bunkers, when used against larger targets like the Thanh Hóa Bridge it did little other than char the structure. The USAF began a series of projects to replace Bullpup, both larger versions of Bullpup, models C and D, as well as a series of Bullpup adaptations offering fire-and-forget guidance. Among the later were the AGM-83 Bulldog, AGM-79 Blue Eye. and AGM-80 Viper.
From 1966 to 1968, Hughes Missile Systems Division and Rockwell competed for the contract to build an entirely new fire-and-forget missile with far greater range performance than any of the Bullpup versions. Each were allocated $3 million for preliminary design and engineering work of the Maverick in 1966. In 1968, Hughes emerged with the $95 million contract for further development and testing of the missile; at the same time, contract options called for 17,000 missiles to be procured. Hughes conducted a smooth development of the AGM-65 Maverick, with the first unguided test launch from a F-4 on 18 September 1969, with the first guided test on 18 December successfully performing a direct hit on a M41 tank target at the Air Force Missile Development Center at Holloman Air Force Base, New Mexico.
In July 1971, the USAF and Hughes signed a $69.9 million contract for 2,000 missiles, the first of which was delivered in 1972. Although early operational results were favorable, military planners predicted that the Maverick would fare less successfully in the hazy conditions of Central Europe, where it would have been used against Warsaw Pact forces. As such, development of the AGM-65B began in 1975 before it was delivered during the late 1970s. When production of the AGM-65A/B was ended in 1978, more than 35,000 missiles had been built.
More versions of the Maverick appeared, among which was the laser-guided AGM-65C/E. Development of the AGM-65C started in 1978 by Rockwell, who built a number of development missiles for the USAF. Due to high cost, the version was not procured by the USAF, and instead entered service with the United States Marine Corps (USMC) as the AGM-65E. 
Another major development was the AGM-65D, which employed an imaging infrared (IIR) seeker. By imaging on radiated heat, the IIR is all-weather operable as well as showing improved performance in acquiring and tracking the hot engines, such as in tanks and trucks, that were to be one of its major missions.. The seekerhead mechanically scanned the scene over a nitrogen-cooled 4-by-4 pixel array using a series of mirrored facets machined into the inner surface of the ring-shaped main gyroscope. The five-year development period of the AGM-65D started in 1977 and ended with the first delivery to the USAF in October 1983. The version received initial operating capability in February 1986.
The AGM-65F is a hybrid Maverick combining the AGM-65D's IIR seeker and warhead and propulsion components of the AGM-65E. Deployed by the United States Navy (USN), the AGM-65F is optimized for maritime strike roles. The first AGM-65F launch from the P-3C took place in 1989, and in 1994, the USN awarded Unisys a contract to integrate the version with the P-3C. Meanwhile, Hughes produced the AGM-65G, which essentially has the same guidance system as the D, with some software modifications that track larger targets, coupled with a shaped-charge warhead.
In the mid-1990s to early 2000s, there were several ideas of enhancing the Maverick's potential. Among them was the stillborn plan to incorporate the Maverick millimeter wave active radar homing, which can determine the exact shape of a target. Another study called "Longhorn Project" was conducted by Hughes, and later Raytheon following the absorption of Hughes into Raytheon, looked a Maverick version equipped with turbojet engines instead of rocket motors. The "Maverick ER", as it was dubbed, would have a "significant increase in range" compared to the Maverick's current range of . The proposal was abandoned, but if the Maverick ER had entered production, it would have replaced the AGM-119B Penguin carried on the MH-60R.
The most modern versions of the Maverick are the AGM-65H/K, which were in production . The AGM-65H was developed by coupling the AGM-65B with a charge-coupled device (CCD) seeker optimized for desert operations and which has three times the range of the original TV-sensor; a parallel USN program aimed at rebuilding AGM-65Fs with newer CCD seekers resulted in the AGM-65J. The AGM-65K, meanwhile, was developed by replacing the AGM-65G's IR guidance system with an electro-optical television guidance system.
Design.
The Maverick has a modular design construction, allowing a different combination of the guidance package and warhead to be attached to the rocket motor section to produce a different weapon. It has long-chord delta wings and a cylindrical body, reminiscent of the AIM-4 Falcon and the AIM-54 Phoenix.
Different models of the AGM-65 have used electro-optical, laser, and infra-red guidance systems. The AGM-65 has two types of warheads: one has a contact fuze in the nose, the other has a heavyweight warhead fitted with a delayed-action fuze, which penetrates the target with its kinetic energy before detonating. The latter is most effective against large, hard targets. The propulsion system for both types is a solid-fuel rocket motor behind the warhead.
The Maverick missile is unable to lock onto targets on its own; it has to be given input by the pilot or Weapon Systems Officer (WSO) after which it follows the path to the target autonomously, allowing the WSO to fire and forget. In an A-10 Thunderbolt, for example, the video fed from the seeker head is relayed to a screen in the cockpit, where the pilot can check the locked target of the missile before launch. A crosshair on the head-up display is shifted by the pilot to set the approximate target while the missile will then automatically recognize and lock on to the target. Once the missile is launched, it requires no further assistance from the launch vehicle and tracks its target automatically. This fire-and-forget property is not shared by the E version that uses semi-active laser homing.
Deployment.
The Maverick was declared operational on 30 August 1972 with the F-4D/Es and A-7s initially cleared for the type; the missile made its combat debut four months later with the USAF in the Vietnam War. During the Yom Kippur War in October 1973, the Israelis used Mavericks to destroy and disable enemy vehicles. Deployment of early versions of the Mavericks in these two wars were successful due to the favorable atmospheric conditions that suited the electro-optical TV seeker. Ninety-nine missiles were fired during the two wars, eighty-four of which were successful.
In June 1975, during a border confrontation, Iranian troops fired twelve Mavericks, all successful, at Iraqi tanks. Five years later, during Operation "Pearl" as part of the Iran–Iraq War, Iranian F-4s used Mavericks to sink three OSA II missile boats and four P-6 combat ships.
Due to weapons embargoes, Iran had to equip its AH-1J SeaCobra helicopters with AGM-65 Maverick missiles and used them with some success in various operations such as Operation "Undeniable Victory" whereas Iranian AH-1J's fired 11 Mavericks.
In August 1990, Iraq invaded Kuwait. In early 1991, the US-led Coalition executed Operation "Desert Storm" during which Mavericks played a crucial role in the ousting of Iraqi forces from Kuwait. Employed by F-15E Strike Eagles, F-18 Hornets, AV-8B Harriers, F-16 Fighting Falcons and A-10 Thunderbolts, but used mainly by the last two, more than 5,000 Mavericks were deployed to attack armored targets. The most-used variant by the USAF was the IIR-guided AGM-65D. The reported hit rate by USAF Mavericks was 80–90%, while for the USMC it was 60%. The Maverick was used again in Iraq during the 2003 Iraq War, during which 918 were fired.
The first time the Maverick were fired from a Lockheed P-3 Orion at a hostile vessel was when the USN and coalition units came to the aid of Libyan rebels to engage the Libyan Coast Guard vessel "Vittoria" in the port of Misrata, Libya, during the late evening of 28 March 2011. "Vittoria" was engaged and fired upon by a USN P-3C Maritime Patrol aircraft with AGM-65 Maverick missiles.
Launch platforms.
United States.
LAU-117 Maverick launchers have been used on USN, USAF, and USMC aircraft:
Export.
The Maverick has been exported to at least 30 countries:

</doc>
<doc id="3152" url="https://en.wikipedia.org/wiki?curid=3152" title="AIM-54 Phoenix">
AIM-54 Phoenix

The AIM-54 Phoenix is a radar-guided, long-range air-to-air missile (AAM), carried in clusters of up to six missiles on the Grumman F-14 Tomcat, its only launch platform. The Phoenix was the United States' only long-range air-to-air missile. The combination of Phoenix missile and the AN/AWG-9 guidance radar was the first aerial weapons system that could simultaneously engage multiple targets. Both the missile and the aircraft were used by the United States Navy and are now retired, the AIM-54 Phoenix in 2004 and the F-14 in 2006. They were replaced by the shorter-range AIM-120 AMRAAM, employed on the F/A-18 Hornet and F/A-18E/F Super Hornet. Following the retirement of the F-14 by the U.S. Navy, the weapon's only current operator is the Islamic Republic of Iran Air Force. Brevity code "Fox Three" was used when firing the AIM-54.
Development.
Background.
Since 1951, the Navy faced the initial threat from the Tupolev Tu-4K 'Bull' carrying anti-ship missiles. Eventually, during the height of the Cold War, the threat would have expanded into regimental-size raids of Tu-16 Badger and Tu-22M Backfire bombers equipped with low-flying, long-range, high-speed, nuclear-armed cruise missiles and considerable electronic countermeasures (ECM) of various types.
The Navy would require a long-range, long-endurance interceptor aircraft to defend carrier battle groups against this threat. The proposed F6D Missileer was intended to fulfill this mission and oppose the attack far from the fleet it was defending. The weapon needed for interceptor aircraft, the Bendix AAM-N-10 Eagle, was to be an air-to-air missile of unprecedented range when compared to contemporary AIM-7 Sparrow missiles. It would work together with Westinghouse AN/APQ-81 radar. The Missileer project was cancelled in December 1960.
AIM-54.
In the early 1960s, the U.S. Navy made the next interceptor attempt with the F-111B, and they needed a new missile design. At the same time, the USAF canceled the projects for their land-based high-speed interceptor aircraft, the North American XF-108 Rapier and the Lockheed YF-12, and left the capable AIM-47 Falcon missile at a quite advanced stage of development, but with no effective launch platform.
The AIM-54 Phoenix, developed for the F-111B fleet air defense fighter, had an airframe with four cruciform fins that was a scaled-up version of the AIM-47. One characteristic of the Missileer ancestry was that the radar sent it mid-course corrections, which allowed the fire control system to "loft" the missile up over the target into thinner air where it had better range.
The F-111B was canceled in 1968. Its weapons system, the AIM-54 working with the AWG-9 radar, migrated to the new U.S. Navy fighter project, the VFX, which would later become the F-14 Tomcat.
In 1977, development of a significantly improved Phoenix version, the AIM-54C, was developed to better counter projected threats from tactical anti-naval aircraft and cruise missiles, and its final upgrade included a re-programmable memory capability to keep pace with emerging ECM.
Usage in comparison to other weapon systems.
The AIM-54/AWG-9 combination had multiple track capability (up to 24 targets) and launch (up to 6 Phoenixes can be launched nearly simultaneously); the large missile is equipped with a conventional warhead.
On the F-14, four missiles can be carried under the fuselage tunnel attached to special aerodynamic pallets, plus two under glove stations. A full load of 6 Phoenix missiles and the unique launch rails weighs in at over , about twice the weight of Sparrows, so it was more common to carry a mixed load of 4 Phoenix, 2 Sparrow, and 2 Sidewinder missiles.
Most other US aircraft relied on the smaller, semi-active medium range AIM-7 Sparrow. Semi-active guidance meant the aircraft no longer had a search capability while supporting the launched Sparrow, reducing situational awareness.
The Tomcat's radar could track up to 24 targets in track-while-scan mode, with the AWG-9 selecting up to 6 potential targets for the missiles. The pilot or radar intercept officer (RIO) could then launch the Phoenix missiles once parameters were met. The large tactical information display (TID) in the RIO's cockpit gave information to the aircrew (the pilot had the ability to monitor the RIO's display) and the radar could continually search and track multiple targets after Phoenix missiles were launched, thereby maintaining situational awareness of the battlespace.
The Link-4 datalink allowed US Navy Tomcats to share information with the E-2C Hawkeye AEW aircraft. During Desert Shield in 1990, the Link-4A was introduced; this allowed the Tomcats to have a fighter-to-fighter datalink capability, further enhancing overall situational awareness. The F-14D entered service with the JTIDS that brought the even better Link-16 datalink "picture" to the cockpit.
Active guidance.
The Phoenix has several guidance modes and achieves its longest range by using mid-course updates from the F-14A/B AWG-9 radar (APG-71 radar in the F-14D) as it climbs to cruise between and at close to Mach 5. Phoenix uses this high altitude to gain gravitational potential energy, which is later converted into kinetic energy as the missile dives at high velocity towards its target. At around from the target, the missile activates its own radar to provide terminal guidance. Minimum engagement range for the Phoenix is around and active homing would initiate upon launch.
The AIM-54 Phoenix was retired from USN service on September 30, 2004. F-14 Tomcats were retired on September 22, 2006. They were replaced by shorter-range AIM-120 AMRAAMs, employed on the F/A-18E/F Super Hornet.
Service history.
U.S. combat experience.
Despite the much-vaunted capabilities, the Phoenix was rarely used in combat, with only two confirmed launches and no confirmed targets destroyed in US Navy service, though a large number of kills were claimed by Iranian F-14s during the Iran–Iraq War. The USAF F-15 Eagle had responsibility for overland combat air patrol duties in Operation Desert Storm in 1991, primarily because of the onboard F-15 IFF capabilities. The Tomcat did not have the requisite IFF capability mandated by the JFACC to satisfy the rules of engagement to utilize the Phoenix capability at beyond visual range. The AIM-54 was not adopted by any foreign nation besides Iran, or any other US armed service, and was not used on any aircraft other than the F-14.
Iranian combat experience.
There is very little information available regarding Iran's use of its 79 F-14A Tomcats (delivered prior to 1979) in most western outlets; the exception being a book released by Osprey Publishing titled "Iranian F-14 Tomcats in Combat" by Tom Cooper and Farzad Bishop. Most of the research contained in the book was based on pilot interviews. Reports vary on the use of the 285 missiles supplied to Iran, during the Iran–Iraq War, 1980–88.
According to Cooper, the Islamic Republic of Iran Air Force was able to keep its F-14 fighters and AIM-54 missiles in regular use during the entire Iran–Iraq War, though periodic lack of spares grounded large parts of the fleet at times. At worst, during late 1987, the stock of AIM-54 missiles was at its lowest, with less than 50 operational missiles available. The missiles needed fresh thermal batteries that could only be purchased from the US. Iran found a clandestine buyer that supplied it with batteries—though those did cost up to US$10,000 each. Iran did receive spares and parts for both the F-14s and AIM-54s from various sources during the Iran–Iraq War, and has received more spares after the conflict. Iran started a heavy industrial program to build spares for the planes and missiles, and although there are claims that it no longer relies on outside sources to keep its F-14s and AIM-54s operational, there is evidence that Iran continues to procure parts clandestinely.
Both the F-14 Tomcat and AIM-54 Phoenix missile continue in the service of the Islamic Republic of Iran Air Force, although the operational abilities of these aircraft and the missiles are questionable, since the US refused to supply spare parts and maintenance after the 1979 revolution, except for a brief period during the Iran-Contra Affair.
Iran claimed to be working on building an equivalent missile and in 2013 unveiled the Fakour-90, an upgraded and reverse-engineered version of the Phoenix.
There were also test, evaluation, ground training, and captive air training versions of the missile; designated ATM-54, AEM-54, DATM-54A, and CATM-54. The flight versions had A and C versions. The DATM-54 was not made in a C version as there was no change in the ground handling characteristics.
Characteristics.
The following is a list of AIM-54 Phoenix specifications:

</doc>
<doc id="3155" url="https://en.wikipedia.org/wiki?curid=3155" title="Lockheed AC-130">
Lockheed AC-130

The Lockheed AC-130 gunship is a heavily armed, long-endurance ground-attack variant of the C-130 Hercules transport fixed-wing aircraft. It carries a wide array of anti-ground oriented weapons that are integrated with sophisticated sensors, navigation, and fire-control systems. Unlike other military fixed-wing aircraft, the AC-130 relies on visual targeting. Because its large profile and low operating altitudes (around 7,000 ft) make it an easy target, it usually flies close air support missions at night.
The airframe is manufactured by Lockheed Martin, while Boeing is responsible for the conversion into a gunship and for aircraft support. Developed during the Vietnam War as 'Project Gunship II', the AC-130 replaced the Douglas AC-47 Spooky, or 'Gunship I'. The sole operator is the United States Air Force, which uses the AC-130U Spooky and AC-130W Stinger II variants for close air support, air interdiction, and force protection, with the AC-130J Ghostrider in development. Close air support roles include supporting ground troops, escorting convoys, and urban operations. Air interdiction missions are conducted against planned targets and targets of opportunity. Force protection missions include defending air bases and other facilities. AC-130Us are based at Hurlburt Field, Florida, while AC-130Ws are based at Cannon AFB, New Mexico; gunships can be deployed worldwide. The squadrons are part of the Air Force Special Operations Command (AFSOC), a component of the United States Special Operations Command (SOCOM).
The AC-130 has a non-pressurised cabin, with the weaponry mounted to fire from the port side of the fuselage. During an attack, the gunship performs a pylon turn, flying in a large circle around the target, therefore being able to fire at it for far longer than in a conventional strafing attack. The AC-130H Spectre was armed with two M61 Vulcan cannons, one Bofors 40 mm autocannon, and one M102 cannon; after 1994, the cannons were removed for most missions. The upgraded AC-130U Spooky has a single GAU-12 Equalizer in place of the Spectre's twin cannons, an improved fire control system, and increased ammunition capacity. New AC-130Js based on the MC-130J Combat Shadow II special operations tanker were planned . The AC-130W is armed with one 30 mm Bushmaster cannon, AGM-176 Griffin missiles, and GBU-39 Small Diameter Bombs.
Development.
Origins.
During the Vietnam War, the C-130 Hercules was selected to replace the Douglas AC-47 Spooky gunship (Project Gunship I) in order to improve mission endurance and increase capacity to carry munitions. Capable of flying faster than helicopters and at high altitudes with excellent loiter time, the use of the pylon turn allowed the AC-47 to deliver continuous accurate fire to a single point on the ground.
In 1967, JC-130A USAF 54-1626 was selected for conversion into the prototype AC-130A gunship (Project Gunship II). The modifications were done at Wright-Patterson Air Force Base by the Aeronautical Systems Division. A direct view night vision telescope was installed in the forward door, an early forward looking infrared (FLIR) in the forward part of the left wheel well, and Gatling guns fixed facing down and aft along the left side. The analog fire control computer prototype was handcrafted by RAF Wing Commander Tom Pinkerton at the USAF Avionics Laboratory at Wright-Patterson AFB. Flight testing of the prototype was performed primarily at Eglin Air Force Base, followed by further testing and modifications. By September 1967, the aircraft was certified ready for combat testing and was flown to Nha Trang Air Base, South Vietnam for a 90-day test program. The AC-130 was later supplemented by the AC-119 Shadow (Project Gunship III), which later proved to be underpowered.
Seven more warplanes were converted to the "Plain Jane" configuration like the AC-130 prototype in 1968, and one aircraft received the "Surprise Package" equipment in 1969. Surprise Package included the latest 20 mm rotary cannons and 40 mm Bofors cannon but no 7.62 mm close support armament. Surprise Package served as a test bed for the avionic systems and armament for the AC-130E.
In 1970, ten more AC-130As were acquired under the "Pave Pronto" project. In the summer of 1971, Surprise Package equipped AC-130s were converted to the Pave Pronto configuration and assumed their new nickname 'Thor'. Conversion of C-130Es into AC-130Es for the "PAVE Spectre" project followed.
Regardless of their project names the aircraft were more commonly referred to by the squadron's call sign 'Spectre'.
Recent and planned upgrades.
In 2007, Air Force Special Operations Command (AFSOC) initiated a program to upgrade the armament of AC-130s. The test program planned for the 25 mm GAU-12/U and 40 mm Bofors cannon on the AC-130U gunships to be replaced with two 30 mm Mk 44 Bushmaster II cannons. In 2007, the Air Force modified four AC-130U gunships as test platforms for the Bushmasters. These were referred to as AC-130U Plus 4 or AC-130U+4. AFSOC, however, canceled its plans to install the new cannons on its fleet of AC-130Us. It has since removed the guns and re-installed the original 40 mm and 25 mm cannons and returned the planes to combat duty. Brigadier General Bradley A. Heithold, AFSOC's director of plans, programs, requirements, and assessments, said on 11 August 2008 that the effort was canceled because of problems with the Bushmaster's accuracy in tests "at the altitude we were employing it". There were also schedule considerations that drove the decision, he said.
There were also plans to possibly replace the 105 mm cannon with a breech-loading 120 mm M120 mortar, and to give the AC-130 a standoff capability using either the AGM-114 Hellfire missile, the Advanced Precision Kill Weapon System (based on the Hydra 70 rocket), or the Viper Strike glide bomb.
In 2010, the Air Force awarded L-3 Communications a $61 million contract to add precision strike packages to eight MC-130W Combat Spear special-mission aircraft to give them a gunship-like attack capability, such-equipped MC-130Ws are known as "Dragon Spears". Air Force Special Operations Command is arming these aircraft to relieve the high operational demands on AC-130 gunships until new AC-130Js enter service. The MC-130W Dragon Spear was renamed the AC-130W Stinger II in 2011.
The Air Force launched an initiative in 2011 to acquire 16 new gunships based on new-built MC-130J Combat Shadow II special operations tankers outfitted with a "precision strike package" to give them an attack capability, requesting $1.6 billion from Fiscal Year 2011 through 2015. This would increase the size of the gunship fleet to 33 aircraft, a net increase of eight after the planned retirement of eight aging AC-130Hs. The first aircraft would be bought in Fiscal 2012, followed by two in Fiscal 2013, five in Fiscal 2014, and the final eight in Fiscal 2015. The decision to retain the C-130 came after funding for 16 C-27Js was removed from the fiscal 2010 budget. The AC-130J will follow the path of the Dragon Spear program, along similar lines to the USMC Harvest HAWK program. On 9 January 2013, the Air Force began converting the first MC-130J Combat Shadow II into an AC-130J Ghostrider and delivered it to AFSOC on 29 July 2015. The first AC-130J is to enter service in 2017.
The Air Force decided to add a 105 mm cannon to the AC-130J in addition to the 30 mm cannon and smart bombs, the shells being more accurate and cheaper than dropping SDBs. AFSOC is interested in adding a directed energy weapon to the AC-130J by 2020, similar to the previous Advanced Tactical Laser program. It is to produce a beam of up to 120 kW, or potentially even 180-200 kW, weigh about , defensively destroy anti-aircraft missiles, and offensively engage communications towers, boats, cars, and aircraft. However, laser armament may only be installed on a few aircraft rather than the entire AC-130J fleet; the laser would need to replace one of the plane's guns. Other potential additions include an active denial system to perform airborne crowd control, and small unmanned aerial vehicles from the common launch tubes to provide remote video feed and coordinates to weapons operators through cloud cover. Called the Tactical Off-board Sensor, the expendable drones would fly along a preprogrammed orbit, with a crewman only watching the feed and directing its camera. They can be used to verify targets the aircraft can't see itself because of bad weather or standing off from air defenses, and avoid collateral damage from human misidentification. The Air Force is also interested in acquiring a glide bomb that can be launched from the common launch tubes capable of hitting ground vehicles traveling as fast as 120 km/h (70 mph) while above ; it could be ready for combat deployment by mid-2017.
Future.
By 2018, AC-130 gunships will have been providing close air support for special operators for 50 years. Although the aircraft have been kept relevant through constant upgrades to their weaponry, sensor packages, and countermeasures, they are not expected to be survivable in future non-permissive environments due to their high signatures and low airspeeds. Military analysts, such as the Center for Strategic and Budgetary Assessments, have suggested that AFSOC invest in more advanced technologies to fill the role to operate in future contested combat zones, including a mix of low-cost disposable unmanned and stealthy strike aircraft.
Design.
Overview.
The AC-130 is a heavily armed long-endurance aircraft carrying an array of anti-ground oriented weapons that are integrated with sophisticated sensors, navigation, and fire-control systems. It is capable of delivering precision firepower or area-saturation fire over a target area over a long period of time, at night or in adverse weather. The sensor suite consists of a television sensor, infrared sensor, and radar. These sensors allow the gunship to visually or electronically identify friendly ground forces and targets in most weather conditions.
The AC-130U is equipped with the AN/APQ-180, a synthetic aperture radar for long-range target detection and identification. The gunship's navigational devices include inertial navigation systems and a Global Positioning System. The AC-130U employs technologies developed in the 1990s which allow it to attack two targets simultaneously. It has twice the munitions capacity of the AC-130H. Although the AC-130U conducts some operations in daylight, most of its combat missions are conducted at night. The AC-130H's unit cost is US$132.4 million, and the AC-130U's cost is US$190 million (fiscal 2001 dollars).
Upgrades.
During the Vietnam era, the various AC-130 versions following the Pave Pronto modifications were equipped with a magnetic anomaly detector (MAD) system called the Black Crow (AN/ASD-5), a highly sensitive passive device with a phased-array antenna located in the left-front nose radome that could pick up localized deviations in Earth's magnetic field that is normally used to detect submerged submarines. The Black Crow system was slaved into the targeting computers of the AC-130A/E/H, enabling the detection of the unshielded ignition coils of North Vietnamese trucks hidden under dense jungle foliage, typical along the Ho Chi Minh trail. It could also detect hand-held transmitter signals of air controllers on the ground to identify and locate targets.
The PGM-38/U enhanced 25 mm high explosive incendiary (HEI) round was created to expand the AC-130U gunships' mission in standoff range and survivability for its 25 mm GAU-12/U gun system. This round is a combination of the existing PGU-25 HEI and a M758 fuze designated as FMU-151/B to meet the MIL-STD-1316. The FMU-151 has an improved arming delay with multi-sensitive range.
Operational history.
Vietnam War.
The AC-130 gunship first arrived in South Vietnam on 21 September 1967 under the Gunship II program and began combat operations over Laos and South Vietnam that year. In June 1968, AC-130s were deployed to Tan Son Nhut AB near Saigon for support against the Tet Offensive. By 30 October 1968, enough AC-130 Gunship IIs arrived to form a squadron, the 16th Special Operations Squadron (SOS) of the 8th Tactical Fighter Wing (TFW), at Ubon Royal Thai Air Force Base, Thailand. It was at this time that the C-130A gunship was designated the AC-130A.
On 18 August 1968, an AC-130 gunship flying an armed reconnaissance mission in Vietnam's III Corps was diverted to support the Katum Special Forces Camp. The ground commander quickly assessed the accurate fire and capabilities of this weapon system and called for fire on his own perimeter when the Viet Cong attempted to bridge the wire on the west side of his position.
By December 1968, most AC-130s flew under F-4 Phantom II escort (to protect the gunship against heavy and concentrated AAA fire) from the 497th Tactical Fighter Squadron, normally three Phantoms per Gunship. On 24 May 1969, the first Spectre gunship was lost to enemy fire.
In late 1969, under code name "Surprise Package", 56-0490 arrived with solid-state laser-illuminated low-light-level-TV with a companion YAG laser designator, an improved forward looking infrared (FLIR) sensor, video recording for TV and FLIR, an inertial navigation system, and a prototype digital fire control computer. The remaining AC-130s were refitted with upgraded similar equipment in the summer of 1970, and then redeployed to Ubon RTAFB. On 25 October 1971, the first "Cadillac" gunship, the AC-130E arrived in Vietnam. On 17 February 1972, the first 105 mm cannon arrived for service with Spectre and was installed on Gunship 570. It was used from mid-February until the aircraft received battle damage to its right flap. The cannon was switched to Gunship 571 and was used until 30 March when the aircraft was shot down.
On 28 January 1973, the Vietnam peace accord went into effect, marking the end of Spectre operations in Vietnam. Spectre was still needed and active in the region, supporting operations in Laos and Cambodia. On 22 February 1973, American offensive operations in Laos ended and the gunships became totally committed to operations in the Cambodian conflict.
On 12 April 1975, the Khmer Rouge were threatening the capital of Phnom Penh and AC-130s were called on to help in Operation Eagle Pull, the final evacuation of American and allied officials from Phnom Penh before it fell to the communists. The AC-130 was also over Saigon on 30 April 1975 to protect the final evacuation in Operation Frequent Wind. Spectres were also called in when the SS Mayaguez was seized, on the open sea, by Khmer Rouge soldiers and sailors on 15 May 1975.
Six AC-130s and 52 air crew members were lost during the war. AC-130s destroyed more than 10,000 trucks and participated in many crucial close air support missions in Vietnam.
Cold War and later action.
With the conclusion of hostilities in Southeast Asia in the mid-1970s, the AC-130H became the sole gunship in the regular Air Force, home based at Hurlburt Field, Florida, while the AC-130A fleet was transferred to the Air Force Reserve's 919th Tactical Airlift Group (919 TAG) at Eglin AFB Auxiliary Field #3/Duke Field, Florida. With the transition to the AC-130A, the 919 TAG was then redesignated as the 919th Special Operations Group (919 SOG).
In the late 1970s, when the AC-130H fleet was first being modified for in-flight refueling capability, a demonstration mission was planned and flown from Hurlburt Field, Florida, non-stop, to conduct a 2-hour live-fire mission over Empire Firing Range in the Republic of Panama, then return home. This 13-hour mission with two in-flight refuelings from KC-135 tankers proved the validity of flying long-range missions outside the contiguous United States to attack targets then return to home base without intermediate stops.
AC-130s from both the 4th and 16th Special Operations Squadrons have been deployed in nearly every conflict the United States has been involved in, officially and unofficially, since the end of the Vietnam War.
In July 1979, AC-130H crews deployed to Howard Air Force Base, Panama, as a precaution against possible hostile actions against American personnel during the Nicaraguan Revolution. New time aloft and non-stop distance records were subsequently set by a 16th SOS 2-ship AC-130H formation flight that departed Hurlburt Field on 13 November 1979 and landed on 15 November at Andersen Air Force Base, Guam, a distance of and 29 hours 43 minutes non-stop, refueling four times in-flight. Refueling support for the Guam deployment was provided by KC-135 crews from the 305th Air Refueling Wing from Grissom AFB, Indiana.
In November 1979, four AC-130H gunships flew nonstop from Hurlburt Field to Anderson AFB, Guam, because of the hostage situation at the Embassy in Iran. At Guam, AC-130H crews developed communications-out/lights-out refueling procedures for later employment by trial-and-error. This deployment with the 1 SOW/CC as Task Force commander was directed from the office of the CJCS for fear that Iranian militants could begin executing American Embassy personnel who had been taken hostage on 4 November. One early option considered AC-130H retaliatory punitive strikes deep within Iran. Later gunship flights exceeded the 1979 Hurlburt-to-Guam flight. Upon return in March 1980, the four planes soon found themselves in Egypt to support the ill-fated hostage rescue attempt.
During Operation Urgent Fury in Grenada in 1983, AC-130s suppressed enemy air defense systems and attacked ground forces enabling the assault of the Point Salines Airfield via airdrop and air-land of friendly forces. The AC-130 aircrew earned the Lieutenant General William H. Tunner Award for the mission.
The AC-130Hs of the 16th Special Operations Squadron unit maintained an ongoing rotation to Howard AB, Panama, monitoring activities in El Salvador and other Central American points of interest, with rules of engagement eventually permitting attacks on FMLN targets. This commitment of Maintainers and crews started in 1983 and lasted until 1990. The AC-130 is considered to have hastened the end of the Salvadoran Civil War in the 1980s. Crews flew undercover missions from Honduras and attacked guerrilla camps and concentrations.
AC-130s also had a primary role during the United States invasion of Panama (named Operation Just Cause) in 1989, when they destroyed Panama Defense Force headquarters and numerous command-and-control facilities, and provided close air support for US ground troops. Aircrews earned the Mackay Trophy for the most meritorious flight of the year, and the Tunner Award.
Gulf War and the 1990s.
During the Gulf War of 1990–91 (Operations Desert Shield and Desert Storm), Regular Air Force and Air Force Reserve AC-130s provided close air support and force protection (air base defense) for ground forces, and battlefield interdiction. The primary interdiction targets were early warning/ground control intercept (EW/GCI) sites along the southern border of Iraq. At its standard altitude of 12,000 feet, the aircraft had a proven ability to engage moving ground targets. The first gunship to enter the Battle of Khafji helped stop a southbound Iraqi armored column on 29 January 1991. One day later, three more gunships provided further aid to Marines participating in the operation. The gunships attacked Iraqi positions and columns moving south to reinforce their positions north of the city.
Despite the threat of surface-to-air missiles (SAMs) and increasing visibility during the early morning hours of 31 January 1991, one AC-130H, AF Serial No. 69-6567, call-sign Spirit 03, opted to stay to continue to protect the Marines. A lone Iraqi with a Strela-2 MANPADS shot Spirit 03 down, and all 14 crew members died.
The military has used AC-130 gunships during the humanitarian operations in Somalia (Operation Restore Hope and Operation United Shield) in 1992–93, Operation Uphold Democracy in Haiti in 1994. AC-130s took part in Operation Assured Response in Liberia in 1996 and in Operation Silver Wake in 1997, the evacuation of American non-combatants from Albania.
AC-130s took part in the NATO missions in Bosnia and Herzegovina and Kosovo during the 1990s.
The AC-130U gunship set a new record for the longest sustained flight by any C-130 on 22 and 23 October 1997, when two AC-130U gunships flew 36 hours nonstop from Hurlburt Field, Florida to Taegu Air Base (Daegu), South Korea, being refueled seven times in the air by KC-135 tankers. The two gunships took on 410,000 lb (186,000 kg) of fuel. Gunships also were part of the buildup of U.S. forces in 1998 to compel Iraq to allow UNSCOM weapons inspections.
War on Terror.
The U.S. has used gunships with deployments to the War in Afghanistan (Operation Enduring Freedom - Afghanistan) (2001–2014), and Iraq War (Operation Iraqi Freedom) (2003–11).
AC-130 strikes were directed by special forces on known Taliban locations during the early days of the war in Afghanistan. U.S. Special Operations Forces are using the AC-130 to support its operations. The day after arriving in Afghanistan, the AC-130s attacked Taliban and Al-Qaeda forces near the city of Konduz and were directly responsible for the city's surrender the next day. On 26 November 2001, Spectres were called in to put down a rebellion at the prison fort of Qala-i-Janghi. The 16 SOS flew missions over Mazar-i-Sharif, Kunduz, Kandahar, Shkin, Asadabad, Bagram, Baghran, Tora Bora, and virtually every other part of Afghanistan. The Spectre participated in countless operations within Afghanistan, performing on-call close air support and armed reconnaissance. In March 2002, three AC-130 Spectres provided 39 crucial combat missions in support of Operation Anaconda in Afghanistan. During the intense fighting, the planes expended more than 1,300 40 mm and 1,200 105 mm rounds.
Close air support was the main mission of the AC-130 in Iraq. Night after night, at least one AC-130 was in the air to fulfill one or more air support requests (ASRs). A typical mission had the AC–130 supporting a single brigade’s ASRs followed by aerial refueling and another 2 hours with another brigade or SOF team. The use of AC-130s in places like Fallujah, urban settings where insurgents were among crowded populations of non-combatants, was criticized by human rights groups. AC-130s were also used for intelligence gathering with their sophisticated long-range video, infrared and radar sensors.
In 2007, US Special Operations forces also used the AC-130 in attacks on suspected Al-Qaeda militants in Somalia.
There were eight AC-130H and seventeen AC-130U aircraft in active-duty service as of July 2010.
In March 2011, the U.S. Air Force deployed two AC-130U gunships to take part in Operation Odyssey Dawn, the U.S. military intervention in Libya, which eventually came under NATO as Operation Unified Protector.
By September 2013, 14 MC-130W Dragon Spear aircraft have been converted to AC-130W Stinger II gunships. The Stinger gunships have been deployed to Afghanistan to replace the aging AC-130H aircraft and provide an example for the new AC-130J Ghostrider. Modifications began with crews cutting holes in the plane to make room for weapons, and adding kits and bomb bases for laser-guided munitions. Crews added a 105 mm cannon, 20-inch infrared and electro-optical sensors, and the ability to carry 250-pound bombs on the wings.
On 3 October 2015, five attacks on a Doctors Without Borders hospital in Kunduz, Afghanistan were reportedly carried out by one or more AC-130s, causing the deaths of hospital workers and patients.
On 15 November 2015, two days after the attacks in Paris by ISIL, AC-130s and A-10 Thunderbolt II attack aircraft destroyed a convoy of over 100 ISIL-operated oil tanker trucks in Syria. The attacks were part of an intensification of the U.S.-led Military intervention against ISIL called Operation Tidal Wave II (named after the original Operation Tidal Wave during World War II, a failed attempt to raid German oil fields that resulted in heavy aircraft and aircrew loss) in an attempt to cut off oil smuggling as a source of funding for the group.
The U.S. has continued to use the aircraft in the War in Afghanistan (2015-present).
United States Air Force
Aircraft on display.
One of the first seven AC-130A aircraft deployed to Vietnam was AF serial no. 53-3129, named "First Lady" in November 1970. This aircraft was a conversion of the first production C-130. On 25 March 1971, it took an anti-aircraft artillery hit in the belly just aft of the nose gear wheel well over the Ho Chi Minh trail in Laos. The 37 mm shell destroyed everything below the crew deck and barely missed striking two crew members. The pilot was able to crash land the aircraft safely. In 1975, after the conclusion of US involvement in the Vietnam war, it was transferred to the Air Force Reserve, where it served with the 711th Special Operations Squadron of the 919th Special Operations Wing. In 1980, the aircraft was upgraded from the original three-bladed propellers to the quieter four-bladed propellers and was eventually retired in late 1995. The retirement also marked an end to the Air Force Reserve Command flying the AC-130A. The aircraft now sits on display in the final Air Force Reserve Command configuration with grey paint, black markings, and the four-bladed Hamilton Sunstrand 54H60-91 props at the Air Force Armament Museum at Eglin Air Force Base, Florida, USA.
A second AC-130A, AF serial no. 56-0509, named the "Ultimate End", was accepted by the Air Force on 28 February 1957, and modified to the AC-130A configuration on 27 July 1970. The aircraft participated in the Vietnam War and the rescue of the SS Mayaguez. "Ultimate End" demonstrated the durability of the C-130 after surviving hits in five places by 37 mm anti-aircraft artillery on 12 December 1970, extensive left wing leading edge damage on 12 April 1971 and a 57 mm round damaging the belly and injuring one crewman on 4 March 1972. "Ultimate End" was reassigned to the Air Force Reserve's 919th Special Operations Wing at Eglin AFB Auxiliary Field No.3 / Duke Field on 17 June 1975, where it continued in service until retired in the fall 1994 and transferred to Air Force Special Operations Command's "Heritage Air Park" at Hurlburt Field, Florida. While assigned to the 711th Special Operations Squadron, "Ultimate End" served in Operations JUST CAUSE in Panama, DESERT STORM in Kuwait and Iraq, and UPHOLD DEMOCRACY in Haiti. After 36 years and seven months of service, 24 years as a gunship, "Ultimate End" retired from active service on 1 October 1994. It made its last flight from Duke Field to Hurlburt Field on 20 October 1994. The Spectre Association dedicated "Ultimate End" (which served with the 16 SOS in Vietnam) on 4 May 1995. Lt Col Michael Byers, then 16 SOS commander, represented the active-duty gunship force and Clyde Gowdy of the Spectre Association represented all Spectre personnel past and present for the unveiling of a monument at the aircraft and the dedication as a whole.
A third AC-130A, AF serial no. 54-1630, is on display in the Cold War Gallery at the National Museum of the United States Air Force at Wright-Patterson AFB, Ohio. Named "Azrael" for the angel of death in Islam who severs the soul from the body. This aircraft figured prominently in the closing hours of Operation Desert Storm. On 26 February 1991, Coalition ground forces were driving the Iraqi Army out of Kuwait. With an Air Force Reserve crew called to active duty, Azrael was sent to the Al Jahra highway (Highway 80) between Kuwait City and Basra, Iraq, to intercept the convoys of tanks, trucks, buses, and cars fleeing the battle. Facing SA-6 and SA-8 surface-to-air missiles and 37 mm and 57 mm radar-guided anti-aircraft artillery the crew attacked and destroyed or disabled most of the convoys. "Azrael" was also assigned to the 919th Special Operations Wing and retired to the museum in October 1995.
Another AC-130A, AF serial no. 54-1626, the original prototype AC-130 named "Gunship II" is on display at the outdoor Air Park at the National Museum of the United States Air Force at Wright-Patterson AFB, Ohio. This aircraft served in Southeast Asia from 1967 to 1972, then served in JC-130A test configuration. It was transferred to the National Museum of the United States Air Force in 1976, and converted back to AC-130A configuration in the late 1990s.
AC-130A serial no. 54-1623, c/n 3010, named "Ghost Rider" served in Southeast Asia and later conflicts until being retired in 1997 to Dobbins AFB, Georgia. Ghost Rider eventually was transferred and displayed at the Lockheed Museum at Marietta, Georgia.
(Prior to c. 2000)
(Current Armament)

</doc>
<doc id="3158" url="https://en.wikipedia.org/wiki?curid=3158" title="Alternative">
Alternative

Alternative may refer to Aida's version.

</doc>
<doc id="3160" url="https://en.wikipedia.org/wiki?curid=3160" title="Alternative algebra">
Alternative algebra

In abstract algebra, an alternative algebra is an algebra in which multiplication need not be associative, only alternative. That is, one must have
for all "x" and "y" in the algebra.
Every associative algebra is obviously alternative, but so too are some strictly non-associative algebras such as the octonions. The sedenions, on the other hand, are not alternative.
The associator.
Alternative algebras are so named because they are precisely the algebras for which the associator is alternating. The associator is a trilinear map given by
By definition a multilinear map is alternating if it vanishes whenever two of its arguments are equal. The left and right alternative identities for an algebra are equivalent to
Both of these identities together imply that the associator is totally skew-symmetric. That is,
for any permutation σ. It follows that
for all "x" and "y". This is equivalent to the "flexible identity"
The associator of an alternative algebra is therefore alternating. Conversely, any algebra whose associator is alternating is clearly alternative. By symmetry, any algebra which satisfies any two of:
is alternative and therefore satisfies all three identities.
An alternating associator is always totally skew-symmetric. The converse holds so long as the characteristic of the base field is not 2.
Properties.
Artin's theorem states that in an alternative algebra the subalgebra generated by any two elements is associative. Conversely, any algebra for which this is true is clearly alternative. It follows that expressions involving only two variables can be written without parenthesis unambiguously in an alternative algebra. A generalization of Artin's theorem states that whenever three elements formula_12 in an alternative algebra associate (i.e. formula_7) the subalgebra generated by those elements is associative.
A corollary of Artin's theorem is that alternative algebras are power-associative, that is, the subalgebra generated by a single element is associative. The converse need not hold: the sedenions are power-associative but not alternative.
The Moufang identities
hold in any alternative algebra.
In a unital alternative algebra, multiplicative inverses are unique whenever they exist. Moreover, for any invertible element formula_17 and all formula_18 one has
This is equivalent to saying the associator formula_20 vanishes for all such formula_17 and formula_18. If formula_17 and formula_18 are invertible then formula_25 is also invertible with inverse formula_26. The set of all invertible elements is therefore closed under multiplication and forms a Moufang loop. This "loop of units" in an alternative ring or algebra is analogous to the group of units in an associative ring or algebra.
Zorn's theorem states that any finite-dimensional non-associative alternative algebra is a generalised octonion algebra.
Applications.
The projective plane over any alternative division ring is a Moufang plane.
The close relationship of alternative algebras and composition algebras was given by Guy Roos in 2008: He shows (page 162) the relation for an algebra "A" with unit element "e" and an involutive anti-automorphism formula_27 such that "a" + "a"* and "aa"* are on the line spanned by "e" for all "a" in "A". Use the notation "n"("a") = "aa"*. Then if "n" is a non-singular mapping into the field of "A", and "A" is alternative, then ("A,n") is a composition algebra.

</doc>
<doc id="3162" url="https://en.wikipedia.org/wiki?curid=3162" title="Arbitrage">
Arbitrage

In economics and finance, arbitrage (, , ) is the practice of taking advantage of a price difference between two or more markets: striking a combination of matching deals that capitalize upon the imbalance, the profit being the difference between the market prices. When used by academics, an arbitrage is a transaction that involves no negative cash flow at any probabilistic or temporal state and a positive cash flow in at least one state; in simple terms, it is the possibility of a risk-free profit after transaction costs. For instance, an arbitrage is present when there is the opportunity to instantaneously buy low and sell high.
In principle and in academic use, an arbitrage is risk-free; in common use, as in statistical arbitrage, it may refer to "expected" profit, though losses may occur, and in practice, there are always risks in arbitrage, some minor (such as fluctuation of prices decreasing profit margins), some major (such as devaluation of a currency or derivative). In academic use, an arbitrage involves taking advantage of differences in price of a "single" asset or "identical" cash-flows; in common use, it is also used to refer to differences between "similar" assets (relative value or convergence trades), as in merger arbitrage.
People who engage in arbitrage are called arbitrageurs —such as a bank or brokerage firm. The term is mainly applied to trading in financial instruments, such as bonds, stocks, derivatives, commodities and currencies.
Arbitrage-free.
If the market prices do not allow for profitable arbitrage, the prices are said to constitute an arbitrage equilibrium, or arbitrage-free market. An arbitrage equilibrium is a precondition for a general economic equilibrium. The "no arbitrage" assumption is used in quantitative finance to calculate a unique risk neutral price for derivatives.
Arbitrage-free pricing approach for bonds.
This refers to the method of valuing a coupon bearing financial instrument by discounting its future cash flows by multiple discount rates. By doing so, a more accurate price will be obtained than if the price is calculated with a present value pricing approach. Arbitrage-free pricing is used for bond valuation and used to detect arbitrage opportunities for investors.
For purpose of valuing the price of a bond its cash flows can each be thought of as packets of incremental cash flows with a large packet upon maturity, being the principal. Since the cash flows are dispersed throughout future periods they must be discounted back to the present. In the present value approach, the cash flows are discounted with one discount rate to find the price of the bond. In arbitrage-free pricing, multiple discount rates are used.
The present value approach assumes that the yield of the bond will stay the same until maturity. This is a simplified model because interest rates may fluctuate in the future, which in turn affects the yield on the bond. The discount rate may be different for each of the cash flows for this reason. Each cash flow can be considered a zero-coupon instrument that pays one payment upon maturity. The discount rates used should be the rates of multiple zero-coupon bonds with maturity dates same as each cash flow and similar risk as the instrument being valued. By using multiple discount rates the arbitrage-free price will be the sum of the discounted cash flows. Arbitrage-free price refers to the price at which no price arbitrage is possible.
The ideas of using multiple discount rates obtained from zero-coupon bonds and discount a similar bonds cash flow to find its price is derived from the yield curve. The yield curve is a curve of the yields of the same bond with different maturities. This curve can be used to view trends in the markets expectations of how interest rates will move in the future. In arbitrage-free pricing of a bond a yield curve of similar zero-coupon bonds with different maturities is created. If the curve were to be created with Treasury securities of different maturities they would be stripped of their coupon payments through bootstrapping. This is to transform the bonds into zero-coupon bonds. The yield of these zero-coupon bonds would then be plotted on a diagram with time on the x-axis and yield on the y-axis.
Since the yield curve in a way displays the markets expectations on how yields and interest rates may move, the arbitrage-free pricing approach is more realistic than using only one discount rate. With this, investors can use this approach to value bonds and find mismatches in prices, resulting in an arbitrage opportunity. If a bond valued with the arbitrage-free pricing approach turns out to be priced higher in the market an investor could have such an opportunity:
If the outcome from the valuation were the reversed case the opposite positions would be taken in the bonds. This arbitrage opportunity comes from the assumption that the prices of bonds with the same properties will converge upon maturity. This can be explained through market efficiency, which states that arbitrage opportunities will eventually be discovered and corrected accordingly. The prices of the bonds in t move closer together to finally become the same at t.
Conditions for arbitrage.
Arbitrage is possible when one of three conditions is met:
Arbitrage is not simply the act of buying a product in one market and selling it in another for a higher price at some later time. The transactions must occur "simultaneously" to avoid exposure to market risk, or the risk that prices may change on one market before both transactions are complete. In practical terms, this is generally possible only with securities and financial products that can be traded electronically, and even then, when each leg of the trade is executed the prices in the market may have moved. Missing one of the legs of the trade (and subsequently having to trade it soon after at a worse price) is called 'execution risk' or more specifically 'leg risk'.
In the simplest example, any good sold in one market should sell for the same price in another. Traders may, for example, find that the price of wheat is lower in agricultural regions than in cities, purchase the good, and transport it to another region to sell at a higher price. This type of price arbitrage is the most common, but this simple example ignores the cost of transport, storage, risk, and other factors. "True" arbitrage requires that there be no market risk involved. Where securities are traded on more than one exchange, arbitrage occurs by simultaneously buying in one and selling on the other.
See rational pricing, particularly arbitrage mechanics, for further discussion.
Mathematically it is defined as follows:
where formula_2 and formula_3 denotes the portfolio value at time "t".
Price convergence.
Arbitrage has the effect of causing prices in different markets to converge. As a result of arbitrage, the currency exchange rates, the price of commodities, and the price of securities in different markets tend to converge. The speed at which they do so is a measure of market efficiency. Arbitrage tends to reduce price discrimination by encouraging people to buy an item where the price is low and resell it where the price is high (as long as the buyers are not prohibited from reselling and the transaction costs of buying, holding and reselling are small relative to the difference in prices in the different markets).
Arbitrage moves different currencies toward purchasing power parity. As an example, assume that a car purchased in the United States is cheaper than the same car in Canada. Canadians would buy their cars across the border to exploit the arbitrage condition. At the same time, Americans would buy US cars, transport them across the border, then sell them in Canada. Canadians would have to buy American dollars to buy the cars and Americans would have to sell the Canadian dollars they received in exchange. Both actions would increase demand for US dollars and supply of Canadian dollars. As a result, there would be an appreciation of the US currency. This would make US cars more expensive and Canadian cars less so until their prices were similar. On a larger scale, international arbitrage opportunities in commodities, goods, securities and currencies tend to change exchange rates until the purchasing power is equal.
In reality, most assets exhibit some difference between countries. These, transaction costs, taxes, and other costs provide an impediment to this kind of arbitrage. Similarly, arbitrage affects the difference in interest rates paid on government bonds issued by the various countries, given the expected depreciation in the currencies relative to each other (see interest rate parity).
Risks.
Arbitrage transactions in modern securities markets involve fairly low day-to-day risks, but can face extremely high risk in rare situations, particularly financial crises, and can lead to bankruptcy. Formally, arbitrage transactions have negative skew – prices can get a small amount closer (but often no closer than 0), while they can get very far apart. The day-to-day risks are generally small because the transactions involve small differences in price, so an execution failure will generally cause a small loss (unless the trade is very big or the price moves rapidly). The rare case risks are extremely high because these small price differences are converted to large profits via leverage (borrowed money), and in the rare event of a large price move, this may yield a large loss.
The main day-to-day risk is that part of the transaction fails – execution risk. The main rare risks are counterparty risk and liquidity risk – that a counterparty to a large transaction or many transactions fails to pay, or that one is required to post margin and does not have the money to do so.
In the academic literature, the idea that seemingly very low risk arbitrage trades might not be fully exploited because of these risk factors and other considerations is often referred to as limits to arbitrage.
Execution risk.
Generally it is impossible to close two or three transactions at the same instant; therefore, there is the possibility that when one part of the deal is closed, a quick shift in prices makes it impossible to close the other at a profitable price. However, this is not necessarily the case. Many exchanges and inter-dealer brokers allow multi legged trades (e.g. basis block trades on LIFFE).
Competition in the marketplace can also create risks during arbitrage transactions. As an example, if one was trying to profit from a price discrepancy between IBM on the NYSE and IBM on the London Stock Exchange, they may purchase a large number of shares on the NYSE and find that they cannot simultaneously sell on the LSE. This leaves the arbitrageur in an unhedged risk position.
In the 1980s, risk arbitrage was common. In this form of speculation, one trades a security that is clearly undervalued or overvalued, when it is seen that the wrong valuation is about to be corrected by events. The standard example is the stock of a company, undervalued in the stock market, which is about to be the object of a takeover bid; the price of the takeover will more truly reflect the value of the company, giving a large profit to those who bought at the current price—if the merger goes through as predicted. Traditionally, arbitrage transactions in the securities markets involve high speed, high volume and low risk. At some moment a price difference exists, and the problem is to execute two or three balancing transactions while the difference persists (that is, before the other arbitrageurs act). When the transaction involves a delay of weeks or months, as above, it may entail considerable risk if borrowed money is used to magnify the reward through leverage. One way of reducing the risk is through the illegal use of inside information, and in fact risk arbitrage with regard to leveraged buyouts was associated with some of the famous financial scandals of the 1980s such as those involving Michael Milken and Ivan Boesky.
Mismatch.
Another risk occurs if the items being bought and sold are not identical and the arbitrage is conducted under the assumption that the prices of the items are correlated or predictable; this is more narrowly referred to as a convergence trade. In the extreme case this is merger arbitrage, described below. In comparison to the classical quick arbitrage transaction, such an operation can produce disastrous losses.
Counterparty risk.
As arbitrages generally involve "future" movements of cash, they are subject to counterparty risk: if a counterparty fails to fulfill their side of a transaction. This is a serious problem if one has either a single trade or many related trades with a single counterparty, whose failure thus poses a threat, or in the event of a financial crisis when many counterparties fail. This hazard is serious because of the large quantities one must trade in order to make a profit on small price differences.
For example, if one purchases many risky bonds, then hedges them with CDSes, profiting from the difference between the bond spread and the CDS premium, in a financial crisis the bonds may default "and" the CDS writer/seller may itself fail, due to the stress of the crisis, causing the arbitrageur to face steep losses.
Liquidity risk.
Arbitrage trades are necessarily synthetic, "leveraged" trades, as they involve a short position. If the assets used are not identical (so a price divergence makes the trade temporarily lose money), or the margin treatment is not identical, and the trader is accordingly required to post margin (faces a margin call), the trader may run out of capital (if they run out of cash and cannot borrow more) and be forced to sell these assets at a loss even though the trades may be expected to ultimately make money. In effect, arbitrage traders synthesize a put option on their ability to finance themselves.
Prices may diverge during a financial crisis, often termed a "flight to quality"; these are precisely the times when it is hardest for leveraged investors to raise capital (due to overall capital constraints), and thus they will lack capital precisely when they need it most.
Types of arbitrage.
Spatial arbitrage.
Also known as Geographical arbitrage is the simplest form of arbitrage. In case of spatial arbitrage, an arbs (arbitrageurs) looks for pricing discrepancies across geographically separate markets. For example, there may be a bond dealer in Virginia offering a bond at 100-12/23 and a dealer in Washington is bidding 100-15/23 for the same bond. For whatever reason, the two dealers have not spotted the aberration in the prices, but the arbs does. The arb immediately buys the bond from the Virginia dealer and sells it to the Washington dealer.
Merger arbitrage.
Also called risk arbitrage, merger arbitrage generally consists of buying/holding the stock of a company that is the target of a takeover while shorting the stock of the acquiring company.
Usually the market price of the target company is less than the price offered by the acquiring company.
The spread between these two prices depends mainly on the probability and the timing of the takeover being completed as well as the prevailing level of interest rates.
The bet in a merger arbitrage is that such a spread will eventually be zero, if and when the takeover is completed. The risk is that the deal "breaks" and the spread massively widens.
Municipal bond arbitrage.
Also called "municipal bond relative value arbitrage", "municipal arbitrage", or just "muni arb", this hedge fund strategy involves one of two approaches. It should be noted that the term "arbitrage" is also used in the context of the Income Tax Regulations governing the investment of proceeds of municipal bonds; these regulations, aimed at the issuers or beneficiaries of tax-exempt municipal bonds, are different and, instead, attempt to remove the issuer's ability to arbitrage between the low tax-exempt rate and a taxable investment rate.
Generally, managers seek relative value opportunities by being both long and short municipal bonds with a duration-neutral book. The relative value trades may be between different issuers, different bonds issued by the same entity, or capital structure trades referencing the same asset (in the case of revenue bonds). Managers aim to capture the inefficiencies arising from the heavy participation of non-economic investors (i.e., high income "buy and hold" investors seeking tax-exempt income) as well as the "crossover buying" arising from corporations' or individuals' changing income tax situations (i.e., insurers switching their munis for corporates after a large loss as they can capture a higher after-tax yield by offsetting the taxable corporate income with underwriting losses). There are additional inefficiencies arising from the highly fragmented nature of the municipal bond market which has two million outstanding issues and 50,000 issuers in contrast to the Treasury market which has 400 issues and a single issuer.
Second, managers construct leveraged portfolios of AAA- or AA-rated tax-exempt municipal bonds with the duration risk hedged by shorting the appropriate ratio of taxable corporate bonds. These corporate equivalents are typically interest rate swaps referencing Libor or SIFMA . The arbitrage manifests itself in the form of a relatively cheap longer maturity municipal bond, which is a municipal bond that yields significantly more than 65% of a corresponding taxable corporate bond. The steeper slope of the municipal yield curve allows participants to collect more after-tax income from the municipal bond portfolio than is spent on the interest rate swap; the carry is greater than the hedge expense. Positive, tax-free carry from muni arb can reach into the double digits. The bet in this municipal bond arbitrage is that, over a longer period of time, two similar instruments—municipal bonds and interest rate swaps—will correlate with each other; they are both very high quality credits, have the same maturity and are denominated in U.S. dollars. Credit risk and duration risk are largely eliminated in this strategy. However, basis risk arises from use of an imperfect hedge, which results in significant, but range-bound principal volatility. The end goal is to limit this principal volatility, eliminating its relevance over time as the high, consistent, tax-free cash flow accumulates. Since the inefficiency is related to government tax policy, and hence is structural in nature, it has not been arbitraged away.
Note, however, that many municipal bonds are callable, and that this imposes substantial additional risks to the strategy.
Convertible bond arbitrage.
A convertible bond is a bond that an investor can return to the issuing company in exchange for a predetermined number of shares in the company.
A convertible bond can be thought of as a corporate bond with a stock call option attached to it.
The price of a convertible bond is sensitive to three major factors:
Given the complexity of the calculations involved and the convoluted structure that a convertible bond can have, an arbitrageur often relies on sophisticated quantitative models in order to identify bonds that are trading cheap versus their theoretical value.
Convertible arbitrage consists of buying a convertible bond and hedging two of the three factors in order to gain exposure to the third factor at a very attractive price.
For instance an arbitrageur would first buy a convertible bond, then sell fixed income securities or interest rate futures (to hedge the interest rate exposure) and buy some credit protection (to hedge the risk of credit deterioration).
Eventually what he'd be left with is something similar to a call option on the underlying stock, acquired at a very low price.
He could then make money either selling some of the more expensive options that are openly traded in the market or delta hedging his exposure to the underlying shares.
Depository receipts.
A depositary receipt is a security that is offered as a "tracking stock" on another foreign market. For instance a Chinese company wishing to raise more money may issue a depository receipt on the New York Stock Exchange, as the amount of capital on the local exchanges is limited. These securities, known as ADRs (American depositary receipt) or GDRs (global depository receipt) depending on where they are issued, are typically considered "foreign" and therefore trade at a lower value when first released. Many ADR's are exchangeable into the original security (known as fungibility) and actually have the same value. In this case there is a spread between the perceived value and real value, which can be extracted. Other ADR's that are not exchangeable often have much larger spreads. Since the ADR is trading at a value lower than what it is worth, one can purchase the ADR and expect to make money as its value converges on the original. However, there is a chance that the original stock will fall in value too, so by shorting it one can hedge that risk.
Dual-listed companies.
A dual-listed company (DLC) structure involves two companies incorporated in different countries contractually agreeing to operate their businesses as if they were a single enterprise, while retaining their separate legal identity and existing stock exchange listings. In integrated and efficient financial markets, stock prices of the twin pair should move in lockstep. In practice, DLC share prices exhibit large deviations from theoretical parity. Arbitrage positions in DLCs can be set up by obtaining a long position in the relatively underpriced part of the DLC and a short position in the relatively overpriced part. Such arbitrage strategies start paying off as soon as the relative prices of the two DLC stocks converge toward theoretical parity. However, since there is no identifiable date at which DLC prices will converge, arbitrage positions sometimes have to be kept open for considerable periods of time. In the meantime, the price gap might widen. In these situations, arbitrageurs may receive margin calls, after which they would most likely be forced to liquidate part of the position at a highly unfavorable moment and suffer a loss. Arbitrage in DLCs may be profitable, but is also very risky.
A good illustration of the risk of DLC arbitrage is the position in Royal Dutch Shell—which had a DLC structure until 2005—by the hedge fund Long-Term Capital Management (LTCM, see also the discussion below). Lowenstein (2000) describes that LTCM established an arbitrage position in Royal Dutch Shell in the summer of 1997, when Royal Dutch traded at an 8 to 10 percent premium. In total $2.3 billion was invested, half of which long in Shell and the other half short in Royal Dutch (Lowenstein, p. 99). In the autumn of 1998 large defaults on Russian debt created significant losses for the hedge fund and LTCM had to unwind several positions. Lowenstein reports that the premium of Royal Dutch had increased to about 22 percent and LTCM had to close the position and incur a loss. According to Lowenstein (p. 234), LTCM lost $286 million in equity pairs trading and more than half of this loss is accounted for by the Royal Dutch Shell trade.
Private to public equities.
The market prices for privately held companies are typically viewed from a return on investment perspective (such as 25%), whilst publicly held and or exchange listed companies trade on a Price to earnings ratio (P/E) (such as a P/E of 10, which equates to a 10% ROI). Thus, if a publicly traded company specialises in the acquisition of privately held companies, from a per-share perspective there is a gain with every acquisition that falls within these guidelines. Exempli gratia, Berkshire Hathaway. A hedge fund that is an example of this type of arbitrage is Greenridge Capital, which acts as an angel investor retaining equity in private companies which are in the process of becoming publicly traded, buying in the private market and later selling in the public market. Private to public equities arbitrage is a term which can arguably be applied to investment banking in general. Private markets to public markets differences may also help explain the overnight windfall gains enjoyed by principals of companies that just did an initial public offering (IPO).
Regulatory arbitrage.
Regulatory arbitrage is where a regulated institution takes advantage of the difference between its real (or economic) risk and the regulatory position. For example, if a bank, operating under the Basel I accord, has to hold 8% capital against default risk, but the real risk of default is lower, it is profitable to securitise the loan, removing the low risk loan from its portfolio. On the other hand, if the real risk is higher than the regulatory risk then it is profitable to make that loan and hold on to it, provided it is priced appropriately. Regulatory arbitrage can result in parts of entire businesses being unregulated as a result of the arbitrage.
This process can increase the overall riskiness of institutions under a risk insensitive regulatory regime, as described by Alan Greenspan in his October 1998 speech on The Role of Capital in Optimal Banking Supervision and Regulation.
The term "Regulatory Arbitrage" was used for the first time in 2005 when it was applied by Scott V. Simpson, a partner at law firm Skadden, Arps, to refer to a new defence tactic in hostile mergers and acquisitions where differing takeover regimes in deals involving multi-jurisdictions are exploited to the advantage of a target company under threat.
In economics, regulatory arbitrage (sometimes, tax arbitrage) may be used to refer to situations when a company can choose a nominal place of business with a regulatory, legal or tax regime with lower costs. For example, an insurance company may choose to locate in Bermuda due to preferential tax rates and policies for insurance companies. This can occur particularly where the business transaction has no obvious physical location: in the case of many financial products, it may be unclear "where" the transaction occurs.
Regulatory arbitrage can include restructuring a bank by outsourcing services such as IT. The outsourcing company takes over the installations, buying out the bank's assets and charges a periodic service fee back to the bank. This frees up cashflow usable for new lending by the bank. The bank will have higher IT costs, but counts on the multiplier effect of money creation and the interest rate spread to make it a profitable exercise.
Example:
Suppose the bank sells its IT installations for 40 million USD. With a reserve ratio of 10%, the bank can create 400 million USD in additional loans (there is a time lag, and the bank has to expect to recover the loaned money back into its books). The bank can often lend (and securitize the loan) to the IT services company to cover the acquisition cost of the IT installations. This can be at preferential rates, as the sole client using the IT installation is the bank. If the bank can generate 5% interest margin on the 400 million of new loans, the bank will increase interest revenues by 20 million. The IT services company is free to leverage their balance sheet as aggressively as they and their banker agree to. This is the reason behind the trend towards outsourcing in the financial sector. Without this money creation benefit, it is actually more expensive to outsource the IT operations as the outsourcing adds a layer of management and increases overhead.
According to PBS Frontline's 2012 four-part documentary, "Money, Power, and Wall Street," regulatory arbitrage, along with asymmetric bank lobbying in Washington and abroad, allowed investment banks in the pre- and post-2008 period to continue to skirt laws and engage in the risky proprietary trading of opaque derivatives, swaps, and other credit-based instruments invented to circumvent legal restrictions at the expense of clients, government, and publics.
Due to the Affordable Care Act’s expansion of Medicaid coverage, one form of Regulatory Arbitrage can now be found when businesses engage in “Medicaid Migration”, a maneuver by which qualifying employees who would typically be enrolled in company health plans elect to enroll in Medicaid instead. These programs that have similar characteristics as insurance products to the employee, but have radically different cost structures, resulting in significant expense reductions for employers.
Telecom arbitrage.
Telecom arbitrage companies allow phone users to make international calls for free through certain access numbers. Such services are offered in the United Kingdom; the telecommunication arbitrage companies get paid an interconnect charge by the UK mobile networks and then buy international routes at a lower cost. The calls are seen as free by the UK contract mobile phone customers since they are using up their allocated monthly minutes rather than paying for additional calls.
Such services were previously offered in the United States by companies such as FuturePhone.com. These services would operate in rural telephone exchanges, primarily in small towns in the state of Iowa. In these areas, the local telephone carriers are allowed to charge a high "termination fee" to the caller's carrier in order to fund the cost of providing service to the small and sparsely populated areas that they serve. However, FuturePhone (as well as other similar services) ceased operations upon legal challenges from AT&T and other service providers.
Statistical arbitrage.
Statistical arbitrage is an imbalance in expected nominal values. A casino has a statistical arbitrage in every game of chance that it offers—referred to as the house advantage, house edge, vigorish or house vigorish.
The fall of Long-Term Capital Management.
Long-Term Capital Management (LTCM) lost 4.6 billion U.S. dollars in fixed income arbitrage in September 1998. LTCM had attempted to make money on the price difference between different bonds. For example, it would sell U.S. Treasury securities and buy Italian bond futures. The concept was that because Italian bond futures had a less liquid market, in the short term Italian bond futures would have a higher return than U.S. bonds, but in the long term, the prices would converge. Because the difference was small, a large amount of money had to be borrowed to make the buying and selling profitable.
The downfall in this system began on August 17, 1998, when Russia defaulted on its ruble debt and domestic dollar debt. Because the markets were already nervous due to the Asian financial crisis, investors began selling non-U.S. treasury debt and buying U.S. treasuries, which were considered a safe investment. As a result, the price on US treasuries began to increase and the return began decreasing because there were many buyers, and the return (yield) on other bonds began to increase because there were many sellers (i.e. the price of those bonds fell). This caused the difference between the prices of U.S. treasuries and other bonds to increase, rather than to decrease as LTCM was expecting. Eventually this caused LTCM to fold, and their creditors had to arrange a bail-out. More controversially, officials of the Federal Reserve assisted in the negotiations that led to this bail-out, on the grounds that so many companies and deals were intertwined with LTCM that if LTCM actually failed, they would as well, causing a collapse in confidence in the economic system. Thus LTCM failed as a fixed income arbitrage fund, although it is unclear what sort of profit was realized by the banks that bailed LTCM out.
Etymology.
"Arbitrage" is a French word and denotes a decision by an arbitrator or arbitration tribunal. (In modern French, "" usually means referee or umpire.) In the sense used here it is first defined in 1704 by Mathieu de la Porte in his treatise " as a consideration of different exchange rates to recognize the most profitable places of issuance and settlement for a bill of exchange (".)

</doc>
<doc id="3165" url="https://en.wikipedia.org/wiki?curid=3165" title="ACF Fiorentina">
ACF Fiorentina

ACF Fiorentina, commonly referred to as simply Fiorentina , is a professional Italian football club from Florence, Tuscany. Founded by a merger in 1926, and refounded in 2002 following bankruptcy, Fiorentina have played at the top level of Italian football for the majority of their existence; only four clubs have played in more Serie A seasons.
Fiorentina has won two Italian Championships, in 1955–56 and again in 1968–69, as well as six Coppa Italia trophies and one Supercoppa Italiana. On the European stage, Fiorentina won the UEFA Cup Winners' Cup in 1960–61 and lost the final one year later. They finished runners-up in the 1956–57 European Cup, losing against Real Madrid, and also came close to winning the 1989–90 UEFA Cup, finishing as runners-up against Juventus.
Since 1931, the club have played at the Stadio Artemio Franchi, which currently has a capacity of 47,282. The stadium has used several names over the years and has undergone several renovations. Fiorentina are known widely by the nickname "Viola", a reference to their distinctive purple colours.
History.
Foundation to World War II.
Associazione Calcio Fiorentina was founded in the autumn of 1926 by local noble and National Fascist Party member Luigi Ridolfi, who initiated the merger of two older Florentine clubs, CS Firenze and PG Libertas. The aim of the merger was to give Florence a strong club to rival those of the more dominant Italian Football Championship sides of the time from Northwest Italy. Also influential was the cultural revival and rediscovery of "Calcio Fiorentino", an ancestor of modern football that was played by members of the Medici family.
After a rough start and three seasons in lower leagues, Fiorentina reached the Serie A in 1931. That same year saw the opening of the new stadium, originally named after Giovanni Berta, after a prominent fascist, but now known as Stadio Artemio Franchi. At the time, the stadium was a masterpiece of engineering, and its inauguration was monumental. To be able to compete with the best teams in Italy, Fiorentina strengthened their team with some new players, notably the Uruguayan Pedro Petrone, nicknamed "el Artillero". Despite enjoying a good season and finishing in fourth place, Fiorentina were relegated the following year, although they would return quickly to Serie A. In 1941, they won their first Coppa Italia, but the team were unable to build on their success during the 1940s because of World War II and other troubles.
First "scudetto" and '50–'60s.
In 1950, Fiorentina started to achieve consistent top-five finishes in the domestic league. The team consisted of great players such as well-known goalkeeper Giuliano Sarti, Sergio Cervato, Francesco Rosella, Guido Gratton, Giuseppe Chiappella and Aldo Scaramucci but above all, the attacking duo of Brazilian Julinho and Argentinian Miguel Montuori. This team won Fiorentina's first "scudetto" (Italian championship) in 1955–56, 12 points ahead of second-place Milan. Milan beat Fiorentina to top spot the following year, but more significantly Fiorentina became the first Italian team to play in a European Cup final, when a disputed penalty led to a 2–0 defeat at the hands of Alfredo Di Stéfano's Real Madrid.
Fiorentina were runners-up again in the three subsequent seasons. In the 1960–61 season, the club won the Coppa Italia again and was also successful in Europe, winning the first Cup Winners' Cup against Scottish side Rangers.
After several years of runner-up finishes, Fiorentina dropped away slightly in the 1960s, bouncing from fourth to sixth place, although the club won the Coppa Italia and the Mitropa Cup in 1966.
Second "scudetto" and '70s.
While the 1960s did result in some trophies and good Serie A finishes for Fiorentina, nobody believed that the club could challenge for the title. The 1968–69 season started with Milan as frontrunners, but on matchday 7, they lost to Bologna and were overtaken by Gigi Riva's Cagliari. Fiorentina, after an unimpressive start, then moved to the top of the Serie A, but the first half of their season finished with a 2–2 draw against Varese, leaving Cagliari as outright league leader. The second half of the season was a three-way battle between the three contending teams, Milan, Cagliari and Fiorentina. Milan fell away, instead focusing their efforts on the European Cup, and it seemed that Cagliari would retain top spot. After Cagliari lost against Juventus, however, Fiorentina took over at the top. The team then won all of their remaining matches, beating rivals Juve in Turin on the penultimate matchday to seal their second, and last, national title. In the European Cup competition the following year, Fiorentina had some good results, including a win in the Soviet Union against Dynamo Kyiv, but they were eventually knocked out in the quarter-finals after a 3–0 defeat in Glasgow to Celtic.
"Viola" players began the 1970s decade with "Scudetto" sewed on their breast, but the period was not especially fruitful for the team. After a fifth-place finish in 1971, they finished in mid-table almost every year, even flirting with relegation in 1972 and 1978. The "Viola" did win the Anglo-Italian League Cup in 1974 and won the Coppa Italia again in 1975. The team consisted of young talents like Vincenzo Guerini and Moreno Roggi, who had the misfortune to suffer bad injuries, and above all Giancarlo Antognoni, who would later become an idol to Fiorentina's fans. The young average age of the players led to the team being called "Fiorentina Ye-Ye".
Pontello era.
In 1980, Fiorentina was bought by Flavio Pontello, who came from a rich house-building family. He quickly changed the team's anthem and logo, leading to some complaints by the fans, but he started to bring in high-quality players such as Francesco Graziani and Eraldo Pecci from Torino; Daniel Bertoni from Sevilla; Daniele Massaro from Monza; and a young Pietro Vierchowod from Sampdoria. The team was built around Giancarlo Antognoni, and in 1982, Fiorentina were involved in an exciting duel with rivals Juventus. After a bad injury to Antognoni, the league title was decided on the final day of the season when Fiorentina were denied a goal against Cagliari and were unable to win. Juventus won the title with a disputed penalty and the rivalry between the two teams erupted.
The following years were strange for Fiorentina, who vacillated between high finishes and relegation battles. Fiorentina also bought two interesting players, "El Puntero" Ramón Díaz and, most significantly, the young Roberto Baggio.
In 1990, Fiorentina fought to avoid relegation right up until the final day of the season, but did reach the UEFA Cup final, where they again faced Juventus. The Turin team won the trophy, but Fiorentina's "tifosi" once again had real cause for complaint: the second leg of the final was played in Avellino (Fiorentina's home ground was suspended), a city with many Juventus fans, and emerging star Roberto Baggio was sold to the rival team on the day of the final. Pontello, suffering from economic difficulties, was selling all the players and was forced to leave the club after serious riots in Florence's streets. The club was then acquired by the famous filmmaker Mario Cecchi Gori.
Cecchi Gori era: from Champions League to bankruptcy.
The first season under Cecchi Gori's ownership was one of stabilisation, after which the new chairman started to sign some good players like Brian Laudrup, Stefan Effenberg, Francesco Baiano and, most importantly, Gabriel Batistuta, who became an iconic player for the team during the 1990s. In 1993, however, Cecchi Gori died and was succeeded as chairman by his son, Vittorio. Despite a good start to the season, Cecchi Gori fired the coach, Luigi Radice, after a defeat against Atalanta, and replaced him with Aldo Agroppi. The results were dreadful: Fiorentina fell into the bottom half of the standings and were relegated on the last day of the season.
Claudio Ranieri was brought in as coach for the 1993–94 season, and that year, Fiorentina dominated Serie B, Italy's second division. Upon their return to Serie A, Ranieri put together a good team centred around new top scorer Batistuta, signing the young talent Rui Costa from Benfica and the new world champion Brazilian defender Márcio Santos. The former became an idol to Fiorentina fans, while the second disappointed and was sold after only a season. The "Viola" finished the season in tenth place.
The following season, Cecchi Gori bought other important players, namely Swedish midfielder Stefan Schwarz. The club again proved its mettle in cup competitions, winning the Coppa Italia against Atalanta and finishing joint-third in Serie A. In the summer, Fiorentina became the first non-national champions to win the Supercoppa Italiana, defeating Milan 2–1 at the San Siro.
Fiorentina's 1995–96 season was disappointing in the league, but they did reach the Cup Winners' Cup semi-final by beating Gloria Bistrița, Sparta Prague and Benfica. The team lost the semi-final to the eventual winner of the competition, Barcelona (away 1–1; home 0–2). The season's main signings were Luís Oliveira and Andrei Kanchelskis, the latter of whom suffered from many injuries.
At the end of the season, Ranieri left Fiorentina for Valencia in Spain, with Cecchi Gori appointing Alberto Malesani as his replacement. Fiorentina played well but struggled against smaller teams, although they did manage to qualify for the UEFA Cup. Malesani left Fiorentina after only a season and was succeeded by Giovanni Trapattoni. With Trapattoni's expert guidance and Batistuta's goals, Fiorentina challenged for the title in 1998–99 but finished the season in third, earning them qualification for the Champions League. The following year was disappointing in Serie A, but "Viola" played some historical matches in the Champions League, beating Arsenal 1–0 at the old Wembley Stadium and Manchester United 2–0 in Florence. They were ultimately eliminated in the second group stage.
At the end of the season, Trapattoni left the club and was replaced by Turkish coach Fatih Terim. More significantly, however, Batistuta was sold to Roma, who eventually won the title the following year. Fiorentina played well in 2000–01 and stayed in the top half of Serie A, despite the resignation of Terim and the arrival of Roberto Mancini. They also won the Coppa Italia for the sixth and last time.
The year 2001 heralded major changes for Fiorentina, as the terrible state of the club's finances was revealed: they were unable to pay wages and had debts of around US$50 million. but even this soon proved to be insufficient resources to sustain the club. Fiorentina were relegated at the end of the 2001–02 season and went into judicially-controlled administration in June 2002. This form of bankruptcy (sports companies cannot exactly fail in this way in Italy, but they can suffer a similar procedure) meant that the club was refused a place in Serie B for the 2002–03 season, and as a result effectively ceased to exist.
The 2000s: Della Valle era.
The club was promptly re-established in August 2002 as Associazione Calcio Fiorentina e Florentia Viola with shoe and leather entrepreneur Diego Della Valle as new owner and the club was admitted into Serie C2, the fourth tier of Italian football. The only player to remain at the club in its new incarnation was Angelo Di Livio, whose commitment to club's cause further endeared him to the fans. Helped by Di Livio and 30-goal striker Christian Riganò, the club won its Serie C2 group with considerable ease, which would normally have led to a promotion to Serie C1. Due to the bizarre "Caso Catania" (Catania Case), however, the club skipped Serie C1 and was admitted into Serie B, something that was only made possible by the Italian Football Federation (FIGC)'s decision to resolve the Catania situation by increasing the number of teams in Serie B from 20 to 24 and promoting Fiorentina for "sports merits." In the 2003 off-season, the club also bought back the right to use the Fiorentina name and the famous shirt design, and re-incorporated itself as ACF Fiorentina. The club finished the 2003–04 season in sixth place and won the playoff against Perugia to return to top-flight football.
In their first season back in Serie A, however, the club struggled to avoid relegation, only securing survival on the last day of the season on head-to-head record against Bologna and Parma. In 2005, Della Valle decided to appoint Pantaleo Corvino as new sports director, followed by the appointment of Cesare Prandelli as head coach in the following season. The club made several signings during the summer transfer market, most notably Luca Toni and Sébastien Frey. This drastic move earned them a fourth-place finish with 74 points and a Champions League qualifying round ticket. Toni scored 31 goals in 38 appearances, the first player to pass the 30-goal mark since Antonio Valentin Angelillo in the 1958–59 season, for which he was awarded the European Golden Boot. On 14 July 2006, however, Fiorentina were relegated to Serie B due to their involvement in the 2006 Serie A match fixing scandal and given a 12-point penalty. The team was reinstated to the Serie A on appeal, but with a 19-point penalty for the 2006–07 season. The team's 2006–07 Champions League place was also revoked. After the start of the season, Fiorentina's penalisation was reduced from 19 points to 15 on appeal to the Italian courts. In spite of this penalty, they managed to secure a place in the UEFA Cup.
Despite Toni's departure to Bayern Munich, Fiorentina had a strong start to the 2007–08 season and were tipped by Italian national team head coach Marcello Lippi, among others, as a surprise challenger for the "Scudetto", and although this form tailed off towards the middle of the season, the "Viola" managed to qualify for the Champions League. In Europe, the club reached the semi-final of the UEFA Cup, where they were ultimately defeated by Rangers on penalties. The 2008–09 season continued this success, a fourth-place finish assuring Fiorentina's spot in 2010's Champions League playoffs. Their European campaign was also similar to that of the previous run, relegated to the 2008–09 UEFA Cup and were eliminated by Ajax in the end.
In the 2009–10 season, Fiorentina started their domestic campaign strongly before steadily losing momentum and slipped to mid-table positions at the latter half of the season. In Europe, the team proved to be a surprise dark horse: after losing their first away fixture against Lyon, they staged a comeback with a five-match streak by winning all their remaining matches (including defeating Liverpool home and away). The "Viola" qualified as group champions, but eventually succumbed to Bayern Munich due to the away goals rule. This was controversial due to a mistaken refereeing decision by Tom Henning Øvrebø, who allowed a clearly offside goal for Bayern in the first leg. Bayern eventually finished the tournament as runners-up, making a deep run all the way to the final. The incident called into attention the possible implementation of video replays in football. Despite a good European run and reaching the semi-finals in the Coppa Italia, Fiorentina failed to qualify for Europe.
During this period, on 24 September 2009, Andrea Della Valle resigned from his position as chairman of Fiorentina, and announced all duties would be temporarily transferred to Mario Cognini, Fiorentina's vice-president until a permanent position could be filled.
The 2010s: Post-Prandelli Era.
In June 2010, the "Viola" bid farewell to long-time manager Cesar Prandelli, by then the longest-serving coach in the team's history, who was departing to coach the Italian national team. Catania manager Siniša Mihajlović was appointed to replace him. The club spent much of the early 2010–11 season in last place, but their form improved and Fiorentina ultimately finished ninth. Following a 1–0 defeat to Chievo in November 2011, Mihajlović was sacked and replaced by Delio Rossi. After a brief period of improvements, the "Viola" were again fighting relegation, prompting the sacking of Sporting Director Pantaleo Corvino in early 2012 following a 0–5 home defeat to Juventus. Their bid for survival was kept alive by a number of upset victories away from home, notably at Roma and Milan. During a home game against Novara, trailing 0–2 within half an hour, manager Rossi decided to substitute midfielder Adem Ljajić early. Ljajić sarcastically applauded him in frustration, whereupon Rossi retaliated by physical assaulting his player, an action that ultimately prompted his termination by the club. His replacement, caretaker manager Vincenzo Guerini, then guided the team away from the relegation zone to a 13th-place finish to end the turbulent year.
To engineer a resurrection of the club after the disappointing season, the Della Valle family invested heavily in the summer of 2012, buying 17 new players and appointing Vincenzo Montella as head coach. The team began the season well, finishing the calendar year in joint third place and eventually finishing the 2012–13 season in fourth, enough for a position in the 2013–14 Europa League.
The club lost fan favourite Stevan Jovetić during the summer of 2013, selling him to English Premier League club Manchester City for a €30 million transfer fee. They also sold Adem Ljajić to Roma and Alessio Cerci to Torino, using the funds to bring in Mario Gómez, Josip Iličić and Ante Rebić, among others. During the season, Fiorentina topped their Europa League group, moving on to the round of 32 to face Danish side Esbjerg fB, which Fiorentina defeated 4–2 on aggregate. In the following round of 16, however, they then lost to Italian rivals Juventus 2–1 on aggregate, ousting them from the competition. At the end of the season, the team finished fourth again in the league, and also finishing they year as Coppa Italia runners-up after losing 3–1 to Napoli in the final.
In 2014–15, during the 2015 winter transfer window, the team club sold star winger Juan Cuadrado to Chelsea for €30 million but were able to secure the loan of Mohamed Salah in exchange, who was a revelation in the second half of the season. Their 2014–15 Europa League campaign saw them progress to the semi-finals, where they were knocked-out by Spanish side Sevilla, the eventual champions. In the 2014–15 domestic season, Fiorentina once again finished fourth, thus qualifying for the 2015–16 Europa League. In June 2015, Vincenzo Montella was sacked as manager after the club grew impatient with the coaches inability to prove his commitment to the club, later appointing Paulo Sousa on June 21 as the team's new head coach.
During the summer of 2015, Fiorentina participated in the International Champions Cup for the first time, where they lost 4–2 against Paris Saint Germain but went on to defeat Barcelona 2–1 at home and Chelsea 0–1 away. The results of the latter two games showed signs of a rejuvenated squad and a positive look towards their 2015–16 campaign.
Managerial history.
Fiorentina have had many managers and head coaches throughout their history. Below is a chronological list from the club's foundation in 1926 to the present day.
Club strip.
Badge.
The official emblem of the city of Florence, a red fleur-de-lis on a white field, has been pivotal in the all-round symbolism of the club.
Over the course of the club's history, they have had several badge changes, all of which incorporated Florence's fleur-de-lis in some way. The first one was nothing more than the city's coat of arms, a white shield with the red fleur-de-lis inside. It was soon changed to a very stylised fleur-de-lis, always red, and sometimes even without the white field. The most common symbol, adopted for about 20 years, had been a white lozenge with the flower inside. During the season they were Italian champions, the lozenge disappeared and the flower was overlapped with the "scudetto".
The logo introduced by owner Flavio Pontello in 1980 was particularly distinct, consisting of one-half of the city of Florence's emblem and one-half of the letter "F", for Fiorentina. People disliked it when it was introduced, believing it was a commercial decision and, above all, because the symbol bore more of a resemblance to a halberd than a fleur-de-lis.
Today's logo is a kite shaped double lozenge bordered in gold. The outer lozenge has a purple background with the letters "AC" in white and the letter "F" in red, standing for the club's name. The inner lozenge is white with a gold border and the red fleur-de-lis of Florence. This logo had been in use from 1992 to 2002, but after the financial crisis and resurrection of the club the new one couldn't use the same logo. Florence's "comune" instead granted Florentia Viola use of the stylised coat of arms used in other city documents. Diego Della Valle acquired the current logo the following year in a judicial auction for a fee of €2.5 million, making it the most expensive logo in Italian football.
Kit and colours.
When Fiorentina was founded in 1926, the players wore red and white halved shirts derived from the colour of the city emblem. The more well-known and highly distinctive purple kit was adopted in 1928 and has been used ever since, giving rise to the nickname "La Viola" ("The Purple (team)"). Tradition has it that Fiorentina got their purple kit by mistake after an accident washing the old red and white coloured kits in the river.
The away kit has always been predominantly white, sometimes with purple and red elements, sometimes all-white. The shorts had been purple when the home kit was with white shorts. Fiorentina's third kit was first one in the 1995–96 season and it was all-red with purple borders and two lilies on the shoulders. The red shirt has been the most worn 3rd shirt by Fiorentina, although they also wore rare yellow shirts ('97–'98, '99–'00 and '10–'11) and a sterling version, mostly in the Coppa Italia, in 2000–01.
Honours.
National titles.
Serie A:
Coppa Italia:
Supercoppa Italiana:
European titles.
European Cup:
UEFA Europa League:
UEFA Cup Winners' Cup:
Minor titles.
Coppa Grasshoppers
Mitropa Cup
Anglo-Italian League Cup
Copa EuroAmericana
Serie B
Serie C2 (as "Florentia Viola")
UEFA rankings.
Club coefficients.
This is the UEFA club's coefficient as of 17 April 2015:
Fiorentina as a company.
A.C. Fiorentina S.p.A. was unable to register for 2002–03 Serie B due to financial difficulties, and then the sports title was transferred to a new company thanks to Article 52 of N.O.I.F., while the old company was liquidated. At that time the club was heavily rely on windfall profit from selling players, especially in pure player swap or cash plus player swap that potentially increase the cost by the increase in amortization of player contracts (an intangible assets). For example, Marco Rossi joined Fiorentina for 17 billion lire in 2000, but at the same time Lorenzo Collacchioni moved to Salernitana for 1 billion lire, making the club had a player profit of 997 million lire and extra 1 billion lire to be amortize in 5-year. In 1999, Emiliano Bigica also swapped with Giuseppe Taglialatela, which the latter was valued for 10 billion lire. The operating income (excluding windfall profit from players trading) of 2000–01 season was minus 113,271,475,933 Italian lire (minus €58,499,835). It was only boosted by the sales of Francesco Toldo, Rui Costa in June 2001 (a profit of 134.883 billion lire; €69.661 million). However, alleged to Parma for a reported 140 million lire. The two players eventually joined Inter Milan and A.C. Milan in 2001–02 financial year instead, for undisclosed fees. Fail to have financial support from the owner Vittorio Cecchi Gori, the club windup due to its huge imbalance in operating income.
Since re-established in 2002, ACF Fiorentina S.p.A. yet to self-sustain to keep the team in top division as well as in European competitions. In the 2005 financial year, which cover the first Serie A season, the club made a net loss of €9,159,356, followed by a net loss of €19,519,789. In 2006 (2005–06 Serie A and 2006–07 Serie A), Fiorentina heavily invested on players, made the amortisation of intangible asset (the player contract) had increased from €17.7 million to €24 million. However the club suffered from 2006 Italian football scandal, meant the club did not qualify for Europe. In 2007 Fiorentina almost break-even, with a net loss of just €3,704,953. In 2007 financial year the TV revenue increased after qualified to 2007–08 UEFA Cup. Despite qualified to 2008–09 UEFA Champions League, Fiorentina made a net loss of €9,179,484 in 2008 financial year after the increase in TV revenue was outweighed by the increase in wage. In the 2009 financial year, Fiorentina made a net profit of €4,442,803, largely due to the profit on selling players (€33,631,489 from players such as Felipe Melo, Giampaolo Pazzini and Zdravko Kuzmanović; increased from about €3.5 million in 2008). However it also offset by the write-down of selling players (€6,062,545, from players such as Manuel da Costa, Arturo Lupoli and Davide Carcuro).
After the club failed to qualify to Europe at the end of 2009–10 Serie A, as well as lack of player profit, Fiorentina turnover was decreased from €140,040,713 in 2009 to just €79,854,928, despite wage bill also fell, "la Viola" still made a net loss of €9,604,353. In the 2011 financial year, the turnover slipped to €67,076,953, as the club's lack of capital gains from selling players and 2010 financial year still included the installments from UEFA for participating 2009–10 UEFA Europa League. Furthermore, the gate income had dropped from €11,070,385 to €7,541,260. The wage bill did not fall much and in reverse the amortization of transfer fee had sightly increased due to new signing. "La Viola" had saving in other cost but counter-weighted by huge €11,747,668 write-down for departed players, due to D'Agostino, Frey and Mutu, but the former would counter-weight by co-ownership financial income, which all made the operating cost remained high as worse as last year. Moreover, in 2010 the result was boosted by acquiring the asset from subsidiary (related to AC Fiorentina) and the re-valuation of its value in separate balance sheet. If deducting that income (€14,737,855), 2010 financial year was net loss 24,342,208 and 2011 result was worsen €8,131,876 only in separate balance sheet. In 2012, the club benefited from the sales of Matija Nastasić and Valon Behrami, followed by Stevan Jovetić and Adem Ljajić in 2013. In 2014, due to €28.4 million drop from the windfall profit of selling players, the club recorded their worst financial results since re-foundation, despite even the club maintained the same level of windfall profit, the result would still worse than in 2013. Moreover, Fiorentina also revealed that the club had a relevant football net income of minus €19.5 million in the first assessment period of UEFA Financial Fair Play Regulations in 2013–14 season (in May 2014). (aggregate of 2012 and 2013 results), which within the limit of minus €45 million, as well as minus €25.5 million in assessment period 2014–15 (aggregate of 2012, 2013 and 2014 results). However, as the limit was reduced to minus €30 million in assessment period 2015–16, 2016–17 and 2017–18 season, the club had to achieve a relevant net income of positive €5.6 million in 2015 financial year. "La Viola" sold Juan Cuadrado to Chelsea in January 2015 for €30 million fee, in order to make the club eligible to 2016–17 edition of UEFA competitions.
 

</doc>
<doc id="3168" url="https://en.wikipedia.org/wiki?curid=3168" title="Afrobeat">
Afrobeat

Afrobeat is a combination of traditional Nigerian music, jazz, highlife, funk, and chanted vocals, fused with percussion and vocal styles, popularised in Africa in the 1970s. It was named by Nigerian multi-instrumentalist and bandleader Fela Kuti, who is responsible for the creation of the style and spreading the genre outside of Nigeria. Fela used it to revolutionize musical structure as well as the political context in his country, Nigeria. It was Kuti who coined the term "afrobeat" upon his return from a U.S. tour with his group Nigeria '70 (formerly Koola Lobitos). Afrobeat features chants, call-and-response vocals, and complex, interacting rhythms.
The new sound hailed from a club that he established called the Afrika Shrine. Upon arriving in Nigeria, Kuti also changed the name of his group to Africa '70. The band maintained a five-year residency in the Afrika Shrine from 1970 to 1975 while afrobeat thrived among Nigerian youth. Afrobeat is now one of the most recognizable music genres in the world and has influenced as many Western musicians as it has African ones with its exuberant style and polyrhythms.
Origins.
Afrobeat originated from Fuji, heavy Nigerian drumbeats and ighlif]. It was later exported to the southern part of Nigeria in the 1970s, Fela Kuti, experimented with many different forms of contemporary music of the time. Prevalent in his and Lagbaja's music are native nigerian harmonies and rhythms, taking different elements and combining, modernizing, and improvising upon them. Politics are essential to Afrobeat, since founder Kuti used social criticism to pave the way for social change. His message can be described as confrontational and controversial, which can be related to the political climate of most of the African countries in the 1970s, many of which were dealing with political injustice and military corruption while recovering from the transition from colonial governments to self-determination. As the genre spread throughout the African continent many bands took up the style. The recordings of these bands and their songs were rarely heard or exported outside the originating countries but many can now be found on compilation albums and CDs from specialist record shops.
Instrumentation.
Big band (15 to 30 pieces: Fela-era afrobeat) and energetic performances
Fela Kuti included the traditional Gbedu drum in his ensemble, with a percussionist pounding out a thunderous rhythm from a drum lying on its side.
Influence.
Many jazz musicians have been attracted to afrobeat. From Roy Ayers in the 1970s to Randy Weston in the 1990s, there have been collaborations that have resulted in albums such as "Africa: Centre of the World" by Roy Ayers, released on the Polydore label in 1981. In 1994 Branford Marsalis, the American jazz saxophonist, included samples of Fela's "Beast of No Nation" on his "Buckshot LeFonque" album. The new generation of DJs and musicians of the 2000s who have fallen in love with both Kuti's material and other rare releases have made compilations and remixes of these recordings, thus re-introducing the genre to new generations of listeners and fans of afropop and groove (see Afrobeats section below).
Afrobeat has profoundly influenced important contemporary producers and musicians like Brian Eno and David Byrne, who credit Fela Kuti as an essential influence. Both worked on Talking Heads' highly acclaimed 1980 album "Remain In Light", which brought polyrhythmic afrobeat influences to Western music. More recently, the horn section of Antibalas have been guest musicians on TV On The Radio's highly acclaimed 2008 album "Dear Science", as well as on British band Foals' 2008 album, "Antidotes". Some Afrobeat influence can also be found in the music of Vampire Weekend and Paul Simon.
Afrobeats.
Afrobeats (a term also sometimes used to denote popular popular Nigerian music, hiplife, or Afropop) is an emerging genre: drawing from broad continental and diasporic sounds. The new genre seeks inspiration from Afrobeat, hiplife, house music, Jamaican dancehall, as well as various local musics. According to David Drake, the eclectic genre “reimagines diasporic influences and—more often than not—completely reinvents them.” However, some caution against equating Afrobeats to contemporary pan-African music, in order to prevent the erasure of local musical contributions.
Afrobeats is primarily produced between Lagos, Accra, and London. Paul Gilroy, of "The Black Atlantic", reflects on the changing London music scene as a result of shifting demographics:"We are moving towards an African majority which is diverse both in its cultural habits and in its relationship to colonial and postcolonial governance, so the shift away from Caribbean dominance needs to be placed in that setting. Most of the grime folks are African kids, either the children of migrants or migrants themselves. It's not clear what Africa might mean to them" Many first and second generation African immigrants follow - and produce - Afrobeats music. Fuse ODG, a UK artist of Ghanaian descent, coins #TINA or This is New Africa as a means to change perceptions of Africa:"This movement will shed light on Africa in a positive way and focus on how we can improve Africa. It’s not about just plying your talents in the Western world; it’s about going back home and helping Africa."
Notable afrobeat musicians.
Today.
There are several active afrobeat bands worldwide today. Afrobeat today is often mixed with other genres, such as hip hop, makossa, gospel, skelewu, shoki, shakitibobo. dancehall and galala.
Modern afrobeat bands/artists include:

</doc>
<doc id="3170" url="https://en.wikipedia.org/wiki?curid=3170" title="Arithmetic function">
Arithmetic function

In number theory, an arithmetic, arithmetical, or number-theoretic function is a real or complex valued function "f"("n") defined on the set of natural numbers (i.e. positive integers) that "expresses some arithmetical property of "n"".
An example of an arithmetic function is the non-principal character (mod 4) defined by
where formula_2 is the Kronecker symbol.
To emphasize that they are being thought of as functions rather than sequences, values of an arithmetic function are usually denoted by "a"("n") rather than "a".
There is a larger class of number-theoretic functions that do not fit the above definition, e.g. the prime-counting functions. This article provides links to functions of both classes.
Notation.
formula_3   and   formula_4   mean that the sum or product is over all prime numbers:
Similarly,   formula_7   and   formula_8   mean that the sum or product is over all prime powers with strictly positive exponent (so 1 is not included):
formula_10   and   formula_11   mean that the sum or product is over all positive divisors of "n", including 1 and "n". E.g., if "n" = 12,
The notations can be combined:   formula_13   and   formula_14   mean that the sum or product is over all prime divisors of "n". E.g., if "n" = 18,
and similarly   formula_16   and   formula_17   mean that the sum or product is over all prime powers dividing "n". E.g., if "n" = 24,
Multiplicative and additive functions.
An arithmetic function "a" is
Two whole numbers "m" and "n" are called coprime if their greatest common divisor is 1; i.e., if there is no prime number that divides both of them.
Then an arithmetic function "a" is
Ω("n"), "ω"("n"), "ν"("n") – prime power decomposition.
The fundamental theorem of arithmetic states that any positive integer "n" can be represented uniquely as a product of powers of primes:   formula_19   where "p" < "p" < ... < "p" are primes and the "a" are positive integers. (1 is given by the empty product.)
It is often convenient to write this as an infinite product over all the primes, where all but a finite number have a zero exponent. Define ν("n") as the exponent of the highest power of the prime "p" that divides "n". I.e. if "p" is one of the "p" then ν("n") = "a", otherwise it is zero. Then
In terms of the above the functions ω and Ω are defined by
To avoid repetition, whenever possible formulas for the functions listed in this article are given in terms of "n" and the corresponding "p", "a", ω, and Ω.
Multiplicative functions.
σ("n"), τ("n"), "d"("n") – divisor sums.
σ("n") is the sum of the "k"th powers of the positive divisors of "n", including 1 and "n", where "k" is a complex number.
σ("n"), the sum of the (positive) divisors of "n", is usually denoted by σ("n").
Since a positive number to the zero power is one, σ("n") is therefore the number of (positive) divisors of "n"; it is usually denoted by "d"("n") or τ("n") (for the German "Teiler" = divisors).
Setting "k" = 0 in the second product gives
φ("n") – Euler totient function.
φ("n"), the Euler totient function, is the number of positive integers not greater than "n" that are coprime to "n".
J("n") – Jordan totient function.
J("n"), the Jordan totient function, is the number of "k"-tuples of positive integers all less than or equal to "n" that form a coprime ("k" + 1)-tuple together with "n". It is a generalization of Euler's totient, .
μ("n") – Möbius function.
μ("n"), the Möbius function, is important because of the Möbius inversion formula. See Dirichlet convolution, below.
This implies that μ(1) = 1. (Because Ω(1) = ω(1) = 0.)
τ("n") – Ramanujan tau function.
τ("n"), the Ramanujan tau function, is defined by its generating function identity:
Although it is hard to say exactly what "arithmetical property of "n"" it "expresses", (τ("n") is (2π) times the "n"th Fourier coefficient in the q-expansion of the modular discriminant function) it is included among the arithmetical functions because it is multiplicative and it occurs in identities involving certain σ("n") and "r"("n") functions (because these are also coefficients in the expansion of modular forms).
"c"("n") – Ramanujan's sum.
"c"("n"), Ramanujan's sum, is the sum of the "n"th powers of the primitive "q"th roots of unity:
Even though it is defined as a sum of complex numbers (irrational for most values of "q"), it is an integer. For a fixed value of "n" it is multiplicative in "q":
Many of the functions mentioned in this article have expansions as series involving these sums; see the article Ramanujan's sum for examples.
Completely multiplicative functions.
λ("n") – Liouville function.
λ("n"), the Liouville function, is defined by
χ("n") – characters.
All Dirichlet characters χ("n") are completely multiplicative. An example is the non-principal character (mod 4) defined in the introduction. Two characters have special notations:
The principal character (mod "n") is denoted by χ("a") (or χ("a")). It is defined as
The quadratic character (mod "n") is denoted by the Jacobi symbol for odd "n" (it is not defined for even "n".):
In this formula formula_32 is the Legendre symbol, defined for all integers "a" and all odd primes "p" by
Following the normal convention for the empty product, formula_34
Additive functions.
ω("n") – distinct prime divisors.
ω("n"), defined above as the number of distinct primes dividing "n", is additive.
Completely additive functions.
Ω("n") – prime divisors.
Ω("n"), defined above as the number of prime factors of "n" counted with multiplicities, is completely additive.
ν("n") – "p"-adic valuation of an integer "n".
For a fixed prime "p", ν("n"), defined above as the exponent of the largest power of "p" dividing "n", is completely additive.
Neither multiplicative nor additive.
("x"), Π("x"), θ("x"), ψ("x") – prime count functions.
These important functions (which are not arithmetic functions) are defined for non-negative real arguments, and are used in the various statements and proofs of the prime number theorem. They are summation functions (see the main section just below) of arithmetic functions which are neither multiplicative nor additive.
π("x"), the prime counting function, is the number of primes not exceeding "x". It is the summation function of the characteristic function of the prime numbers.
A related function counts prime powers with weight 1 for primes, 1/2 for their squares, 1/3 for cubes, … It is the summation function of the arithmetic function which takes the value 1/"k" on integers which are the k-th power of some prime number, and the value 0 on other integers.
θ"("x") and ψ"("x"), the Chebyshev functions,
are defined as sums of the natural logarithms of the primes not exceeding "x".
The Chebyshev function "ψ"("x") is the summation function of the von Mangoldt function just below.
Λ("n") – von Mangoldt function.
Λ("n"), the von Mangoldt function, is 0 unless the argument is a prime power, in which case it is the natural log of the prime:
"p"("n") – partition function.
"p"("n"), the partition function, is the number of ways of representing "n" as a sum of positive integers, where two representations with the same summands in a different order are not counted as being different:
λ("n") – Carmichael function.
λ("n"), the Carmichael function, is the smallest positive number such that formula_41   for all "a" coprime to "n". Equivalently, it is the least common multiple of the orders of the elements of the multiplicative group of integers modulo "n".
For powers of odd primes and for 2 and 4, λ("n") is equal to the Euler totient function of "n"; for powers of 2 greater than 4 it is equal to one half of the Euler totient function of "n":
and for general "n" it is the least common multiple of λ of each of the prime power factors of "n":
"h"("n") – Class number.
"h"("n"), the class number function, is the order of the ideal class group of an algebraic extension of the rationals with discriminant "n". The notation is ambiguous, as there are in general many extensions with the same discriminant. See quadratic field and cyclotomic field for classical examples.
"r"("n") – Sum of "k" squares.
"r"("n") is the number of ways "n" can be represented as the sum of "k" squares, where representations that differ only in the order of the summands or in the signs of the square roots are counted as different.
Summation functions.
Given an arithmetic function "a(n)", its summation function "A(x)" is defined by
"A" can be regarded as a function of a real variable. Given a positive integer "m", "A" is constant along open intervals "m" < "x" < "m" + 1, and has a jump discontinuity at each integer for which "a(m)" ≠ 0.
Since such functions are often represented by series and integrals, to achieve pointwise convergence it is usual to define the value at the discontinuities as the average of the values to the left and right:
Individual values of arithmetic functions may fluctuate wildly – as in most of the above examples. Summation functions "smooth out" these fluctuations. In some cases it may be possible to find asymptotic behaviour for the summation function for large "x".
A classical example of this phenomenon is given by the divisor summatory function, the summation function of "d"("n"), the number of divisors of "n":
An average order of an arithmetic function is some simpler or better-understood function which has the same summation function asymptotically, and hence takes the same values "on average". We say that "g" is an "average order" of "f" if
as "x" tends to infinity. The example above shows that "d"("n") has the average order log("n").
Dirichlet convolution.
Given an arithmetic function "a(n)", let "F(s)", for complex "s", be the function defined by the corresponding Dirichlet series (where it converges):
"F(s)" is called a generating function of "a(n)". The simplest such series, corresponding to the constant function "a"("n") = 1 for all "n", is ς("s") the Riemann zeta function.
The generating function of the Möbius function is the inverse of the zeta function:
Consider two arithmetic functions "a" and "b" and their respective generating functions "F"("s") and "F"("s"). The product "F"("s")"F"("s") can be computed as follows:
It is a straightforward exercise to show that if "c"("n") is defined by
then
This function "c" is called the Dirichlet convolution of "a" and "b", and is denoted by formula_56.
A particularly important case is convolution with the constant function "a"("n") = 1 for all "n", corresponding to multiplying the generating function by the zeta function:
Multiplying by the inverse of the zeta function gives the Möbius inversion formula:
If "f" is multiplicative, then so is "g". If "f" is completely multiplicative, then "g" is multiplicative, but may or may not be completely multiplicative.
Relations among the functions.
There are a great many formulas connecting arithmetical functions with each other and with the functions of analysis, especially powers, roots, and the exponential and log functions.
Here are a few examples:
Sums of squares.
There is a formula for r in the section on class numbers below.
Define the function σ("n") as
That is, if "n" is odd, σ("n") is the sum of the "k"th powers of the divisors of "n", i.e. σ("n"), and if "n" is even it is the sum of the "k"th powers of the even divisors of "n" minus the sum of the "k"th powers of the odd divisors of "n".
Adopt the convention that Ramanujan's τ("x") = 0 if "x" is not an integer.
Divisor sum convolutions.
Here "convolution" does not mean "Dirichlet convolution" but instead refers to the formula for the coefficients of the product of two power series:
The sequence formula_84 is called the convolution or the Cauchy product of the sequences "a" and "b".
<br>See Eisenstein series for a discussion of the series and functional identities involved in these formulas.
Since σ("n") (for natural number "k") and τ("n") are integers, the above formulas can be used to prove congruences for the functions. See Tau-function for some examples.
Extend the domain of the partition function by setting "p"(0) = 1.
Class number related.
Peter Gustav Lejeune Dirichlet discovered formulas that relate the class number "h" of quadratic number fields to the Jacobi symbol.
An integer "D" is called a fundamental discriminant if it is the discriminant of a quadratic number field. This is equivalent to "D" ≠ 1 and either a) "D" is squarefree and "D" ≡ 1 (mod 4) or b) "D" ≡ 0 (mod 4), "D"/4 is squarefree, and "D"/4 ≡ 2 or 3 (mod 4).
Extend the Jacobi symbol to accept even numbers in the "denominator" by defining the Kronecker symbol:
Then if "D" < −4 is a fundamental discriminant
There is also a formula relating "r" and "h". Again, let "D" be a fundamental discriminant, "D" < −4. Then
Prime-count related.
Let formula_94   be the "n"th harmonic number.   Then
The Riemann hypothesis is also equivalent to the statement that, for all "n" > 5040,
Menon's identity.
In 1965 P. Kesava Menon proved
This has been generalized by a number of mathematicians, e.g.:
B. Sury
N. Rao
where "a", "a", ..., "a" are integers, gcd("a", "a", ..., "a", "n") = 1.
L. Tóth
where "m" and "m" are odd, "m" = lcm("m", "m").
In fact, if "f" is any arithmetical function
where * stands for Dirichlet convolution.
Miscellaneous.
Let "m" and "n" be distinct, odd, and positive. Then the Jacobi symbol satisfies the law of quadratic reciprocity:
Let λ("n") be Liouville's function. Then
Let λ("n") be Carmichael's function. Then

</doc>
<doc id="3172" url="https://en.wikipedia.org/wiki?curid=3172" title="ANSI C">
ANSI C

ANSI C, ISO C and Standard C refer to the successive standards for the C programming language published by the American National Standards Institute (ANSI) and the International Organization for Standardization (ISO). Historically, the names referred specifically to the original and best-supported version of the standard (known as C89 or C90). Software developers writing in C are encouraged to conform to the standards, as doing so aids portability between compilers.
History and outlook.
The first standard for C was published by ANSI. Although this document was subsequently adopted by International Organization for Standardization (ISO) and subsequent revisions published by ISO have been adopted by ANSI, the name ANSI C (rather than ISO C) is still more widely used. While some software developers use the term ISO C, others are standards body–neutral and use Standard C.
C89.
In 1983, the American National Standards Institute formed a committee, X3J11, to establish a standard specification of C. The standard was completed in 1989 and ratified as ANSI X3.159-1989 "Programming Language C." This version of the language is often referred to as "ANSI C". Later on sometimes the label "C89" is used to distinguish it from C99 but using the same labelling method.
C90.
The same standard as C89 was ratified by the International Organization for Standardization as ISO/IEC 9899:1990, with only formatting changes, which is sometimes referred to as C90. Therefore, the terms "C89" and "C90" refer to essentially the same language.
This standard has been withdrawn by both ANSI/INCITS and ISO/IEC.
C95.
In 1995 the ISO published an extension, called Amendment 1, for the ANSI-C standard. Its full name finally was "ISO/IEC 9899/AMD1:1995" or nicknamed "C95". Aside to error correction there were further changes to the language capabilities, such as:
In addition to the amendment, two technical corrigenda were published by ISO for C90:
C99.
In March 2000, ANSI adopted the ISO/IEC 9899:1999 standard. This standard is commonly referred to as C99. Some notable additions to the previous standard include:
Three technical corrigenda were published by ISO for C99: 
This standard has been withdrawn by both ANSI/INCITS and ISO/IEC in favour of C11.
C11.
"C11" is the current standard for the C programming language. Notable features introduced over the previous revision include improved Unicode support, type-generic expressions using the new codice_15 keyword, a cross-platform multi-threading API (codice_16) and atomic types support in both core language and the library (codice_17).
One technical corrigendum has been published by ISO for C11:
Other ISO publications.
As part of the standardization process, ISO also publishes technical reports and specifications:
More technical specifications are in development and pending approval, including the fifth and final part of TS 18661, a software transactional memory specification, and parallel library extensions.
Support from major compilers.
ANSI C is now supported by almost all the widely used compilers. Most of the C code being written nowadays is based on ANSI C. Any program written "only" in standard C and without any hardware dependent assumptions is virtually guaranteed to compile correctly on any platform with a conforming C implementation. Without such precautions, most programs may compile only on a certain platform or with a particular compiler, due, for example, to the use of non-standard libraries, such as GUI libraries, or to the reliance on compiler- or platform-specific attributes such as the exact size of certain data types and byte endianness.
Compliance detectability.
To mitigate the differences between K&R C and the ANSI C standard, the codice_18 ("standard c") macro can be used to split code into ANSI and K&R sections.
In the above example, a prototype is used in a function declaration for ANSI compliant implementations, while an obsolescent non-prototype declaration is used otherwise. Those are still ANSI-compliant as of C99. Note how this code checks both definition and evaluation: this is because some implementations may set codice_18 to zero to indicate non-ANSI compliance.

</doc>
<doc id="3173" url="https://en.wikipedia.org/wiki?curid=3173" title="Alien and Sedition Acts">
Alien and Sedition Acts

The Alien and Sedition Acts were four bills passed by the Federalist dominated 5th United States Congress, and signed into law by Federalist President John Adams in 1798. They made it harder for an immigrant to become a citizen (Naturalization Act), allowed the president to imprison and deport noncitizens who were deemed dangerous (Alien Friends Act) or who were from a hostile nation (Alien Enemies Act), and criminalized making false statements that were critical of the federal government (Sedition Act). The Federalists argued that they strengthened national security during an undeclared naval war with France. Critics argued that they were primarily an attempt to suppress voters who disagreed with the Federalist party, and violated the right of freedom of speech in the First Amendment. Three of the acts were repealed after the Democratic-Republican party of Thomas Jefferson came to power. But the Alien Enemies Act remained in effect, was revised and codified in 1918 for use in World War I, and was used by President Franklin Delano Roosevelt to imprison Japanese, German, and Italian aliens during World War II. Following cessation of hostilities, the act was used by President Harry S. Truman to continue to imprison, then deport, aliens of the formerly hostile nations. In 1948 the Supreme Court determined that presidential powers under the acts continued after cessation of hostilities, until there was a peace treaty with the hostile nation. The revised Alien Enemies Act remains in effect today.
The Naturalization Act increased the residency requirement for American citizenship from five to 14 years. At the time, the majority of immigrants supported Thomas Jefferson and the Democratic-Republicans, the political opponents of the Federalists. The Alien Friends Act allowed the president to imprison or deport aliens considered "dangerous to the peace and safety of the United States" at any time, while the Alien Enemies Act authorized the president to do the same to any male citizen of a hostile nation above the age of 14 during times of war. Lastly, the controversial Sedition Act restricted speech which was critical of the federal government. Under the Sedition Act, the Federalists allowed people, who were accused of violating the sedition laws, to use truth as a defense. The Sedition Act resulted in the prosecution and conviction of many Jeffersonian newspaper owners who disagreed with the government.
The acts were denounced by Democratic-Republicans and ultimately helped them to victory in the 1800 election, when Thomas Jefferson defeated the incumbent President Adams. The Sedition Act and the Alien Friends Act were allowed to expire in 1800 and 1801, respectively. The Alien Enemies Act, however, remains in effect as 50 USC Sections 21–24. 
History.
The opposition to the Federalists, spurred on by Democratic-Republicans, reached new heights at this time with the Democratic-Republicans supporting France still in the midst of the French Revolution. Some appeared to desire an event similar to the French Revolution to come to the United States to overthrow the government. When Democratic-Republicans in some states refused to enforce federal laws, such as the 1791 whiskey tax, the first tax levied by the national government, and threatened to rebel, Federalists threatened to send in the army to force them to capitulate. As the unrest sweeping Europe was bleeding over into the United States, calls for secession reached unparalleled heights, and the fledgling nation seemed ready to tear itself apart. Some of this was seen by Federalists as having been caused by French and French-sympathizing immigrants. The Alien Act and the Sedition Act were meant to guard against this perceived threat of anarchy.
They were a major political issue in the elections of 1798 and 1800. They were very controversial in their own day, as they remain to the present day. Opposition to them resulted in the highly controversial Virginia and Kentucky Resolutions, authored by James Madison and Thomas Jefferson. Prominent prosecutions under the Sedition Act include:
19th century.
The Democratic-Republicans made the Alien and Sedition Acts an important issue in the 1800 election. Thomas Jefferson, upon assuming the Presidency, pardoned those still serving sentences under the Sedition Act, and their fines were soon repaid. It has been said that the Alien Acts were aimed at Albert Gallatin, and the Sedition Act aimed at Benjamin Bache's "Aurora". While government authorities prepared lists of aliens for deportation, many aliens fled the country during the debate over the Alien and Sedition Acts, and Adams never signed a deportation order.
The Alien and Sedition Acts were never appealed to the Supreme Court, whose right of judicial review was not established until "Marbury v. Madison" in 1803. Subsequent mentions in Supreme Court opinions beginning in the mid-20th century have assumed that the Sedition Act would today be found unconstitutional.
Thomas Jefferson and James Madison also secretly drafted the Kentucky and Virginia Resolutions denouncing the federal legislation, though many other state legislatures strongly opposed these resolutions. Though the resolutions followed Madison's "interposition" approach, Jefferson advocated nullification and at one point drafted a threat for Kentucky to secede. Jefferson's biographer Dumas Malone argued that this might have gotten Jefferson impeached for treason, had his actions become known at the time. In writing the Kentucky Resolutions, Jefferson warned that, "unless arrested at the threshold," the Alien and Sedition Acts would "necessarily drive these states into revolution and blood." Historian Ron Chernow says of this "he wasn't calling for peaceful protests or civil disobedience: he was calling for outright rebellion, if needed, against the federal government of which he was vice president." Jefferson "thus set forth a radical doctrine of states' rights that effectively undermined the constitution." Chernow argues that neither Jefferson nor Madison sensed that they had sponsored measures as inimical as the Alien and Sedition Acts themselves. Historian Garry Wills argued "Their nullification effort, if others had picked it up, would have been a greater threat to freedom than the misguided lien and seditio laws, which were soon rendered feckless by ridicule and electoral pressure" The theoretical damage of the Kentucky and Virginia resolutions was "deep and lasting, and was a recipe for disunion". George Washington was so appalled by them that he told Patrick Henry that if "systematically and pertinaciously pursued", they would "dissolve the union or produce coercion". The influence of Jefferson's doctrine of states' rights reverberated right up to the Civil War and beyond. Future president James Garfield, at the close of the Civil War, said that Jefferson's Kentucky Resolution "contained the germ of nullification and secession, and we are today reaping the fruits".
20th and 21st centuries.
The Alien Enemies Acts remained in effect at the outset of World War I. It was recodified to be part of the US war and national defense statutes (50 USC 21-24).
On December 7, 1941, responding to the bombing of Pearl Harbor, President Franklin Delano Roosevelt used the authority of the revised Alien Enemies Act to issue presidential proclamations 2525 (Alien Enemies - Japanese), 2526 (Alien Enemies - German), and 2527 (Alien Enemies - Italian), to apprehended, restrain, secure and remove Japanese, German, and Italian noncitizens. On February 19, 1942, citing authority of the wartime powers of the president and commander in chief, Roosevelt made Executive Order 9066, authorizing the Secretary of War to prescribe military areas, and giving him authority that superseded authority of other executives under Proclamations 2525-7. EO 9066 led to the internment of Japanese Americans, whereby over 110,000 people of Japanese ancestry living on the Pacific coast were forcibly relocated and forced to live in camps in the interior of the country, 62% of whom were United States citizens, not aliens. 
Hostilities ended as to Germany and Italy in May 1945, and as to Japan in August 1945. Alien enemies, and US citizens, continued to be held. On July 14, 1945, President Harry S. Truman issued Presidential Proclamation 2655, titled “Removal of Alien Enemies”. The proclamation gave the Attorney General authority regarding aliens enemies within the continental United States, to decide whether they are "dangerous to the public peace and safety of the United States", to order them removed, and to create regulations governing their removal. The proclamation cited the revised Alien Enemies Act (50 U.S.C. 21-24), as to powers of the President to makes public proclamation regarding "subjects of the hostile nation" more than 14 years old, inside the United States but not naturalized, to remove them as alien enemies and determine the means of removal. 
On September 8, 1945, Truman issued Presidential Proclamation 2662, titled "Removal of Alien Enemies". The revised Alien Enemies Act (50 U.S.C. 21-24) was cited as to removal of alien enemies in the interest of the public safety. The United States had agreed, at a conference in Rio de Janeiro in 1942, to assume responsibility for the restraint and repatriation of dangerous alien enemies to be sent to the United States from Latin American republics. In another inter-American conference in Mexico City on March 8, 1945, North and South American governments resolved to recommended adoption of measures to prevent aliens of hostile nations who were deemed to be security threats or threats to welfare, from remaining in North or South America. Truman gave authority to the Secretary of State to determine if alien enemies in the United States who were sent to the United States from Latin America, or who were in the United States illegally, endangered the welfare or security. The Secretary of State was given power to remove them "to destinations outside the limits of the Western Hemisphere", to the former enemy territory of the governments to whose "principles of which (the alien enemies) have adhered". The Department of Justice was directed to assist the Secretary of State I their prompt removal. 
On April 10, 1946, Truman issued Presidential Proclamation 2685, titled “Removal of Alien Enemies”, citing the revised Alien Enemies Act (50 U.S.C. 21-24) as to its provision for the “removal from the United States of alien enemies in the interest of the public safety”. Truman proclaimed regulations that were in addition to and supplemented other "regulations affecting the restraint and removal of alien enemies". As to alien enemies who had been brought into the continental United States from Latin America after December 1941, the proclamation gave the Secretary of State authority to decide if their presence was "prejudicial to the future security or welfare of the Americas", and to make regulations for their removal. 30 days was set as the reasonable time for them to "effect the recovery, disposal, and removal of (their) goods and effects, and for (their) departure.
In 1947 New York's Ellis Island continued to incarcerate hundreds of ethnic Germans. Fort Lincoln was a large internment camp still holding internees in North Dakota. North Dakota was represented by controversial Senator William "Wild Bill" Langer. Langer introduced a bill (S. 1749) "for the relief of all persons detained as enemy aliens", and directing the US Attorney General to cancel "outstanding warrants of arrest, removal, or deportation" for many German aliens still interned, listing many by name, and all of those detained by the Immigration and Naturalization Service (INS), which was under the Department of Justice (DOJ). It directed the INS not to issue any more warrants or orders, if their only basis was the original warrants of arrest. The bill never passed. The Attorney General gave up plenary jurisdiction over the last internee in Ellis Island late in 1948. Langer's bill did not pass. 
In Ludecke v. Watkins (1948), the Supreme Court weighed as to interpreting time of release under the Alien Enemies Act. German alien Kurt G. W. Ludecke was detained in 1941, under Proclamation 2526. Ludecke continued to be held after cessation of hostilities. In 1947, Ludecke petitioned for a writ of habeas corpus to order his release, after the Attorney General ordered him deported. The court ruled 5-4 to release Ludecke, but also found that the Alien Enemies Act allowed for detainment beyond the time hostilities ceased, until an actual treaty was signed with the hostile nation or government.
In 2015 presidential candidate Donald Trump and some legal scholars cited Roosevelt's application of the Alien Enemies Act, or the act itself, as a good example or legal precedent, to justify Trump's proposal to ban all Muslims from entering the United States, as part of the war on terror. Trump's proposal created a national and international media firestorm, even drawing criticism from foreign heads of state that historically do not get involved in United States presidential campaigns, and calling Trump xenophobic. A former Reagan Administration member countered that critics of the proposal, not Trump, were xenophobic, because "the Alien Enemies Act... is still on the books... (and people) in Congress for many decades (haven’t) repealed the law... (nor has) Barack Obama". Other critics argued that the proposal violated founding principals and was unconstitutional for singling out a religion, not a hostile nation, including the United States Pentagon and others who made the criticism that the proposal, and citation of the Alien Enemies proclamations as authority, played into the narrative of ISIS terrorists, that the United States was at war with the entire Muslim religion, not just with ISIS and other terrorist entities.
in JSTOR

</doc>
<doc id="3175" url="https://en.wikipedia.org/wiki?curid=3175" title="Antinomy">
Antinomy

Antinomy (Greek ἀντί, "antí", "against, in opposition to," and νόμος, "nómos", "law") literally means the mutual incompatibility, real or apparent, of two laws. It is a term used in logic and epistemology, particularly in the philosophy of Kant and Roberto Unger.
Kant's use.
The term acquired a special significance in the philosophy of Immanuel Kant (1724–1804), who used it to describe the equally rational but contradictory results of applying to the universe of pure thought the categories or criteria of reason that are proper to the universe of sensible perception or experience (phenomena). Empirical reason cannot here play the role of establishing rational truths because it goes beyond possible experience and is applied to the sphere of that which transcends it.
For Kant there are four antinomies, connected with:
In each antinomy, a thesis is contradicted by an antithesis. For example: in the First Antinomy, Kant proves the thesis that time must have a beginning by showing that if time had no beginning, then an infinity would have elapsed up until the present moment. This is a manifest contradiction because infinity cannot, by definition, be completed by "successive synthesis"—yet just such a finalizing synthesis would be required by the view that time is infinite; so the thesis is proven. Then he proves the antithesis, that time has no beginning, by showing that if time had a beginning, then there must have been "empty time" out of which time arose. This is incoherent (for Kant) for the following reason: Since, necessarily, no time elapses in this pretemporal void, then there could be no alteration, and therefore nothing (including time) would ever come to be: so the antithesis is proven. Reason makes equal claim to each proof, since they are both correct, so the question of the limits of time must be regarded as meaningless.
This was part of Kant's critical program of determining limits to science and philosophical inquiry. These contradictions are inherent in reason when it is applied to the world as it is in itself, independently of our perceptions of it (this has to do with the distinction between phenomena and noumena). Kant's goal in his critical philosophy was to identify what claims we are and are not justified in making, and the antinomies are a particularly illustrative example of his larger project.
However, there are many other examples of antinomy besides these four. A self-contradictory phrase such as "There is no absolute truth" can be considered an antinomy because this statement is suggesting in itself to be an absolute truth, and therefore denies itself any truth in its statement. A paradox such as "this sentence is false" can also be considered to be an antinomy; for the sentence to be true, it must be false, and vice versa. 

</doc>
<doc id="3189" url="https://en.wikipedia.org/wiki?curid=3189" title="Ascending chain condition">
Ascending chain condition

In mathematics, the ascending chain condition (ACC) and descending chain condition (DCC) are finiteness properties satisfied by some algebraic structures, most importantly, ideals in certain commutative rings. These conditions played an important role in the development of the structure theory of commutative rings in the works of David Hilbert, Emmy Noether, and Emil Artin.
The conditions themselves can be stated in an abstract form, so that they make sense for any partially ordered set. This point of view is useful in abstract algebraic dimension theory due to Gabriel and Rentschler.
Definition.
A partially ordered set (poset) "P" is said to satisfy the ascending chain condition (ACC) if every strictly ascending sequence of elements eventually terminates. Equivalently, given any sequence
there exists a positive integer "n" such that
Similarly, "P" is said to satisfy the descending chain condition (DCC) if every strictly descending sequence of elements eventually terminates, that is, there is no infinite descending chain. Equivalently every descending sequence
of elements of "P", eventually stabilizes.

</doc>
<doc id="3192" url="https://en.wikipedia.org/wiki?curid=3192" title="Adin Steinsaltz">
Adin Steinsaltz

Rabbi Adin Steinsaltz (Hebrew: עדין שטיינזלץ) or Adin Even Yisrael (Hebrew: עדין אבן ישראל) (born 1937) is a teacher, philosopher, social critic, and spiritual mentor, who has been hailed by "Time" magazine as a "once-in-a-millennium scholar". He has devoted his life to making the Talmud accessible to all Jews. Originally published in modern Hebrew, with a running commentary to facilitate learning, his "Steinsaltz edition of the Talmud" has also been translated into English, French, Russian and Spanish. Beginning in 1989, Steinsaltz published several tractates in Hebrew and English of the Babylonian (Bavli) Talmud in an English-Hebrew edition. The first volume of a new English-Hebrew edition, the Koren Talmud Bavli, was released in May, 2012, with thirteenth tractates in print by July 2014. New volumes are being released following the Daf Yomi cycle.
Biography.
Born in Jerusalem in 1937 to secular parents, Steinsaltz studied mathematics, physics, and chemistry at the Hebrew University, in addition to rabbinical studies. Following graduation, he established several experimental schools after an unsuccessful attempt to start a neo-Hassidic community in the Negev desert, and, at the age of 23, became Israel’s youngest school principal.
In 1965, he founded the Israel Institute for Talmudic Publications and began his monumental work on the Talmud, including translation into Hebrew, English, Russian, and various other languages. The Steinsaltz editions of the Talmud include translation from the original Aramaic and a comprehensive commentary. Steinsaltz completed his Hebrew edition of the entire Babylonian Talmud in November 2010, at which time Koren Publishers Jerusalem became the publisher of all of his works, including the Talmud. While not without criticism (such as by Jacob Neusner, 1998), the Steinsaltz edition is widely used throughout Israel, the United States and the world. Over 2 million volumes of the Steinsaltz Talmud have been distributed to date. The out-of-print Random House publication of "" is widely regarded as the most accurate and least redacted of any English language edition and is sought after on that basis by scholars and collectors. Controversial Talmud passages previously obscured, omitted entirely or confined to footnotes in English translations like the Soncino Talmud, receive full exposition in the Steinsaltz Talmud. Random House halted publication of the Steinsaltz Talmud after less than one-third of the English translation had been published.
The Steinsaltz editions of the Talmud have opened up the world of Talmud study to thousands of people outside the walls of the traditional yeshiva, including women, who traditionally were not taught Talmud. Regarding the access that his work provides, Rabbi Steinsaltz says: “I never thought that spreading ignorance has any advantage, except for those who are in a position of power and want to deprive others of their rights and spread ignorance in order to keep them underlings.”
Rabbi Steinsaltz's classic work of Kabbalah, "The Thirteen Petalled Rose", was first published in 1980 and now appears in eight languages. In all, Steinsaltz has authored some 60 books and hundreds of articles on subjects including Talmud, Jewish mysticism, Jewish philosophy, sociology, historical biography, and philosophy. Many of these works have been translated into English by his close personal friend, now deceased, Yehuda Hanegbi. His latest book is a memoir-biography on the Lubavitcher Rebbe, Rabbi Menachem Mendel Schneerson, published by Maggid Books (2014).
In the summer of 1989, a group of rabbis including Elazar Shach placed a ban on three of Steinsaltz's books.
Continuing his work as a teacher and spiritual mentor, Steinsaltz established a network of schools and educational institutions in Israel and the former Soviet Union. He has served as scholar in residence at the Woodrow Wilson International Center for Scholars in Washington, D.C. and the Institute for Advanced Study in Princeton. His honorary degrees include doctorates from Yeshiva University, Ben Gurion University of the Negev, Bar Ilan University, Brandeis University, and Florida International University. Steinsaltz is also Rosh Yeshiva of Yeshivat Hesder Tekoa.
Being a follower of Rabbi Menachem Mendel Schneerson of Chabad-Lubavitch, he went to help Jews in the Soviet Union assisting Chabad's "shluchim" (propagators) network. Deeply involved in the future of the Jews in the former Soviet Union, Steinsaltz serves as the region's "Duchovny Ravin" (Spiritual Rabbi), a historic Russian title which indicates that he is the spiritual mentor of Russian Jewry. In this capacity, Steinsaltz travelled to Russia and the Republics once each month from his home in Jerusalem. During his time in the former Soviet Union he founded the Jewish University, both in Moscow and Saint Petersburg. The Jewish University is the first degree-granting institution of Jewish studies in the former Soviet Union.
Steinsaltz has taken a cautious approach to interfaith dialogues. During a visit of a delegation of Roman Catholic cardinals in Manhattan in January 2004, he said that “you do not have to raise over-expectations of a meeting as it doesn't signify in itself a breakthrough, however, the opportunity for cardinals and rabbis to speak face to face is valuable. It's part of a process in which we can talk to each other in a friendly way”, and called for “a theological dialogue that asks the tough questions, such as whether Catholicism allows for Jews to enter eternal paradise.”
Steinsaltz and his wife live in Jerusalem, and have three children and more than ten grandchildren. His son, Rabbi Menachem Even-Israel, is the Executive Director of Shefa - Rabbi Steinsaltz's umbrella organization, located in the Steinsaltz Center in the Nachlaot neighborhood of Jerusalem.
Head of the new Sanhedrin.
Rabbi Steinsaltz accepted the position as Nasi (President) of the 2004 attempt to revive the Sanhedrin. In 2008 he resigned from this position due to differences of opinion.
As a speaker.
Steinsaltz is a popular University and radio commentator. He has been invited to speak at the Aspen Institute for Humanistic Studies at Yale University in 1979. In Jerusalem, he gives evening seminars, which according to Newsweek usually last till 2 in the morning, and have attracted prominent politicians as the former Prime Minister Levi Eshkol and former Finance Minister Pinhas Sapir.
Awards and critical reception.
Rabbi Steinsaltz has received many awards and prizes, among them the Israel Prize for Jewish studies in 1988.
On 9 February 2012, Steinsaltz was honored by Israeli President Shimon Peres with Israel's first President's Prize for his scholarship in Talmud.
The Jewish Book Council named the Koren Talmud Bavli with commentary, translation and notes by Rabbi Adin Steinsaltz, a 2012 National Jewish Book Award winner in the category of Modern Jewish Thought and Experience.
However, not all reception of Steinsaltz' studies have been wholly positive. For example, Jacob Neusner's "How Adin Steinsaltz Misrepresents the Talmud. Four False Propositions from his "Reference Guide"" (1998) displays strong disagreement.

</doc>
<doc id="3198" url="https://en.wikipedia.org/wiki?curid=3198" title="A. E. Housman">
A. E. Housman

Alfred Edward Housman (; 26 March 1859 – 30 April 1936), usually known as A. E. Housman, was an English classical scholar and poet, best known to the general public for his cycle of poems "A Shropshire Lad". Lyrical and almost epigrammatic in form, the poems wistfully evoke the dooms and disappointments of youth in the English countryside . Their beauty, simplicity and distinctive imagery appealed strongly to late Victorian and Edwardian taste, and to many early 20th-century English composers (beginning with Arthur Somervell) both before and after the First World War. Through their song-settings, the poems became closely associated with that era, and with Shropshire itself.
Housman was one of the foremost classicists of his age and has been ranked as one of the greatest scholars who ever lived. He established his reputation publishing as a private scholar and, on the strength and quality of his work, was appointed Professor of Latin at University College London and then at Cambridge. His editions of Juvenal, Manilius and Lucan are still considered authoritative.
Life.
The eldest of seven children, Housman was born at Valley House in Fockbury, a hamlet on the outskirts of Bromsgrove in Worcestershire, to Sarah Jane (née Williams, married 17 June 1858 in Woodchester, Gloucester) and Edward Housman (whose family came from Lancaster), and was baptised on 24 April 1859 at Christ Church, in Catshill. His mother died on his twelfth birthday, and his father, a country solicitor, remarried, to an elder cousin, Lucy, in 1873. Housman's brother Laurence Housman and their sister Clemence Housman also became writers.
Housman was educated at Bromsgrove School, where he revealed his academic promise and won prizes for his poems. In 1877 he won an open scholarship to St John's College, Oxford, where he studied classics. Although introverted by nature, Housman formed strong friendships with two roommates, Moses Jackson and A. W. Pollard. Jackson became the great love of Housman's life, but he was heterosexual and did not reciprocate Housman's feelings. Housman obtained a first in classical Moderations in 1879, but his dedication to textual analysis, particularly of Propertius, led him to neglect the ancient history and philosophy that formed part of the Greats curriculum. Accordingly, he failed to obtain a degree. Though some attribute Housman's unexpected failure in his final exams directly to his rejection by Jackson, most biographers adduce more obvious causes. Housman was indifferent to philosophy and overconfident in his exceptional gifts; he felt contempt for inexact scholarship; and he enjoyed idling away his time with Jackson and others. He may also have been distracted by news of his father's desperate illness. He felt deeply humiliated by his failure and became determined to vindicate his genius.
After Oxford Jackson got a job as a clerk in the Patent Office in London and arranged a job there for Housman too. The two shared a flat with Jackson's brother Adalbert until 1885, when Housman moved to lodgings of his own, probably after Jackson responded to a declaration of love by telling Housman that he could not reciprocate his feelings. Moses Jackson moved to India in 1887, placing more distance between himself and Housman. When Jackson returned briefly to England in 1889, to marry, Housman was not invited to the wedding and knew nothing about it until the couple had left the country. Adalbert Jackson died in 1892 and Housman commemorated him in a poem published as "XLII – A.J.J." of "More Poems" (1936).
Meanwhile, Housman pursued his classical studies independently, and published scholarly articles on such authors as Horace, Propertius, Ovid, Aeschylus, Euripides and Sophocles. He gradually acquired such a high reputation that in 1892 he was offered and accepted the professorship of Latin at University College London (UCL).
Housman was an atheist. When R. W. Chambers discovered an immensely rare original Coverdale Bible of 1535 in the UCL library he presented it to the Library Committee, where Housman remarked that it would be better to sell it to "buy some really useful books with the proceeds". Many years later UCL's academic common room was dedicated to his memory as the Housman Room.
In his private life Housman enjoyed gastronomy, flying in aeroplanes and making frequent visits to France, where he read "books which were banned in Britain as pornographic". A fellow don described him as being "descended from a long line of maiden aunts".
Although Housman's early work and his responsibilities as a professor included both Latin and Greek, he began to specialise in Latin poetry. When asked later why he had stopped writing about Greek verse, he responded, "I found that I could not attain to excellence in both."
In 1911 he took the Kennedy Professorship of Latin at Trinity College, Cambridge, where he remained for the rest of his life. G. P. Goold, Classics Professor at University College, wrote of Housman's accomplishments: "The legacy of Housman's scholarship is a thing of permanent value; and that value consists less in obvious results, the establishment of general propositions about Latin and the removal of scribal mistakes, than in the shining example he provides of a wonderful mind at work. ... He was and may remain the last great textual critic." Between 1903 and 1930 Housman published his critical edition of Manilius's "Astronomicon" in five volumes. He also edited works by Juvenal (1905) and Lucan (1926). Many colleagues were unnerved by his scathing attacks on those he thought guilty of shoddy scholarship. In his paper "The Application of Thought to Textual Criticism" (1921) Housman wrote: "A textual critic engaged upon his business is not at all like Newton investigating the motion of the planets: he is much more like a dog hunting for fleas." He declared many of his contemporary scholars to be stupid, lazy, vain, or all three, saying: "Knowledge is good, method is good, but one thing beyond all others is necessary; and that is to have a head, not a pumpkin, on your shoulders, and brains, not pudding, in your head." His younger colleague A. S. F. Gow quoted examples of these attacks, noting that they "were often savage in the extreme". Gow also related how Housman intimidated his students, sometimes reducing them to tears. According to Gow, Housman could never remember his students' names, maintaining that "had he burdened his memory by the distinction between Miss Jones and Miss Robinson, he might have forgotten that between the second and fourth declension". One notable pupil was Enoch Powell. Housman found his true vocation in classical studies and treated his poems as secondary. He did not speak about his poetry in public until 1933 when he gave a lecture, "The Name and Nature of Poetry", in which he argued that poetry should appeal to emotions rather than to the intellect.
Housman died, aged 77, in Cambridge. His ashes are buried just outside St Laurence's Church, Ludlow, Shropshire.
Poetry.
"A Shropshire Lad".
During his years in London, A. E. Housman completed "A Shropshire Lad", a cycle of 63 poems. After several publishers had turned it down, he published it at his own expense in 1896. The emotion and vulnerability revealed in the book surprised both his colleagues and his students. At first selling slowly, it rapidly became a lasting success. Its appeal to English musicians had helped to make it widely known before World War I, when its themes struck a powerful chord with English readers. "A Shropshire Lad" has been in print continuously since May 1896.
The poems are marked by deep pessimism and preoccupation with death, without religious consolation. Housman wrote most of them while living in Highgate, London, before ever visiting that part of Shropshire (about thirty miles from his boyhood home), which he presented in an idealised pastoral light, as his 'land of lost content'. Housman himself acknowledged the influence of the songs of William Shakespeare, the Scottish Border ballads and Heinrich Heine, but specifically denied any influence of Greek and Latin classics in his poetry.
Later collections.
Housman began writing a new set of poems after the First World War. He was an influence on many British poets who became famous by their writing about the war, and wrote several poems as occasional verse to commemorate the war dead. This included his "Epitaph on an Army of Mercenaries", honouring the British Expeditionary Force, a small force of professional soldiers sent to Belgium at the start of the war. Fighting a well-equipped and larger German army, they suffered heavy losses.
In the early 1920s, when Moses Jackson was dying in Canada, Housman wanted to assemble his best unpublished poems so that Jackson could read them before his death. These later poems, mostly written before 1910, show a greater variety of subject and form than those in "A Shropshire Lad" but lack the consistency of his previously published work. He published them as "Last Poems" (1922), feeling that his inspiration was exhausted and that he should not publish more in his lifetime. After his death Housman's brother, Laurence, published further poems in "More Poems" (1936), "A. E .H.: Some Poems, Some Letters and a Personal Memoir by his Brother" (1937), and "Collected Poems" (1939). "A. E. H." includes humorous verse such as a parody of Longfellow's poem "Excelsior". Housman also wrote a parodic "Fragment of a Greek Tragedy", in English, published posthumously with humorous poems under the title "Unkind to Unicorns".
John Sparrow quoted a letter written late in Housman's life that described the genesis of his poems:
Sparrow himself adds, "How difficult it is to achieve a satisfactory analysis may be judged by considering the last poem in "A Shropshire Lad". Of its four stanzas, Housman tells us that two were 'given' him ready made; one was coaxed forth from his subconsciousness an hour or two later; the remaining one took months of conscious composition. No one can tell for certain which was which."
"De Amicitia" (Of Friendship).
In 1942 Laurence Housman also deposited an essay entitled "A. E. Housman's 'De Amicitia'" in the British Library, with the proviso that it was not to be published for 25 years. The essay discussed A. E. Housman's homosexuality and his love for Moses Jackson. Despite the conservative nature of the times and his own caution in public life, Housman was quite open in his poetry, and especially in "A Shropshire Lad", about his deeper sympathies. Poem XXX of that sequence, for instance, speaks of how "Fear contended with desire": "Others, I am not the first, / Have willed more mischief than they durst". In "More Poems", he buries his love for Moses Jackson in the very act of commemorating it, as his feelings of love are not reciprocated and must be carried unfulfilled to the grave:
<poem>
Because I liked you better
Than suits a man to say
It irked you, and I promised
To throw the thought away.
To put the world between us
We parted, stiff and dry;
Goodbye, said you, forget me.
I will, no fear, said I
If here, where clover whitens
The dead man's knoll, you pass,
And no tall flower to meet you
Starts in the trefoiled grass,
Halt by the headstone naming
The heart no longer stirred,
And say the lad that loved you
Was one that kept his word.
</poem>
His poem "Oh who is that young sinner with the handcuffs on his wrists?", written after the trial of Oscar Wilde, addressed more general injustice towards homosexuals. In the poem the prisoner is suffering "for the colour of his hair", a natural quality that, in a coded reference to homosexuality, is reviled as "nameless and abominable" (recalling the legal phrase "peccatum illud horribile, inter Christianos non-nominandum", "the sin so horrible, not to be named amongst Christians").
Housman in other art forms.
Music and art song.
Housman's poetry, especially "A Shropshire Lad", was set to music by many British, and in particular English, composers in the first half of the 20th century. The national, pastoral and traditional elements of his style resonated with similar trends in English music. In 1904 the cycle "A Shropshire Lad" was set by Arthur Somervell, who had begun to develop the concept of the English song-cycle in his version of Tennyson's "Maud" a little previously. Ralph Vaughan Williams produced his most famous settings of six songs, the cycle "On Wenlock Edge", for string quartet, tenor and piano (dedicated to Gervase Elwes) in 1909, and it became very popular after Elwes recorded it with the London String Quartet and Frederick B. Kiddle in 1917. Between 1909 and 1911 George Butterworth produced settings in two collections or cycles, as "Six Songs from A Shropshire Lad", and "Bredon Hill and Other Songs". He also wrote an orchestral tone poem on "A Shropshire Lad", first performed at Leeds Festival under Arthur Nikisch in 1912.
Butterworth's death on the Somme in 1916 was considered a great loss to English music; Ivor Gurney, another most important setter of Housman ("Ludlow and Teme", a work for voice and string quartet, and a song-cycle on Housman works, both of which won the Carnegie Award) experienced emotional breakdowns which were popularly (but wrongly) believed to have originated from shell-shock. The fatalism of the poems and their earlier settings foreshadowed responses to the universal bereavement of the First World War and became assimilated into them. This was reinforced when their foremost interpreter and performer, Gervase Elwes (who had initiated the music festivals at Brigg in Lincolnshire at which Percy Grainger and others had developed their collections of country music) died in a horrific accident in 1921. Elwes had worked hard to maintain morale during the war, having given six benefit performances of "The Dream of Gerontius" on consecutive nights in 1916, and many concerts in France in 1917 for British soldiers.
Among other composers who set Housman songs were John Ireland (song cycle, "The Land of Lost Content" (192021)), Michael Head (e.g. 'Ludlow Fair'), Graham Peel (a famous version of 'In Summertime on Bredon'), Ian Venables (Songs of Eternity and Sorrow), and the American Samuel Barber (e.g. 'With rue my heart is laden'). Gerald Finzi began several settings, but never finished them. Even composers not directly associated with the 'pastoral' tradition, such as Arnold Bax, Lennox Berkeley and Arthur Bliss, were attracted to Housman's poetry. A 1976 catalogue listed 400 musical settings of Housman's poems. Housman's poetry influenced British music in a way comparable to that of Walt Whitman in the music of Delius, Vaughan Williams and others: Housman's works provided song texts, Whitman's the texts for larger choral works. The contemporary New Zealand composer David Downes includes a setting of "March" on his CD "The Rusted Wheel of Things".
Works titled after Housman.
Housman is the main character in the 1997 Tom Stoppard play "The Invention of Love". Many titles for novels and films have been drawn from Housman's poetry. The line "There's this to say for blood and breath,/ they give a man a taste for death" supplies the title for Peter O'Donnell's 1969 Modesty Blaise thriller, "A Taste for Death", also the inspiration for P. D. James' 1986 crime novel, "A Taste for Death", the seventh in her Adam Dalgliesh series. The title of Nicholas Blake's 1949 detective novel "Head of a Traveller" is a quotation from Housman's parody "Fragment of a Greek Tragedy". The last words of the poem "On Wenlock Edge" are used by Audrey R. Langer for the title of the 1989 novel "Ashes Under Uricon". The Nobel Prize winning novelist Patrick White named his 1955 novel "The Tree of Man" after another line in "On Wenlock Edge" and Arthur C. Clarke's first novel, "Against the Fall of Night", is taken from "XLV" in Housman's "More Poems". The 2009 novel "Blood's a Rover" by James Ellroy takes its title from Housman's poem "Reveille", and a line from Housman's poem XVI "How Clear, How Lovely Bright", was used for the title of the last "Inspector Morse" book "The Remorseful Day" by Colin Dexter. "Blue Remembered Hills", a television play by Dennis Potter, takes its title from "Into My Heart an Air That Kills" from "A Shropshire Lad", and the cycle provides the name for the James Bond film "Die Another Day": "But since the man that runs away / Lives to die another day". The title of T.H.White's "The Queen of Air and Darkness" comes from Housman's "Last Poems" III 'Her strong enchantments failing'. The title of Ursula Le Guin's short story collection 'The Wind's Twelve Quarters' is taken from Housman's 'From Far, From Eve And Morning.'
In the 1985 film "Out of Africa" Karen "Tanja" Blixen, played by Meryl Streep, cites poems by A.E. Housman twice. In one key scene, when she is finally invited by the male members of the country club, she gives a toast quoting from "With rue my heart is laden". In another scene, when she gives the eulogy at Denys Finch Hatton's funeral, she recites an abbreviated version of "To an athlete dying young".
"Nothing but the night" a film referenced in Wikipedia based on the novel by John Blackburn.
The 1938 English translation by Stuart Gilbert of the 1887 French novel "Les lauriers sont coupés" by Édouard Dujardin is titled "We'll to the Woods No More", the first line of the prefatory poem in "Last Poems".
Works.
Published lectures.
These lectures are listed by date of delivery, with date of first publication given separately if different.
Prose collections.
"Selected Prose", edited by John Carter, Cambridge University Press, 1961

</doc>
<doc id="3201" url="https://en.wikipedia.org/wiki?curid=3201" title="Attribution of recent climate change">
Attribution of recent climate change

Attribution of recent climate change is the effort to scientifically ascertain mechanisms responsible for recent changes observed in the Earth's climate, commonly known as 'global warming'. The effort has focused on changes observed during the period of instrumental temperature record, when records are most reliable; particularly in the last 50 years, when human activity has grown fastest and observations of the troposphere have become available. The dominant mechanisms (to which the IPCC attributes climate change) are anthropogenic, i.e., the result of human activity. They are:
There are also natural mechanisms for variation including climate oscillations, changes in solar activity, and volcanic activity.
According to the Intergovernmental Panel on Climate Change (IPCC), it is "extremely likely" that human influence was the dominant cause of global warming between 1951 and 2010. The IPCC defines "extremely likely" as indicating a probability of 95 to 100%, based on an expert assessment of all the available evidence.
Multiple lines of evidence support attribution of recent climate change to human activities:
The IPCC's attribution of recent global warming to human activities is a view shared by most scientists, and is also supported by 196 other scientific organizations worldwide (see also: scientific opinion on climate change).
Background.
This section introduces some concepts in climate science that are used in the following sections:
Factors affecting Earth's climate can be broken down into feedbacks and forcings.
A forcing is something that is imposed externally on the climate system. External forcings include natural phenomena such as volcanic eruptions and variations in the sun's output. Human activities can also impose forcings, for example, through changing the composition of the atmosphere.
Radiative forcing is a measure of how various factors alter the energy balance of the Earth's atmosphere. A positive radiative forcing will tend to increase the energy of the Earth-atmosphere system, leading to a warming of the system. Between the start of the Industrial Revolution in 1750, and the year 2005, the increase in the atmospheric concentration of carbon dioxide (chemical formula: CO) led to a positive radiative forcing, averaged over the Earth's surface area, of about 1.66 watts per square metre (abbreviated W m).
Climate feedbacks can either amplify or dampen the response of the climate to a given forcing.
There are many feedback mechanisms in the climate system that can either amplify (a positive feedback) or diminish (a negative feedback) the effects of a change in climate forcing.
Aspects of the climate system will show variation in response to changes in forcings.
In the absence of forcings imposed on it, the climate system will still show internal variability (see images opposite). This internal variability is a result of complex interactions between components of the climate system, such as the coupling between the atmosphere and ocean (see also the later section on Internal climate variability and global warming). An example of internal variability is the El Niño-Southern Oscillation.
Detection vs. attribution.
Detection and attribution of climate signals, as well as its common-sense meaning, has a more precise definition within the climate change literature, as expressed by the IPCC. Detection of a climate signal does not always imply significant attribution. The IPCC's Fourth Assessment Report says "it is "extremely likely" that human activities have exerted a substantial net warming influence on climate since 1750," where "extremely likely" indicates a probability greater than 95%. "Detection" of a signal requires demonstrating that an observed change is statistically significantly different from that which can be explained by natural internal variability.
"Attribution" requires demonstrating that a signal is:
Key attributions.
Greenhouse gases.
Carbon dioxide is the primary greenhouse gas that is contributing to recent climate change. is absorbed and emitted naturally as part of the carbon cycle, through animal and plant respiration, volcanic eruptions, and ocean-atmosphere exchange. Human activities, such as the burning of fossil fuels and changes in land use (see below), release large amounts of carbon to the atmosphere, causing concentrations in the atmosphere to rise.
The high-accuracy measurements of atmospheric CO concentration, initiated by Charles David Keeling in 1958, constitute the master time series documenting the changing composition of the atmosphere. These data have iconic status in climate change science as evidence of the effect of human activities on the chemical composition of the global atmosphere.
Along with CO, methane and nitrous oxide are also major forcing contributors to the greenhouse effect. The Kyoto Protocol lists these together with hydrofluorocarbons (HFCs), perfluorocarbons (PFCs), and sulphur hexafluoride (SF), which are entirely artificial (i.e. anthropogenic) gases, which also contribute to radiative forcing in the atmosphere. The chart at right attributes anthropogenic greenhouse gas emissions to eight main economic sectors, of which the largest contributors are power stations (many of which burn coal or other fossil fuels), industrial processes, transportation fuels (generally fossil fuels), and agricultural by-products (mainly methane from enteric fermentation and nitrous oxide from fertilizer use).
Water vapor.
Water vapor is the most abundant greenhouse gas and also the most important in terms of its contribution to the natural greenhouse effect, despite having a short atmospheric lifetime (about 10 days). Some human activities can influence local water vapor levels. However, on a global scale, the concentration of water vapor is controlled by temperature, which influences overall rates of evaporation and precipitation. Therefore, the global concentration of water vapor is not substantially affected by direct human emissions.
Land use.
Climate change is attributed to land use for two main reasons. Between 1750 and 2007, about two-thirds of anthropogenic emissions were produced from burning fossil fuels, and about one-third of emissions from changes in land use, primarily deforestation. Deforestation both reduces the amount of carbon dioxide absorbed by deforested regions and releases greenhouse gases directly, together with aerosols, through biomass burning that frequently accompanies it.
A second reason that climate change has been attributed to land use is that the terrestrial albedo is often altered by use, which leads to radiative forcing. This effect is more significant locally than globally.
Livestock and land use.
Worldwide, livestock production occupies 70% of all land used for agriculture, or 30% of the ice-free land surface of the Earth.
More than 18% of anthropogenic greenhouse gas emissions are attributed to livestock and livestock-related activities such as deforestation and increasingly fuel-intensive farming practices. Specific attributions to the livestock sector include:
Aerosols.
With virtual certainty, scientific consensus has attributed various forms of climate change, chiefly cooling effects, to aerosols, which are small particles or droplets suspended in the atmosphere.
Key sources to which anthropogenic aerosols are attributed include:
Attribution of 20th century climate change.
Over the past 150 years human activities have released increasing quantities of greenhouse gases into the atmosphere. This has led to increases in mean global temperature, or global warming. Other human effects are relevant—for example, sulphate aerosols are believed to have a cooling effect. Natural factors also contribute. According to the historical temperature record of the last century, the Earth's near-surface air temperature has risen around 0.74 ± 0.18 °Celsius (1.3 ± 0.32 °Fahrenheit).
A historically important question in climate change research has regarded the relative importance of human activity and non-anthropogenic causes during the period of instrumental record. In the 1995 Second Assessment Report (SAR), the IPCC made the widely quoted statement that "The balance of evidence suggests a discernible human influence on global climate". The phrase "balance of evidence" suggested the (English) common-law standard of proof required in civil as opposed to criminal courts: not as high as "beyond reasonable doubt". In 2001 the Third Assessment Report (TAR) refined this, saying "There is new and stronger evidence that most of the warming observed over the last 50 years is attributable to human activities". The 2007 Fourth Assessment Report (AR4) strengthened this finding:
Other findings of the IPCC Fourth Assessment Report include:
Over the past five decades there has been a global warming of approximately 0.65 °C (1.17 °F) at the Earth's surface (see historical temperature record). Among the possible factors that could produce changes in global mean temperature are internal variability of the climate system, external forcing, an increase in concentration of greenhouse gases, or any combination of these. Current studies indicate that the increase in greenhouse gases, most notably , is mostly responsible for the observed warming. Evidence for this conclusion includes:
Details on attribution.
Recent scientific assessments find that most of the warming of the Earth's surface over the past 50 years has been caused by human activities (see also the section on scientific literature and opinion). This conclusion rests on multiple lines of evidence. Like the warming "signal" that has gradually emerged from the "noise" of natural climate variability, the scientific evidence for a human influence on global climate has accumulated over the past several decades, from many hundreds of studies. No single study is a "smoking gun." Nor has any single study or combination of studies undermined the large body of evidence supporting the conclusion that human activity is the primary driver of recent warming.
The first line of evidence is based on a physical understanding of how greenhouse gases trap heat, how the climate system responds to increases in greenhouse gases, and how other human and natural factors influence climate. The second line of evidence is from indirect estimates of climate changes over the last 1,000 to 2,000 years. These records are obtained from living things and their remains (like tree rings and corals) and from physical quantities (like the ratio between lighter and heavier isotopes of oxygen in ice cores), which change in measurable ways as climate changes. The lesson from these data is that global surface temperatures over the last several decades are clearly unusual, in that they were higher than at any time during at least the past 400 years. For the Northern Hemisphere, the recent temperature rise is clearly unusual in at least the last 1,000 years (see graph opposite).
The third line of evidence is based on the broad, qualitative consistency between observed changes in climate and the computer model simulations of how climate would be expected to change in response to human activities. For example, when climate models are run with historical increases in greenhouse gases, they show gradual warming of the Earth and ocean surface, increases in ocean heat content and the temperature of the lower atmosphere, a rise in global sea level, retreat of sea ice and snow cover, cooling of the stratosphere, an increase in the amount of atmospheric water vapor, and changes in large-scale precipitation and pressure patterns. These and other aspects of modelled climate change are in agreement with observations.
"Fingerprint" studies.
Finally, there is extensive statistical evidence from so-called "fingerprint" studies. Each factor that affects climate produces a unique pattern of climate response, much as each person has a unique fingerprint. Fingerprint studies exploit these unique signatures, and allow detailed comparisons of modelled and observed climate change patterns. Scientists rely on such studies to attribute observed changes in climate to a particular cause or set of causes. In the real world, the climate changes that have occurred since the start of the Industrial Revolution are due to a complex mixture of human and natural causes. The importance of each individual influence in this mixture changes over time. Of course, there are not multiple Earths, which would allow an experimenter to change one factor at a time on each Earth, thus helping to isolate different fingerprints. Therefore, climate models are used to study how individual factors affect climate. For example, a single factor (like greenhouse gases) or a set of factors can be varied, and the response of the modelled climate system to these individual or combined changes can thus be studied.
For example, when climate model simulations of the last century include all of the major influences on climate, both human-induced and natural, they can reproduce many important features of observed climate change patterns. When human influences are removed from the model experiments, results suggest that the surface of the Earth would actually have cooled slightly over the last 50 years (see graph, opposite). The clear message from fingerprint studies is that the observed warming over the last half-century cannot be explained by natural factors, and is instead caused primarily by human factors.
Another fingerprint of human effects on climate has been identified by looking at a slice through the layers of the atmosphere, and studying the pattern of temperature changes from the surface up through the stratosphere (see the section on solar activity). The earliest fingerprint work focused on changes in surface and atmospheric temperature. Scientists then applied fingerprint methods to a whole range of climate variables, identifying human-caused climate signals in the heat content of the oceans, the height of the tropopause (the boundary between the troposphere and stratosphere, which has shifted upward by hundreds of feet in recent decades), the geographical patterns of precipitation, drought, surface pressure, and the runoff from major river basins.
Studies published after the appearance of the IPCC Fourth Assessment Report in 2007 have also found human fingerprints in the increased levels of atmospheric moisture (both close to the surface and over the full extent of the atmosphere), in the decline of Arctic sea ice extent, and in the patterns of changes in Arctic and Antarctic surface temperatures.
The message from this entire body of work is that the climate system is telling a consistent story of increasingly dominant human influence – the changes in temperature, ice extent, moisture, and circulation patterns fit together in a physically consistent way, like pieces in a complex puzzle.
Increasingly, this type of fingerprint work is shifting its emphasis. As noted, clear and compelling scientific evidence supports the case for a pronounced human influence on global climate. Much of the recent attention is now on climate changes at continental and regional scales, and on variables that can have large impacts on societies. For example, scientists have established causal links between human activities and the changes in snowpack, maximum and minimum (diurnal) temperature, and the seasonal timing of runoff over mountainous regions of the western United States. Human activity is likely to have made a substantial contribution to ocean surface temperature changes in hurricane formation regions. Researchers are also looking beyond the physical climate system, and are beginning to tie changes in the distribution and seasonal behaviour of plant and animal species to human-caused changes in temperature and precipitation.
For over a decade, one aspect of the climate change story seemed to show a significant difference between models and observations. In the tropics, all models predicted that with a rise in greenhouse gases, the troposphere would be expected to warm more rapidly than the surface. Observations from weather balloons, satellites, and surface thermometers seemed to show the opposite behaviour (more rapid warming of the surface than the troposphere). This issue was a stumbling block in understanding the causes of climate change. It is now largely resolved. Research showed that there were large uncertainties in the satellite and weather balloon data. When uncertainties in models and observations are properly accounted for, newer observational data sets (with better treatment of known problems) are in agreement with climate model results.
This does not mean, however, that all remaining differences between models and observations have been resolved. The observed changes in some climate variables, such as Arctic sea ice, some aspects of precipitation, and patterns of surface pressure, appear to be proceeding much more rapidly than models have projected. The reasons for these differences are not well understood. Nevertheless, the bottom-line conclusion from climate fingerprinting is that most of the observed changes studied to date are consistent with each other, and are also consistent with our scientific understanding of how the climate system would be expected to respond to the increase in heat-trapping gases resulting from human activities.
Extreme weather events.
One of the subjects discussed in the literature is whether or not extreme weather events can be attributed to human activities. Seneviratne "et al." (2012) stated that attributing individual extreme weather events to human activities was challenging. They were, however, more confident over attributing changes in long-term trends of extreme weather. For example, Seneviratne "et al." (2012) concluded that human activities had likely led to a warming of extreme daily minimum and maximum temperatures at the global scale.
Another way of viewing the problem is to consider the effects of human-induced climate change on the probability of future extreme weather events. Stott "et al." (2003), for example, considered whether or not human activities had increased the risk of severe heat waves in Europe, like the one experienced in 2003. Their conclusion was that human activities had very likely more than doubled the risk of heat waves of this magnitude.
An analogy can be made between an athlete on steroids and human-induced climate change. In the same way that an athlete's performance may increase from using steroids, human-induced climate change increases the risk of some extreme weather events.
Hansen "et al." (2012) suggested that human activities have greatly increased the risk of summertime heat waves. According to their analysis, the land area of the Earth affected by very hot summer temperature anomalies has greatly increased over time (refer to graphs on the left). In the base period 1951-1980, these anomalies covered a few tenths of 1% of the global land area. In recent years, this has increased to around 10% of the global land area. With high confidence, Hansen "et al." (2012) attributed the 2010 Moscow and 2011 Texas heat waves to human-induced global warming.
An earlier study by Dole "et al." (2011) concluded that the 2010 Moscow heatwave was mostly due to natural weather variability. While not directly citing Dole "et al." (2011), Hansen "et al." (2012) rejected this type of explanation. Hansen "et al." (2012) stated that a combination of natural weather variability and human-induced global warming was responsible for the Moscow and Texas heat waves.
Scientific literature and opinion.
There are a number of examples of published and informal support for the consensus view. As mentioned earlier, the IPCC has concluded that most of the observed increase in globally averaged temperatures since the mid-20th century is "very likely" due to human activities. The IPCC's conclusions are consistent with those of several reports produced by the US National Research Council.
A report published in 2009 by the U.S. Global Change Research Program concluded that "loba warming is unequivocal and primarily human-induced."
A number of scientific organizations have issued statements that support the consensus view. Two examples include:
Detection and attribution studies.
The IPCC Fourth Assessment Report (2007), concluded that attribution was possible for a number of observed changes in the climate (see effects of global warming). However, attribution was found to be more difficult when assessing changes over smaller regions (less than continental scale) and over short time periods (less than 50 years).
Over larger regions, averaging reduces natural variability of the climate, making detection and attribution easier.
As described above, a small minority of scientists do disagree with the consensus: see list of scientists opposing global warming consensus. For example, Willie Soon and Richard Lindzen say that there is insufficient proof for anthropogenic attribution. Generally this position requires new physical mechanisms to explain the observed warming.
Solar activity.
Solar sunspot maximum occurs when the magnetic field of the sun collapses and reverse as part of its average 11 year solar cycle (22 years for complete North to North restoration).
The role of the sun in recent climate change has been looked at by climate scientists. Since 1978, output from the Sun has been measured by satellites significantly more accurately than was previously possible from the surface. These measurements indicate that the Sun's total solar irradiance has not increased since 1978, so the warming during the past 30 years cannot be directly attributed to an increase in total solar energy reaching the Earth (see graph above, left). In the three decades since 1978, the combination of solar and volcanic activity probably had a slight cooling influence on the climate.
Climate models have been used to examine the role of the sun in recent climate change.
Models are unable to reproduce the rapid warming observed in recent decades when they only take into account variations in total solar irradiance and volcanic activity. Models are, however, able to simulate the observed 20th century changes in temperature when they include all of the most important external forcings, including human influences and natural forcings. As has already been stated, Hegerl "et al." (2007) concluded that greenhouse gas forcing had "very likely" caused most of the observed global warming since the mid-20th century. In making this conclusion, Hegerl "et al." (2007) allowed for the possibility that climate models had been underestimated the effect of solar forcing.
The role of solar activity in climate change has also been calculated over longer time periods using "proxy" datasets, such as tree rings.
Models indicate that solar and volcanic forcings can explain periods of relative warmth and cold between A.D. 1000 and 1900, but human-induced forcings are needed to reproduce the late-20th century warming.
Another line of evidence against the sun having caused recent climate change comes from looking at how temperatures at different levels in the Earth's atmosphere have changed.
Models and observations (see figure above, middle) show that greenhouse gas results in warming of the lower atmosphere at the surface (called the troposphere) but cooling of the upper atmosphere (called the stratosphere). Depletion of the ozone layer by chemical refrigerants has also resulted in a cooling effect in the stratosphere. If the sun was responsible for observed warming, warming of the troposphere at the surface and warming at the top of the stratosphere would be expected as increase solar activity would replenish ozone and oxides of nitrogen. The stratosphere has a reverse temperature gradient than the troposphere so as the temperature of the troposphere cools with altitude, the stratosphere rises with altitude. Hadley cells are the mechanism by which equatorial generated ozone in the tropics (highest area of UV irradiance in the stratosphere) is moved poleward. Global climate models suggest that climate change may widen the Hadley cells and push the jetstream northward thereby expanding the tropics region and resulting in warmer, dryer conditions in those areas overall.
Non-consensus views.
Habibullo Abdussamatov (2004), head of space research at St. Petersburg's Pulkovo Astronomical Observatory in Russia, has argued that the sun is responsible for recently observed climate change. Journalists for news sources canada.com (Solomon, 2007b), National Geographic News (Ravillious, 2007), and LiveScience (Than, 2007) reported on the story of warming on Mars. In these articles, Abdussamatov was quoted. He stated that warming on Mars was evidence that global warming on Earth was being caused by changes in the sun.
Ravillious (2007) quoted two scientists who disagreed with Abdussamatov: Amato Evan, a climate scientist at the University of Wisconsin-Madison, in the US, and Colin Wilson, a planetary physicist at Oxford University in the UK. According to Wilson, "Wobbles in the orbit of Mars are the main cause of its climate change in the current era" (see also orbital forcing). Than (2007) quoted Charles Long, a climate physicist at Pacific Northwest National Laboratories in the US, who disagreed with Abdussamatov.
Than (2007) pointed to the view of Benny Peiser, a social anthropologist at Liverpool John Moores University in the UK. In his newsletter, Peiser had cited a blog that had commented on warming observed on several planetary bodies in the Solar system. These included Neptune's moon Triton, Jupiter, Pluto and Mars. In an e-mail interview with Than (2007), Peiser stated that:"I think it is an intriguing coincidence that warming trends have been observed on a number of very diverse planetary bodies in our solar system, (...) Perhaps this is just a fluke."Than (2007) provided alternative explanations of why warming had occurred on Triton, Pluto, Jupiter and Mars.
The US Environmental Protection Agency (US EPA, 2009) responded to public comments on climate change attribution. A number of commenters had argued that recent climate change could be attributed to changes in solar irradiance. According to the US EPA (2009), this attribution was not supported by the bulk of the scientific literature. Citing the work of the IPCC (2007), the US EPA pointed to the low contribution of solar irradiance to radiative forcing since the start of the Industrial Revolution in 1750. Over this time period (1750 to 2005), the estimated contribution of solar irradiance to radiative forcing was 5% the value of the combined radiative forcing due to increases in the atmospheric concentrations of carbon dioxide, methane and nitrous oxide (see graph opposite).
Effect of cosmic rays.
Henrik Svensmark has suggested that the magnetic activity of the sun deflects cosmic rays, and that this may influence the generation of cloud condensation nuclei, and thereby have an effect on the climate. The website ScienceDaily reported on a 2009 study that looked at how past changes in climate have been affected by the Earth's magnetic field. Geophysicist Mads Faurschou Knudsen, who co-authored the study, stated that the study's results supported Svensmark's theory. The authors of the study also acknowledged that plays an important role in climate change.
Consensus view on cosmic rays.
The view that cosmic rays could provide the mechanism by which changes in solar activity affect climate is not supported by the literature. Solomon "et al." (2007) state: the cosmic ray time series does not appear to correspond to global total cloud cover after 1991 or to global low-level cloud cover after 1994. Together with the lack of a proven physical mechanism and the plausibility of other causal factors affecting changes in cloud cover, this makes the association between galactic cosmic ray-induced changes in aerosol and cloud formation controversial
Studies by Lockwood and Fröhlich (2007) and Sloan and Wolfendale (2008) found no relation between warming in recent decades and cosmic rays. Pierce and Adams (2009) used a model to simulate the effect of cosmic rays on cloud properties. They concluded that the hypothesized effect of cosmic rays was too small to explain recent climate change. Pierce and Adams (2009) noted that their findings did not rule out a possible connection between cosmic rays and climate change, and recommended further research.
Erlykin "et al." (2009) found that the evidence showed that connections between solar variation and climate were more likely to be mediated by direct variation of insolation rather than cosmic rays, and concluded: "Hence within our assumptions, the effect of varying solar activity, either by direct solar irradiance or by varying cosmic ray rates, must be less than 0.07 °C since 1956, i.e. less than 14% of the observed global warming." Carslaw (2009) and Pittock (2009) review the recent and historical literature in this field and continue to find that the link between cosmic rays and climate is tenuous, though they encourage continued research. US EPA (2009) commented on research by Duplissy "et al." (2009):The CLOUD experiments at CERN are interesting research but do not provide conclusive evidence that cosmic rays can serve as a major source of cloud seeding. Preliminary results from the experiment (Duplissy et al., 2009) suggest that though there was some evidence of ion mediated nucleation, for most of the nucleation events observed the contribution of ion processes appeared to be minor. These experiments also showed the difficulty in maintaining sufficiently clean conditions and stable temperatures to prevent spurious aerosol bursts. There is no indication that the earlier Svensmark experiments could even have matched the controlled conditions of the CERN experiment. We find that the Svensmark results on cloud seeding have not yet been shown to be robust or sufficient to materially alter the conclusions of the assessment literature, especially given the abundance of recent literature that is skeptical of the cosmic ray-climate linkage
 

</doc>
<doc id="3203" url="https://en.wikipedia.org/wiki?curid=3203" title="Achduart">
Achduart

Achduart (Gaelic: Achadh Dhubhaird) is a small hamlet in Coigach, in Wester Ross in northwestern Scotland, now within the Highland council area. It is situated about 4 km southeast of the village of Achiltibuie, at the end of a minor road. A footpath continues on to the hamlet of Culnacraig, then along the coast past Ben More Coigach to Strathcanaird. 
Achduart has accommodation facilities for tourists, who come for its proximity to the ocean as well as its seclusion and remoteness. There is a Scottish Youth Hostels Association hostel in Acheninver, a short distance to the north.
The name of Achduart comes from the Gaelic for "the field at the black headland". Achduart was part of the Estate of Coigach, Lochbroom, belonging to the Countess of Cromartie.
The dominant geographical feature in the area is Cairn Conmheall, which rises to 541 metres.

</doc>
<doc id="3204" url="https://en.wikipedia.org/wiki?curid=3204" title="Achiltibuie">
Achiltibuie

Achiltibuie (; or "Field of the yellow-haired boy") is a long linear village in Ross and Cromarty, Highland, on the Coigach coast of northwestern Scotland, overlooking Badentarbet Bay to the west. Loch Broom and the Summer Isles lie to the south. Located 10 miles (16 km) northwest of Ullapool as the crow flies. Achiltibuie is the central community of a series of townships and communities stretching from Culnacraig, through Badenscallie and Polglass (where the community hall, the primary school and the Piping School are located), Polbain (where the architecturally acclaimed holiday accommodation "the Brochs of Coigach" are located), and Reiff to Achnahaird. 
History.
The first post office in the village opened on 28 July 1884.
Hydroponicum.
The Hydroponicum, a facility for growing fresh fruit and vegetables indoors using hydroponics, was built in the village in the 1980s by Robert Irvine, then owner of the Summer Isles Hotel. The Hydroponicum was known for growing exotic fruit such as bananas all year round. It attracted up to 10,000 visitors a year until it was sold in 2007 to a company based in the Isle of Man. New greenhouses have since been built apart from the original hydroponicum buildings, and the new owners continue to grow fruit and vegetables for local businesses and residents. A community buyout attempt in 2011 by the Coigach Community Development Company fell through when the site's sellers pulled out. The building has now been demolished. Some of the former staff of the Hydroponicum run a small-scale activity known as The Achiltibuie Garden, situated nearby.
The Eagle Of The Ninth.
The Roman epic The Eagle, based on the 1954 novel "The Eagle of the Ninth" by Rosemary Sutcliff, was filmed on location in Achiltibuie for a week in October 2009. The main location was Fox Point, Old Dornie. The Pictish village which was constructed at Fox Point was used on most days of the filming. Other sites included Achnahaird beach where a horse chase was filmed and Loch Lurgainn.
Notable recent achievements.
'Coigach Community Rowing' the crew members of which coastal rowing club are all local, won the World St Ayles Skiff Rowing Championships in July 2013 and a mixed crew from the club won the Alan Spong Trophy for 1st Mixed crew 4-oar rowing at the Thames Great River Race in September 2013. Coigach Community Rowing hand-built their two St Ayles rowing skiffs, the 'Coigach Lass' and the 'Lily~Rose' and race under the auspices of the Scottish Coastal Rowing Association, which is the governing body of St Ayles class coastal rowing around the world.

</doc>
<doc id="3205" url="https://en.wikipedia.org/wiki?curid=3205" title="Adaptive expectations">
Adaptive expectations

In economics, adaptive expectations is a hypothesized process by which people form their expectations about what will happen in the future based on what has happened in the past. For example, if inflation has been higher than expected in the past, people would revise expectations for the future.
One simple version of adaptive expectations is stated in the following equation, where formula_1 is the next year's rate of inflation that is currently expected; formula_2is this year's rate of inflation that was expected last year; and formula_3 is this year's actual rate of inflation:
where formula_5 is between 0 and 1. This says that current expectations of future inflation reflect past expectations and an "error-adjustment" term, in which current expectations are raised (or lowered) according to the gap between actual inflation and previous expectations. This error-adjustment is also called ""partial adjustment"."
The theory of adaptive expectations can be applied to all previous periods so that current inflationary expectations equal:
where formula_7 equals actual inflation formula_8 years in the past. Thus, current expected inflation reflects a weighted average of all past inflation, where the weights get smaller and smaller as we move further in the past.
Once a forecasting error is made by agents, due to a stochastic shock, they will be unable to correctly forecast the price level again even if the price level experiences no further shocks since they only ever incorporate part of their errors. The backward nature of expectation formulation and the resultant systematic errors made by agents (see Cobweb model) was unsatisfactory to economists such as John Muth, who was pivotal in the development of an alternative model of how expectations are formed, called rational expectations. This has largely replaced adaptive expectations in macroeconomic theory since its assumption of optimality of expectations is consistent with economic theory. However, it must be stressed that confronting adaptivity and rationality is not necessarily justified, in other words, there are situations in which following the adaptive scheme is a rational response.
Adaptive expectations were instrumental in the Phillips curve outlined by Milton Friedman. For Friedman, workers form adaptive expectations, so the government can easily surprise them through unexpected monetary policy changes. As agents are trapped by the money illusion, they are unable to correctly perceive price and wage dynamics, so, for Friedman, unemployment can always be reduced through monetary expansions. The result is an increasing level of inflation if the government chooses to fix unemployment at a low rate for an extended period of time. However, in this framework it is clear why and how adaptive expectations are problematic. Agents are arbitrarily supposed to ignore sources of information which, otherwise, would affect their expectations. For example, government announcements are such sources: agents are expected to modify their expectations and break with the former trends when changes in economic policy necessitate it. This is the reason why the theory of adaptive expectations is often regarded as a deviation from the reational tradition of economics.
Maurice Allais’s Hereditary, Relativist and Logistic (HRL) theory of monetary dynamics contains an original theory of expectations formation that is a genuine alternative to both adaptive and rational expectations. Praised by Milton Friedman in 1968 with the following words:
"This work" he HRL formulatio" introduces a very basic and important distinction between psychological time and chronological time. It is one of the most important and original paper that has been written for a long time … for its consideration of the problem of the formation of expectations.”
Allais’s contribution has nevertheless been “lost”: it has been absent from the debate about expectations.

</doc>
<doc id="3209" url="https://en.wikipedia.org/wiki?curid=3209" title="Mexican tetra">
Mexican tetra

The Mexican tetra or blind cave fish ("Astyanax mexicanus") is a freshwater fish
of the family Characidae of the order Characiformes. The type species of its genus, it is native to the Nearctic ecozone, originating in the lower Rio Grande and the Neueces and Pecos Rivers in Texas, as well as the central and eastern parts of Mexico.
Growing to a maximum overall length of , the Mexican tetra is of typical characin shape, with unremarkable, drab coloration. Its blind cave form, however, is notable for having no eyes and being albino, that is, completely devoid of pigmentation; it has a pinkish-white color to its body.
This fish, especially the blind variant, is reasonably popular among aquarists.
"A. mexicanus" is a peaceful species that spends most of its time in midlevel water above the rocky and sandy bottoms of pools and backwaters of creeks and rivers of its native environment. Coming from a subtropical climate, it prefers water with 6.0–7.8 pH, a hardness of up to 30 dGH, and a temperature range of . In the winter, it migrates to warmer waters. Its natural diet consists of crustaceans, insects, and annelids, although in captivity it is omnivorous.
The Mexican tetra has been treated as a subspecies of "A. fasciatus", but this is not widely accepted.
Blind cave form.
"A. mexicanus" is famous for its blind cave form, which is known by such names as blind cave tetra, blind tetra, blind cave characin and blind cavefish. Depending on the which population, cave forms can have degenerated sight or have total loss of sight and even their eyes. The fish in the Pachón caves have lost their eyes completely whilst the fish from the Micos cave only have limited sight. 
Cave fish and surface fish are able to produce fertile offspring.
These fish can still, however, find their way around by means of their lateral lines, which are highly sensitive to fluctuating water pressure. Currently, 29 cave populations are known, dispersed over three geographically distinct areas in a karst region of San Luis Potosí, northeastern Mexico. Recent studies suggest at least two distinct genetic lineages occur among the blind populations, and the current distribution of populations arose by at least five independent invasions.
The eyed and eyeless forms of "A. mexicanus," being members of the same species, are closely related and can interbreed making this species an excellent model organism for examining convergent and parallel evolution, regressive evolution in cave animals, and the genetic basis of regressive traits.
"Astyanax jordani", another blind cave fish, is sometimes confused with the cave form of "A. mexicanus."
Evolution research.
The surface and cave forms of the Mexican tetra have proven powerful subjects for scientists studying evolution. When the surface-dwelling ancestors of current cave populations entered the subterranean environment, the change in ecological conditions rendered their phenotype—which included many biological functions dependent on the presence of light—subject to natural selection and genetic drift. One of the most striking changes to evolve was the loss of eyes. This is referred to as a "regressive trait" because the surface fish that originally colonized caves possessed eyes. In addition to regressive traits, cave forms evolved "constructive traits". In contrast to regressive traits, the purpose or benefit of constructive traits is generally accepted. Active research focuses on the mechanisms driving the evolution of regressive traits, such as the loss of eyes, in "A. mexicanus". Recent studies have produced evidence that the mechanism may be direct selection, or indirect selection through antagonistic pleiotropy, rather than genetic drift and neutral mutation, the traditionally favored hypothesis for regressive evolution.
The blind form of the Mexican tetra is different from the surface-dwelling form in a number of ways, including having unpigmented skin, having a better olfactory sense by having taste buds all over its head, and by being able to store four times more energy as fat, allowing it to deal with irregular food supplies more effectively.
Darwin said of sightless fish:
Modern genetics has made clear that the lack of use does not, in itself, necessitate a feature's disappearance. In this context, the positive genetic benefits have to be considered, i.e., what advantages are obtained by cave-dwelling tetras by losing their eyes? Possible explanations include:
Another likely explanation for the loss of its eyes is that of selective neutrality and genetic drift; in the dark environment of the cave, the eyes are neither advantageous nor disadvantageous and thus any genetic factors that might impair the eyes (or their development) can take hold with no consequence on the individual or species. Because there is no selection pressure for sight in this environment, any number of genetic abnormalities that give rise to the damage or loss of eyes could proliferate among the population with no effect on the fitness of the population.
Among some creationists, the cave tetra is seen as evidence 'against' evolution. One argument claims this is an instance of "devolution"—showing an evolutionary trend of decreasing complexity. But evolution is a non-directional process, and while increased complexity is a common effect, there is no reason why evolution cannot tend towards simplicity if that makes an organism better suited to its environment.
Inhibition of the HSP90 protein has a dramatic effect in the development of the blind tetra. This research is seen by creationists as evidence of "built-in adaptability, not slow and gradual evolution".
In the aquarium.
The blind cave tetra is a fairly hardy species. Their lack of sight does not hinder their ability to get food. They prefer subdued lighting with a rocky substrate, like gravel, mimicking their natural environment. They become semi-aggressive as they age, and are by nature schooling fish. Experiments have shown that keeping these fish in bright aquarium set-ups has no effect on the development of the skin flap that forms over their eyes as the grow.

</doc>
<doc id="3211" url="https://en.wikipedia.org/wiki?curid=3211" title="Atom probe">
Atom probe

The atom probe was introduced at the 14th International Field Emission Symposium in 1967 by Erwin Wilhelm Müller and J. A. Panitz. It combined a field ion microscope with a mass spectrometer having a single particle detection capability and, for the first time, an instrument could “... determine the nature of one single atom seen on a metal surface and selected from neighboring atoms at the discretion of the observer”.
Atom probes are unlike conventional optical or electron microscopes, in that the magnification effect comes from the magnification provided by a highly curved electric field, rather than by the manipulation of radiation paths. The method is destructive in nature removing ions from a sample surface in order to image and identify them, generating magnifications sufficient to observe individual atoms as they are removed from the sample surface. Through coupling of this magnification method with time of flight mass spectrometry, ions evaporated by application of electric pulses can have their mass-to-charge ratio computed.
Through successive evaporation of material, layers of atoms are removed from a specimen, allowing for probing not only of the surface, but also through the material itself. Computer methods are utilised to rebuild a three-dimensional view of the sample, prior to it being evaporated, providing atomic scale information on the structure of a sample, as well as providing the type atomic species information. The instrument allows the three-dimensional reconstruction of up to billions of atoms from a sharp tip (corresponding to specimen volumes of 10,000-10,000,000 nm).
Overview.
Atom probe samples are shaped to implicitly provide a highly curved electric potential to induce the resultant magnification, as opposed to direct use of lensing, such as via magnetic lenses. Furthermore, in normal operation (as opposed to a field ionization modes) the atom probe does not utilize a secondary source to probe the sample. Rather, the sample is evaporated in a controlled manner (field evaporation) and the evaporated ions are impacted onto a detector, which is typically 10 to 100 cm away.
The samples are required to have a needle geometry and are produced by similar techniques as TEM sample preparation electropolishing, or focused ion beam methods. Since 2006, commercial systems with laser pulsing have become available and this has expanded applications from metallic only specimens into semiconducting, insulating such as ceramics, and even geological materials. Preparation is done, often by hand, to manufacture a tip radius sufficient to induce a high electric field, with radii on the order of 100 nm.
To conduct an atom probe experiment a very sharp needle shaped specimen is placed in an ultra high vacuum chamber. After introduction into the vacuum system, the sample is reduced to cryogenic temperatures (typically 20-100 K) and manipulated such that the needle's point is aimed towards an ion detector. A high voltage is applied to the specimen, and either a laser pulse is applied to the specimen or a voltage pulse (typically 1-2 kV) with pulse repetition rates in the hundreds of kilohertz range is applied to a counter electrode. The application of the pulse to the sample allows for individual atoms at the sample surface to be ejected as an ion from the sample surface at a known time. Typically the pulse amplitude and the high voltage on the specimen are computer controlled to encourage only one atom to ionize at a time, but multiple ionizations are possible. The delay between application of the pulse and detection of the ion(s) at the detector allow for the computation of a mass-to-charge ratio.
Whilst the uncertainty in the atomic mass computed by time-of-flight methods in atom probe is sufficiently small to allow for detection of individual isotopes within a material this uncertainty may still, in some cases, confound definitive identification of atomic species. Effects such as superposition of differing ions with multiple electrons removed, or through the presence of complex species formation during evaporation may cause two or more species to have sufficiently close time-of-flights to make definitive identification impossible.
History.
Field ion microscopy.
Field ion microscopy is a modification of field emission microscopy where a stream of tunneling electrons is emitted from the apex of a sharp needle-like "tip" cathode when subjected to a sufficiently high electric field (~3-6 V/nm). The needle is oriented towards a phosphor screen to create a projected image of the work function at the tip apex. The image resolution is limited to (2-2.5 nm), due to quantum mechanical effects and lateral variations in the electron velocity.
In field ion microscopy the tip is cooled by a cryogen and its polarity is reversed. When an "imaging gas" (usually hydrogen or helium) is introduced at low pressures (< 0.1 Pascal) gas ions in the high electric field at the tip apex are "field ionized" and produce a projected image of protruding atoms at the tip apex. The image resolution is determined primarily by the temperature of the tip but even at 78 Kelvin atomic resolution is achieved.
10-cm Atom Probe.
The 10-cm Atom Probe, invented in 1973 by J. A. Panitz was a “new and simple atom probe which permits rapid, in depth species identification or the more usual atom-by atom analysis provided by its predecessors ... in an instrument having a volume of less than two liters in which tip movement is unnecessary and the problems of evaporation pulse stability and alignment common to previous designs have been eliminated.” This was accomplished by combining a time of flight (TOF) mass spectrometer with a proximity focussed, dual channel plate detector, an 11.8 cm drift region and a 38° field of view. An FIM image or a desorption image of the atoms removed from the apex of a field emitter tip could be obtained. The 10-cm Atom Probe has been called the "progenitor" of later atom probes including the commercial instruments.
Imaging Atom-Probe (IAP).
The Imaging Atom-Probe (IAP), invented in 1974 by J. A. Panitz as the "Field Desorption Spectrometer" “... departs completely from reviou atom probe philosophy. Rather than attempt to determine the identity of a surface species producing a preselected ion-image spot, we wish to determine the complete crystallographic distribution of a surface species of preselected mass-to-charge ratio. Now suppose that instead of operating the etecto continuously, it is turned on for a short time coincidentally with the arrival of a preselected species of interest by applying a gate pulse a time T after the evaporation pulse has reached the specimen. If the duration of the gate pulse is shorter than the travel time between adjacent species, only that surface species having the unique travel time T will be detected and its complete crystallographic distribution displayed.” By 'time-gating' the detector for the arrival of a particular species of interest its crystallographic distribution on the surface, and as a function of depth, can be determined. Without time-gating all of the species reaching the detector are analyzed. The "Imaging Atom Probe" moniker was coined by A. J. Waugh in 1978.
Atom-probe tomography (APT).
Modern day atom probe tomography (APT) uses a position-sensitive detector to deduce the lateral location of atoms. This allows 3-D reconstructions to be generated. The idea of the APT, inspired by J. A. Panitz's "Field Desorption Spectrometer" patent, was developed by Mike Miller starting in 1983 and culminated with the first prototype in 1986. Various refinements were made to the instrument, including the use of a so-called position-sensitive (PoS) detector by Alfred Cerezo, Terence Godfrey, and George D. W. Smith at Oxford University in 1988. The Tomographic Atom Probe (TAP), developed by researchers at the University of Rouen in France in 1993, introduced a multichannel timing system and multianode array. Both instruments (PoSAP and TAP) were commercialized by Oxford Nanoscience and CAMECA respectively. Since then, there have been many refinements to increase the field of view, mass and position resolution, and data acquisition rate of the instrument. The Local Electrode Atom Probe was first introduced in 2003 by Imago Scientific Instruments. In 2005, the commercialization of the pulsed laser atom probe (PLAP) expanded the avenues of research from highly conductive materials (metals) to poor conductors (semiconductors like silicon) and even insulating materials. AMETEK acquired CAMECA in 2007 and Imago Scientific Instruments (Madison, WI) in 2010, making the company the sole commercial developer of APTs with more than 70 instruments installed around the world in 2015.
The first few decades of work with APT focused on metals. However, more recent work has been done on semiconductors, ceramic and geologic materials, with some work on biomaterials. The most advanced study of biological material to date using APT involved analyzing the chemical structure of teeth of the radula of chiton "Chaetopleura apiculata". In this study, the use of APT showed chemical maps of organic fibers in the surrounding nano-crystalline magnetite in the chiton teeth, fibers which were often co-located with sodium or magnesium. This has been furthered to study elephant tusks, dentin and potentially human enamel.
Theory.
Field evaporation.
Field evaporation is an effect that can occur when an atom bonded at the surface of a material is in the presence of a sufficiently high and appropriately directed electric field, where the electric field is the differential of electric potential (voltage) with respect to distance. Once this condition is met, it is sufficient that local bonding at the specimen surface is capable of being overcome by the field, allowing for evaporation of an atom from the surface to which it is otherwise bonded.
Ion flight.
Whether evaporated from the material itself, or ionised from the gas, the ions that are evaporated are accelerated by electrostatic force, acquiring most of their energy within a few tip-radii of the sample.
Subsequently, the accelerative force on any given ion is controlled by the electrostatic equation, where "n" is the ionisation state of the ion, and "e" is the fundamental electric charge.
This can be equated with the mass of the ion, "m", via Newton's law (F=ma):
Relativistic effects in the ion flight are usually ignored, as realisable ion speeds are only a very small fraction of the speed of light.
Assuming that the ion is accelerated during a very short interval, the ion can be assumed to be travelling at constant velocity. As the ion will travel from the tip at voltage V to some nominal ground potential, the speed at which the ion is travelling can be estimated by the energy transferred into the ion during (or near) ionisation. Therefore the ion speed can be computed with the following equation, which relates kinetic energy to energy gain due to the electric field, the negative arising from the loss of electrons forming a net positive charge.
Where "U" is the ion velocity. Solving for "U", the following relation is found:
Let's say that for at a certain ionization voltage, a singly charged hydrogen ion acquires a resulting velocity of X ms. A singly charged deuterium ion under the sample conditions would have acquired roughly X/1.41 ms. If a detector was placed at a distance of 1 m, the ion flight times would be 1/X and 1.41/X s. Thus, the time of the ion arrival can be used to infer the ion type itself, if the evaporation time is known.
From the above equation, it can be re-arranged to show that
given a known flight distance. F, for the ion, and a known flight time, t,
and thus one can substitute these values to obtain the mass-to-charge for the ion.
Thus for an ion which traverses a 1 m flight path, across a time of 2000 ns, given an initial accelerating voltage of 5000 V (V in Si units is kg.m^2.s^-3.A^-1) and noting that one amu is 1×10 kg, the mass-to-charge ratio (more correctly the mass-to-ionisation value ratio) becomes ~3.86 amu/charge. The number of electrons removed, and thus net positive charge on the ion is not known directly, but can be inferred from the histogram (spectrum) of observed ions.
Magnification.
The magnification in an atom is due to the projection of ions radially away from the small, sharp tip. Subsequently, in the far field, the ions will be greatly magnified. This magnification is sufficient to observe field variations due to individual atoms, thus allowing in field ion and field evaporation modes for the imaging of single atoms.
The standard projection model for the atom probe is an emitter geometry that is based upon a revolution of a conic section, such as a sphere, hyperboloid or paraboloid. For these tip models, solutions to the field may be approximated or obtained analytically. The magnification for a spherical emitter is inversely proportional to the radius of the tip, given a projection directly onto a spherical screen, the following equation can be obtained geometrically.
Where r is the radius of the detection screen from the tip centre, and r the tip radius. Practical tip to screen distances may range from several centimeters to several meters, with increased detector area required at larger to subtend the same field of view.
Practically speaking, the usable magnification will be limited by several effects, such as lateral vibration of the atoms prior to evaporation.
Whilst the magnification of both the field ion and atom probe microscopes is extremely high, the exact magnification is dependent upon conditions specific to the examined specimen, so unlike for conventional electron microscopes, there is often little direct control on magnification, and furthermore, obtained images may have strongly variable magnifications due to fluctuations in the shape of the electric field at the surface.
Reconstruction.
The computational conversion of the ion sequence data, as obtained from a position sensitive detector, to a three-dimensional visualisation of atomic types, is termed "reconstruction". Reconstruction algorithms are typically geometrically based, and have several literature formulations. Most models for reconstruction assume that the tip is a spherical object, and utilise empirical corrections to stereographic projection to convert detector positions back to a 2D surface embedded in R. By sweeping this surface through R as a function of the ion sequence input data, such as via ion-ordering, a volume is generated onto which positions the 2D detector positions can be computed and placed three-dimensional space.
Typically the sweep takes the simple form of an advancement of the surface, such that the surface is expanded in a symmetric manner about its advancement axis, with the advancement rate set by a volume attributed to each ion detected and identified. This causes the final reconstructed volume to assume a rounded-conical shape, similar to a badminton shuttlecock. The detected events thus become a point cloud data with attributed experimentally measured values, such as ion time of flight or experimentally derived quantities, e.g. time of flight or detector data.
This form of data manipulation allows for rapid computer visualisation and analysis, with data presented as point cloud data with additional information, such as each ion's mass to charge (as computed from the velocity equation above), voltage or other auxiliary measured quantity or computation therefrom.
Data features.
The canonical feature of atom probe data its high spatial resolution in the direction through the material, which has been attributed to an ordered evaporation sequence. This data can therefore image near atomically sharp buried interfaces with the associated chemical information.
The data obtained from the evaporative process is however not without artefacts that form the physical evaporation or ionisation process. A key feature of the evaporation or field ion images is that the data density is highly inhomogeneous, due to the corrugation of the specimen surface at the atomic scale. This corrugation gives rise to strong electric field gradients in the near-tip zone (on the order of an atomic radii or less from the tip), which during ionisation deflects ions away from the electric field normal.
The resultant deflection means that in these regions of high curvature, atomic terraces are belied by a strong anisotropy in the detection density. Where this occurs due to a few atoms on a surface is usually referred to as a "pole", as these are coincident with the crystallographic axes of the specimen (FCC, BCC, HCP) etc. Where the edges of an atomic terrace causes deflection, a low density line is formed and is termed a "zone line".
These poles and zone-lines, whilst inducing fluctuations in data density in the reconstructed datasets, which can prove problematic during post-analysis, are critical for determining information such as angular magnification, as the crystallographic relationships between features are typically well known.
When reconstructing the data, owing to the evaporation of successive layers of material from the sample, the lateral and in-depth reconstruction values are highly anisotropic. Determination of the exact resolution of the instrument is of limited use, as the resolution of the device is set by the physical properties of the material under analysis.
Systems.
Many designs have been constructed since the method's inception. Initial field ion microscopes, precursors to modern atom probes, were usually glass blown devices developed by individual research laboratories.
System layout.
At a minimum, an atom probe will consist of several key pieces of equipment.
Optionally, an atom probe may also include laser-optical systems for laser beam targeting and pulsing, if using laser-evaporation methods. Staged vacuum systems are regularly employed to ensure that the system vacuum conditions remain stable. In-situ reaction systems may also be employed for some studies.
Performance.
Collectable ion volumes were previously limited to several thousand, or tens of thousands of ionic events. Subsequent electronics and instrumentation development has increased the rate of data accumulation, with datasets of hundreds of million atoms (dataset volumes of 10 nm). Data collection times vary considerably depending upon the experimental conditions and the number of ions collected. Experiments take from a few minutes, to many hours to complete.
Applications.
Metallurgy.
Atom probe has typically been employed in the chemical analysis of alloy systems at the atomic level. This has arisen as a result of voltage pulsed atom probes providing good chemical and sufficient spatial information in these materials. Metal samples from large grained alloys may be simple to fabricate, particularly from wire samples, with hand-electropolishing techniques giving good results.
Subsequently, atom probe has been used in the analysis of the chemical composition of a wide range of alloys.
Such data is critical in determining the effeto of alloy constituents in a bulk material, identification of solid-state reaction features, such as solid phase precipitates. Such information may not be amenable to analysis by other means (e.g. TEM) owing to the difficulty in generating a three-dimensional dataset with composition.
Semiconductors.
Semi-conductor materials are often analysable in atom probe, however sample preparation may be more difficult, and interpretation of results may be more complex, particularly if the semi-conductor contains phases which evaporate at differing electric field strengths.
Applications such as ion implantation may be used to identify the distribution of dopants inside a semi-conducting material, which is increasingly critical in the correct design of modern nanometre scale electronics.

</doc>
<doc id="3212" url="https://en.wikipedia.org/wiki?curid=3212" title="Al Capone">
Al Capone

Alphonse Gabriel "Al" Capone (; January 17, 1899 – January 25, 1947) was an American gangster who attained fame during the Prohibition era as the co-founder and boss of the Chicago Outfit. His seven-year reign as crime boss ended when he was 33 years old.
Capone was born in the borough of Brooklyn in New York City to Italian immigrants. He was considered a Five Points Gang member who became a bouncer in organized crime premises such as brothels. In his early twenties, he moved to Chicago and became bodyguard and trusted factotum for Johnny Torrio, head of a criminal syndicate that illegally supplied alcohol – the forerunner of the Outfit – and that was politically protected through the Unione Siciliana. A conflict with the North Side Gang was instrumental in Capone's rise and fall. Torrio went into retirement after North Side gunmen almost killed him, handing control to Capone. Capone expanded the bootlegging business through increasingly violent means, but his mutually profitable relationships with mayor William Hale Thompson and the city's police meant that Capone seemed safe from law enforcement.
Capone apparently reveled in attention, such as the cheers from spectators when he appeared at ball games. He made donations to various charities and was viewed by many to be a "modern-day Robin Hood". However, the Saint Valentine's Day Massacre of gang rivals, resulting in the killing of seven men in broad daylight, damaged Chicago's image - as well as Capone's - leading influential citizens to demand governmental action and newspapers to dub him "Public Enemy No. 1".
The federal authorities became intent on jailing Capone, and they prosecuted him for tax evasion in 1931, a federal crime and a novel strategy during the era. During the highly publicized case, the judge admitted as evidence Capone's admissions of his income and unpaid taxes during prior (and ultimately abortive) negotiations to pay the government any back taxes he owed. Capone was convicted and sentenced to 11 years in federal prison. After conviction, he replaced his old defense team with experts in tax law, and his grounds for appeal were strengthened by a Supreme Court ruling, but his appeal ultimately failed.
He was already showing signs of syphilitic dementia early in his sentence, and he became increasingly debilitated before being released after eight years. On January 25, 1947, Capone died of cardiac arrest after suffering a stroke.
Early life.
Alphonse Gabriel Capone was born in the borough of Brooklyn in New York on January 17, 1899. His parents were Italian immigrants Gabriele Capone (December 12, 1865 – November 14, 1920) and Teresina (née Raiola; December 28, 1867 – November 29, 1952). His father was a barber and his mother was a seamstress, both born in Angri, a town in the Province of Salerno.
Gabriele and Teresa had nine children: Alphonse "Al" Capone; James Vincenzo Capone, who later changed his name to Richard Hart and ironically became a Prohibition agent in Homer, Nebraska; Raffaele James Capone, AKA Ralph "Bottles" Capone, who took charge of his brother's beverage industry; Salvatore "Frank" Capone, John Capone, Albert Capone, Matthew Capone, Rose Capone, and Mafalda Capone (who married John J. Maritote). His two brothers Ralph and Frank worked with him in his criminal empire. Frank did so until his death on April 1, 1924. Ralph ran the bottling companies (both legal and illegal) early on, and was also the front man for the Chicago Outfit for some time until he was imprisoned for tax evasion in 1932.
The Capone family immigrated to the United States, first immigrating from Italy to Fiume, Austria-Hungary (present day Rijeka, Croatia) in 1893, traveling on a ship to the U.S., and finally settling at 95 Navy Street, in the Navy Yard section of downtown Brooklyn. Gabriele Capone worked at a nearby barber shop at 29 Park Avenue. When Al was 11, the Capone family moved to 38 Garfield Place in Park Slope, Brooklyn.
Capone showed promise as a student, but had trouble with the rules at his strict parochial Catholic school. His schooling ended at the age of 14, after he was expelled for hitting a female teacher in the face. He worked at odd jobs around Brooklyn, including a candy store and a bowling alley. During this time, Capone was influenced by gangster Johnny Torrio, whom he came to regard as a mentor.
Career.
Capone initially became involved with small-time gangs that included the Junior Forty Thieves and the Bowery Boys. He then joined the Brooklyn Rippers, and then the powerful Five Points Gang based in Lower Manhattan. During this time, he was employed and mentored by fellow racketeer Frankie Yale, a bartender in a Coney Island dance hall and saloon called the Harvard Inn. Capone inadvertently insulted a woman while working the door at a Brooklyn night club and was slashed by her brother Frank Gallucio. The wounds led to the nickname that Capone loathed: "Scarface". Yale insisted that Capone apologize to Gallucio, and later Capone hired him as a bodyguard. When photographed, Capone hid the scarred left side of his face, saying that the injuries were war wounds. Capone was called "Snorky," a term for a sharp dresser, by his closest friends.
Marriage and family.
Capone married Mae Josephine Coughlin on December 30, 1918 at age 19. She was Irish Catholic and, earlier that month, had given birth to their son Albert Francis "Sonny" Capone. Capone was under the age of 21, so his parents had to consent to the marriage in writing.
Chicago.
At about 20 years of age, Capone left New York for Chicago at the invitation of Johnny Torrio, who was imported by bootlegger James "Big Jim" Colosimo as an enforcer. Capone began in Chicago as a bouncer in a brothel, where he contracted syphilis. Timely use of Salvarsan probably could have cured the infection, but he apparently never sought treatment. In 1923, he purchased a small house at 7244 South Prairie Avenue in the Park Manor neighborhood on the city's south side for . In the early years of the decade, Capone's name began appearing in newspaper sports pages, where he was described as a boxing promoter.
Chicago's location on Lake Michigan gave access to a vast inland territory, and it was well-served by railroads. Torrio took over Colosimo's crime empire after Colosimo's murder on May 11, 1920, in which Capone was suspected of being involved.
Torrio headed an essentially Italian organized crime group that was the biggest in the city, with Capone as his right-hand man. He was wary of being drawn into gang wars and tried to negotiate agreements over territory between rival crime groups. The smaller, mixed ethnicity, North Side Gang led by Dean O'Banion (also known as Dion O'Banion) came under pressure from the Genna brothers, who were allied with Torrio. O'Banion found that, for all Torrio's pretensions to be a settler of disputes, he was unhelpful with the encroachment of the Gennas into the North Side. In a fateful step, Torrio either arranged for or acquiesced to the murder of O'Banion at the latter's flower shop in October 1924. This placed Hymie Weiss at the head of the gang, backed by Vincent Drucci and Bugs Moran. Weiss had been a close friend of O'Banion, and the North Siders treated revenge on his killers as a priority.
Boss.
In January 1925, Capone was ambushed, leaving him shaken but unhurt. Twelve days later, Torrio was returning from a shopping trip when he was shot several times. After recovering, Torrio effectively resigned and handed control to Capone, age 26, who became the new boss of an organization that took in illegal breweries and a transportation network that reached to Canada, with political and law-enforcement protection. In turn, he was able to use more violence to increase revenue. Refusal by an establishment to purchase liquor from him often resulted in the premises being blown up. As many as 100 people were killed in such bombings during the 1920s. Rivals saw Capone as responsible for the proliferation of brothels in the city.
Capone indulged in custom suits, cigars, gourmet food and drink (his preferred liquor was Templeton Rye from Iowa), and female companionship. He was particularly known for his flamboyant and costly jewelry. His favorite responses to questions about his activities were: "I am just a businessman, giving the people what they want"; and, "All I do is satisfy a public demand." Capone had become a national celebrity and talking point.
Capone based himself in Cicero after using bribery and widespread intimidation to take over during elections for the town council. This made it difficult for the North Siders to target him. Capone's driver was found tortured and murdered, and there was an attempt on Weiss's life in the Chicago Loop. On September 20, 1926, the North Side Gang used a ploy outside the Capone headquarters at the Hawthorne Inn, aimed at drawing him to the windows. Gunmen in several cars then opened fire with Thompson submachine guns and shotguns at the windows of the first-floor restaurant. Capone was unhurt and called for a truce, but the negotiations fell through. Three weeks later, Weiss was killed outside the former O'Banion flower shop North Side headquarters. In January 1927, the Hawthorne's restaurant owner, a friend of Capone's, was kidnapped and killed by Moran and Drucci.
Capone became increasingly security-minded and desirous of getting away from Chicago. As a precaution, he and his entourage would often show up suddenly at one of Chicago's train depots and buy up an entire Pullman sleeper car on a night train to a place like Cleveland, Omaha, Kansas City, Little Rock, or Hot Springs, where they would spend a week in luxury hotel suites under assumed names. In 1928, Capone paid $40,000 to beer magnate August Busch for a 14-room retreat at 93 Palm Avenue on Palm Island, Florida, in Biscayne Bay between Miami and Miami Beach. Capone never registered any property under his name. He did not even have a bank account, but always used Western Union for cash delivery, not more than $1,000.
Political alliances.
The protagonists of Chicago's politics had long been associated with questionable methods, and even newspaper circulation "wars", but the need for bootleggers to have protection in city hall introduced a far more serious level of violence and graft. Capone is generally seen as having an appreciable effect in bringing about the victories of Republican William Hale Thompson, especially in the 1927 mayoral race when Thompson campaigned for a wide open town, at one time hinting that he'd reopen illegal saloons. Such a proclamation helped his campaign gain the support of Capone, and he allegedly accepted a contribution of $250,000 from the gangster. In the 1927 mayoral race, Thompson beat William Emmett Dever by a relatively slim margin. Thompson's powerful Cook County political machine had drawn on the often-parochial Italian community, but this was in tension with his highly successful courting of African Americans.
Capone continued to back Thompson. Voting booths were targeted by Capone's bomber James Belcastro in the wards where Thompson's opponents were thought to have support, on the polling day of April 10, 1928, in the so-called Pineapple Primary, causing the deaths of at least 15 people. Belcastro was also accused of the murder of lawyer Octavius Granady, an African American who challenged Thompson's candidate for the African American vote, and was chased through the streets on polling day by cars of gunmen before being shot dead. Four policemen were among those charged along with Belcastro, but all charges were dropped after key witnesses recanted their statements. An indication of the attitude of local law enforcement to Capone's organization came in 1931 when Belcastro was wounded in a shooting; police suggested to skeptical journalists that Belcastro was an independent operator.
The 1929 Saint Valentine's Day Massacre led to public disquiet about Thompson's alliance with Capone and was a factor in Anton J. Cermak winning the mayoral election on April 6, 1931.
Saint Valentine's Day Massacre.
Capone was widely assumed to have been responsible for ordering the 1929 Saint Valentine's Day Massacre in an attempt to kill Bugs Moran, the head of the North Side Gang. Moran was the last survivor of the main North Side gunmen; his succession had come about because his similarly aggressive predecessors Vincent Drucci and Hymie Weiss had been killed in the violence that followed the murder of original leader Dean O'Banion.
To monitor their targets' habits and movements, Capone's men rented an apartment across from the trucking warehouse and garage at 2122 North Clark Street that served as Moran headquarters. On the morning of Thursday, February 14, 1929, Capone's lookouts signaled gunmen disguised as police to start a "raid." The "faux" police lined the seven victims along a wall without a struggle, then signaled for accomplices with machine guns. The seven victims were machine-gunned and shot-gunned. Photos of the victims shocked the public and damaged Capone's reputation. Within days, Capone received a summons to testify before a Chicago grand jury on violations of the federal Prohibition Law, but he claimed to be too unwell to attend at that time.
Trials.
Capone was arrested by FBI agents on March 27, 1929 as he left a Chicago courtroom after testifying to a grand jury investigating violations of federal prohibition laws, on charges of having committed contempt of court by feigning illness to avoid an earlier appearance. In May 1929, Capone was sentenced to a prison term in Philadelphia's Eastern State Penitentiary, having been convicted within 16 hours of being arrested for carrying a gun during a trip there. A week after he was released, in March 1930, Capone was listed as the number one "Public Enemy" on the unofficial Chicago Crime Commission's widely publicized list.
In April 1930, Capone was arrested on vagrancy charges when visiting Miami Beach, the governor having ordered sheriffs to run him out of the state. Capone claimed that Miami police had refused him food and water and threatened to arrest his family. He was charged with perjury for making these statements, but was acquitted after a three-day trial in July. In September, a Chicago judge issued a warrant for Capone on charges of vagrancy, and then used the publicity to run against Thompson in the Republican primary. In February 1931, Capone was tried on the contempt of court charge. In court, Judge James Herbert Wilkerson intervened to reinforce questioning of Capone's doctor by the prosecutor. Wilkerson sentenced Capone to six months, but he remained free while on appeal of the contempt conviction.
In 1927, the Supreme Court ruled that illegally earned income was subject to income tax; Justice Oliver Wendell Holmes Jr. rejected the argument that the Fifth Amendment protected criminals from reporting illegal income. The IRS special investigation unit chose Frank J. Wilson to investigate Capone, with the focus on his spending. The key to Capone's conviction on tax charges was proving his income, and the most valuable evidence in that regard originated in his offer to pay tax. Ralph, his brother and a gangster in his own right, was tried for tax evasion in 1930. Ralph spent the next three years in prison after being convicted in a two-week trial over which Wilkerson presided. Capone ordered his lawyer to regularize his tax position. Crucially, during the ultimately abortive negotiations that followed, his lawyer stated the income that Capone was willing to pay tax on for various years, admitting income of $100,000 for 1928 and 1929, for instance. Hence, without any investigation, the government had been given a letter from a lawyer acting for Capone conceding his large taxable income for certain years. In 1931, Capone was charged with income tax evasion, as well as with various violations of the Volstead Act (Prohibition) at the Chicago Federal Building in the courtroom of Judge James Herbert Wilkerson. U. S. Attorney George E. Q. Johnson agreed to a deal that he hoped might result in the judge giving Capone a couple of years, but Judge Wilkerson had been aware of the deal all along and refused to allow Capone to plead guilty for a reduced sentence. On the second day of the trial, Judge Wilkerson overruled objections that a lawyer could not confess for his client, saying that anyone making a statement to the government did so at his own risk. Wilkerson deemed that the 1930 letter to federal authorities could be admitted into evidence from a lawyer acting for Capone.
Much was later made of other evidence, such as witnesses and ledgers, but these strongly implied Capone's control rather than stating it. The ledgers were inadmissible on grounds of statute of limitations, but Capone's lawyers incompetently failed to make the necessary timely objection; they also ran a basically irrelevant defense of gambling losses. Judge Wilkerson allowed Capone's spending to be presented at very great length. There was no doubt that Capone "spent" vast sums but, legally speaking, the case against him centered on the size of his "income." Capone was convicted and was sentenced to eleven years in federal prison in November 1931, fined $50,000 plus $7,692 for court costs, and was held liable for $215,000 plus interest due on his back taxes. The contempt of court sentence was served concurrently. New lawyers hired to represent Capone were Washington-based tax experts. They filed a writ of habeas corpus based on a Supreme Court ruling that tax evasion was not fraud, which apparently meant that Capone had been convicted on charges relating to years that were actually outside the time limit for prosecution. However, a judge interpreted the law so that the time that Capone had spent in Miami was subtracted from the age of the offenses, thereby denying the appeal of both Capone's conviction and sentence.
Imprisonment.
Capone was sent to Atlanta U.S. Penitentiary in May 1932, aged 33. Upon his arrival at Atlanta, the Capone was officially diagnosed with syphilis and gonorrhea. He was also suffering from withdrawal symptoms from cocaine addiction, use of which had perforated his septum. Capone was competent at his prison job of stitching soles on shoes for eight hours a day, but his letters were barely coherent. He was seen as a weak personality, and so out of his depth dealing with bullying fellow inmates that his cellmate, seasoned convict Red Rudinsky, feared that Capone would have a breakdown. Rudinsky was formerly a small time criminal associated with the Capone gang, and found himself becoming a protector for Capone. The conspicuous protection of Rudinsky and other prisoners drew accusations from less friendly inmates, and fueled suspicion that Capone was receiving special treatment. No solid evidence ever emerged, but it formed part of the rationale for moving Capone to the recently opened Alcatraz Federal Penitentiary off the coast of San Francisco.
At Alcatraz, Capone's decline became increasingly evident as neurosyphilis progressively eroded his mental faculties. He spent the last year of his sentence in the prison hospital, confused and disoriented. Capone completed his term in Alcatraz on January 6, 1939, and was transferred to the Federal Correctional Institution at Terminal Island in California to serve out his sentence for contempt of court. He was paroled on November 16, 1939.
Later years and death.
After Capone was released from prison, he was referred to Johns Hopkins Hospital in Baltimore for the treatment of paresis (caused by late-stage syphilis). Hopkins refused to admit him based solely on his reputation, but Union Memorial Hospital took him in. Capone was grateful for the compassionate care that he received, and donated two Japanese weeping cherry trees to Union Memorial Hospital in 1939. A very sickly Capone left Baltimore on March 20, 1940, after a few weeks inpatient and a few weeks outpatient, for Palm Island, Florida.
In 1946, his physician and a Baltimore psychiatrist performed examinations and concluded that Capone had the mental capability of a 12-year-old child. Capone spent the last years of his life at his mansion in Palm Island, Florida. On January 21, 1947, Capone had a stroke. He regained consciousness and started to improve but contracted pneumonia. He suffered a fatal cardiac arrest the next day. On January 25, 1947, Al Capone died in his home, surrounded by his family; he wаs buried аt Mount Carmel Cemetery in Hillside, Illinois.
Chicago aftermath.
The main effect of Capone's conviction was that he ceased to be boss immediately on his imprisonment, but those involved in the jailing of Capone portrayed it as considerably undermining the city's organized crime syndicate. Far from being smashed, the Chicago Outfit continued without being troubled by the Chicago police, but at a lower-level and without the open violence that had marked Capone's rule. Organized crime in the city had a lower profile once Prohibition was repealed, already wary of attention after seeing Capone's notoriety bring him down, to the extent that there is a lack of consensus among writers about who was actually in control and who was a figurehead 'front boss'. Prostitution, labor union racketeering, and gambling became moneymakers for organized crime in the city without incurring serious investigation. In the late 1950s, FBI agents discovered an organization led by Capone's former lieutenants reigning supreme over the Chicago underworld.
In popular culture.
Capone is one of the most notorious American gangsters of the 20th century and has been the subject of numerous articles, books, and films. His personality and character have been used in fiction as a model for crime lords and criminal masterminds ever since his death. The stereotypical image of a mobster wearing a blue pinstriped suit and tilted fedora is based on photos of Capone. His accent, mannerisms, facial construction, physical stature, and parodies of his name have been used for numerous gangsters in comics, movies, music, and literature.
Film and television.
Capone has been portrayed on screen by:
Actors playing characters based on Capone include:

</doc>
<doc id="3214" url="https://en.wikipedia.org/wiki?curid=3214" title="Amplifier figures of merit">
Amplifier figures of merit

In electronics, the figures of merit of an amplifier are numerical measures that characterize its properties and performance. Figures of merit can be given as a list of specifications that include properties such as gain, bandwidth, noise and linearity, among others listed in this article. Figures of merit are important for determining the suitability of a particular amplifier for an intended use.
Gain.
The gain of an amplifier is the ratio of output to input power or amplitude, and is usually measured in decibels. (When measured in decibels it is logarithmically related to the power ratio: "G"(dB)=10 log("P /("P)). RF amplifiers are often specified in terms of the maximum power gain obtainable, while the voltage gain of audio amplifiers and instrumentation amplifiers will be more often specified (since the amplifier's input impedance will often be much higher than the source impedance, and the load impedance higher than the amplifier's output impedance). For example, an audio amplifier with a gain given as 20 dB will have a "voltage gain" of ten (but a power gain of 100 would only occur in the event the input and output impedances were identical).
If two equivalent amplifiers are being compared, the amplifier with higher gain settings would be more sensitive as it would take less input signal to produce a given amount of power.
Bandwidth.
The bandwidth of an amplifier is the range of frequencies for which the amplifier gives "satisfactory performance". The definition of "satisfactory performance" may be different for different applications. However, a common and well-accepted metric is the half power points (i.e. frequency where the power goes down by half its peak value) on the output vs. frequency curve. Therefore, bandwidth can be defined as the difference between the lower and upper half power points. This is therefore also known as the bandwidth. Bandwidths (otherwise called "frequency responses") for other response tolerances are sometimes quoted (, etc.) or "plus or minus 1dB" (roughly the sound level difference people usually can detect).
The gain of a good quality full-range audio amplifier will be essentially flat between 20 Hz to about 20 kHz (the range of normal human hearing). In ultra high fidelity amplifier design, the amplifier's frequency response should extend considerably beyond this (one or more octaves either side) and might have points < 10 Hz and > . Professional touring amplifiers often have input and/or output filtering to sharply limit frequency response beyond ; too much of the amplifier's potential output power would otherwise be wasted on infrasonic and ultrasonic frequencies, and the danger of AM radio interference would increase. Modern switching amplifiers need steep low pass filtering at the output to get rid of high frequency switching noise and harmonics.
The range of frequency over which the gain is equal to or greater than 70.7% of its maximum gain is termed as bandwidth.
Efficiency.
Efficiency is a measure of how much of the power source is usefully applied to the amplifier's output. Class A amplifiers are very inefficient, in the range of 10–20% with a max efficiency of 25% for direct coupling of the output. Inductive coupling of the output can raise their efficiency to a maximum of 50%.
Drain efficiency is the ratio of output RF power to input DC power when primary input DC power has been fed to the drain of a field-effect transistor. Based on this definition, the drain efficiency cannot exceed 25% for a class A amplifier that is supplied drain bias current through resistors (because RF signal has its zero level at about 50% of the input DC). Manufacturers specify much higher drain efficiencies, and designers are able to obtain higher efficiencies by providing current to the drain of the transistor through an inductor or a transformer winding. In this case the RF zero level is near the DC rail and will swing both above and below the rail during operation. While the voltage level is above the DC rail current is supplied by the inductor.
Class B amplifiers have a very high efficiency but are impractical for audio work because of high levels of distortion (See: Crossover distortion). In practical design, the result of a tradeoff is the class AB design. Modern Class AB amplifiers commonly have peak efficiencies between 30–55% in audio systems and 50-70% in radio frequency systems with a theoretical maximum of 78.5%.
Commercially available Class D switching amplifiers have reported efficiencies as high as 90%. Amplifiers of Class C-F are usually known to be very high efficiency amplifiers. RCA manufactured an AM broadcast transmitter employing a single class-C low mu triode with an RF efficiency in the 90% range.
More efficient amplifiers run cooler, and often do not need any cooling fans even in multi-kilowatt designs. The reason for this is that the loss of efficiency produces heat as a by-product of the energy lost during the conversion of power. In more efficient amplifiers there is less loss of energy so in turn less heat.
In RF linear Power Amplifiers, such as cellular base stations and broadcast transmitters, special design techniques can be used to improve efficiency. Doherty designs, which use a second output stage as a "peak" amplifier, can lift efficiency from the typical 15% up to 30-35% in a narrow bandwidth. Envelope Tracking designs are able to achieve efficiencies of up to 60%, by modulating the supply voltage to the amplifier in line with the envelope of the signal.
Linearity.
An ideal amplifier would be a totally linear device, but real amplifiers are only linear within limits.
When the signal drive to the amplifier is increased, the output also increases until a point is reached where some part of the amplifier becomes saturated and cannot produce any more output; this is called clipping, and results in distortion.
In most amplifiers a reduction in gain takes place before hard clipping occurs; the result is a "compression" effect, which (if the amplifier is an audio amplifier) sounds much less unpleasant to the ear. For these amplifiers, the 1 dB compression point is defined as the input power (or output power) where the gain is 1 dB less than the small signal gain. Sometimes this non linearity is deliberately designed in to reduce the audible unpleasantness of hard clipping under overload.
Ill effects of non linearity can be reduced with negative feedback.
Linearization is an emergent field, and there are many techniques, such as feed forward, predistortion, postdistortion, in order to avoid the undesired effects of the non-linearities.
Noise.
This is a measure of how much noise is introduced in the amplification process. Noise is an undesirable but inevitable product of the electronic devices and components; also, much noise results from intentional economies of manufacture and design time. The metric for noise performance of a circuit is noise figure or noise factor. Noise figure is a comparison between the output signal to noise ratio and the thermal noise of the input signal.
Output dynamic range.
Output dynamic range is the range, usually given in dB, between the smallest and largest useful output levels. The lowest useful level is limited by output noise, while the largest is limited most often by distortion. The ratio of these two is quoted as the amplifier dynamic range. More precisely, if "S" = maximal allowed signal power and "N" = noise power, the dynamic range "DR" is "DR = (S + N ) /N".
In many switched mode amplifiers, dynamic range is limited by the minimum output step size.
Slew rate.
Slew rate is the maximum rate of change of the output, usually quoted in volts per second (or microsecond). Many amplifiers are ultimately slew rate limited (typically by the impedance of a drive current having to overcome capacitive effects at some point in the circuit), which sometimes limits the full power bandwidth to frequencies well below the amplifier's small-signal frequency response.
Rise time.
The rise time, t, of an amplifier is the time taken for the output to change from 10% to 90% of its final level when driven by a step input.
For a Gaussian response system (or a simple RC roll off), the rise time is approximated by:
t * BW = 0.35, where t is rise time in seconds and BW is bandwidth in Hz.
Settling time and ringing.
The time taken for the output to settle to within a certain percentage of the final value (for instance 0.1%) is called the settling time, and is usually specified for oscilloscope vertical amplifiers and high accuracy measurement systems. Ringing refers to an output variation that cycles above and below an amplifier's final value and leads to a delay in reaching a stable output. Ringing is the result of overshoot caused by an underdamped circuit.
Overshoot.
In response to a step input, the overshoot is the amount the output exceeds its final, steady-state value.
Stability.
Stability is an issue in all amplifiers with feedback, whether that feedback is added intentionally or results unintentionally. It is especially an issue when applied over multiple amplifying stages.
Stability is a major concern in RF and microwave amplifiers. The degree of an amplifier's stability can be quantified by a so-called stability factor. There are several different stability factors, such as the Stern stability factor and the Linvil stability factor, which specify a condition that must be met for the absolute stability of an amplifier in terms of its two-port parameters.

</doc>
<doc id="3217" url="https://en.wikipedia.org/wiki?curid=3217" title="Army of Darkness">
Army of Darkness

Army of Darkness is a 1992 American horror comedy film directed by Sam Raimi. It is the third installment of the "Evil Dead" franchise. The film was written by Raimi and his brother Ivan, produced by Robert Tapert, and stars Bruce Campbell (also acting as co-producer) and Embeth Davidtz. Continuing from "Evil Dead II", Ash Williams (Campbell) is trapped in the Middle Ages and battles the undead in his quest to return to the present.
The film was produced as part of a production deal with Universal Studios after the financial success of "Darkman". Filming took place in California in 1991. "Army of Darkness" premiered on October 9, 1992 at the Sitges Film Festival, and was released in the United States on February 19, 1993. It grossed $11.503 million domestically and another $10 million outside the USA for a total worldwide gross of $21.5 million. Critical response was positive. Since its video release it has acquired a massive cult following, along with the other two films in the trilogy. The film was dedicated to Irvin Shapiro, who died during the film's production in 1989 on New Year's Day. The makeup and creature effects for the film were handled by two different companies: Tony Gardner (designer) and his company Alterian Studios, Inc. (Alterian, Inc.) were responsible for the Ash & Sheila Makeup Effects, while Kurtzman, Nicotero & Berger EFX Group was credited for the remaining Special Makeup Effects characters.
Plot.
After being pulled through a time portal, Ash Williams lands in A.D. 1300, where he is soon captured by Lord Arthur's men, who suspect him to be an agent for Duke Henry, with whom Arthur is at war. He is enslaved along with the captured Henry, his gun and chainsaw confiscated, and is taken to a castle. Ash is thrown in a pit where he fights off a Deadite and regains his weapons from Arthur's Wise Man. After demanding Henry and his men be set free (as he knew Henry was innocent, and his persecution was simply a witch hunt) and killing a Deadite in full view of everyone, Ash is celebrated as a hero. He also grows attracted to Sheila, the sister of one of Arthur's fallen knights.
According to the Wise Man, the only way Ash can return to his time is to retrieve the "Necronomicon Ex-Mortis", a book with magical powers. After bidding goodbye to Sheila, Ash starts his search for the "Necronomicon". As he enters a haunted forest, an unseen force pursues Ash through the woods. Fleeing, he ducks into a windmill where he crashes into a mirror. The small reflections of Ash climb out from the shattered mirror and torment him. One of the reflections dives down Ash's throat and uses his body to become a life-sized clone of Ash and attack him, after which Ash kills and buries the clone.
When he arrives at the "Necronomicon"s location, he finds three books instead of one. Ash eventually finds the real one and attempts to say the magic phrase that will allow him to remove the book safely – "Klaatu barada nikto". However, forgetting the last word, he tries to trick the book by mumbling and coughing the missing word. He then grabs the book from the cradle, and rushes back to the castle, while the dead rise from graves all around. During Ash's panicked ride back, his evil copy rises from his grave and unites the Deadites into the Army of Darkness.
Despite causing the predicament faced by the medieval soldiers, Ash initially demands to be returned to his own time. However, Sheila is captured by a Flying Deadite, and later transformed into a Deadite. Ash becomes determined to lead the humans against the army of the dead. Reluctantly, the people agree to join Ash. Using scientific knowledge from textbooks in the trunk of his 1973 Oldsmobile Delta 88, and enlisting the help of Duke Henry, Ash successfully leads the medieval soldiers to victory over the Deadites and Evil Ash, saving Sheila and bringing peace between Arthur and Henry in the process. The Wise Men return him to his own time, giving him a potion to drink after reciting the magic phrase.
Back in the present, Ash recounts his story to a fellow employee at his job, working in housewares at a store called "S-Mart". As he talks to a girl who is interested in his story, a surviving deadite, allowed to come to the present due to Ash again forgetting the last word of the magic phrase, attacks the customers. Ash attacks and kills it using a Winchester rifle from the store's Sporting Goods department, finally ending the deadite threat.
Original ending.
The original ending, preferred by Raimi and Campbell themselves, in which Ash oversleeps in the cave and wakes up in a post-apocalyptic future, was restored to the film for the UK VHS release, which also had the S-Mart ending put in as a post-credit extra. This scene has been restored on the "Army of Darkness: Director's Cut" Region 3 DVD released by Metro-Goldwyn-Mayer, the "director's cut bootleg edition" DVD and the double-disc DVD, which also featured the S-Mart ending of the film. The S-Mart ending was shot for the American release; the studio wanted to end the film on a high note for the character of Ash. Raimi believed Ash to be more of a fool, which is why he liked to torture him so much in his films; Ash being a goof and drinking too much potion was in his character.
Production.
Development.
Plans to make a third "Evil Dead" film had been circulating for a number of years, even prior to the production of "Darkman". "Evil Dead II" made enough money internationally that Dino De Laurentiis was willing to finance a sequel. Director and script writer Sam Raimi drew from a variety of sources, including literature with "A Connecticut Yankee in King Arthur's Court" and Jonathan Swift's "Gulliver's Travels" and films like "The Seventh Voyage of Sinbad", "Jason and the Argonauts", and The Three Stooges. "Evil Dead II", according to Bruce Campbell, "was originally designed to go back into the past to 1300, but we couldn't muster it at the time, so we decided to make an interim version, not knowing if the 1300 story would ever get made". Promotional drawings were created and published in "Variety" during the casting process before the budget was deemed too little for the plot. The working title for the project was "Evil Dead III: Army of Darkness". The title "Army of Darkness" came from an idea by Irvin Shapiro, during the production of "Evil Dead II". This was used after Sam Raimi was unable to use his original title "The Medieval Dead." ("The Medieval Dead" would later be used as the film's subtitle for its UK release as "Army of Darkness: The Medieval Dead").
Screenplay and pre-production.
Initially, Raimi invited Scott Spiegel to co-write "Army of Darkness" because he had done a good job on "Evil Dead II", but he was busy on rewrites for the Clint Eastwood film "The Rookie". After the good experience of writing the screenplay for a film called "Easy Wheels", Sam and his brother Ivan decided to co-write the film together. They worked on the script throughout the pre-production and production of "Darkman". After filming "Darkman", they took the script out and worked on it in more detail. Raimi says that Ivan "has a good sense of character" and that he brought more comedy into the script. Campbell remembers, "We all decided, 'Get him out of the cabin.' There were earlier drafts where part three still took place there, but we thought, 'Well, we all know that cabin, it's time to move on.' The three of us decided to keep it in 1300, because it's more interesting". Campbell and Tapert would read the script drafts, give Raimi their notes and he would decide which suggestions to keep and which ones to discard.
The initial budget was $8 million but during pre-production, it became obvious that this was not going to be enough. "Darkman" was also a financial success and De Laurentiis had a multi-picture deal with Universal and so "Army of Darkness" became one of the films. The studio decided to contribute half of the film's $12 million budget. However, the film's ambitious scope and its extensive effects work forced Campbell, Raimi and producer Robert Tapert to put up $1 million of their collective salaries to shoot a new ending and not film a scene where a possessed woman pushes down some giant pillars. Visual effects supervisor William Mesa showed Raimi storyboards he had from Victor Fleming's film "Joan of Arc" that depicted huge battle scenes and he picked out 25 shots to use in "Army of Darkness". A storyboard artist worked closely with the director in order to blend the shots from the "Joan of Arc" storyboards with the battle scenes in his film.
Traci Lords was among the actresses auditioning for the film, saying in 2001, "I didn't get the part but I clicked with Bruce ampbel," with whom she would later work as a guest star in the TV series "".
Principal photography.
Principal photography took place between soundstage and on-location work. "Army of Darkness" was filmed in Bronson Canyon and Vasquez Rocks Natural Area Park. The interior shots were filmed on an Introvision stage in Hollywood. Raimi's use of the Introvision process was a tribute to the stop-motion animation work of Ray Harryhausen. Introvision uses front-projected images with live actors instead of the traditional rear projection that Harryhausen and others used. Introvision blended components with more realistic-looking results. To achieve this effect, Raimi used 60-foot-tall Scotchlite front-projection screens, miniatures and background plates. According to the director, the advantage of using this technique was "the incredible amount of interaction between the background, which doesn't exist, and the foreground, which is usually your character".
Shooting began in mid-1991, and it lasted for about 100 days. It was a mid-summer shoot and while on location on a huge castle set that was built near Acton, California on the edge of the Mojave Desert, the cast and crew endured very hot conditions during the day and very cold temperatures at night. Most of the film took place at night and the filmmakers shot most of the film during the summer when the days were longest and the nights were the shortest. It would take an hour and a half to light an area leaving the filmmakers only six hours left to shoot a scene. Money problems forced cinematographer Bill Pope to shoot only for certain hours Monday through Friday because he could not be paid his standard fee. Mesa shot many of the action sequences on the weekend.
It was a difficult shoot for Campbell who had to learn elaborate choreography for the battle scenes, which involved him remembering a number system because the actor was often fighting opponents that were not really there. Mesa remembers, "Bruce was cussing and swearing some of the time because you had to work on the number system. Sam would tell us to make it as complicated and hard for Bruce as possible. 'Make him go through torture!' So we'd come up with these shots that were really, really difficult, and sometimes they would take thirty-seven takes". Some scenes, like Evil Ash walking along the graveyard while his skeleton minions come to life, blended stop-motion animation with live skeletons that were mechanically rigged, with prosthetics and visual effects.
Post-production.
While Dino De Laurentiis gave Raimi and his crew freedom to shoot the film the way they wanted, Universal took over during post-production. Universal was not happy with Raimi's cut because it did not like his original ending, feeling it was negative. A more upbeat ending was shot a month later in a lumber store in Malibu, California. Then, two months after principal filming was finished, a round of re-shoots began in Santa Monica and involved Ash in the windmill and the scenes with Bridget Fonda. Raimi recalls, "Actually, I kind of like the fact that there are two endings, that in one alternate universe Bruce is screwed, and in another universe he's some cheesy hero".
Raimi needed $3 million to finish his film, but Universal was not willing to give him the money and delayed its release due to a dispute with De Laurentiis over the rights to the Hannibal Lecter character which Universal needed so that they could film a sequel to "The Silence of the Lambs". The matter was finally resolved, but the release date for "Army of Darkness"' was pushed back from summer of 1992 to February 1993.
For the film's poster, Universal brought Campbell in to take several reference head shots and asked him to strike a sly look on his face. They showed him a rough of the Frank Frazetta-like painting. The actor had a day to approve it or, as he was told, there would be no ad campaign for the film. Raimi ran into further troubles when the MPAA gave it an NC-17 rating for a shot of a female Deadite being decapitated early on in the film. Universal wanted a PG-13 rating, so Raimi made a few cuts and was still stuck with an R rating. In response, Universal turned the film over to outside film editors who cut the film to 81 minutes and another version running 87 minutes that was eventually released in theaters, still with an R rating.
Music.
Danny Elfman, who composed the score for "Darkman", wrote the "March of the Dead" theme for "Army of Darkness". After the re-shoots were completed, Joseph LoDuca, who composed the music for "The Evil Dead" and "Evil Dead II", returned to score the film. The composer used his knowledge of synthesizers and was able to present many cues in a mock-up form before he took them in front of an orchestra. The score is set for a release during the MondoCon in Austin, Texas on 3 and 4 October 2015, on Vinyl, over Mondo Records.
Reception.
Box office.
"Army of Darkness" was released by Universal on February 19, 1993 in 1,387 theaters in the United States, grossing $4.4 million (38.5% of total gross) on its first weekend. In total, the film earned $11.5 million in the US.
Critical reception.
The film currently holds a 72% "Fresh" rating on the review aggregate website Rotten Tomatoes, based on 46 reviews, which made its critical reception above average but much lower than "The Evil Dead" and "Evil Dead II", which received 96% and 98% respectively. On Metacritic, the film holds a score of 57 out of 100, indicating "mixed or average reviews". Roger Ebert gave the film two out of four stars and wrote, "The movie isn't as funny or entertaining as "Evil Dead II", however, maybe because the comic approach seems recycled." In her review for "The New York Times", Janet Maslin praised, "Mr. Campbell's manly, mock-heroic posturing is perfectly in keeping with the director's droll outlook." Desson Howe, in this review for "The Washington Post" praised the film's style: "Bill Pope's cinematography is gymnastic and appropriately frenetic. The visual and make-up effects (from artist-technicians William Mesa, Tony Gardner and others) are incredibly imaginative." However, "Entertainment Weekly" gave the film a "C+" rating and wrote, "This spoofy cast of thousands looks a little too much like a crew of bland Hollywood extras. By the time "Army of Darkness" turns into a retread of "Jason and the Argonauts", featuring an army of fighting skeletons, the film has fallen into a ditch between parody and spectacle."
Accolades.
"Army of Darkness" won the Saturn Award for Best Horror Film (1994). It was also nominated for Best Make-Up. "Army of Darkness" was nominated for the Grand Prize at Avoriaz Fantastic Film Festival, and won the Golden Raven at the Brussels International Festival of Fantasy Film in 1993. The film also won the Critics' Award at Fantasporto, and was nominated for the International Fantasy Film Award in the category of Best Film in 1993. It was also nominated for Best Film at Sitges, the Spanish International Film Festival.
Sequel.
In March 2013, shortly before the release of "Evil Dead", a reboot and loose continuation of the franchise, Raimi confirmed that the next "Evil Dead" film will be "Army of Darkness 2". Campbell confirmed that he would star as an older, but not necessarily wiser, Ash. At a WonderCon panel in March 2013, Campbell and Fede Alvarez, director of the reboot, stated that their ultimate plan was for Alvarez's "Evil Dead 2" and Raimi's "Army of Darkness 2" to be followed by a seventh film which would merge the narratives of Ash and Mia. On October 18, 2013, Campbell once again confirmed in an interview with ComicBook.com that he will be reprising his role as Ash in the sequel. Fede Alvarez posted a status update on his Twitter account that Raimi will direct the sequel. Campbell later commented that the rumor about him returning is false.
In July 2014, Campbell stated it was likely the planned sequel would instead be a TV series with him as the star. The ten-episode season of "Ash vs. Evil Dead" premiered on Starz on October 31, 2015, with the pilot co-written and directed by Sam Raimi. Due to legal issues with Universal, the events from "Army of Darkness" can not specifically be mentioned on the show. In addition to Campbell, the series stars Dana DeLorenzo, Ray Santiago, and Lucy Lawless.
Adaptations.
Comics.
"Army of Darkness" had a comic book adaptation and several comic book sequels. The movie adaptation, from publisher Dark Horse Comics, was actually published before the film's theatrical release.
Role-playing game.
Eden Studios, Inc. published the "Army of Darkness Roleplaying Game" in 2005.

</doc>
<doc id="3218" url="https://en.wikipedia.org/wiki?curid=3218" title="RUR-5 ASROC">
RUR-5 ASROC

The RUR-5 ASROC (for Anti-Submarine ROCket) is an all-weather, all sea-conditions anti-submarine missile system. Developed by the United States Navy in the 1950s, it was deployed in the 1960s, updated in the 1990s, and eventually installed on over 200 USN surface ships, specifically cruisers, destroyers, and frigates. The ASROC has been deployed on scores of warships of many other navies, including Canada, Germany, Italy, Japan, the Republic of China, Greece, Pakistan and others.
History.
ASROC started development as the Rocket Assisted Torpedo (RAT) program by the Naval Ordnance Test Station at China Lake in the early 1950s to develop a surface warship ASW weapon counter to the new post-World War II submarines which ran quieter, at much higher speed and could attack from much longer range with high speed homing torpedoes. In addition, the goal was to take advantage of modern sonars with a much larger detection range. An extended range torpedo delivered by parachute from the air would allow warships the stand-off capability to attack hostile submarines with very little advance notice to the hostile submarine. The RAT program came in three phases: RAT-A, RAT-B and RAT-C. RAT-A (and its follow-on, RAT-B) were efforts to develop a compact and economical stand-off ASW for smaller warships, but were found to be either unreliable or had too short a range. RAT-C was a program to develop a stand-off ASW weapon that used a nuclear depth charge. This would require a range of at least 8,000 yards to escape potential damage from the underwater blast. Unlike the original RAT program rockets, the RAT-C was considerably larger to accomplish the extended range needed and was to be fitted to larger warships. With the failure of both the RAT-A and RAT-B programs, RAT-C was redesigned from a stand-off nuclear ASW weapon to one that could use not only a nuclear depth charge but also a homing ASW torpedo. To obtain the accuracy needed, the RAT-C rocket launcher had to be redesigned with larger side fins. This program finally combined reliability and accuracy, along with the necessary stand-off range. However, before RAT-C reached initial operational status in 1960 aboard the large US Navy destroyer leader , its name was changed to the present ASROC.
Description.
After a surface ship, patrol plane or anti-submarine helicopter detects an enemy submarine by using sonar or other sensors, it could relay the sub's position to an ASROC-equipped ship for attack. The attacking ship would then fire an ASROC missile carrying an acoustic homing torpedo or a Nuclear Depth Bomb (NDB) onto an unguided ballistic trajectory toward the target. At a pre-determined point on the missile's trajectory, the payload separates from the missile and deploys a parachute to permit splashdown and water entry at a low speed and with minimum detectable noise. The water entry activates the torpedo, which is guided by its own sonar system, and homes in on the target using either active sonar or passive sonar.
In cases where the ASROC missile carried an NDB, the unguided bomb would sink quickly to a predetermined depth where it would detonate. The nuclear-armed ASROC was never used beyond one or two tests in 1961-62. Eventually the Limited Nuclear Test Ban Treaty banning underwater nuclear tests went into effect. The nuclear weapon was never used in combat. An ASROC missile could hypothetically carry a 10 kiloton W44 nuclear warhead, although the W44-armed nuclear weapons were retired by 1989, and all types of nuclear depth bombs were removed from deployment.
The first ASROC system using the MK-112 "Matchbox" launcher, was developed in the 1950s and installed in the 1960s. This system was phased out in the 1990s and replaced with the RUM-139 Vertical Launch ASROC, or "VLA".
Specific installations.
The 31 U.S. Navy s were all built with the Mark 16 Mod 7 ASROC Launching Group and MK 4 ASROC Weapons Handling System (AWHS) reload system. These had one standard Mark 112 octuple ASROC launcher, located immediately above a reload system holding an additional 16 assembled rounds (two complete reloads of eight missiles apiece). Thus, each "Spruance"-class destroyer originally carried a maximum total of 24 ASROC.
Most other US Navy and allied navy destroyers, destroyer escorts, frigates, and several different classes of cruisers only carried the one ASROC 'matchbox' MK 112 launcher with eight ASROC missiles (although later in service, some of those missiles could be replaced by the Harpoon anti-ship missile). The "matchbox" Mk 112 launchers were capable of carrying a mixture of the two types. Reloads were carried in many classes, either on first level of the superstructure immediately abaft the launcher, or in a separate deckhouse just forward or abaft the Mk 112.
The MK 16 Launching Group also had configurations that supported RGM-84 Harpoon (onboard destroyer escorts (frigates)) or a variation of the Tartar missile in limited distribution.
Ships with the Mk 26 GMLS, and late marks of the Mk 10 GMLS aboard the s, could accommodate ASROC in these power-loaded launchers (the Mk 13 GMLS was not able to fire the weapon, as the launcher rail was too short).
Most "Spruance"-class destroyers were later modified to include the Mk 41 VLS, these launchers are capable of carrying a mixture of the RUM-139 VL-ASROC, the Tomahawk TLAM, and other missiles. All of the "Spruance" destroyers carried two separate quad Harpoon launchers. Other US ships with the Mk 41 can also accommodate VL-ASROC.
Movie appearance.
In the movie "The Bedford Incident" (1965) an ASROC is inadvertently launched against a Soviet submarine.

</doc>
<doc id="3221" url="https://en.wikipedia.org/wiki?curid=3221" title="Ahmed al-Nami">
Ahmed al-Nami

Ahmed bin Abdullah al-Nami (Arabic: أحمد بن عبد الله النعمي, ; also transliterated as Alnami; August 17, 1977 – September 11, 2001) was one of four hijackers of United Airlines Flight 93 as part of the September 11 attacks. 
Born in Saudi Arabia, Nami had served as a muezzin and was a college student. He left his family in 2000 to complete the Hajj, but later went to Afghanistan bound for an al-Qaeda training camp where he befriended other future hijackers and would soon be chosen to participate in the attacks.
He arrived in the United States in May 2001, on a tourist visa, where he would settle in Florida up until the attacks. On September 11, 2001, Nami boarded United 93 and assisted in the hijacking of the plane, which crashed into a field in rural Shanksville, Pennsylvania, after a passenger uprising, due to the passengers receiving information from their families of the 3 other hijacked planes that hit the World Trade Center and the Pentagon.
History.
Nami, much like Abdulaziz al-Omari, Wail al-Shehri, Waleed al-Shehri, and Mohand al-Shehri was born in the 'Asir Province in Saudi Arabia. Born to the Quraish tribe of Saudi Arabia, Nami served as a muezzin at the Seqeley mosque after having reportedly become very religious sometime in early 1999. That autumn he left his family home in Khamis Mushayt in the summer of 2000 to complete the Hajj, but never returned – instead travelling to the Al Farouq training camp in Afghanistan where he met and befriended Waleed and Wail al-Shehri, two brothers from Khamis Mushayt, and Saeed al-Ghamdi. The four reportedly pledged themselves to Jihad in the Spring of 2000, in a ceremony presided over by Wail – who had dubbed himself "Abu Mossaeb al-Janubi" after one of Muhammad's companions. Dubbed "Abu Hashim", Nami was considered "gentle in manner" by his colleagues, and reported that he had a dream in which he rode a mare along with Muhammad, and that the prophet told him to dismount and fight his enemies to liberate his land.
During his time at al-Farooq, there is a curious mention under Mushabib al-Hamlan's details that Nami had recently had laser eye surgery, an uncited fact that does not reappear. 
By October he had taken a prospective hijacker Mushabib al-Hamlan from Afghanistan to Saudi Arabia where they both procured B-1/B-2 tourist/business visas on October 28 – but Hamlan then decided not to proceed and is thought to have returned to his family. Nami's Visa application has since been reviewed, and while he mentioned that Mushabib will be travelling with him, he listed his occupation as "student" but failed to provide an address for his school, and listed his intended address in the United States merely as Los Angeles – in the end he never used this Visa to enter the United States, and reported his passport (C115007, which showed evidence of travel to Afghanistan) as "lost", and procured a new one from Jeddah (C505363). He used the new passport to acquire a new B-1/B-2 visa in Jeddah on April 23, again recopying his answers from previously although crossing out the lines regarding Mushabib and previous attempts to acquire a visa. He was interviewed by a consular officer, who again approved his application. Records at the time only recorded past failures to procure a visa, so the officer had no way of realising that Nami had successfully received an earlier visa.
In mid-November 2000, the 9/11 Commission believes that Nami, Wail and Waleed al-Shehri, all of whom had obtained their U.S. visas in late October, traveled in a group from Saudi Arabia to Beirut and then onward to Iran where they could travel through to Afghanistan without getting their passports stamped. This probably followed their return to Saudi Arabia to get "clean" passports. An associate of a senior Hezbollah operative is thought to have been on the same flight, although this may have been a coincidence. 
While in the United Arab Emirates, Nami purchased traveler's cheques presumed to have been paid for by Mustafa al-Hawsawi. Five other hijackers also passed through the UAE and purchased travellers cheques, including Majed Moqed, Saeed al-Ghamdi, Hamza al-Ghamdi, Ahmed al-Haznawi and Wail al-Shehri.
2001.
In March 2001, Ahmed al-Nami appeared in an al-Qaeda farewell video showing 13 of the "muscle hijackers" before they left their training centre in Kandahar; while he does not speak, he is seen studying maps and flight manuals.
On April 23, Nami was recorded obtaining a new US Visa.
On May 28, Nami arrived in the United States from Dubai with fellow-hijackers Mohand al-Shehri and Hamza al-Ghamdi. By early June, Nami was living in apartment 1504 at the Delray Racquet Club condominiums with Saeed al-Ghamdi in Delray Beach, Florida. He telephoned his family in 'Asir shortly after arriving in the country.
In June, he phoned his family for the last time.
He was one of 9 hijackers to open a SunTrust bank account with a cash deposit around June 2001, and on June 29 received either a Florida State Identification Card or Drivers License. 
He may have been one of three hijackers that listed the Naval Air Station in Pensacola, Florida as their permanent address on drivers' licenses, though other sources claim he listed the Delray condominium.
On August 28, Nami and Ahmed al-Haznawi reportedly bothered a Delray Beach resident, Maria Siscar Simpson, to let them through her apartment to retrieve a towel that had fallen off their balcony onto hers.
On September 5, Nami and Saeed al-Ghamdi purchased tickets for a September 7 flight to Newark at Mile High Travel on Commercial Boulevard—paying cash for their tickets. Ziad Jarrah and Ahmed al-Haznawi also purchased tickets for the same flight from Passage Tours.
On September 7, all four Flight 93 hijackers flew from Fort Lauderdale to Newark International Airport aboard Spirit Airlines.
Attacks.
On September 11, 2001, Nami arrived in Newark to board United Airlines Flight 93 along with Saeed al-Ghamdi, Ahmed al-Haznawi and Ziad Jarrah. Some reports suggest Haznawi was pulled aside for screening while others claim there is no record of whether any of the four were screened; the lack of CCTV cameras at the time has compounded the problem. Nami boarded the plane between 7:39 am and 7:48 am; seated in First Class 3C, next to Saeed al-Ghamdi.
Due to the flight's routine delay, the pilot and crew were notified of the previous hijackings and were told to be on the alert, though within two minutes Jarrah had stormed the cockpit leaving the pilots dead or injured.
At least two of the cellphone calls made by passengers indicate that all the hijackers they saw were wearing red bandanas, which some have questioned may have signified an allegiance to the Egyptian Islamic Jihad. The calls also indicated that one of the men had tied a box around his torso, and claimed there was a bomb inside; it is not known which hijacker this was.
Passengers on the plane heard through phone calls the fates of the other hijacked planes, and organized a brief assault to retake the cockpit. The hijackers crashed the plane into the Pennsylvanian countryside rather than cede control of the plane. All aboard died.
Aftermath.
After the attacks, an employee of Saudi Arabian Airlines named Ahmed al-Nami came forward to say that he feared his identity had been stolen, although he had never lost his passport.
In popular culture.
He has been portrayed by British actor Jamie Harding in the 2006 film "United 93" and Asim Wali in the film Flight 93.

</doc>
<doc id="3222" url="https://en.wikipedia.org/wiki?curid=3222" title="Ahmed al-Haznawi">
Ahmed al-Haznawi

Ahmed Ibrahim al-Haznawi (, ) (October 11, 1980 – September 11, 2001) was one of four hijackers of United Airlines Flight 93 as part of the September 11 attacks.
He left his family to fight in Chechnya in 2000 but was probably sent to training camps in Afghanistan. It was there he was chosen to participate in the 9/11 attacks. He arrived in the United States in June 2001 under the direction of Al-Qaeda for terrorist attacks, on a tourist visa. Once he was in the U.S., he settled in Florida and helped plan out how the attacks would take place.
On September 11, 2001, Haznawi boarded United Airlines Flight 93 and assisted in the hijacking of the plane, which crashed into a field in Shanksville, Pennsylvania, after a passenger uprising.
Early life.
Ahmed al-Haznawi was the son of a Saudi imam from the Al-Bahah province, a province in the south west of Saudi Arabia. It is the capital of Al Bahah Province nestled between the resorts of Mecca and Abha, Al Bahah is one of the Kingdom’s prime tourist attractions. Haznawi grew up in the village of Hazna, where his father was a cleric at the mosque in the central marketplace section of the village. Haznawi belonged to a family that was part of the larger, al-Ghamdi tribe, sharing the same tribal affiliation with fellow hijackers Saeed al-Ghamdi, Hamza al-Ghamdi, and Ahmed al-Ghamdi. He memorised the Quran, giving him the title Hafiz.
This group is noted as being some of the more religiously observant of the hijackers, and they are thought to have met each other some time in 1999.
History.
1999–2000.
Alghamdi announced he was leaving his family in 1999 to fight in Chechnya, although his father forbade him. His father and brother, Abdul Rahman al-Haznawi, reportedly last heard from him in late 2000, after he made references to training in Afghanistan.
On November 12, 2000, Haznawi applied for and received a two-year U.S. B-1/B-2
(tourist/business) visa in Jeddah, Saudi Arabia.
From November 27, 2000 through December 27, 2000, Haznawi was in Saudi Arabia for Ramadan. It is theorized that during this trip, he may have initially told Saeed and Hamza al-Ghamdi about the operation.
Some time late in 2000, Haznawi traveled to the United Arab Emirates, where he purchased traveler's cheques presumed to have been paid for by Mustafa al-Hawsawi. Five other hijackers also passed through the UAE and purchased travellers cheques, including Majed Moqed, Saeed al-Ghamdi, Hamza al-Ghamdi, Wail al-Shehri and Ahmed al-Nami.
2001.
He was one of four hijackers believed to be staying at a Kandahar guest house in March 2001, where they were seen by Mohammed Jabarah. Jabarah remembered Haznawi specifically, saying that he was "very devout and could recite the entire Koran from memory."
On June 8 he arrived in Miami, Florida with fellow hijacker Wail al-Shehri. He was one of 9 hijackers to open a SunTrust bank account with a cash deposit around June 2001. He is believed to have moved in with Ziad Jarrah, who got a new apartment on Bougainvilla Dr. in Lauderdale-by-the-Sea, after both men gave the landlord photocopies of their German passports, which he later turned over to the FBI.
On June 25, Jarrah took Haznawi to Holy Cross Hospital in Fort Lauderdale on advice of his landlord Charles Lisa. Haznawi was treated by Dr. Christos Tsonas, who gave him antibiotics for a small gash on his left calf. While he told staff that he had bumped into a suitcase, the media briefly reported it as a sign of cutaneous anthrax and a possible link to the 2001 anthrax attacks, although FBI later addressed the rumors stating that "Exhaustive testing did not support that anthrax was present anywhere the hijackers had been."
On July 10 Haznawi obtained a Florida driver's license, later obtaining another copy on September 7, 2001 by filling out a change-of-address form. Five other hijackers also received duplicate Florida licenses in 2001, and others had licenses from different states. Some have speculated that this was to allow multiple persons to use the same identity.
Jarrah and Haznawi both received their one-way tickets for United Airlines Flight 93, on September 5. On September 7, all four Flight 93 hijackers flew from Fort Lauderdale to Newark International Airport aboard Spirit Airlines.
Attacks.
On September 11, 2001, Haznawi arrived at Newark International Airport to board Flight 93. Although he was selected for additional security by CAPPS and screened, he was able to board the flight without incident, with only his checked bags requiring extra screening for explosives.
Due to the flight's delay, the pilot and crew were notified of the previous hijackings that day and were told to be on the alert. Within minutes, Flight 93 was hijacked as well.
At least two of the cellphone calls made by passengers indicate that all the hijackers they saw were wearing red bandanas, which some believe may have signified an allegiance to the Egyptian Islamic Jihad. The calls also indicated that one of the men had tied a box around his torso, and claimed there was a bomb inside - it is not known which hijacker this was. Some passengers expressed doubt that the bomb was real.
Passengers on the plane heard through phone calls the fates of the other hijacked planes. A passenger uprising soon took place. Hijacker-pilot, Ziad Jarrah, crashed the plane into an empty field near Shanksville, Pennsylvania in order to prevent the passengers from gaining control of the plane. The crash killed everyone on board.
Aftermath.
After the attacks, before the release of the FBI pictures of the hijackers, Arab News reported that Haznawi's brother Abdul Rahman had told al-Madinah newspaper that a photograph published by local newspapers bore no resemblance to his brother.
A videotape released with The Wills of the New York and Washington Battle Martyrs, was aired on Al Jazeera on April 16, 2002. While the name beneath the speaker read "al-Ghamdi", the image is of Haznawi speaking. Officials suggested that the name was merely a reference to his tribal affiliation. The film was thought to have been made in March 2001. In it, he talked about his plans to bring the "bloodied message" to America. In September 2002, a similar tape made by Abdulaziz al-Omari appeared.
He has been portrayed by actors Omar Berdouni in "United 93", and Zak Santiago in "Flight 93".

</doc>
<doc id="3225" url="https://en.wikipedia.org/wiki?curid=3225" title="Athanasius of Alexandria">
Athanasius of Alexandria

Saint Athanasius of Alexandria (; ; "c". 296–298 – 2 May 373), also called Athanasius the Great, Athanasius the Confessor or, primarily in the Coptic Orthodox Church, Athanasius the Apostolic, was the twentieth bishop of Alexandria (as Athanasius I). His episcopate lasted 45 years (c. 8 June 328 – 2 May 373), of which over 17 were spent in five exiles ordered by four different Roman emperors. Athanasius is a renowned Christian theologian, a Church Father, the chief defender of Trinitarianism against Arianism, and a noted Egyptian leader of the fourth century.
Conflict with Arius and Arianism as well as successive Roman emperors shaped Athanasius's career. In 325, at the age of 27, Athanasius began his leading role against the Arians as his bishop's assistant during the First Council of Nicaea. Roman emperor Constantine the Great had convened the council in May–August 325 to address the Arian position that the Son of God, Jesus of Nazareth, is of a distinct substance from the Father. Three years after that council, Athanasius succeeded his mentor as archbishop of Alexandria. In addition to the conflict with the Arians (including powerful and influential Arian churchmen led by Eusebius of Nicomedia), he struggled against the Emperors Constantine, Constantius II, Julian the Apostate and Valens. He was known as "Athanasius Contra Mundum" (Latin for "Athanasius Against the World").
Nonetheless, within a few years of his death, Gregory of Nazianzus called him the "Pillar of the Church". His writings were well regarded by all Church fathers who followed, in both the West and the East, who noted their rich devotion to the Word-become-man, great pastoral concern, and profound interest in monasticism. Athanasius is counted as one of the four great Eastern Doctors of the Church in the Roman Catholic Church. In the Eastern Orthodox Church, he is labeled the "Father of Orthodoxy". Some Protestants label him "Father of the Canon". Athanasius is venerated as a Christian saint, whose feast day is 2 May in Western Christianity, 15 May in the Coptic Orthodox Church, and 18 January in the other Eastern Orthodox Churches. He is venerated by the Oriental and Eastern Orthodox Churches, the Roman Catholic Church, the Lutherans, and the Anglican Communion.
Biography.
Athanasius was born to a Christian family in the city of Alexandria or possibly the nearby Nile Delta town of Damanhur sometime between the years 293 and 298. The earlier date is sometimes assigned due to the maturity revealed in his two earliest treatises "Contra Gentes" ("Against the Heathens") and "De Incarnatione" ("On the Incarnation"), which were admittedly written about the year 318 before Arianism had begun to make itself felt, as those writings do not show an awareness of Arianism.
However Cornelius Clifford places his birth no earlier than 296 and no later than 298, based on the fact that Athanasius indicates no first hand recollection of the Maximian persecution of 303, which he suggests Athanasius would have remembered if he had been ten years old at the time. Secondly, the "Festal Epistles" state that the Arians had accused Athanasius, among other charges, of not having yet attained the canonical age (30) and thus could not have been properly ordained as Patriarch of Alexandria in 328. The accusation must have seemed plausible. The Orthodox Church places his year of birth around 297.
Education.
His parents were wealthy enough to afford giving him a fine secular education. Some Western scholars consider his command of Greek, in which he wrote most of his surviving works, evidence that he was a Greek born in Alexandria. However, in Coptic literature, Athanasius is the first patriarch of Alexandria to use Coptic as well as Greek in his writings.
Rufinus relates a story that as Bishop Alexander stood by a window, he watched boys playing on the seashore below, imitating the ritual of Christian baptism. He sent for the children and discovered that one of the boys (Athanasius) had acted as bishop. After questioning Athanasius, Bishop Alexander informed him that the baptisms were genuine, as both the form and matter of the sacrament had been performed through the recitation of the correct words and the administration of water, and that he must not continue to do this as those baptized had not been properly catechized. He invited Athanasius and his playfellows to prepare for clerical careers.
Alexandria was the most important trade center in the whole empire during Athanasius's boyhood. Intellectually, morally, and politically—it epitomized the ethnically diverse Graeco-Roman world, even more than Rome or Constantinople, Antioch or Marseilles. Its famous catechetical school, while sacrificing none of its famous passion for orthodoxy since the days of Pantaenus, Clement of Alexandria, Origen of Alexandria, Dionysius and Theognostus, had begun to take on an almost secular character in the comprehensiveness of its interests, and had counted influential pagans among its serious auditors.
Athanasius recounts being a student, as well as being educated by the Martyrs of the Great (tenth) and last persecution of Christianity by pagan Rome. This persecution was most severe in the East, particularly in Egypt and Palestine. Peter of Alexandria, the 17th archbishop of Alexandria, was martyred in 311 in the closing days of that persecution, and may have been one of those teachers. His successor as bishop of Alexandria, Alexander of Alexandria (312–328) was an Origenist as well as a documented mentor of Athanasius. According to Sozomen, Bishop Alexander "invited Athanasius to be his commensal and secretary. He had been well educated, and was versed in grammar and rhetoric, and had already, while still a young man, and before reaching the episcopate, given proof to those who dwelt with him of his wisdom and acumen". Athanasius's earliest work, "Against the Heathen – On the Incarnation" (written before 319), bears traces of Origenist Alexandrian thought (such as repeatedly quoting Plato and used a definition from Aristotle's "Organon") but in an orthodox way. Athanasius was also familiar with the theories of various philosophical schools, and in particular with the developments of Neo-Platonism. Ultimately, Athanasius would modify the philosophical thought of the School of Alexandria away from the Origenist principles such as the "entirely allegorical interpretation of the text". Still, in later works, Athanasius quotes Homer more than once ("Hist. Ar. 68, Orat. iv. 29"). In his letter to Emperor Constantius, he presents a defense of himself bearing unmistakable traces of a study of Demosthenes "de Corona".
Athanasius knew Greek and admitted not knowing Hebrew ee, e.g., the 39th Festal Letter of St. Athan. The Old Testament passages he quotes frequently come from the Septuagint Greek translation. Only rarely did he use other Greek versions (to Aquila once in the "Ecthesis", to other versions once or twice on the Psalms), and his knowledge of the Old Testament was limited to the Septuagint. Nonetheless, during his later exile, with no access to a copy of the Scriptures, Athanasius could quote from memory every verse in the Old Testament with a supposed reference to the Trinity without missing any. The combination of Scriptural study and of Greek learning was characteristic of the famous Alexandrian School.
Bishop (or Patriarch, meaning the head of the Centre of the Church, in Alexandria) Alexander ordained Athanasius a deacon in 319. In 325, Athanasius served as Alexander's secretary at the First Council of Nicaea. Already a recognized theologian and ascetic, he was the obvious choice to replace his aging mentor Alexander as the Patriarch of Alexandria, despite the opposition of the followers of Arius and Meletius of Lycopolis.
At length, in the Council of Nicaea, the term "consubstantial" (homoousion) was suggested by Athanasius: it was immediately adopted, and a formulary of faith embodying it was drawn up by Hosius, Hosius of Cordoba. From this time to the end of the Arian controversies the word "consubstantial" continued to be the test of Catholic orthodoxy. The formulary of faith drawn up by Hosius is known as the Nicene Creed.
While still a deacon under Alexander's care (or early in his patriarchate as discussed below) Athanasius may have also become acquainted with some of the solitaries of the Egyptian desert, and in particular Anthony the Great, whose life he is said to have written.
Opposition to Arianism.
In about 319, when Athanasius was a deacon, a presbyter named Arius came into a direct conflict with Alexander of Alexandria. It appears that Arius reproached Alexander for what he felt were misguided or heretical teachings being taught by the bishop. Arius's theological views appear to have been firmly rooted in Alexandrian Christianity, and his Christological views were certainly not radical at all. He embraced a subordinationist Christology which taught that Christ was the divine Son ("Logos") of God, made, not begotten, heavily influenced by Alexandrian thinkers like Origen, and which was a common Christological view in Alexandria at the time. Support for Arius from powerful bishops like Eusebius of Caesarea and Eusebius of Nicomedia, further illustrate how Arius's subordinationist Christology was shared by other Christians in the Empire. Arius was subsequently excommunicated by Alexander, and he would begin to elicit the support of many bishops who agreed with his position.
Patriarch.
Frances A. M. Forbes writes that when the Patriarch Alexander was on his death-bed he called Athanasius, who fled fearing he would be constrained to be made Bishop. "When the Bishops of the Church assembled to elect their new Patriarch, the whole Catholic population surrounded the church, holding up their hands to Heaven and crying; "Give us Athanasius!" The Bishops had nothing better. Athanasius was thus elected, as Gregory tells us..." (Pope Gregory I, would have full access to the Vatican Archives).
T. Gilmartin, (Professor of History, Maynooth, 1890), writes in Church History, Vol. 1, Ch XVII: On the death of Alexander, five months after the termination of the Council of Nice, Athanasius was unanimously elected to fill the vacant see. He was most unwilling to accept the dignity, for he clearly foresaw the difficulties in which it would involve him. The clergy and people were determined to have him as their bishop, Patriarch of Alexandria, and refused to accept any excuses. He at length consented to accept a responsibility that he sought in vain to escape, and was consecrated in 326, when he was about thirty years of age.
Athanasius's episcopate began on 9 May 328 as the Alexandrian Council elected Athanasius to succeed the aged Alexander. That council also denounced various heresies and schisms, many of which continued to preoccupy his 45-year-long episcopate (c. 8 June 328 – 2 May 373). Patriarch Athanasius spent over 17 years in five exiles ordered by four different Roman Emperors, not counting approximately six more incidents in which Athanasius fled Alexandria to escape people seeking to take his life. This gave rise to the expression "Athanasius contra mundum" or "Athanasius against the world". However, during his first years as bishop, Athanasius visited the churches of his territory, which at that time included all of Egypt and Libya. He established contacts with the hermits and monks of the desert, including Pachomius, which proved very valuable to him over the years. Shortly thereafter, Athanasius became occupied with the theological disputes against Arians within the Byzantine Empire that would occupy much of his life.
First exile.
Athanasius's first problem lay with Meletius of Lycopolis and his followers, who had failed to abide by the First Council of Nicaea. That council also anathematized Arius. Accused of mistreating Arians and Meletians, Athanasius answered those charges at a gathering of bishops in Tyre, the First Synod of Tyre, in 335. There, Eusebius of Nicomedia and other supporters of Arius deposed Athanasius. On 6 November, both sides of the dispute met with Emperor Constantine I in Constantinople. At that meeting, the Arians claimed Athanasius would try to cut off essential Egyptian grain supplies to Constantinople. He was found guilty, and sent into exile to Augusta Treverorum in Gaul (now Trier in Germany).
When Athanasius reached his destination in exile in 336, Maximinus of Trier received him not as a disgraced person. Athanasius stayed with him for two years. Also, Paul I of Constantinople stayed with him, who was banished by the Emperor Constantius. Maximinus, precautioned the Emperor Constans against the Arians, revealing their plots.
Second exile.
When Emperor Constantine I died, Athanasius was allowed to return to his See of Alexandria. Shortly thereafter, however, Constantine's son, the new Roman Emperor Constantius II, renewed the order for Athanasius's banishment in 338. Athanasius went to Rome, where he was under the protection of Constans, the Emperor of the West. During this time, Gregory of Cappadocia was installed as the Patriarch of Alexandria, usurping the absent Athanasius. Athanasius did, however, remain in contact with his people through his annual "Festal Letters", in which he also announced on which date Easter would be celebrated that year.
In 339 or 340, nearly one hundred bishops met at Alexandria, declared in favor of Athanasius, and vigorously rejected the criticisms of the Eusebian faction at Tyre. Plus, Pope Julius I wrote to the supporters of Arius strongly urging Athanasius's reinstatement, but that effort proved in vain. Pope Julius I called a synod in Rome in 340 to address the matter, which proclaimed Athanasius the rightful bishop of Alexandria.
Early in the year 343 we find Athanasius had travelled, via Rome, from Alexandria, North Africa, to Gaul; nowadays Belgium / Holland and surrounding areas, where Hosius of Cordoba was Bishop, the great champion of orthodoxy in the West. The two, together, set out for Sardica. A full Council of the Church was convened / summoned there in deference to the Roman pontiff's wishes. The travel was a mammoth task in itself. At this great gathering of prelates, leaders of the Church, the case of Athanasius was taken up once more, that is, Athanasius was formally questioned over misdemeanours and even murder, (a man called Arsenius and using his body for magic, – an absurd charge.). he Council was convoked for the purpose of inquiring into the charges against Athanasius and other bishops, on account of which they were deposed from their sees by the Semi-Arian Synod of Antioch (341), and went into exile. It was called according to Socrates, (E. H. ii. 20) by the two Emperors, Constans and Constantius; but, according to Baronius by Pope Julius (337–352), (Ad an. 343). One hundred and seventy six attended. Eusebian bishops objected to the admission of Athanasius and other deposed bishops to the Council, except as accused persons to answer the charges brought against them. Their objections were overridden by the orthodox bishops, about a hundred were orthodox, who were the majority. The Eusebians, seeing they had no chance of having their views carried, retired to Philoppopolis in Thrace, [[Philippopolis (Thracia)]], where they held an opposition council, under the presidency of the Patriarch of Antioch, and confirmed the decrees of the Synod of Antioch.. Once more, at the Council of Sardica, was his innocence reaffirmed. Two conciliar letters were prepared, one to the clergy and faithful of Alexandria, the other to the bishops of Egypt and Libya, in which the will of the Council was made known. Meanwhile, the Eusebian party had gone to Philippopolis, where they issued an anathema against Athanasius and his supporters. The persecution against the orthodox party broke out with renewed vigour, and Constantius was induced to prepare drastic measures against Athanasius and the priests who were devoted to him. Orders were given that if the Saint attempt to re-enter his see, he should be put to death. Athanasius, accordingly, withdrew from Sardica to Naissus in Mysia, where he celebrated the Easter festival of the year 344. It was Hosius who presided over the Council of Sardica, as he did for the First Council of Nicaea, which like the 341 synod, found Athanasius innocent. &. He celebrated his last Easter in exile in Aquileia in April 345, received by bishop Fortunatianus.
After the death of the replacement bishop Gregory in 345, Constans used his influence to allow Athanasius to return to Alexandria in October 345, amidst the enthusiastic demonstrations of the populace. This began a "golden decade" of peace and prosperity, during which time Athanasius assembled several documents relating to his exiles and returns from exile in the "Apology Against the Arians". However, upon Constans's death in 350, another civil war broke out, which left pro-Arian Constantius as sole emperor. An Alexandria local council in 350 replaced (or reaffirmed) Athanasius in his see.
Pope Julius had died in April, 352, and was succeeded by Liberius. For two years Liberius had been favourable to the cause of Athanasius; but driven at last into exile, he was induced to sign an ambiguous formula, from which the great Nicene text, the "homoousion", had been studiously omitted. In 355 a council was held at Milan, where in spite of the vigorous opposition of a handful of loyal prelates among the Western bishops, a fourth condemnation of Athanasius was announced to the world. With his friends scattered, the saintly Hosius in exile, and Pope Liberius denounced as acquiescing in Arian formularies, Athanasius could hardly hope to escape. On the night of 8 February, 356, while engaged in services in the Church of St. Thomas, a band of armed men burst in to secure his arrest. It was the beginning of his third exile.
T. Gilmartin, (Professor of History, Maynooth, 1890), writes in Church History, Vol. 1, Ch XVII: By Constantius's order, the sole ruler of The Roman Empire at the death of his brother Constans, the Council of Arles in 353, was held, which was presided over by Vincent, Bishop of Capua, in the name of Pope Liberius. The fathers terrified of the threats of the Emperor, an avowed Arian, they consented to the condemnation of Athanasius. The Pope refused to accept their decision, and requested the Emperor to hold another Council, in which the charges against Athanasius could be freely investigated. To this Constantius consented, for he felt able to control it, at Milan. Milan was named as the place, here three hundred bishops assembled, most from the West, only a few from the East, in 355. They met in the Church of Milan. Shortly, the Emperor ordered them to a hall in the Imperial Palace, thus ending any free debate. He presented an Arian formula of faith for their acceptance. He threatened any who refused with exile and death. All, with the exception of Dionysius (bishop of Milan), and the two Papal Legates, viz., Eusebius of Vercelli and Lucifer of Cagliari, consented to the Arian Creed and the condemnation of Athanasius. Those who refused were sent into exile. The decrees were forwarded to the Pope for approval, but were rejected, because of the violence to which the bishops were subjected.
Third exile.
Through the influence of the Eusebian faction at Constantinople, an Arian bishop, George of Cappadocia, was now appointed to rule the see of Alexandria. Athanasius, after remaining some days in the neighbourhood of the city, finally withdrew into the desert of Upper Egypt, where he remained for a period of six years, living the life of the monks, devoting himself to the composition of a group of writings; "Apology to Constantius", the "Apology for his Flight", the "Letter to the Monks", and the "History of the Arians".
Constantius, renewing his previous policies favoring the Arians, banished Athanasius from Alexandria once again. This was followed, in 356, by an attempt to arrest Athanasius during a vigil service. Athanasius fled to Upper Egypt, where he stayed in several monasteries and other houses. During this period, Athanasius completed his work "Four Orations against the Arians" and defended his own recent conduct in the "Apology to Constantius" and "Apology for His Flight". Constantius's persistence in his opposition to Athanasius, combined with reports Athanasius received about the persecution of non-Arians by the new Arian bishop George of Laodicea, prompted Athanasius to write his more emotional "History of the Arians", in which he described Constantius as a precursor of the Antichrist.
Constantius, ordered Liberius into exile in 356 giving him, then, three days to comply. He was ordered into banishment to Beroea, in Thrace; Beroea (Thrace). He sent expensive presents, too, if he were to accept the Arian position but were refused. He sent him, indeed, five hundred pieces of gold "to bear his charges" but Liberius refused them, saying, he might bestow them on his flatters; as he did also a like present from the empress, bidding the messenger learn to believe in Christ, and not to persecute the Church of God. Attempts were made to leave the presents in The Church, but Liberius threw them out. Constantius hereupon sent for him under a strict guard to Milan, where, in a conference recorded by Theodoret, he boldly told Constantius that Athanasius had been acquitted at Sardica, and his enemies proved calumniators (see: "calumny") and impostors, and that it was unjust to condemn a person who could not be legally convicted of any crime. The emperor was reduced to silence on every article, but being the more out of patience, ordered him into banishment. Liberius went into exile. Constantius, after two years went to Rome to celebrate the twentieth year of his reign. The ladies joined in a petition to him that he would restore Liberius. He assented, upon condition that he should comply with the bishops, then, at court. He subscribed the condemnation of Athanasius, and a confession or creed which had been framed by the Arians at Sirmium. And he no sooner had recovered his see that he declared himself for the Creed of Niceae, as Theodoret testifies. (Theodoret, Hist. lib. ii. c. 17.). The Emperor knew what he wanted people to believe. So did the bishops at his court. Athanasius stuck by the orthodox creed. Constantius was an avowed Arian, became sole ruler in 350, at the death of his brother, Constans.
T. Gilmartin, (Professor of History, Maynooth, 1890), writes in Church History, Vol. 1, Ch XVII: The Arians sought the approval of an Ecumenical Council. They sought to hold two councils. Constantius, summoned the bishops of the East to meet at Seleucia in Isauria, and those of the West to Rimini in Italy. A preliminary conference was held by the Arians at Sirmium, to agree a formula of faith. A "Homoeon" creed was adopted, declaring The Son to be "like the Father". The two met in autumn of 359. At Seleucia, one hundred and fifty bishops, of which one hundred and five were semi-Arian. The semi-Arians refused to accept anything less than the "Homoiousion", (see: Homoiousian), formulary of faith. The Imperial Prefect was obliged to disband, without agreeing on any creed. Acacius, the leader of the "Homoean" party went to Constantinople, where the Sirmian formulary of faith was approved by the "Home Synod", (consisted of those bishops who happened to be present at the Court for the time), and a decree of deposition issued against the leaders of the semi-Arians. At Rimini were over four hundred of which eighty were Arian, the rest were orthodox. The orthodox fathers refused to accept any creed but the Nicene, while the others were equally in favour of the Sirmian. Each party sent a deputation to the Emperor to say there was no probability to agreement, and asked for the bishops to return to their dioceses. For the purpose of wearing-down the orthodox bishops; (Sulpitius Severius says), Constantius delayed his answer for several months, and finally prevailed on them to accept the Sirmian creed. It was after this Council that Jerome said: " ...the whole world groaned in astonishment to find itself Arian."
In 361, after the death of Emperor Constantius, shortly followed by the murder of the very unpopular Bishop George, Athanasius returned to his patriarchate. The following year he convened a council at Alexandria, and presided over it with Eusebius of Vercelli. Athanasius appealed for unity among all those who had faith in Christianity, even if they differed on matters of terminology. This prepared the groundwork for his definition of the orthodox doctrine of the Trinity. However, the council also was directed against those who denied the divinity of the Holy Spirit, the human soul of Christ, and Christ's divinity. Mild measures were agreed on for those heretic bishops who repented, but severe penance was decreed for the chief leaders of the major heresies.
The Arians no longer presented an unbroken front to their orthodox opponents. The Emperor Constantius, who had been the cause of so much trouble, died 4 November, 361 and was succeeded by Julian. The proclamation of the new prince's accession was the signal for a pagan outbreak against the still dominant Arian faction in Alexandria. George, the usurping Bishop, was flung into prison and murdered. An obscure presbyter of the name of Pistus was immediately chosen by the Arians to succeed him, when fresh news arrived that filled the orthodox party with hope. An edict had been put forth by Julian permitting the exiled bishops of the "Galileans" to return to their "towns and provinces". Athanasius received a summons from his own flock, and he accordingly re-entered his episcopal capitol on 22 February, 362.
With characteristic energy he set to work to re-establish the somewhat shattered fortunes of the orthodox party and to purge the theological atmosphere of uncertainty. To clear up the misunderstandings that had arisen in the course of the previous years, an attempt was made to determine still further the significance of the Nicene formularies. In the meanwhile, Julian, who seems to have become suddenly jealous of the influence that Athanasius was exercising at Alexandria, addressed an order to Ecdicius, the Prefect of Egypt, peremptorily commanding the expulsion of the restored primate, on the ground that he had never been included in the imperial act of clemency. The edict was communicated to the bishop by Pythicodorus Trico, who, though described in the "Chronicon Athanasianum" (XXXV) as a "philosopher", seems to have behaved with brutal insolence. On 23 October the people gathered about the proscribed bishop to protest against the emperor's decree; but Athanasius urged them to submit, consoling them with the promise that his absence would be of short duration.
Fourth exile.
In 362, the new Emperor Julian, noted for his opposition to Christianity, ordered Athanasius to leave Alexandria once again. Athanasius left for Upper Egypt, remaining there with the Desert Fathers until Julian's death in 363. Julian terminated his brief career 26 June, 363; and Athanasius returned in secret to Alexandria, where he soon received a document from the new emperor, Jovian, reinstating him once more in his episcopal functions.
His first act was to convene a council which reaffirmed the terms of the Nicene Creed. Early in September 363 he set out for Antioch on the Orontes, bearing a synodal letter, in which the pronouncements of this council had been embodied. At Antioch he had an interview with the new emperor, who received him graciously and even asked him to prepare an exposition of the orthodox faith. But in the following February Jovian died; and in October, 364, Athanasius was once more an exile.
Fifth exile.
Two years later, the Emperor Valens, who favored the Arian position, in his turn exiled Athanasius. This time however, Athanasius simply left for the outskirts of Alexandria, where he stayed for only a few months before the local authorities convinced Valens to retract his order of exile. Some early reports state that Athanasius spent this period of exile at his family's ancestral tomb in a Christian cemetery. It was during this period, the final exile, that he is said to have spent four months in hiding in his father's tomb. (Soz., "Hist. Eccl.", VI, xii; Soc., "Hist. Eccl.", IV, xii).
The accession of Valens gave a fresh lease of life to the Arian party. He issued a decree banishing the bishops who had been deposed by Constantius, but who had been permitted by Jovian to return to their sees. The news created the greatest consternation in the city of Alexandria itself, and the prefect, in order to prevent a serious outbreak, gave public assurance that the very special case of Athanasius would be laid before the emperor. But the saint seems to have divined what was preparing in secret against him. He quietly withdrew from Alexandria, 5 October, and took up his abode in a country house outside the city. Valens, who seems to have sincerely dreaded the possible consequences of another popular outbreak, within a few weeks issued orders allowing Athanasius to return to his episcopal see.
In 366 Pope Liberius died and was succeeded by Pope Damasus, a man of strong character and holy life. Two years later, in a council of the Church, it was decreed that no Bishop should be consecrated unless he held the Creed of Nicea. (F. A. Forbes)...
Final years and death.
After returning to Alexandria in early 366, Athanasius spent his final years repairing all the damage done during the earlier years of violence, dissent, and exile. He resumed writing and preaching undisturbed, and characteristically re-emphasized the view of the Incarnation which had been defined at Nicaea. On 2 May 373, having consecrated Peter II, one of his presbyters as his successor, Athanasius died quietly in his own bed, surrounded by his clergy and faithful supporters.
Works.
In Coptic literature, Athanasius is the first patriarch of Alexandria to use Coptic as well as Greek in his writings.
Polemical and theological works.
Athanasius was not a speculative theologian. As he stated in his "First Letters to Serapion", he held on to "the tradition, teaching, and faith proclaimed by the apostles and guarded by the fathers." He held that not only was the Son of God consubstantial with the Father, but so was the Holy Spirit, which had a great deal of influence in the development of later doctrines regarding the Trinity.
Athanasius's "Letter Concerning the Decrees of the Council of Nicaea" ("De Decretis"), is an important historical as well as theological account of the proceedings of that council, and another letter from 367 is the first known listing of all those books now accepted as the New Testament. (Earlier similar lists vary by the omission or addition of a few books.)
Examples of Athanasius's polemical writings against his theological opponents include "Orations Against the Arians", his defence of the divinity of the Holy Spirit ("Letters to Serapion" in the 360s, and "On the Holy Spirit"), against Macedonianism and On the Incarnation.
Athanasius also wrote a two-part "Against the Heathen" and "The Incarnation of the Word of God". Completed probably early in his life, before the Arian controversy, they constitute the first classic work of developed Orthodox theology. In the first part, Athanasius attacks several pagan practices and beliefs. The second part presents teachings on the redemption. Also in these books, Athanasius put forward the belief that the Son of God, the eternal Word through whom God created the world, entered that world in human form to lead men back into the harmony from which they had earlier fallen away.
His other important works include his "Letters to Serapion", which dealt with the divinity of the Holy Spirit. In a letter to Epictetus of Corinth, Athanasius anticipates future controversies in his defense of the humanity of Christ. Another of his letters, to Dracontius, urges that monk to leave the desert for the more active duties of a bishop.
Athanasius also wrote several works of Biblical exegesis, primarily of volumes in the Old Testament. Excerpts remain of his discussions concerning the Book of Genesis, the Song of Solomon, and Psalms.
Perhaps, his most notable letter was his Festal Letter, written to his Church in Alexandria when he was in exile, as he could not be in their presence. This letter shows clearly his stand that accepting Jesus is the Divine Son of God is not optional but necessary; "I know moreover that not only this thing saddens you, but also the fact that while others have obtained the churches by violence, you are meanwhile cast out from your places. For they hold the places, but you the Apostolic Faith. They are, it is true, in the places, but outside of the true Faith; while you are outside the places indeed, but the Faith, within you. Let us consider whether is the greater, the place or the Faith. Clearly the true Faith. Who then has lost more, or who possesses more? He who holds the place, or he who holds the Faith?
Biographical and ascetic.
His biography of Anthony the Great entitled "Life of Antony"(Βίος καὶ Πολιτεία Πατρὸς Ἀντωνίου, "Vita Antonii") became his most widely-read work. Translated into several languages, it played an important role in the spreading of the ascetic ideal in Eastern and Western Christianity. Depicting Anthony as an illiterate and holy man who through his existence in a primordial landscape has an absolute connection to the divine truth, the biography also resembles the life of his biographer Athanasius. It later served as an inspiration to Christian monastics in both the East and the West. The so-called Athanasian Creed dates from well after Athanasius's death and draws upon the phraseology of Augustine's "De trinitate".
Athanasius's works on ascetism also include a "Discourse on Virginity", a short work on "Love and Self-Control", and a treatise "On Sickness and Health" (of which only fragments remain).
Misattributed works.
There are several other works ascribed to him, although not necessarily generally accepted as being his own. These include the Athanasian creed, which is today generally seen as being of 5th-century Galician origin.
Veneration.
Athanasius was originally buried in Alexandria, Egypt, but his remains were later transferred to the Chiesa di San Zaccaria in Venice, Italy. During Pope Shenouda III's visit to Rome from 4 to 10 May 1973, Pope Paul VI gave the Coptic Patriarch a relic of Athanasius, which he brought back to Egypt on 15 May. The relic is currently preserved under the new Saint Mark's Coptic Orthodox Cathedral in Cairo, Egypt. However, the majority of Athanasius's corpse remains in the Venetian church.
All major Christian denominations which officially recognize saints venerate Athanasius. Western Christians observe his feast day on 2 May, the anniversary of his death. The Roman Catholic Church considers Athanasius a Doctor of the Church. For Coptic Christians, his feast day is Pashons 7 (now circa 15 May). Eastern Orthodox liturgical calendars remember Athanasius on 18 January.
Gregory of Nazianzus (330–390, also a Doctor of the Church), said: "When I praise Athanasius, virtue itself is my theme: for I name every virtue as often as I mention him who was possessed of all virtues. He was the true pillar of the Church. His life and conduct were the rule of bishops, and his doctrine the rule of the orthodox faith."
Historical significance and controversies.
New Testament canon.
It was the custom of the bishops of Alexandria to circulate a letter after Epiphany each year establishing the date of Easter, and therefore other moveable feasts. They also took the occasion to discuss other matters. Athanasius wrote forty-five festal letters. Athanasius's "39th Festal Letter", written in 367, is widely regarded as a milestone in the evolution of the canon of New Testament books.
Athanasius is the first person to identify the same 27 books of the New Testament that are in use today. Up until then, various similar lists of works to be read in churches were in use. Athanasius compiled the list to resolve questions about such texts as "The Epistle of Barnabas". Athanasius includes the Book of Baruch and the Letter of Jeremiah and places the Book of Esther among the "7 books not in the canon but to be read" along with the Wisdom of Solomon, Sirach (Ecclesiasticus), Judith, Tobit, the Didache, and the Shepherd of Hermas.
Athanasius's list is similar to the Codex Vaticanus in the Vatican Library, probably written in Rome, in 340 by Alexandrian scribes for Emperor Constans, during the period of Athanasius's seven-year exile in the city. The establishment of the canon was not a unilateral decision by a bishop in Alexandria, but the result of a process of careful investigation and deliberation, as documented in a codex of the Greek Bible and, twenty-seven years later, in his festal letter.
Pope Damasus I, the Bishop of Rome in 382, promulgated a list of books which contained a New Testament canon identical to that of Athanasius. A synod in Hippo in 393 repeated Athanasius's and Damasus's New Testament list (without the Epistle to the Hebrews), and a synod in Carthage in 397 repeated Athanasius's and Damasus's complete New Testament list.
Scholars debate whether Athanasius's list in 367 formed the basis for later lists. Because Athanasius's canon is the closest canon of any of the Church Fathers to the one used by Protestant churches today, many Protestants point to Athanasius as the father of the canon.
Episcopal consecration.
In the light of Mother F. A. Forbes research and reference to Pope Saint Gregory's writings, it would appear that Athanasius was constrained to be Bishop: She writes that when the Patriarch Alexander was on his death-bed he called Athanasius, who fled fearing he would be constrained to be made Bishop. "When the Bishops of the Church assembled to elect their new Patriarch, the whole Catholic population surrounded the church, holding up their hands to Heaven and crying; "Give us Athanasius!" The Bishops had nothing better. Athanasius was thus elected, as Gregory tells us..." (Pope Gregory I, would have full access to the Vatican Archives).
Alban Butler, writes on the subject: "Five months after this great Council, Nicae, St Alexander lying on his death-bed, recommended to his clergy and people the choice of Athanasius for his successor, thrice repeating his name. In consequence of his recommendation, the bishops of all Egypt assembled at Alexandria, and finding the people and clergy unanimous in their choice of Athanasius for patriarch, they confirmed the election about the middle of year 326. He seems, then, to have been about thirty years of age. " 
Character.
Athanasius has always been a controversial, if not divisive, figure. While some scholars praise him as an orthodox saint with great character, others see him as a power-hungry politician who employed questionable ecclesiastical tactics.
Historian Cornelius Clifford says: "His career almost personifies a crisis in the history of Christianity; and he may be said rather to have shaped the events in which he took part than to have been shaped by them." 
The greater majority of Church leaders and the emperors fell into support for Arianism, so much so that Saint Jerome, 340–420, wrote of the period: "The whole world groaned and was amazed to find itself Arian". He, Athanasius, even suffered an unjust excommunication from Pope Liberius (325–366) who was exiled and leant towards the Arians, until he was allowed back to the See of Rome. Athanasius stood virtually alone against the world. (..see: "Third Exile", above.)
Supporters.
Many Christian denominations revere Athanasius as a saint, teacher, and father. They cite his defense of the Christology described in the first chapter of the Gospel of John and his significant theological works (C.S. Lewis calls "On the Incarnation of the Word of God" a "masterpiece") as evidence of his righteousness. They also emphasize his close relationship with Anthony the Great, who is almost universally revered throughout Christendom.
The Gospel of John and particularly the first chapter demonstrates the Divinity of Jesus. This Gospel in itself is the greatest support of Athanasius's stand. The Gospel of John's first chapter began to be said at the end of Mass, we believe as a result of Athanasius, and his life's stand, but quietly. The Last Gospel of The Mass, The Eucharist, St John, together with the prayer; "Placeat tibi", the Blessing, are all private devotions that have been gradually absorbed by the liturgical service. The beginning of John's Gospel was much used as an object of special devotion throughout the Middle Ages. Nevertheless, the practice of saying it at the altar grew; eventually Pius V made this practice universal for the Roman Rite in his edition of the Missal (1570). It became a firm custom with exceptions in using an other Gospel in use from 1920. So the Missals showed different last Gospel for certain Feast days. A Prayer Card for the St John's Gospel. Also:
Gregory of Nazianzus (330–390) begins Or. 21 with: "When I praise Athanasius, virtue itself is my theme: for I name every virtue as often as I mention him who was possessed of all virtues. He was the true pillar of the church. His life and conduct were the rule of bishops, and his doctrine the rule of the orthodox faith."
Cyril of Alexandria (370–444) in the first letter says: "Athanasius is one who can be trusted: he would not say anything that is not in accord with sacred scripture." (Ep 1).
Many modern historians point out that such a hostile attitude towards Athanasius is based on an unfair judgment of historical sources.
Saint Pope Pius X said in a letter to philosopher-friend and correspondent in the closing years of his life, (Epist. lxxi, ad Max.): "Let what was confessed by the fathers of Nicaea prevail".
Historian Cornelius Clifford said in his account: "Athanasius was the greatest champion of Catholic belief on the subject of the Incarnation that the Church has ever known and in his lifetime earned the characteristic title of "Father of Orthodoxy", by which he has been distinguished ever since."
Bl. John Henry Newman described him as a "principal instrument, after the Apostles, by which the sacred truths of Christianity have been conveyed and secured to the world". etters.
Critics.
Throughout most of his career, Athanasius had many detractors. Classical scholar Timothy Barnes relates contemporary allegations against Athanasius: from defiling an altar, to selling Church grain that had been meant to feed the poor for his own personal gain, and even violence and murder to suppress dissent. Athanasius used "Arian" to describe both followers of Arius, and as a derogatory polemical term for Christians who disagreed with his formulation of the Trinity. Athanasius called many of his opponents "Arian", except for Miletus.
Scholars now believe that the Arian Party was not monolithic, but held drastically different theological views that spanned the early Christian theological spectrum. They supported the tenets of Origenist thought and theology, but had little else in common. Moreover, many labelled "Arian" did not consider themselves followers of Arius. In addition, non-Homoousian bishops disagreed with being labeled as followers of Arius, since Arius was merely a presbyter, while they were fully ordained bishops. However, others point to the Council of Nicaea as proof in and of itself that Arianism was a real theological ideology.
Conflict lawyer Richard E. Rubenstein suggests that Athanasius ascended to the rank of bishop in Alexandria under questionable circumstances because some questioned whether he had reached the minimum age of 30 years, and further that Athanasius employed force when it suited his cause or personal interests. Thus, he argues that a small number of bishops who supported Athanasius held a private consecration to make him bishop.
Popular Culture.
A detailed depiction of Athanasius as a villain is given in the 2016 novel, "The Secular Gospel of Sophia," by Daniel G. Helton.

</doc>
<doc id="3226" url="https://en.wikipedia.org/wiki?curid=3226" title="Azores">
Azores

The Azores ( or ; , ), officially the Autonomous Region of the Azores (""), is one of the two autonomous regions of Portugal, composed of nine volcanic islands in the North Atlantic Ocean about west of continental Portugal, about northwest of Madeira, about southeast of Newfoundland, and about northeast of Brazil. Its main industries are agriculture, dairy farming (for cheese and butter products primarily), livestock ranching, fishing, and tourism, which is becoming the major service activity in the region. In addition, the government of the Azores employs a large percentage of the population directly or indirectly in the service and tertiary sectors. The main settlement of the Azores is Ponta Delgada.
There are nine major Azorean islands and an islet cluster, in three main groups. These are Flores and Corvo, to the west; Graciosa, Terceira, São Jorge, Pico, and Faial in the centre; and São Miguel, Santa Maria, and the Formigas Reef to the east. They extend for more than and lie in a northwest-southeast direction.
All the islands have volcanic origins, although some, such as Santa Maria, have had no recorded activity since the islands were settled. Mount Pico, on the island of Pico, is the highest point in Portugal, at . The Azores are actually some of the tallest mountains on the planet, measured from their base at the bottom of the ocean to their peaks, which thrust high above the surface of the Atlantic.
The climate of the Azores is very mild for such a northerly location, being influenced by its distance to continents and the passing Gulf Stream. Due to the marine influence, temperatures remain mild year-round. Daytime temperatures normally fluctuate between and depending on season. Temperatures above or below are unknown in the major population centres. It is also generally wet and cloudy.
The culture, dialect, cuisine, and traditions of the Azorean islands vary considerably, because these once-uninhabited and remote islands were settled sporadically over a span of two centuries.
History.
A small number of alleged hypogea, earthen structures carved into rocks that were used for burials, have been identified on the islands of Corvo, Santa Maria and Terceira by Portuguese archaeologist Nuno Ribeiro, who speculated that they might date back 2000 years, alluding to a human presence on the island before the Portuguese. However, these kinds of structures have always been used in the Azores to store cereals, and suggestions by Ribeiro that they might be burial sites are unconfirmed. Detailed examination and dating to authenticate the validity of these speculations is lacking. It is unclear whether these structures are natural or man-made and whether they predate the 15th-century Portuguese colonization of the Azores. Solid confirmation of a pre-Portuguese human presence in the archipelago has not yet been published.
Discovery.
The islands were known in the fourteenth century and parts of them appear in the Atlas Catalan. In 1427, a captain sailing for Henry the Navigator, possibly Gonçalo Velho, rediscovered the Azores, but this is not certain. In Thomas Ashe's 1813 work, "A History of the Azores", the author identified a Fleming, Joshua Vander Berg of Bruges, who made landfall in the archipelago during a storm on his way to Lisbon. He stated that the Portuguese explored the area and claimed it for Portugal. Other stories note the discovery of the first islands (São Miguel Island, Santa Maria Island and Terceira Island) by sailors in the service of Henry the Navigator, although there are few documents to support the claims.
Although it is commonly said that the archipelago received its name from the goshawk ( in Portuguese), a common bird at the time of discovery, it is unlikely that the bird nested or hunted in the islands.
Settlement.
Following the discovery of Santa Maria and before settlement began, sheep were let loose on the island to supply future settlers with food, because there were no large animals on the island. Settlement did not take place right away, however. There was not much interest among the Portuguese people in an isolated archipelago hundreds of miles from civilization. However, Gonçalo Velho Cabral patiently gathered resources and settlers for the next three years (1433–1436) and sailed to establish colonies on Santa Maria first and then São Miguel.
Settlers cleared bush and rocks to plant crops—grain, grape vines, sugar cane, and other plants suitable for local use and of commercial value. They brought domesticated animals, such as chickens, rabbits, cattle, sheep, goats, and pigs and built houses and established villages.
The archipelago was settled over the centuries largely from mainland Portugal. Portuguese settlers came from the provinces of Algarve, Minho, Alentejo and Ribatejo as well as Madeira. São Miguel was first settled in 1444, the settlers – mainly from the Estremadura, Alto Alentejo and Algarve areas of continental Portugal, under the command of Gonçalo Velho Cabral – landing at the site of modern-day Povoação. Many of the early settlers were also Portuguese Sephardic Jews (New Christians - Jews who became Christian through forced conversion) who fled the pressures of inquisition in mainland Portugal. In 1522 Vila Franca do Campo, then the capital of the island, was devastated by an earthquake and landslide that killed about 5,000 people, and the capital was moved to Ponta Delgada. The town of Vila Franca do Campo was rebuilt on the original site and today is a thriving fishing and yachting port. Ponta Delgada received its city status in 1546. Since the first settlement, the pioneers applied themselves to the area of agriculture. By the 15th century Graciosa exported wheat, barley, wine and brandy. The goods were sent to Terceira largely because of the proximity of the island.
During the 18th and 19th century, Graciosa was host to many prominent figures, including Chateaubriand, the French writer who passed through upon his escape to America during the French revolution; Almeida Garrett, the Portuguese poet who visited an uncle and wrote some poetry while there; and Prince Albert of Monaco, the 19th century oceanographer who led several expeditions in the waters of the Azores. He arrived on his yacht "Hirondelle", and visited the "furna da caldeira", the noted hot springs grotto. Author Mark Twain published in 1869, "The Innocents Abroad" a travel book, where he described his time in the Azores.
The first reference to the island of São Jorge was made in 1439 but the actual date of discovery is unknown. In 1443 the island was already inhabited but active settlement only began with the arrival of the noble Flemish native "Wilhelm Van der Haegen". Arriving at Topo, where he lived and died, he became known as "Guilherme da Silveira" to the islanders. João Vaz Corte-Real received the captaincy of the island in 1483. Velas became a town before the end of the 15th century. By 1490, there were 2,000 Flemings living in the islands of Terceira, Pico, Faial, São Jorge and Flores. Because there was such a large Flemish settlement, the Azores became known as the Flemish Islands or the Isles of Flanders. Prince Henry the Navigator was responsible for this settlement. His sister, Isabel, was married to Duke Philip of Burgundy of which Flanders was a part. There was a revolt against Philip's rule and disease and hunger became rampant. Isabel appealed to Henry to allow some of the unruly Flemings to settle in the Azores. He granted this and supplied them with the necessary transportation and goods.
The settlement of the then-unoccupied islands started in 1439 with people mainly from the continental provinces of Algarve and Alentejo. In 1583, Philip II of Spain, as king of Portugal, sent his fleet to clear the Azores of a combined multinational force of adventurers, mercenaries, volunteers and soldiers who were attempting to establish the Azores as a staging post for a rival pretender to the Portuguese throne. Following the success of his fleet at the Battle of Ponta Delgada, the captured enemies were hanged from yardarms, as they were considered pirates by Philip II. This was added to the "Black Legend" by his enemies. An English expedition to the Azores in 1589 was met with success as a few of the islands along with the harbouring ships were plundered. Another English expedition against the Azores in 1597, the Islands Voyage, however failed. Spain held the Azores in what is called The Babylonian captivity of 1580–1642. Into the late 16th century, the Azores as well as Madeira began to face problems of overpopulation. Spawning from that particular economic problem, some of the people began to emigrate to Brazil.
Iberian Union.
Following the death of Henry, the Cardinal-King of Portugal the nation fell into a dynastic crisis with various pretenders to the Crown of Portugal. Following his proclamation in Santarém, António, Prior of Crato was acclaimed in the Azores in 1580 (through his envoy António da Costa), but was expelled from the continent following the Battle of Alcântara. Yet, through the administration of Cipriano de Figueiredo, governor of Terceira (who continued to govern Terceira in the name of ill-fated, former-king Sebastian of Portugal), the Azoreans resisted attempts to conquer the islands (including specifically at the Battle of Salga). It was Figueiredo and Violante do Canto who helped organize a resistance on Terceira that influenced some of the response of the other islands, even as internal politics and support for Philip's faction increased on the other islands (including specifically on São Miguel, where the Gonçalvez da Câmara family supported the Spanish pretender).
The Azores were the last part of the Portuguese Empire to resist Philip's reign over Portugal (Macau resisted any official recognition) and were returned to Portuguese control with the end of the Iberian Union in 1640, not by the professional military, who were used in the Restoration War in the mainland, but by local people attacking a fortified Castilian garrison.
Liberal Wars.
The Portuguese Civil War (1828–1834) had strong repercussions in the Azores. In 1829, in Praia da Vitória, the Liberals won over the absolutists, making Terceira Island the main headquarters of the new Portuguese regime and also where the Council of Regency () of Maria II of Portugal was established.
Beginning in 1868, Portugal issued its stamps overprinted with "" for use in the islands. Between 1892 and 1906, it also issued separate stamps for the three administrative districts of the time.
From 1836 to 1976, the archipelago was divided into three districts, equivalent (except in area) to those in the Portuguese mainland. The division was arbitrary, and did not follow the natural island groups, rather reflecting the location of each district capital on the three main cities (none of which were on the western group).
20th century.
In 1931 the Azores (together with Madeira and Portuguese Guinea) revolted against the Ditadura Nacional and were held briefly by military rebels.
In 1943, during World War II, the Portuguese ruler António de Oliveira Salazar leased air and naval bases in the Azores to the British Empire. The occupation of these facilities in October 1943 was codenamed "Operation Alacrity" by the British.
This was a key turning point in the Battle of the Atlantic, enabling the Royal Air Force, the U.S. Army Air Forces, and the U.S. Navy to provide aerial coverage in the Mid-Atlantic gap. This helped them to protect convoys and to hunt hostile Kriegsmarine U-boats.
In 1944, the American armed forces constructed a small and short-lived air base on the island of Santa Maria. In 1945, a new base was constructed on the island of Terceira, and it is named Lajes Field. This air base is in an area called Lajes, a broad, flat sea terrace that had been a large farm. Lajes Field is a plateau rising out of the sea on the northeast corner of the island. This air base is a joint American and Portuguese venture. Lajes Field continues to support the American and Portuguese Armed Forces. During the Cold War, U.S. Navy P-3 Orion antisubmarine warfare squadrons patrolled the North Atlantic Ocean for Soviet Navy submarines and surface warships. Since its opening, Lajes Field has been used for refuelling American cargo planes bound for Europe, Africa, and the Middle East. The U.S. Navy keeps a small squadron of its ships at the harbor of Praia da Vitória, three kilometers southeast of Lajes Field.
The airfield also has a small commercial terminal handling scheduled and chartered passenger flights from the other islands in the Azores, Europe, Africa, and North America.
In 1976, the Azores became the Autonomous Region of the Azores (), one of the autonomous regions of Portugal, and the subdistricts of the Azores were eliminated.
Geography.
Physical geography.
The archipelago of the Azores is located in the middle of the northern hemisphere of the Atlantic Ocean and extends along a west-northwest to east-southeast orientation (between 36.5°–40° North latitudes and 24.5°–31.5° West longitudes) in an area approximately wide. The islands of the Azores emerged from what is called the Azores Platform, a 5.8 million km region that is morphologically accented by a depth of 2000 meters.
From a geostructural perspective the Azores is located above an active triple junction between three of the world's large tectonic plates (the North American Plate, the Eurasian Plate and the African Plate), a condition that has translated into the existence of many faults and fractures in this region of the Atlantic. The westernmost islands of the archipelago (Corvo and Flores) are located in the North American Plate, while the remaining islands are located within the boundary that divides the Eurasian and African Plates.
The principal tectonic structures that exist in the region of the Azores are the Mid-Atlantic Ridge, the Terceira Rift, the Azores Fracture Zone and the Glória Fault. The Mid-Atlantic Ridge is the main frontier between the American Plate and the African-Eurasian Plates that crosses the Azores Platform between the islands of Flores and Faial from north to south then to the southwest; it is an extensive form crossed by many transform faults running perpendicular to its north-south orientation, that is seismically active and susceptible to volcanism. The Terceira Rift is a system of fractures that extends from the Mid-Atlantic Ridge to the Glória Fault that represents the main frontier between the Eurasian and African Plates. It is defined by a line of submarine volcanoes and island mounts that extend northwest to southeast for about , from the area west of Graciosa until the islets of the Formigas, that includes the islands of Graciosa, Terceira and São Miguel. Its northwest limit connects to the Mid-Atlantic Ridge, while the southeast section intersects the Gloria Fault southeast of the island of Santa Maria. The Azores Fracture Zone is that extends from the Glória Fault and encompasses a relatively inactive area to the south of the islands of the Central and Eastern groups north to the Terceira Rift, along a 45° angle. The Glória Fault, for its part, extends along a linear line from the Azores to the Azores–Gibraltar Transform Fault.
The island's volcanism is associated with the rifting along the Azores Triple Junction; the spread of the crust along the existing faults and fractures has produced many of the active volcanic and seismic events, while supported by buoyant upwelling in the deeper mantle, some associate with an Azores hotspot. Most of the volcanic activity has centered, primarily, along the Terceira Rift. From the beginning of the island's settlement, around the 15th century, there have been 28 registered volcanic eruptions (15 terrestrial and 13 submarine). The last significant volcanic eruption, the Capelinhos volcano (), occurred off the coast of the island of Faial in 1957; the most recent volcanic activity occurred in the seamounts and submarine volcanoes off the coast of Serreta and in the Pico-São Jorge Channel. The islands have many examples of volcano-built geomorphology including many of the caves and subterranean lava tubes (such as the Gruta das Torres, Algar do Carvão, Gruta do Natal, Gruta das Cinco Ribeiras), the coastal lava fields (like the coast of Feteiras, Faial, the Mistério of Prainha or São João on Pico Island) in addition to the currently inactive cones in central São Miguel Island, the aforementioned Capelinhos on Faial, the volcanic complexes of Terceira or Plinian caldeira of Corvo Island.
The islands of the archipelago were formed through volcanic and seismic activity during the Neogene Period; the first embryonic surfaces started to appear in the waters of Santa Maria during the Miocene epoch (from circa 8 million years ago). The sequence of the island formation has been generally characterized as: Santa Maria (8.12 Ma), São Miguel (4.1 Ma), Terceira (3.52 Ma), Graciosa (2.5 Ma), Flores (2.16 Ma), Faial (0.7 Ma), São Jorge (0.55 Ma), Corvo (0.7 Ma) and the youngest, Pico (0.27 Ma). Although all islands have experienced volcanism during their geological history, within recorded "human settlement" history the islands of Santa Maria, Flores, Corvo and Graciosa have not experienced any volcanic eruptions; in addition to active fumaroles and hot-springs, the remaining islands have had sporadic eruptions since the 14th century. Apart from the Capelinhos volcano in 1957–58, the last recorded instance of "island formation" occurred off the coast of São Miguel, when the island of Sabrina was briefly formed.
Owing to its geodynamic environment, the region has been center of intense seismic activity, particularly along its tectonic boundaries on the Mid-Atlantic Ridge and Terceira Rift. Seismic events although frequent, usually tectonic or vulco-tectonic in nature, but in general low to medium intensities, occasionally punctuated by events of level 5 or greater on the Richter magnitude scale. The most severe earthquake was registered in 1757, near Calheta on the island of São Jorge, which exceeded 7 on the Richter magnitude scale. In comparison, the 1522 earthquake that was mentioned by historian Gaspar Frutuoso measured 6.8, but its effects were judged to be X ("Extreme") on the Mercalli intensity scale, and was responsible for the destruction of Vila Franca do Campo and landslides that may have killed less than 5,000 of the inhabitants.
The nine islands that comprise the archipelago occupy a surface area of , that includes both the main islands and many islets located in their vicinities. Each of the islands have their own distinct geomorphological characteristics that make them unique: Corvo (the smallest island) is a crater of a major Plinian eruption; Flores (its neighbor on the North American Plate) is a rugged island carved by many valleys and escarpments; Faial characterized for its shield volcano and caldera (Cabeço Gordo); Pico, is the highest point, at , in the Azores and continental Portugal; Graciosa is known for its active Furnas do Enxofre and mixture of volcanic cones and plains; São Jorge is a long slender island, formed from fissural eruptions over thousands of years; Terceira, almost circular, is the location of one of the largest craters in the region; São Miguel is the largest island, and is pitted with many large craters and fields of spatter cones; and Santa Maria, the oldest island, is heavily eroded, being one of the few places to encounter brown sandy beaches in the archipelago. They range in surface area from the largest, São Miguel, at to the smallest, Corvo, at approximately .
These islands can be divided into three recognizable groups located on the Azores Platform:
In addition, several sub-surface reefs (particularly the Dollabarat on the fringe of the Formigas), banks (specifically the Princess Alice Bank and D. João de Castro Bank, as well as many hydrothermal vents and sea-mounts are monitored by the regional authorities, owing to the complex geotectonic and socioeconomic significance within the economic exclusion zone of the archipelago.
Biome.
The archipelago lies in the Palearctic ecozone, forming a unique biome that includes the macaronesian subtropical laurissilva, with many endemic species of plants. Even though the Azores look very green and sometimes wild, the vegetation has been extremely altered. Approximately 95% of laurisilva has been wiped out in the past 600 years for its valuable wood (for tools, buildings, boats, fire wood, and so on) and to clear land for agriculture. As a result, it is estimated that more than half of insects on the islands have disappeared or will become extinct. Many cultivated places (which are traditionally dedicated to pasture or to growing colocasia, potatoes, maize and other crops) have now been abandoned, especially as a result of emigration. Consequently, some invasive plants have filled these deserted and disturbed lands. The two most common of these alien species are "Pittosporum undulatum" and "Acacia melanoxylon". They are usually restricted to ancient agricultural land and only rarely penetrate into undisturbed native vegetation. The main loss is in the lowlands (below 400 metres) where virtually all laurisilva was eradicated.
A few "Persea indica" and "Picconia azorica" survive in some places, but appear extremely vulnerable. Only "Myrica faya" seems to have survived human impact quite well, and it is commonly found in hedges or among exotic trees. More recent introductions could become a serious threat, like "Leptospermum scoparium", which has the ability to colonize the still nearly untouched medium-altitude vegetation ("Ilex", "Myrsine africana", "Erica", and so on).
Hydrangeas are another potential pest, but their threat is less serious. Notwithstanding the fact that Hydrangeas were introduced from America or Asia, some locals consider them a symbol of the archipelago, and propagate them along roadsides, helping them to escape into the wild. "Cryptomeria", the Japanese cedar, is a conifer extensively grown for its timber; many seedlings can be found in the last remnants of medium-altitude native vegetation.
The Azores has two endemic bird species. The Azores bullfinch, or "Priolo", is restricted to remnant laurisilva forest in the mountains at the eastern end of São Miguel and is classified by BirdLife International as endangered. Monteiro's storm-petrel, described to science as recently as 2008, is known to breed in just two locations in the islands, but may occur more widely. An extinct species of owl, the São Miguel scops owl, has also recently been described, which probably became extinct after human settlement due to habitat destruction and the introduction of alien species. The Azores also has an endemic bat, the Azores noctule, which is unusual in regularly feeding during the day.
The islets of the Formigas (the Portuguese word for "ants"), including the area known as the Dollabarat Reef, has a rich environment of maritime species, such as black coral and manta rays, sharks, and sea turtles. On São Miguel there are notable micro-habitats formed by hot springs that host extremophile microorganisms.
Climate.
The archipelago is spread out in the area between 37° N and the parallels of latitude that pass through the Lisbon area (38° 43' / 38° 55' N), giving it generally a tepid, oceanic, subtropical climate, with mild annual oscillations. Daily maximum temperatures usually range between . The average annual rainfall increases from east to west, and it ranges from 700 to 1600 annual millimetres (27.6–63 in) on average, reaching on Mount Pico, the highest Portuguese mountain at . The Azores High, an area of high atmospheric pressure, is named after the islands. Under the Köppen climate classification, the local climate is "dry-summer subtropical", often referred to as "Mediterranean". The Köppen subtype for this climate is "".
In addition, the Instituto de Meteorologia has identified the following weather extremes:
Hurricanes.
A total of 11 tropical or subtropical cyclones have affected the region in history. Most of them were either extratropical or tropical storms when they impacted the region, although several Category 1 hurricanes have reached the Azores. The following storms have impacted the region while at Category 1 strength: Hurricane Fran in 1973, Hurricane Emmy in 1976, Hurricane Gordon in 2006, Hurricane Gordon in 2012 and Hurricane Alex in 2016. Several tropical storms have hit the region, including Tropical Storm Irma in 1978, Hurricane Bonnie in 1992 and Hurricane Erika in 1997. Storms that were extratropical when they impacted the region include Hurricane Tanya in 1995, Tropical Storm Ana in 2003 and Tropical Storm Grace in 2009. In addition, the 2005 Azores subtropical storm impacted the region in October 2005.
Demographics.
The Azores are divided into 19 municipalities (); each municipality is further divided into parishes (), of which there is a total of 156 in all of the Azores. The municipalities, by island, are:
There are six cities (Portuguese: "cidades") in the Azores: Ponta Delgada, Lagoa and Ribeira Grande on the island of São Miguel; Angra do Heroísmo and Praia da Vitória on the island of Terceira, and Horta on Faial. Three of these, Ponta Delgada, Angra and Horta are considered capital/administrative cities to the regional government: homes to the President (Ponta Delgada), the Judiciary (Angra) and the Regional Assembly (Horta). Angra also serves as the ecclesiastical centre of the Roman Catholic Diocese of Angra, the episcopal see of the Azores.
Population.
According to the 2011 Census, population in the Azores was 246,746 at a density of .
The Azores were uninhabited when Portuguese navigators arrived in the early 15th century; the settlement process was initiated in 1439 with individuals from various regions of mainland Portugal and from Madeira. The islands were populated mainly by Portuguese descendants immigrants from Algarve, Alentejo, and Minho; however, in an effort to escape the pressures of the Portuguese inquisition, many Portuguese Sephardic Jews, also known as the 'New Christians', (those who were forced to convert to Christianity during the Portuguese inquisition), settled on the islands in large numbers. Azorean Jews had surnames such as: Rodrigues, Oliveira, Pereira, Pimentel, Cardozo, Teixeira, etc. The islands were also settled by Moorish prisoners, and African slaves from Guinea, Cape Verde and São Tomé; Flemish, French and Galicians also contributed to the initial settlement. Thus the Azorean population received a significant contribution from people with genetic backgrounds other than Portuguese.
The nature of the economy dictated that African slavery never became common in the Azores because they were sent to Brazil and the Caribbean. Only a few remained in the Azores to help with domestic chores, although the islands sometimes served as a waypoint for ships carrying African slaves.
Genetics.
As in continental Portugal, the most frequent mtDNA haplogroup in the Azores is H (45.2%), followed by U (16.7%), T (10.1%), K (6.5%), pre-HV clades (5.6%) and a smaller sub-Saharan L haplogroups frequency (3.4%) than in Madeira as the number of sub-Saharan slaves in the Açores never reached the proportions that took place in Madeira.
Emigration.
Since the 17th century, many Azoreans have emigrated, mainly to Brazil, Uruguay, the United States and Canada. Rhode Island and Southeastern Massachusetts, especially the cities of New Bedford, Bristol, Barrington, Pawtucket, Central Falls, West Warwick, Hudson, Marlborough, East Providence, River Point, Taunton and Fall River have been, and remain, the primary destination for Azorean emigrants. It was emigrant from the East coast returned to their homeland that taught the American dory fishing technique to Portuguese that started to catch again cod in the Grand Bank in the 19th century.
Northern California was the final destination for many of the Massachusetts immigrants who then moved on to the San Joaquin Valley, especially the city of Turlock, just south of Modesto. In the late 1800s many Azoreans emigrated to the Hawaiian islands. The tuna fishing industry drew a significant number of Azoreans to the Point Loma neighborhood of San Diego, in Southern California. From 1921 to 1977, about 250,000 Azoreans immigrated to
Rhode Island and Massachusetts.
Many Azoreans also moved to Bermuda and Hawaii. Florianópolis and Porto Alegre in the Southern Region of Brazil were founded by Azoreans, who accounted for over half of Rio Grande do Sul and Santa Catarina's population in the late 18th century. As late as 1960 mass immigration currents were registered to Brazil, and many were from the Azores.
Politics.
Since 1976, the Azores is an autonomous region integrated within the framework of the Portuguese Republic. It has its own government and autonomous legislature within its own political-administrative statute and organic law. Its governmental organs include: the Legislative Assembly, a unicameral parliament composed of 52 elected deputies, elected by universal suffrage for a four-year term; the Regional Government and Presidency, with parliamentary legitimacy, composed of a President, a Vice-President and seven Regional Secretaries responsible for day-to-day operations. It is represented in the Council of Ministers by a representative appointed by the President of the Republic, which was created during the revision of the constitution of 2004 (which, among other things, removed the older Portuguese representative that was appointed by the President of the Republic, beholden to the Council of State and coincident with the President).
Since becoming a Portuguese autonomous region, the executive branch of the regional authority has been located in Ponta Delgada, the legislative branch in Horta, and the judicial branch in Angra do Heroísmo.
The islands of the archipelago do not have independent status in law, except in electoral law and are governed by 19 municipalities that subdivide the islands. In addition, until the administrative reform of the 19th century, the following civil parishes had municipal standing: Topo (today integrated into the municipality of Calheta, São Jorge); Praia (today integrated into municipality of Santa Cruz da Graciosa); São Sebastião (today an integral part of the municipality of Angra do Heroísmo); Capelas (now part of the municipality of Ponta Delgada); and Água de Pau (now a civil parish in the municipality of Lagoa). These civil parishes still retain their titles of "vila" in name only, by Regional Legislative Decree nº 29/2003/A, 24 June 2003; the populations of Capelas and neighbouring parish still protest the change and promote the restoration of their status. The municipalities are further subdivided into several civil parishes, with the exception of Corvo (the only municipality by law without a civil parish, owing to its size).
Azorean politics is dominated by the two largest Portuguese political parties, the Social Democratic Party (PSD) and the Socialist Party (PS), the latter holding a majority in the Regional Legislative Assembly. The Democratic and Social Center / People's Party (CDS/PP), the Left Bloc (BE), the Unitarian Democratic Coalition (CDU) and the People's Monarchist Party (PPM) are also represented in the local parliament. Currently, , the Socialist Party (PS) and its leader, Carlos César have a plurality of the seats in the Assembly, and operate the Regional Government. Although the PS dominates the regional politics, the PSD is traditionally popular in city and town council elections.
International affairs.
In 2003, the Azores saw international attention when United States President George W. Bush, British Prime Minister Tony Blair, Spanish Prime Minister José María Aznar, and Portuguese Prime Minister José Manuel Durão Barroso held a summit there days before the commencement of the Iraq War.
Transport.
Aviation.
Each of the nine islands has an airfield, although the majority are airfields rather than airports. The commercial terminals in Ponta Delgada, Horta, Vila do Porto and Santa Cruz das Flores are operated by ANA – Aeroportos de Portugal, a public entity that oversees the operations of airports across Portugal. The remaining, except for Lajes Field, are operated by the Regional Government. Lajes is a military airbase, as well as a commercial airport, and is operated by the Portuguese Armed Forces in conjunction with the United States.
The airports are:
Marine transport.
The Azores has had a long history of water transport to overcome distances and establish inter-community contacts and trade. Consequently, the shipbuilding industry developed in many islands, from small fishing boats, to whaling sloops to larger passenger services. Passenger traffic to the main islands (São Miguel, Santa Maria, Terceira and Faial) began in the 17th century, and between the 18th–19th century, the "Pico Yacht" controlled the lucrative summer traffic season.
After 1871, the "Insulana Shipping Company" was the only entity responsible for regular traffic between the islands (except Corvo), Madeira and the United States. Yet, cargo and passenger transportation ceased in the 1970s, and the ships were sold or converted into tuna fishing boats. For the next 20 years, commercial maritime service between the islands ceased (except between Faial-Pico and Lajes das Flores-Vila do Corvo).
"Transmaçor" (Transportes Marítimos Açorianos, Lda.) was founded on 22 December 1987, resulting from the fusion of "Empresa das Lanchas do Pico, Ld", owners of the ships "Espalamaca" and "Calheta" (ships that had travelled the canal between Faial and Pico for several years); "Empresa Açoreana de Transportes Marítimos, Lda", which operated the ship "Terra Alta"; and "Transcanal (Transportes Marítimos do Canal, Lda.)" operator the traditional boats "Picaroto" and "Manuel José". In the Central Group, the shipping company operates four to six time daily connections between Horta and Madalena throughout the year, using its small fleet of ships ("Cruzeiro das Ilhas", "Cruzeiro do Canal", "Expresso das Ilhas" and "Expresso do Triângulo"), in addition to inter-island connections between Faial, Pico, São Jorge and Terceira during the summer months.
Meanwhile, new initiatives began in the late 1990s: the catamaran "Iapetos" began services, followed by "Lady of Mann" and "Golfinho Azul" (chartered by Açorline). In 2005, "Atlânticoline" was established, providing services with the ships "Ilha Azul" and , later adding the "Viking" in 2009. In 2009, Atlanticoline was involved in a controversial rejection of a 750 passenger, 150 vehicle ship ordered from the "Estaleiros de Viana do Castelo" ("Viana do Castelo Shipyards"). The "Atlantida", a 50 million Euro cruiser (as part of a two-ship deal with the other named "Anticiclone") was rejected in 2009 by Atlanticoline for the under-performance of the power-plant. Although it would only result in a five-minute delay between islands, the public company rejected the ship, and the contract was broken over the builder's inability to deliver the required ship on time. While, the ship was being shopped to other interested parties (Hugo Chávez once considered purchasing the ferryboat in 2010), no interested buyers appeared, and ENVC decided to cede the "Atlantida" to Atlânticoline as part of the latter's open international competition to charter two ships in 2012.
On 20 June 2011, the Regional Government announced that it would purchase 60% of Transmaçor, equivalent to 500,000 Euro of the company's capital. With this acquisition the Autonomous government of the Azores controlled 88% of the capital, with 12% to shareholders. The signed memorandum of understanding concluded negotiations between the various parties involved, under which the liability of Transmaçor (worth a total of 8 million Euro) was divided equally between the Region and businessman José Almeida, who is the holder of a majority stake in the company.
Similarly, the Regional Government approved the consolidation of the three individual port authorities (Administração dos Portos do Triângulo e Grupo Ocidental, Administração dos Portos da Terceira e Graciosa and the Administração dos Portos das Ilhas de São Miguel e Santa Maria) and regional Portos dos Açores into one entity that resulted in a 2.2 million Euro cost savings, in addition to a reduction from 11 to three administrators.
Culture.
Azoreans have developed their own distinct regional identity and cultural traits, from a combination of continental Portuguese customs brought by various waves of immigration and local political and environmental factors.
Religious festivals, patron saints and traditional holidays mark the Azorean calendar. The most important religious events are tied with the festivals associated with the cult of the Holy Spirit, commonly referred to as the festivals of the Holy Spirit (or "Espírito Santo"), rooted in millenarian dogma and held on all islands from May to September. These festivals are very important to the Azorean people, who are primarily Roman Catholic, and combine religious rituals with processions celebrating the benevolence and egalitarianism of neighbours. These events are centred around "treatros" or "impérios", small buildings that host the meals, adoration and charity of the participants, and used to store the artefacts associated with the events. On Terceira, for example, these impérios have grown into ornate buildings painted and cared for by the local brotherhoods in their respective parishes. The events focus on the members of local parishes, not tourists, but all are welcome, as sharing is one of the main principles of the festivals. Some limited events focus on tourists, including a public event that the city government of Ponta Delgada on the island of São Miguel holds, which attracts visitors and locals.
Another event, the Festival of the Lord Holy Christ of the Miracles (or "Senhor Santo Cristo dos Milagres") in Ponta Delgada on the island of São Miguel, is the largest individual religious event in the Azores, and takes place on the fifth Sunday after Easter. Pilgrims from within the Portuguese diaspora normally travel to Ponta Delgada to participate in an afternoon procession behind the image of Christ along the flower-decorated streets of the city. Although the solemn procession is only held on one day, the events of the Festival of Senhor Santo Cristo occur over a period of a week and involve a ritual of moving the image between the main church and convent nightly, ultimately culminating in the procession, which is televised within the Azores and to the Portuguese diaspora.
The Sanjoaninas Festivities in Angra do Heroísmo on Terceira are held in June honoring Saint Anthony, Saint Peter and Saint John the Baptist, in a large religious celebration.
The festival of Our Lady of Lourdes (or "Nossa Senhora de Lourdes"), patron saint of whalers, begins in Lajes on Pico Island on the last Sunday of August and runs through the week—Whalers Week. It is marked by social and cultural events connected to the tradition of whale hunting. The Wine Harvest Festival (or "Festa das Vindimas"), takes place during the first week of September and is a century-old custom of the people of Pico.
On Corvo the people celebrate their patron saint Nossa Senhora dos Milagres (Our Lady of Miracles) on 15 August every year in addition to the festivals of the Divine Holy Spirit. The Festival da Maré de Agosto (August Sea Festival), takes place every year beginning on 15 August in Praia Formosa on Santa Maria. Also, the Semana do Mar (Sea Week), dedicated almost exclusively to water sports, takes place in August in the city of Horta, on Faial.
Carnaval is also celebrated in the Azores. Parades and pageants are the heart of the Carnaval festivities. There is lively music, colorful costumes, hand-made masks, and floats.
The traditional bullfights in the bullring are ongoing as is the running of bulls in the streets.

</doc>
<doc id="3229" url="https://en.wikipedia.org/wiki?curid=3229" title="Outback">
Outback

The Outback is the vast, remote, arid interior of Australia. The term "the outback" is generally used to refer to locations that are comparatively more remote than those areas named "the bush" which, colloquially, can refer to any lands outside the main urban areas.
History.
Early European exploration of inland Australia was sporadic. More focus was on the more accessible and fertile coastal areas. The first party to successfully cross the Blue Mountains just outside Sydney was led by Gregory Blaxland in 1813, 25 years after the colony was established. People starting with John Oxley in 1817, 1818 and 1821, followed by Charles Sturt in 1829–1830 attempted to follow the westward-flowing rivers to find an "inland sea", but these were found to all flow into the Murray River and Darling River which turn south.
Over the period 1858 to 1861, John McDouall Stuart led six expeditions north from Adelaide into the outback, culminating in successfully reaching the north coast of Australia and returning, without the loss of any of the party's members' lives. This contrasts with the ill-fated Burke and Wills expedition in 1860–61 which was much better funded, but resulted in the deaths of three of the members of the transcontinental party.
The Overland Telegraph line was constructed in the 1870s along the route identified by Stuart.
Exploration of the outback continued in the 1950s when Len Beadell explored, surveyed and built many roads in support of the nuclear weapons tests at Emu Field and Maralinga and rocket testing on the Woomera Prohibited Area. Mineral exploration continues as new mineral deposits are identified and developed.
While the early explorers used horses to cross the outback, the first woman to make the journey riding a horse was Anna Hingley, who rode from Broome to Cairns in 2006.
Mining.
Other than agriculture and tourism, the main economic activity in this vast and sparsely settled area is mining. Owing to the complete absence of mountain building and glaciation since the Permian (in many areas since the Cambrian) ages, the outback is extremely rich in iron, aluminium, manganese and uranium ores, and also contains major deposits of gold, nickel, iron, lead and zinc ores. Because of its size, the value of grazing and mining is considerable. Major mines and mining areas in the outback include opals at Coober Pedy, Lightning Ridge and White Cliffs, metals at Broken Hill, Tennant Creek, Olympic Dam and the remote Challenger Mine. Oil and gas are extracted in the Cooper Basin around Moomba.
In Western Australia the Argyle diamond mine in the Kimberley is the world's biggest producer of natural diamonds and contributes approximately one-third of the world's natural supply. The Pilbara region's economy is dominated by mining and petroleum industries. Most of Australia's iron ore is also mined in the Pilbara and it also has one of the world's major manganese mines.
Population.
Aboriginal communities in outback regions, such as the Anangu Pitjantjatjara Yankunytjatjara lands in northern South Australia, have not been displaced as they have been in areas of intensive agriculture and large cities, in coastal areas.
The total population of the Outback in Australia declined from 700,000 in 1996 to 690,000 in 2006. The largest decline was noted in the Outback Northern Territory, while the Kimberley and Pilbara showed population increases during the same period. The sex ratio is 1040 males for 1000 females and 17% of the total population is indigenous.
Medicine.
The Royal Flying Doctor Service started service in 1928 and helps people who live in the outback of Australia. In former times, serious injuries or illnesses often meant death due to the lack of proper medical facilities and trained personnel.
Education.
In most outback communities, the number of children is too small for a conventional school to operate. Children are educated at home by the School of the Air. Originally the teachers communicated with the children via radio, but now satellite telecommunication is used instead.
Some children attend boarding school, mostly only those in secondary school.
Terminology.
The concept of 'back' country, which initially meant land beyond the settled regions, was in existence in 1800. Crossing of the Blue Mountains and other exploration of the inland however gave a different dimension to the perception. The term "outback" was first used in print in 1869, when the writer clearly meant west of Wagga Wagga, New South Wales.
It is colloquially said that 'the outback' is located "beyond the Black Stump". The location of the black stump may be some hypothetical location or may vary depending on local custom and folklore. It has been suggested that the term comes from the "Black Stump Wine Saloon" that once stood about 10 kilometres out of Coolah, New South Wales on the Gunnedah Road. It is claimed that the saloon, named after the nearby Black Stump Run and Black Stump Creek, was an important staging post for traffic to north-west New South Wales and it became a marker by which people gauged their journeys.
"The Never-Never" is a term referring to remoter parts of the Australian outback. The outback can be also referred to as "back of beyond", "back o' Bourke" although these terms are more frequently used when referring to something a long way from anywhere, or a long way away. The well-watered north of the continent is often called the "Top End" and the arid interior "The Red Centre", owing to its vast amounts of red soil and sparse greenery amongst its landscape.
Wildlife.
The Australian Outback is full of very important well-adapted wildlife, although much of it may not be immediately visible to the casual observer. Many animals, such as red kangaroos and dingoes, hide in bushes to rest and keep cool during the heat of the day.
Birdlife is prolific, most often seen at waterholes at dawn and dusk. Huge flocks of budgerigars, cockatoos, corellas and galahs are often sighted. On bare ground or roads during the winter, various species of snakes and lizards bask in the sun, but they are rarely seen during the summer months.
Feral animals such as camels thrive in central Australia, brought to Australia by the early Afghan drivers. Feral horses known as 'brumbies' are station horses that have run wild. Feral pigs, foxes, cats and rabbits are also imported animals that degrade the environment, so time and money is spent eradicating them in an attempt to help protect fragile rangelands.
Tourism.
There are many popular tourist attractions in the outback. Some of the well known destinations include:
Visitors to the outback often drive their own or rented vehicles, or take organised tours. Travel through remote areas on main roads is easily done and requires no planning. However travel through very remote areas, on isolated tracks, requires planning and a suitable, reliable vehicle (usually a four-wheel drive). On very remote routes considerable supplies and equipment may be required, this can include prearranged caches. It is not advisable to travel into these especially remote areas with a single vehicle, unless fully equipped with good communication technology (e.g. a satellite phone, EPIRB etc.). Many visitors prefer to travel in these areas in a convoy. Deaths from tourists and locals becoming stranded on outback trips occasionally occur, sometimes because insufficient water and food supplies were taken, or because people have walked away from their vehicle in search of help. Travellers through very remote areas should always inform a reliable person of their route and expected destination arrival time, and remember that a vehicle is much easier to locate in an aerial search, than a person, so in the event of a breakdown, they must not leave their vehicle.
The outback is home to a diverse set of animal species, such as the kangaroo, emu and dingo. The Dingo Fence was built to restrict dingo movements into agricultural areas towards the south east of the continent. The marginally fertile parts are primarily utilised as rangelands and have been traditionally used for sheep or cattle grazing, on cattle stations which are leased from the Federal Government. While small areas of the outback consist of clay soils the majority has exceedingly infertile palaeosols. Riversleigh, in Queensland, is one of Australia's most renowned fossil sites and was recorded as a World Heritage site in 1994. The 100 km2 (39 sq mi) area contains fossil remains of ancient mammals, birds and reptiles of Oligocene and Miocene age.
Transport.
The outback is criss-crossed by historic tracks. Most of the major highways have an excellent bitumen surface and other major roads are usually well-maintained dirt roads. Tracks in very sandy or exceedingly rocky areas may require high-clearance four wheel drives and spare fuel, tires, food and water before attempting to travel them, however most outback roads are easily traversed in ordinary vehicles, provided care is taken. Drivers unused to dirt roads should be especially cautious – it is recommended that drivers reduce their speed, drive with extra care, and avoid driving at night because animals can stray on to roads. Travelling in remote areas in northern Australia is not advisable during the wet season (November to April), as heavy tropical downpours can quickly make dirt roads impassable. In the remotest parts of Australia fuel sellers are located hundreds of kilometres apart, so spare fuel must be carried or refuelling spots calculated carefully in order not to run out of fuel in between towns. In addition, multiple trailer trucks (known as Road Trains) traverse these roads and extreme care must be taken when around these vehicles, due to their weight, length (often three full trailers long) and amount of dust thrown up by 46+ tyres.
The Stuart Highway runs from north to south through the centre of the continent, roughly paralleled by the Adelaide–Darwin railway. There is a proposal to develop some of the roads running from the SW to the NE to create an all-weather road named the Outback Highway, crossing the continent diagonally from Laverton, Western Australia (north of Kalgoorlie, through the Northern Territory to Winton, in Queensland.
Air transport is relied on for mail delivery in some areas, owing to sparse settlement and wet-season road closures. Most outback mines have an airstrip and many have a fly-in fly-out workforce. Most outback sheep stations and cattle stations have an airstrip and quite a few have their own light plane. Medical and ambulance services are provided by the Royal Flying Doctor Service. The School of the Air is a radio-based school using the RFDS radios.

</doc>
<doc id="3231" url="https://en.wikipedia.org/wiki?curid=3231" title="Absolute Infinite">
Absolute Infinite

The Absolute Infinite is mathematician Georg Cantor's concept of an "infinity" that transcends the transfinite numbers. Cantor linked the Absolute Infinite with God. He held that the Absolute Infinite had various mathematical properties, including the reflection principle which says that every property of the Absolute Infinite is also held by some smaller object.
Cantor's view.
Cantor is quoted as saying:
Cantor also mentioned the idea in his letters to Richard Dedekind (text in square brackets not present in original):
The Burali-Forti paradox.
The idea that the collection of all ordinal numbers cannot logically exist seems paradoxical to many. This is related to Cesare Burali-Forti's "paradox" which states that there can be no greatest ordinal number. All of these problems can be traced back to the idea that, for every property that can be logically defined, there exists a set of all objects that have that property. However, as in Cantor's argument (above), this idea leads to difficulties.
More generally, as noted by A.W. Moore, there can be no end to the process of set formation, and thus no such thing as the "totality of all sets", or the "set hierarchy". Any such totality would itself have to be a set, thus lying somewhere within the hierarchy and thus failing to contain every set.
A standard solution to this problem is found in Zermelo's set theory, which does not allow the unrestricted formation of sets from arbitrary properties. Rather, we may form the set of all objects that have a given property "and lie in some given set" (Zermelo's Axiom of Separation). This allows for the formation of sets based on properties, in a limited sense, while (hopefully) preserving the consistency of the theory.
While this solves the logical problem, one could argue that the philosophical problem remains. It seems natural that a set of individuals ought to exist, so long as the individuals exist. Indeed, naive set theory might be said to be based on this notion. Although Zermelo's fix allows a class to describe arbitrary (possibly "large") entities, these predicates of the meta-language may have no formal existence (i.e., as a set) within the theory. For example, the class of all sets would be a proper class. This is philosophically unsatisfying to some and has motivated additional work in set theory and other methods of formalizing the foundations of mathematics such as New Foundations by Willard Van Orman Quine.

</doc>
<doc id="3233" url="https://en.wikipedia.org/wiki?curid=3233" title="Acceptance testing">
Acceptance testing

In engineering and its various subdisciplines, acceptance testing is a test conducted to determine if the requirements of a specification or contract are met. It may involve chemical tests, physical tests, or performance tests.
In systems engineering it may involve black-box testing performed on a system (for example: a piece of software, lots of manufactured mechanical parts, or batches of chemical products) prior to its delivery.
In software testing the ISTQB defines "acceptance" as: formal testing with respect to user needs, requirements, and business processes conducted to determine whether a system satisfies the acceptance criteria and to enable the user, customers or other authorized entity to determine whether or not to accept the system. Acceptance testing is also known as user acceptance testing (UAT), end-user testing, operational acceptance testing (OAT) or field (acceptance) testing.
A smoke test may be used as an acceptance test prior to introducing a build of software to the main testing process.
Overview.
Testing is a set of activities conducted to facilitate discovery and/or evaluation of properties of one or more items under test. Each individual test, known as a test case, exercises a set of predefined test activities, developed to drive the execution of the test item to meet test objectives; including correct implementation, error identification, quality verification and other valued detail. The test environment is usually designed to be identical, or as close as possible, to the anticipated production environment. It includes all facilities, hardware, software, firmware, procedures and/or documentation intended for or used to perform the testing of software.
UAT and OAT test cases are ideally derived in collaboration with business customers, business analysts, testers, and developers. It's essential that these tests include both business logic tests as well as operational environment conditions. The business customers (product owners) are the primary stakeholders of these tests. As the test conditions successfully achieve their acceptance criteria, the stakeholders are reassured the development is progressing in the right direction.
Process.
The acceptance test suite may need to be performed multiple times, as all of the test cases may not be executed within a single test iteration.
The acceptance test suite is run using predefined acceptance test procedures to direct the testers which data to use, the step-by-step processes to follow and the expected result following execution. The actual results are retained for comparison with the expected results. If the actual results match the expected results for each test case, the test case is said to pass. If the quantity of non-passing test cases does not breach the project's predetermined threshold, the test suite is said to pass. If it does, the system may either be rejected or accepted on conditions previously agreed between the sponsor and the manufacturer.
The anticipated result of a successful test execution:
The objective is to provide confidence that the developed product meets both the functional and non-functional requirements. The purpose of conducting acceptance testing is that once completed, and provided the acceptance criteria are met, it is expected the sponsors will sign-off on the product development/enhancement as satisfying the defined requirements (previously agreed between business and product provider/developer).
User acceptance testing.
User acceptance testing (UAT) consists of a process of verifying that a solution works for the user. It is not system testing (ensuring software does not crash and meets documented requirements), but rather ensures that the solution will work for the user (i.e., tests that the user accepts the solution); software vendors often refer to this as "Beta testing".
This testing should be undertaken by a subject-matter expert (SME), preferably the owner or client of the solution under test, and provide a summary of the findings for confirmation to proceed after trial or review. In software development, UAT as one of the final stages of a project often occurs before a client or customer accepts the new system. Users of the system perform tests in line with what would occur in real-life scenarios.
It is important that the materials given to the tester be similar to the materials that the end user will have. Provide testers with real-life scenarios such as the three most common tasks or the three most difficult tasks you expect an average user will undertake. Instructions on how to complete the tasks must not be provided.
The UAT acts as a final verification of the required business functionality and proper functioning of the system, emulating real-world usage conditions on behalf of the paying client or a specific large customer. If the software works as required and without issues during normal use, one can reasonably extrapolate the same level of stability in production.
User tests, usually performed by clients or by end-users, do not normally focus on identifying simple problems such as spelling errors or cosmetic problems, nor on showstopper defects, such as software crashes; testers and developers previously identify and fix these issues during earlier unit testing, integration testing, and system testing phases.
UAT should be executed against test scenarios. Test scenarios usually differ from System or Functional test cases in the sense that they represent a "player" or "user" journey. The broad nature of the test scenario ensures that the focus is on the journey and not on technical or system-specific key presses, staying away from "click-by-click" test steps to allow for a variance in users' steps through systems. Test scenarios can be broken down into logical "days", which are usually where the actor (player/customer/operator) or system (backoffice, front end) changes.
In the industrial sector, a common UAT is a factory acceptance test (FAT). This test takes place before installation of the concerned equipment. Most of the time testers not only check if the equipment meets the pre-set specification, but also if the equipment is fully functional. A FAT usually includes a check of completeness, a verification against contractual requirements, a proof of functionality (either by simulation or a conventional function test) and a final inspection.
The results of these tests give confidence to the client(s) as to how the system will perform in production. There may also be legal or contractual requirements for acceptance of the system.
Operational acceptance testing.
Operational Acceptance Testing (OAT) is used to conduct operational readiness (pre-release) of a product, service or system as part of a quality management system. OAT is a common type of non-functional software testing, used mainly in software development and software maintenance projects. This type of testing focuses on the operational readiness of the system to be supported, and/or to become part of the production environment. 
Acceptance testing in extreme programming.
Acceptance testing is a term used in agile software development methodologies, particularly extreme programming, referring to the functional testing of a user story by the software development team during the implementation phase.
The customer specifies scenarios to test when a user story has been correctly implemented. A story can have one or many acceptance tests, whatever it takes to ensure the functionality works. Acceptance tests are black-box system tests. Each acceptance test represents some expected result from the system. Customers are responsible for verifying the correctness of the acceptance tests and reviewing test scores to decide which failed tests are of highest priority. Acceptance tests are also used as regression tests prior to a production release. A user story is not considered complete until it has passed its acceptance tests. This means that new acceptance tests must be created for each iteration or the development team will report zero progress.
Types of acceptance testing.
Typical types of acceptance testing include the following

</doc>
<doc id="3234" url="https://en.wikipedia.org/wiki?curid=3234" title="Archbishopric of Riga">
Archbishopric of Riga

The Archbishopric of Riga (, ) was an archbishopric in Medieval Livonia, a subject to the Holy See. It was established in 1186 as the bishopric of Livonia at Üxküll, then after moving to Riga it became the bishopric of Riga in 1202 and was elevated to an archbishopric in 1255.
Archbishops of Riga.
The archbishops of Riga were also the secular rulers of Riga until 1561 when during the reformation the territory converted from Catholicism to Lutheranism and all church territories were secularized. The see was restored as a diocese of the Catholic Church in 1918 and raised into an archdiocese in 1923.
Bishops and Archbishops of Riga.
A new Bishopric of Livonia was established in Latgalia in 1621 during the Inflanty Voivodeship of the Polish–Lithuanian Commonwealth.
Coinage.
The Archbishops of Riga were innovators in the field of minting currency, reviving techniques abandoned since the collapse of Rome. The names of individual archbishops after 1418, as well as the years of their respective reigns, are stamped on Livonian pennies excavated at archaeological sites. In many cases, this is the only biographical data available. No Livonian pennies before 1418 have been found.

</doc>
<doc id="3235" url="https://en.wikipedia.org/wiki?curid=3235" title="Albert Frederick, Duke of Prussia">
Albert Frederick, Duke of Prussia

Albert Frederick (, ; 7 May 1553, in Königsberg – 28 August 1618, in Fischhausen, Rybaki) was Duke of Prussia from 1568 until his death. He was a son of Albert of Prussia and Anna Marie of Brunswick-Lüneburg. He was the second and last Prussian duke of the Ansbach branch of the Hohenzollern family.
Duke of Prussia.
Albert became Duke of Prussia after paying feudal homage to the King of Poland, Zygmunt August (Ducal Prussia was a fief of Poland), on July 19, 1569 in Lublin. The homage was described by the Polish chronicler Jan Kochanowski in his work "Proporzec" ("Standard"). During the 1573 Polish election, Albert Frederick attempted to gain acceptance to the Polish senate but was opposed by the powerful Jan Zamoyski (later Grand Hetman of the Crown of the Kingdom of Poland) who feared the influence of Protestants in the Polish legislative body. Albert Frederick initially refused to recognize the election of Stefan Bathory and supported the candidacy of Maximilian of Habsburg. However, at the Toruń sejm of October 1576 he gave his support to the new monarch.
As the great grandson of the Polish king Casimir IV Jagiellon, and as a Duke in Prussia who was fluent in Polish, Albert Frederick was seriously considered for a time as a possible candidate for the Polish throne. He particularly enjoyed the support of Polish Lutherans.
In 1572 he began to exhibit signs of mental disorder. In early 1578, the regency was taken over by his cousin, George Frederick of Brandenburg-Kulmbach (1539–1603). After George Frederick's death in 1603, the Polish king Sigismund III Vasa appointed Joachim Frederick as regent in 1605, and permitted his son, John Sigismund, to succeed him in 1611. The latter became Duke of Prussia after Albert Frederick's death in 1618.
Marriage.
Albert Frederick was married in 1573 to Marie Eleonore of Cleves, a daughter of Wilhelm, Duke of Jülich-Cleves-Berg and Archduchess Maria of Austria (1531–1581). Maria was a daughter of Ferdinand I, Holy Roman Emperor and Anna of Bohemia and Hungary.
Issue.
Albert Frederick and Marie were parents to seven children:
At his death, the duchy passed to his son-in-law John Sigismund, Margrave of Brandenburg, combining the two territories under a single dynasty and forming Brandenburg-Prussia.
References.
 

</doc>
<doc id="3236" url="https://en.wikipedia.org/wiki?curid=3236" title="Ansbach">
Ansbach

Ansbach (; ) is a city in the German state of Bavaria. It is the capital of the administrative region of Middle Franconia. Ansbach is situated southwest of Nuremberg and north of Munich, on the Fränkische Rezat (Rezat River), a tributary of the Main river. As of 2004, its population was 40,723.
Developed in the 8th century as a Benedictine monastery, it became the seat of the Hohenzollern family in 1331. In 1460, the Margraves of Branderberg-Anspach lived here. The city has a castle known as Margrafen–Schloss, built between 1704-1738. It was not badly damaged during the World Wars and hence retains its original historical baroque sheen. Ansbach is now home to a US military base and to the Ansbach University of Applied Sciences.
The city has connections via autobahn A6 and highways B13 and B14. Ansbach station is on the Nürnberg–Crailsheim and Treuchtlingen–Würzburg railways and is the terminus of line S4 of the Nuremberg S-Bahn.
Name origin.
Ansbach was originally been called Onoltesbach (about 790 AD), a term composed of three parts.
The individual word elements are "Onold" (the city founders name), the Suffix "-es" (in this relation it can be translated with "sb. owns sth.") and the Old High German expression "pah" or "bach" (for Brook). The name of the city has slightly changed throughout the centuries into Onoltespah (837 AD), Onoldesbach (1141 AD), Onoldsbach (1230 AD), Onelspach (1338 AD), Onsbach (1508 AD) and finally Ansbach (1732 AD). 
It was also formerly known as Anspach.
History.
According to folklore, towards the end of the 7th centurie a group of franconian peasants and their families went up into the wilderness to found a new settlement. Their leader Onold led them to a area called the "Rezattal" (Rezat valley). This is where they founded the "Urhöfe" (meaning the first farms: Knollenhof, Voggenhof and Rabenhof). Gradually more settlers, such as the "Winden-Tribe" came and the farms grew into a small village. Many villages around Ansbach were founded by the "Winden" during that period (even today their settlements can easily identified by their names, like "Meinhardswinden", "Dautenwinden" or "Brodswinden" for example).
A Benedictine monastery was established there around 748 by the Frankish noble St Gumbertus. The adjoining village of Onoltesbach is first noticed as a proper town in 1221. 
The counts of Öttingen ruled over Ansbach until the Hohenzollern burgraves of Nürnberg took over in 1331. The Hohenzollerns made Ansbach the seat of their dynasty until their acquisition of the Margraviate of Brandenburg in 1415. After the 1440 death of Frederick I, a cadet branch of the family established itself as the margraves of Ansbach. George the Pious introduced the Protestant Reformation to Ansbach in 1528, leading to the secularization of Gumbertus Abbey in 1563. 
The Margrafen–Schloss was built between 1704-1738; its gardens continued to be a notable attraction into the 19th century. In 1791, the last margrave sold his realm to the Kingdom of Prussia. In 1796, the Duke of Zweibrücken, Maximilian Joseph—the future Bavarian king Max I Joseph—was exiled to Ansbach after Zweibrücken had been taken by the French. In Ansbach, Maximilian von Montgelas wrote an elaborate concept for the future political organization of Bavaria, which is known as the Ansbacher Mémoire. In 1806, Napoleon forced Prussia to cede Ansbach and its principality to Bavaria. The act was confirmed by the 1815 Congress of Vienna; Prussia was compensated with the Bavarian duchy of Berg. Ansbach became the capital of the circle of Middle Franconia following the unification of Germany; at the time, it had a population of 12,635.
Jewish families were resident in Ansbach from at least the end of the 18th century. They set up a Jewish Cemetery in the Ruglaender Strasse, which was vandalised and razed under the Nazi tyranny. It was repaired in 1946, but it was damaged several times more. A plaque on the wall of the cemetery commemorates these events. The Jewish Congregation built its synagogue at No 3 Rosenbadstrasse, but it too was damaged by the SA, though it was not burnt down for fear of damaging the neighbouring buildings. It serves today as a "Symbolic House of God". A plaque in the entrance serves as a memorial to the synagogue and to Jewish residents who were murdered during the Holocaust. In 1940, at least 500 patients were deported from the Heil- und Pflegeanstalt Ansbach 'Ansbach Medical and Nursing Clinic' to the extermination facilities Sonnenstein and Hartheim which were disguised as psychiatric institutions, as part of the Action T4 euthanasia action. They were gassed there. At the clinic in Ansbach itself, around 50 intellectually disabled children were injected with the drug Luminal and killed that way. A plaque was erected in their memory in 1988 in the local hospital at No. 38 Feuchtwangerstrasse.
During World War II, a subcamp of Flossenbürg concentration camp was located here. Also during the Second World War the Luftwaffe and Wehrmacht had bases here. The nearby airbase was the home station for the Stab & I/KG53 (Staff & 1st Group of Kampfgeschwader 53) operating 38 Heinkel He 111 bombers. On 1 September 1939 this unit was one of the many that participated in the attack on Poland that started the war. All of its bridges were destroyed during the course of the war. During the Western Allied invasion of Germany in April 1945, the airfield was seized by the United States Third Army, and used by the USAAF 354th Fighter Group which flew P-47 Thunderbolts from the aerodrome (designated ALG R-82) from late April until the German capitulation on 7 May 1945. At the end of the war, 19-year-old student Robert Limpert tried to get the town to surrender to the US Forces without a fight. He was betrayed by Hitler Youth and was hung from the portal of the City Hall by the city's military commander, Col. ("Oberst") Ernst Meyer. Several memorials to his heroic deed have been erected over the years, despite opposition from some residents — in the Ludwigskirche, in the Gymnasium Carolinum and at No 6 Kronenstrasse. After the Second World War, Ansbach belonged to the American Zone. The American Military authorities established a displaced persons (DP) camp in what used to be a sanatorium in what is today the Strüth quarter. 
Bachwoche Ansbach has been held in Ansbach since 1947. Since 1970, Ansbach has enlarged its municipal area by incorporating adjacent communities. Ansbach hosts several units of the U.S. armed forces, associated with German units under NATO. There are five separate U.S. installations: Shipton Kaserne, home to 412th Aviation Support Battalion, Katterbach Kaserne, formally the home of the 1st Infantry Division's 4th Combat Aviation Brigade, which has been replaced by the 12th Combat Aviation Brigade as of 2006, as part of the 1st Infantry Division's return to Fort Riley, Kansas; Bismarck Kaserne, which functions as a satellite post to Katterbach, hosting their Post Theater, barracks, Von Steuben Community Center, Military Police, and other support agencies, Barton Barracks, home to the USAG Ansbach and Bleidorn Barracks, which has a library and housing, and Urlas, which hosts the Post Exchange as well as a housing area opened in 2010. Ansbach was also home to the headquarters of the 1st Armored Division (United States) from 1972 to the early 1990s.
Climate.
Climate in this area has mild differences between highs and lows, and there is adequate rainfall year round. The Köppen climate classification subtype for this climate is "" (Marine West Coast Climate/Oceanic climate).
Economy.
Around the time of the unification of Germany, the chief manufactures of Ansbach were woolen, cotton, and half-silk goods; earthenware; tobacco; cutlery; and playing cards. A considerable trade in grain, wool, and flax was also supported. By the onset of the First World War, it also produced machinery, toys, and embroidery.
Today there is a large density of plastics industry in the City and rural districts around Ansbach.
International relations.
Ansbach is twinned with:

</doc>
<doc id="3237" url="https://en.wikipedia.org/wiki?curid=3237" title="National Alliance (Italy)">
National Alliance (Italy)

National Alliance (, AN) was a conservative political party in Italy. It was the successor of the post-fascist Italian Social Movement that distanced itself from its former ideology on its convention in Fiuggi ("Fiuggi turning point") and dissolved in favour of the new National Alliance.
Gianfranco Fini was the leader of the party following its foundation in 1995, however he stepped down in 2008 after being elected to the nominally non-partisan post of President of the Italian Chamber of Deputies and was succeeded by Ignazio La Russa, who managed the merger of the party into The People of Freedom (PdL), which happened in 2009.
The AN's official newspaper was "Secolo d'Italia".
History.
Foundation.
National Alliance, launched in 1994, was officially founded in January 1995, when the Italian Social Movement (MSI), the former neo-fascist party, merged with conservative elements of the former Christian Democracy, which had disbanded in 1994 after two years of scandals and various splits due to corruption at its highest levels, exposed by the "Mani pulite" investigation, and the Italian Liberal Party, disbanded in the same year. Former MSI members were however still the bulk of the new party and former MSI leader Gianfranco Fini was elected leader of the new party.
The AN logo followed a template very similar to that of the Democratic Party of the Left, with the logo of the direct predecessor party in a small circle, as a means of legally preventing others from using it. The name was suggested by an article on the Italian newspaper "Il Tempo" written in 1992 by Domenico Fisichella, a prominent conservative academic. Starting in the 1990s, the MSI gradually transformed into a mainstream right-wing party, culminating in its 1995 dissolution into AN.
Government participation.
The party was part of all three House of Freedoms coalition governments led by Silvio Berlusconi. Gianfranco Fini was notably nominated Deputy Prime Minister after the 2001 general election and was Foreign Minister from November 2004 to May 2006.
When Gianfranco Fini visited Israel in late November 2003 in the function of Italian Deputy Prime Minister, he labeled the racial laws issued by the fascist regime in 1938 as "infamous", as also Giorgio Almirante, historic leader of MSI, had done before. He also referred to the Italian Social Republic as belonging to the most shameful pages of the past, and considered fascism part of an era of "absolute evil", something which was hardly acceptable to the few remaining hardliners of the party. As a result, Alessandra Mussolini, the granddaughter of the former fascist dictator Benito Mussolini, who had been at odds with the party on a number of issues for a long time, and some hardliners left the party and formed Social Action.
In occasion of the 2006 general election, AN ran within the House of Freedoms, with new allies. The centre-right lost by 24,000 votes in favour of the centre-left coalition The Union. Individually AN received nearly 5 million votes, amounting to 12.3%. In July 2007 a group of splinters led by Francesco Storace formed The Right, which was officially founded on 10 November. Seven MPs of AN, including Teodoro Buontempo and Daniela Santanchè, joined the new party.
The People of Freedom.
In November 2007 Silvio Berlusconi announced that Forza Italia would have soon merged or transformed into The People of Freedom (PdL) party.
After the sudden fall of the second Prodi government in January 2008, the breakup of The Union and the subsequent political crisis which lead to a fresh general election, Berlusconi hinted that Forza Italia would have probably contested its last election and the new party would have been officially founded only after that election. In an atmosphere of reconciliation with Gianfranco Fini, Berlusconi also stated that the new party could see the participation of other parties. Finally, on 8 February, Berlusconi and Fini agreed to form a joint list under the banner of the "The People of Freedom", allied with Lega Nord. After the victory of the PdL in the 2008 general election, AN was merged into the PdL in early 2009.
Ideology.
National Alliance's political program emphasized:
Distinguishing itself from the MSI, the party distanced itself from Benito Mussolini and Fascism and made efforts to improve relations with Jewish groups. With most hardliners leaving the party, it sought to present itself as a respectable conservative party and to join forces with Forza Italia in the European People's Party and, eventually, in a united party of the centre-right.
Although the party approved the market economy and held favourable views on liberalizations and the privatization of state industries, however AN was to the left of Forza Italia on economic issues and sometimes supported statist policies. That is why the party was strong in Rome and Lazio, where most civil servants live. Moreover, AN presented itself as a party promoting national cohesion, national identity and patriotism.
Regarding institutional reforms, the party was a long-time supporter of presidentialism and a plurality voting system, and came to support also federalism and to fully accept the alliance with Lega Nord, although the relations with that party were tense at times, especially about issues regarding national unity.
Gianfranco Fini, a moderniser who saw Nicolas Sarkozy and David Cameron as role-models, impressed an ambitious political line to the party, combining the pillars of conservative ideology like security, family values and patriotism with a progressive approach in other areas such as stem cell research and supporting voting rights for legal aliens. Some of these positions were not shared by many members of the party, most of whom staunchly opposed stem cell research and artificial insemination.
Factions.
National Alliance was a heterogeneous political party and within it members were divided in different factions, some of them very organized:
In the party there was also a group named Ethic-Religious Council, whose board members included Gaetano Rebecchini (founder, ex-DC), Riccardo Pedrizzi (president), Franco Tofoni (vice president), Luigi Gagliardi (secretary-general), Alfredo Mantovano, Antonio Mazzocchi and Riccardo Migliori. This was not a faction but an official organism within the party and expressed the official position of the party on ethical and religious matters. Sometimes the group criticized Gianfranco Fini for his liberal views on abortion, artificial insemination and stem-cell research, which led some notable ex-DC members as Publio Fiori to leave the party. Some members of the Council, such as Pedrizzi and Mantovano were described as members of an unofficial Catholic Right faction.
Popular support.
The party had roughly 10–15% support across Italy, having its stongholds in Central and Southern Italy (Lazio 18.6%, Umbria 15.2%, Marche 14.3%, Abruzzo 14.3%, Apulia 13.2%, Sardinia 12.9%, Tuscany 12.6% and Campania 12.6% in the last general election), scoring badly in Lombardy (10.2%) and Sicily (10.9%), while competing in the North-East (Friuli-Venezia Giulia 15.5% and Veneto 11.3%).
The party had a good showing in the first general election to which it took part (13.5% in 1994) and reached 15.7% in 1996, when Fini tried for the first time to replace Silvio Berlusconi as leader of the centre-right. From that moment the party suffered an electoral decline, but remained the third force of Italian politics.
In the 2006 general election, the final election to which the party participated with its own list, AN won 12.3% of the vote, securing 71 seats in the Chamber of Deputies and 41 in the Senate. In the 2008 general election the party got 90 deputies and 48 senators elected.
The electoral results of National Alliance in the 10 most populated regions of Italy are shown in the table below.

</doc>
<doc id="3240" url="https://en.wikipedia.org/wiki?curid=3240" title="Arno">
Arno

The Arno is a river in the Tuscany region of Italy. It is the most important river of central Italy after the Tiber.
Source and route.
The river originates on Mount Falterona in the Casentino area of the Apennines, and initially takes a southward curve. The river turns to the west near Arezzo passing through Florence, Empoli and Pisa, flowing into the Tyrrhenian Sea at Marina di Pisa.
With a length of , it is the largest river in the region. It has many tributaries: Sieve at long, Bisenzio at , and the Era, Elsa, Pesa, and Pescia. The drainage basin amounts to more than and drains the waters of the following subbasins:
It crosses Florence, where it passes below the Ponte Vecchio and the Santa Trìnita bridge (built by Bartolomeo Ammanati but inspired by Michelangelo). The river flooded this city regularly in historical times, most recently in 1966, with after rainfall of in Badia Agnano and in Florence, in only 24 hours.
The flow rate of the Arno is irregular. It is sometimes described as having a torrentlike behaviour, because it can easily go from almost dry to near flood in a few days. At the point where the Arno leaves the Apennines, flow measurements can vary between . New dams built upstream of Florence have greatly alleviated the problem in recent years.
The flood on November 4, 1966 collapsed the embankment in Florence, killing at least 40 people and damaging or destroying millions of works of art and rare books. New conservation techniques were inspired by the disaster, but even 40 years later hundreds of works still await restoration.
Etymology.
From Latin "Arnus" (Pliny, "Natural History" 3.50). The philologist Hans Krahe related this toponym on a paleo-European basis "*Ar-n-", derived from the Proto-Indo-European root *"er-", "flow, move".

</doc>
<doc id="3244" url="https://en.wikipedia.org/wiki?curid=3244" title="Aveiro, Portugal">
Aveiro, Portugal

Aveiro ( or ) is a city and a municipality in Portugal. In 2011, the population was 78,450, in an area of : it is the second most populous city in the Centro Region of Portugal (after Coimbra). Along with the neighbouring city of Ílhavo, Aveiro is part of an urban agglomeration that includes 120,000 inhabitants, making it one of the most important populated regions by density in the Centro Region, and primary centre of the Intermunicipal Community of Aveiro and Baixo Vouga. Administratively, the president of the municipal government is José Ribau Esteves (elected by coalition between the Social Democratic Party and the Democratic Social Centre, who governs the ten civil parishes ().
History.
The presence of human settlement in the territory of Aveiro extends to the period associated with the great dolmens of pre-history, which exist in most of the region.
For a long period Aveiro was important economic link in the production of salt and commercial shipping. It was a centre of salt exploration by the Romans and trade since 26 January 959 (from the testament of Countess Mumadona Dias to the "cenóbio" of Guimarães). During this testament, Mumadona Dias also highlighted the ancient name for Aveiro, referring to the monastery's lands in "Alauario et Salinas", literally, "a gathering place or preserve of birds and of great salt".
The Moors invaded and then held it until the 11th century, after which it became popular with Portuguese royalty.
Kingdom.
Later, King John I, on the advise of his son Peter (who was the donatary of Aveiro, requested the construction of fortification walls.
King D. Duarte conceded in 1435 the privilege of providing an annual duty-free fair, later referred to as the "Feira de Março" ("March Fair"), today still an annual tradition.
The Princess St. Joana, daughter of Afonso V lived in Aveiro, entering the convent of Jesus, and lived their until her death on 12 May 1490. During her life her presence brought attention the town, and favoured it with an elevated level of development for the time.
The first charter (foral) was conceded by Manuel I of Portugal on 4 August 1515, as indicated in the "Livro de Leituras Novas de Forais da Estremadura". Its geographic position along the Aveiro River had always helped it to subsist and grow, supported by salt market, fishing and maritime commercial development.
By the beginning of the 15th century, there are already existed a great wall around the historical centre, intonating the significance of the community and growth of the population. This included the founding of many religious institutions and their supports, which assisted during the 17th and 18th century crises associated with silt in the waterway. In the winter of 1575, a terrible storm closed the entrance to its port, ending a thriving trade in metals and tiles, and creating a reef barrier at the Atlantic Ocean. The walls were subsequently demolished and used to create the docks around the new sand bar.
Between the 16th and 17th centuries, the rivers instability at the mouth (between the Ria and open ocean) resulted in the closure of the canal, impeding the use of the port of Aveiro, and creating stagnation in the waters of the lagoon. This blow to the economy creating a social and economic crisis, and resulting in the decrease in the population and emigration. It was at this time that the Church of the Miserícordia was constructed, during the Philippine Dynastic union.
In 1759, Joseph I of Portugal elevate the town to the status of city, a few months after condemning the Duke of Aveiro (a title established in 1547 by John III), José Mascarenhas, to death. As a result, Aveiro became known as Nova Bragança: it was later abandoned much later, and returned to Aveiro. In 1774, by request of King Joseph, Pope Clement XIV instituted the Diocese of Aveiro.
In the 19th century, the Aveirense were active during the Liberal Wars, and it was José Estêvão Coelho de Magalhães, a parliamentary member who was determinant in resolving the problem of access along the Ria, and development of transport, especially the railway line between Lisbon and Porto. It was the opening of the artificial canals, completed in 1808, that allowed Aveiro to expand economically, marking the beginning in the town's growth.
The municipality was elevated to the status of town, centred on the its principal church, consecrated to the Archangel Michael, today the location of the "Praça da Republica" (having been demolished in 1835.
Geography.
Located on the shore of the Atlantic Ocean, Aveiro is an industrial city with an important seaport.
The seat of the municipality is the city of Aveiro, comprising the five urban parishes with about 73,003 inhabitants. The city of Aveiro is also the capital of the District of Aveiro, and the largest city in the Baixo Vouga intermunicipal community subregion.
Aveiro is known as "The Portuguese Venice", due to its system of canals and boats similar to the Italian city of Venice. The people's quality of life is very high.
Climate.
Aveiro has a warm-summer mediterranean climate influenced by its proximity to the Atlantic Ocean. The maritime influence causes a narrow temperature range resulting in summers averaging around in daytime temperatures, considerably lower than inland areas on the same parallel on the Iberian Peninsula. As typical of mediterranean climates, summers are dry and winters are wet. A coastal feature is that frosts are rare and never severe. The hottest temperature recored was set in July. Temperatures above are extremely occasional, and averages only a couple of times per annum.
Human geography.
Administratively, the municipality is divided into 10 civil parishes ():
São Jacinto is located on an eponymous peninsula, between the Atlantic Ocean and Ria de Aveiro. Aveiro had 61,430 eligible voters in 2006.
International relations.
Aveiro's sister cities are:
Economy.
Aveiro is known for its production of salt and for its seaweed harvest, which is used for fertilizer in the area.
The region is also known for the preponderance of ceramics industries and commerce, a reflection of the regions advancements, resulting in a long productive tradition since the late Roman, early Medieval period (reflected in the ceramics kilns).
The city of Aveiro has several shopping centers and malls (Pingo Doce Shopping Center, Fórum Aveiro, Glicínias Plaza (Jumbo – Auchan), Aveiro's Shopping Center (Continente & Mediamarkt), Aveiro's Retail Park and the Oita Shopping Center). This city has lots of traditional commerce stores. The most central one being Forum Aveiro with clothes stores, restaurant zone, a book shop and a cinema.
The unemployment rate is very low (about 5%), sustained by a university and commerce.
Transport.
The local economy is fed by a series of transport networks that cross the municipal boundaries. Regional gateways include air service through the Aeródromo de Aveiro/São Jacinto (LPAV) and the Porto de Aveiro (Ílhavo/Aveiro). Rail service includes service by Alfa Pendular (between Lisbon and Braga; Lisbon and Oporto; Faro and Oporto) and Intercity (between Lisbon and Oporto as well as Lisbon and Guimarães) trains; suburban links through the Urbanos do Porto and, also, the Linha do Vouga, a narrow gauge railway to Águeda and Sernada do Vouga.
The primary expressways and inter-regional thoroughfares include: A1 (between Porto and Lisbon); and the A25 (which links Viseu, Guarda and Vilar Formoso).
"Moliceiros" provide access along the Ria for tourist visits, in addition to traditional fishing or recreational purposes, including regattas.
Architecture.
The architecture of Aveiro is influenced by two phases: the pre-Kingdom era, with a number of historical monuments; and the modernist movements resulting from the expansion of economy during the 19th-20th centuries.
The city's primary landmark is the 15th century Monastery of Jesus (), containing the tomb of King Afonso V's daughter, St. Joana (who died in 1490). The presence of this royal personage, beatified in 1693, proved to be of great benefit when she bequeathed her valuable estate to the convent. In the 17th and 18th centuries, the convent housed a school of embroidery, but was transformed into the "Museu de Santa Joana", or simply, the Museum of Aveiro, housing many of these handicrafts.
The abundance of 19th-20th century architectural buildings reflects the effects of the boom during that period, including many of the Art Novo and Art Deco buildings, inspired by modernist trends and Nationalist tendencies of the Estado Novo regime. The best of these in the university campus, where many the nationalist architects were involved in construction projects.
There are several attractions in the city of Aveiro, including cathedrals, canals and the beache, including the "Ílhavo ceramica de Vista Alegre" and the beaches of Barra, Costa Nova do Prado, and Gafanha da Nazaré.
Culture.
Aveiro is known in Portugal for its traditional sweets, "Ovos Moles de Aveiro" (PGI), "trouxas de ovos", both made from eggs. "Raivas" are also a typical biscuit of Aveiro.
The municipal holiday is 12 May, the day of Joanna, Princess of Portugal.
Education.
The University of Aveiro was created in 1973 and is considered one of the most dynamic and innovative universities of Portugal, attracting thousands of students to the city. It is one of the best in Portugal and 354th best university in the World.
The University has about 430 professors (with Ph.D. degrees), 11,000 undergraduate students, and 1,300 post-graduate students.
Sport.
Sport Clube Beira-Mar, an association football club. Founded in 1922, it has a sports academy with various youth levels participating in all kinds of sports codes notably in Basketball and Futsal in both National and Provincial levels. The club plays at the Estádio Municipal de Aveiro, designed by Portuguese architect Tomás Taveira for Euro 2004, where it held two group matches.
The other long established club in the city 'Os Galitos' was founded in 1904 and houses a wide variety of sports. Some of its older and stronger sports include basketball and water sports such as swimming, sailing and rowing. Other sections in the club include chess, snooker, pool and billiards among others. Despite all the sections of the club, rowing is the modality in which the club has maintained a long and proud tradition going back more than one hundred years, reaching the highest possible excellence as a club with several of its individual and team of rowers having successfully represented Portugal in international tournaments including the Olympic Games. 

</doc>
<doc id="3246" url="https://en.wikipedia.org/wiki?curid=3246" title="Anthony the Great">
Anthony the Great

Saint Anthony or Antony (, "Antṓnios"; , ; –356) was a Christian monk from Egypt, revered since his death as a saint. He is distinguished from other saints named Anthony by various epithets: , , and For his importance among the Desert Fathers and to all later Christian monasticism, he is also known as the . His feast day is celebrated on January 17 among the Orthodox and Catholic churches and on Tobi 22 in the Egyptian calendar used by the Coptic Church.
The biography of Anthony's life by Athanasius of Alexandria helped to spread the concept of Christian monasticism, particularly in Western Europe via its Latin translations. He is often erroneously considered the first Christian monk, but as his biography and other sources make clear, there were many ascetics before him. Anthony was, however, the first to go into the wilderness (about  270), a geographical move that seems to have contributed to his renown. Accounts of Anthony enduring supernatural temptation during his sojourn in the Eastern Desert of Egypt inspired the often-repeated subject of the temptation of St. Anthony in Western art and literature.
Anthony is appealed to against infectious diseases, particularly skin diseases. In the past, many such afflictions, including ergotism, erysipelas, and shingles, were historically referred to as "St. Anthony's fire".
Life.
Early life.
Anthony was born in Coma in Lower Egypt in  251 to wealthy landowner parents. When he was about 18 years old, his parents died and left him with the care of his unmarried sister. Shortly thereafter, he decided to follow the Evangelical counsel of Jesus which reads, "If you want to be perfect, go, sell what you have and give to the poor, and you will have treasures in heaven." Anthony gave away some of his family's lands to his neighbors, sold the remaining property, and donated the funds thus raised to the poor. He then left to live an ascetic life, placing his sister with a group of Christian virgins, a sort of proto-nunnery. 
Hermit.
For the next fifteen years, Anthony remained in the area, spending the first years as the disciple of another local hermit. There are various legends associating Anthony with pigs: one is that he worked as a swineherd during this period.
Anthony is sometimes considered the first monk, but there were others before him. There were already ascetic pagan hermits (the "Therapeutae") and loosely organized cenobitic communities were described by the Hellenized Jewish philosopher Philo of Alexandria in the 1st century  as long established in the harsh environment of Lake Mareotis and in other less accessible regions. Philo opined that "this class of persons may be met with in many places, for both Greece and barbarian countries want to enjoy whatever is perfectly good." Christian ascetics such as Thecla had likewise retreated to isolated locations at the outskirts of cities. Anthony is notable for having decided to surpass this tradition and headed out into the desert proper. He left for the alkaline Nitrian Desert (later the location of the noted monasteries of Nitria, Kellia, and Scetis) on the edge of the Western Desert about west of Alexandria. He remained there for 13 years.
According to Athanasius, the devil fought Anthony by afflicting him with boredom, laziness, and the phantoms of women, which he overcame by the power of prayer, providing a theme for Christian art. After that, he moved to a tomb, where he resided and closed the door on himself, depending on some local villagers who brought him food. When the devil perceived his ascetic life and his intense worship, he was envious and beat him mercilessly, leaving him unconscious. When his friends from the local village came to visit him and found him in this condition, they carried him to a church.
After he recovered, he made a second effort and went back into the desert to a farther mountain by the Nile called Pispir (now Der-el-Memun), opposite Arsinoe. There he lived strictly enclosed in an old abandoned Roman fort for some 20 years. According to Athanasius, the devil again resumed his war against Anthony, only this time the phantoms were in the form of wild beasts, wolves, lions, snakes, and scorpions. They appeared as if they were about to attack him or cut him into pieces. But the saint would laugh at them scornfully and say, "If any of you have any authority over me, only one would have been sufficient to fight me." At his saying this, they disappeared as though in smoke. While in the fort he only communicated with the outside world by a crevice through which food would be passed and he would say a few words. Anthony would prepare a quantity of bread that would sustain him for six months. He did not allow anyone to enter his cell; whoever came to him stood outside and listened to his advice.
Then one day he emerged from the fort with the help of villagers, who broke down the door. By this time most had expected him to have wasted away or to have gone insane in his solitary confinement. Instead, he emerged healthy, serene, and enlightened. Everyone was amazed that he had been through these trials and emerged spiritually rejuvenated. He was hailed as a hero and from this time forth the legend of Anthony began to spread and grow. Anthony went to Fayyum and confirmed the brethren there in the Christian faith before returning to his fort.
Amid the Diocletian Persecutions, Anthony wished to become a martyr and in 311 went to Alexandria. He visited those who were imprisoned for the sake of Christ and comforted them. When the Governor saw that he was confessing his Christianity publicly, not caring what might happen to him, he ordered him not to show up in the city. However, the Saint did not heed his threats. He faced him and argued with him in order that he might arouse his anger so that he might be tortured and martyred, but it did not happen.
Father of Monks.
At the end of the persecutions, Anthony returned to his old Roman fort. By this time, many more had heard of his sanctity and he had many more visitors than before. He saw these visits as interfering with his worship and went further into the Eastern Desert. He traveled for three days before reaching a small oasis with a spring and some palm trees and chose to settle there. Disciples soon found him out and his number of visitors again continued to grow. 
Anthony had not been the first ascetic or hermit, but he may properly be called the "Father of Monasticism" in Christianity, as he organized his disciples into a worshipful community and inspired similar withdrawn communities throughout Egypt and, following the spread of Athanasius's hagiography, the Greek and Roman world. His follower Macarius the Great was particularly active in continuing his legacy.
Anthony anticipated the rule of Benedict by about 200 years, engaging himself and his disciples in manual labor. Anthony himself cultivated a garden and wove rush mats. He and his disciples were regularly sought for words of enlightenment. These statements were later collected into the book of "Sayings of the Desert Fathers". Anthony himself is said to have spoken to those of a spiritual disposition personally, leaving the task of addressing the more worldly visitors to Macarius. On occasions, he would go to the monastery on the outskirts of the desert by the Nile to visit the brethren, then return to his inner monastery.
The backstory of one of the surviving epistles, directed to Constantine I, recounts how the fame of Saint Anthony spread abroad and reached Emperor Constantine. The Emperor wrote to him offering praise and requesting prayers. The brethren were pleased with the Emperor's letter, but Anthony did not pay any attention to it, and he said to them, "The books of God, the King of Kings and the Lord of Lords, commands us every day, but we do not heed what they tell us, and we turn our backs on them." Under the persistence of the brethren who told him "Emperor Constantine loves the church", he accepted to write him a letter blessing him, and praying for the peace and safety of the empire and the church.
According to Athanasius, Saint Anthony heard a voice telling him "Go out and see." He went out and saw an angel who wore a girdle with a cross, one resembling the holy Eskiem (Tonsure or Schema), and on his head was a head cover (Kolansowa). He was sitting while braiding palm leaves, then he stood up to pray, and again he sat to weave. A voice came to him saying, "Anthony, do this and you will rest." Henceforth, he started to wear this tunic that he saw, and began to weave palm leaves, and never was bored again. Saint Anthony prophesied about the persecution that was about to happen to the church and the control of the heretics over it, the church victory and its return to its former glory, and the end of the age. When Saint Macarius visited Saint Anthony, Saint Anthony clothed him with the monk's garb, and foretold him what would be of him. When the day drew near of the departure of Saint Paul the First Hermit in the desert, Saint Anthony went to him and buried him, after clothing him in a tunic which was a present from St Athanasius the Apostolic, the 20th Patriarch of Alexandria.
In 338, he left the desert temporarily to visit Alexandria to help refute the teachings of Arius. Although not particularly learned, Anthony was able to confound the Arians.
Final days.
When Saint Anthony felt that the day of his departure had approached, he commanded his disciples to give his staff to Saint Macarius, and to give one sheepskin cloak to Saint Athanasius and the other sheepskin cloak to Saint Serapion, his disciple. He further instructed his disciples to bury his body in an unmarked, secret grave.
He probably spoke only his native language, Coptic, but his sayings were spread in a Greek translation. He himself left no writings. His biography was written by Saint Athanasius and titled "Life of Saint Anthony the Great". Many stories are also told about him in various collections of sayings of the Desert Fathers.
Though Anthony himself did not organize or create a monastery, a community grew around him based on his example of living an ascetic and isolated life. Athanasius' biography helped propagate Anthony's ideals. Athanasius writes, "For monks, the life of Anthony is a sufficient example of asceticism."
Temptation.
Famously, Anthony is said to have faced a series of supernatural temptations during his pilgrimage to the desert. The first to report on the temptation was his contemporary Athanasius of Alexandria. It is possible these events, like the paintings, are full of rich metaphor or in the case of the animals of the desert, perhaps a vision or dream. Some of the stories included in Saint Anthony's biography are perpetuated now mostly in paintings, where they give an opportunity for artists to depict their more lurid or bizarre interpretations. Many artists, including Martin Schongauer, Hieronymus Bosch, Dorothea Tanning, Max Ernst, Leonora Carrington and Salvador Dalí, have depicted these incidents from the life of Anthony; in prose, the tale was retold and embellished by Gustave Flaubert in "The Temptation of Saint Anthony".
Emphasis on these stories, however, did not really begin until the Middle Ages, when the psychology of the individual became of greater interest. Below are some of these controversial tales.
The satyr and the centaur.
Saint Anthony was on a journey in the desert to find Saint Paul of Thebes, who according to his dream was a better Hermit than he. Saint Anthony had been under the impression that he was the first person to ever dwell in the desert; however, due to the dream, Saint Anthony was called into the desert to find his "better", Saint Paul. On his way there, he ran into two demons in the forms of a centaur and a satyr, which Western theology considers to have been temptations.
At any rate, he was stopped by the two demons and he asked them, "Who are you?" To that the satyr replied, "I am a corpse, one of those whom the heathen call satyrs, and by whom they are snared into idolatry." The satyr then tried to terrify the saint while the centaur acknowledged the overthrow of the gods. In the end, the centaur tried to show Saint Anthony the way to his destination while the satyr ended up asking for Saint Anthony's blessing.
Silver and gold.
Another time Saint Anthony was travelling in the desert, he found a plate of silver coins in his path. He pondered for a moment as to why a plate of silver coins would be out in the desert where no one else travels, and realised the Devil must have laid it out there to tempt him. To that he said, "Ha! Devil, thou weenest to tempt me and deceive me, but it shall not be in thy power." Once he said this, the plate of silver vanished.
Saint Anthony continued walking along and saw a pile of gold in his way which the Devil had laid there to deceive him. Saint Anthony cast the pile of gold into a fire, and it vanished just like the silver coins did. After these events, Saint Anthony had a vision where the whole world was full of snares and traps. He cried to the Lord, "Oh good Lord, who may escape from these snares?" A voice replied, "Humility shall escape them without more."
Demons in the cave.
Once, Saint Anthony tried hiding in a cave to escape the demons that plagued him. There were so many little demons in the cave though that Saint Anthony's servant had to carry him out because they had beaten him to death. When the hermits were gathered to Saint Anthony's corpse to mourn his death, Saint Anthony was revived. He demanded that his servants take him back to that cave where the demons had beaten him. When he got there he called out to the demons, and they came back as wild beasts to rip him to shreds. All of a sudden a bright light flashed, and the demons ran away. Saint Anthony knew that the light must have come from God, and he asked God where was he before when the demons attacked him. God replied, "I was here but I would see and abide to see thy battle, and because thou hast mainly fought and well maintained thy battle, I shall make thy name to be spread through all the world."
Veneration.
Most of what is known about Saint Anthony comes from the "Life of Anthony". Written in Greek around 360 by Athanasius of Alexandria, it depicts Anthony as an illiterate and holy man who through his existence in a primordial landscape has an absolute connection to the divine truth, which always is in harmony with that of Athanasius as the biographer. Sometime before 374, it was translated into Latin by Evagrius of Antioch. The Latin translation helped the "Life" become one of the best known works of literature in the Christian world, a status it would hold through the Middle Ages. In addition to the "Life", several surviving homilies and epistles of varying authenticity provide some additional autobiographical detail.
Anthony had been secretly buried on the mountain-top where he had chosen to live. His remains were reportedly discovered in 361, and transferred to Alexandria. Some time later, they were taken from Alexandria to Constantinople, so that they might escape the destruction being perpetrated by invading Saracens. In the eleventh century, the Byzantine emperor gave them to the French Count Jocelin. Jocelin had them transferred to La-Motte-Saint-Didier, which was then renamed Saint-Antoine-en-Dauphiné. There, Anthony is credited with assisting in a number of miraculous healings, primarily from ergotism, which became known as "St. Anthony's Fire". He was credited by two local noblemen of assisting them in recovery from the disease. They then founded the Hospital Brothers of St. Anthony in honor of him, who specialized in nursing the victims of skin diseases.
Veneration of Anthony in the East is more restrained. There are comparatively few icons and paintings of him. He is regarded as the "first master of the desert and the pinnacle of holy monks", however, and there are monastic communities of the Maronite, Chaldean, and Orthodox churches which state that they follow his monastic rule. During the Middle Ages, Anthony, along with Quirinus of Neuss, Cornelius and Hubertus, was venerated as one of the Four Holy Marshals ("Vier Marschälle Gottes") in the Rhineland.
Coptic literature.
Examples of purely Coptic literature are the works of Saint Anthony and Saint Pachomius, who only spoke Coptic, and the sermons and preachings of Saint Shenouda the Archmandrite, who chose to only write in Coptic. Saint Shenouda was a popular leader who only spoke to Egyptians in the Egyptian language (Coptic), not in Greek.
The earliest original writings in Coptic language were the letters by Saint Anthony. During the 3rd and 4th centuries many ecclesiastics and monks wrote in Coptic.
Popular literature.
The main character in the Hervey Allen novel "Anthony Adverse", and the 1936 film of the same name, is an abandoned child who is placed in a foundling wheel on the saint's feast day, and given the name Anthony in his honor. 

</doc>
<doc id="3250" url="https://en.wikipedia.org/wiki?curid=3250" title="Amblypoda">
Amblypoda

Amblypoda is a taxonomic hypothesis uniting a group of extinct, herbivorous mammals. They were considered a suborder of the primitive ungulate mammals and have since been shown to represent a polyphyletic group.
Characteristics.
The Amblypoda take their name from their short and stumpy feet, which were furnished with five toes each and supported massive pillar-like limbs. The brain cavity was extremely small and insignificant in comparison to the bodily mass, which was equal to that of the largest rhinoceroses. These animals were descendants of the small ancestral ungulates that retained all the primitive characteristics of the latter, accompanied by a huge increase in body size.
The Amblypoda were confined to the Paleocene and Eocene periods and occurred in North America, Asia (especially Mongolia) and Europe. The cheek teeth were short-crowned (brachyodont), with the tubercles more-or-less completely fused into transverse ridges, or cross-crests (lophodont type), and the total number of teeth was in one case the typical 44, but in another was fewer. The vertebra of the neck unite on nearly flat surfaces, the humerus had lost the foramen, or perforation, at the lower end, and the third trochanter to the femur may have also been wanting. In the forelimb, the upper and lower series of carpal (finger) bones scarcely alternated, but in the hind foot, the astragalus overlapped the cuboid, while the fibula, which was quite distinct from the tibia (as was the radius from the ulna in the forelimb), articulated with both astragalus and calcaneum.
Types of amblypods.
The most generalized type was "Coryphodon", representing the family Coryphodontidae, from the lower Eocene of Europe and North America, in which there were 44 teeth and no horn-like excrescences on the long skull, while the femur had a third trochanter. The canines were somewhat elongated and were followed by a short gap in each jaw, and the cheek-teeth were adapted for succulent food. The length of the body reached about six feet in some cases.
In the middle Eocene formations of North America occurred the more specialized "Uintatherium" (or "Dinoceras"), typifying the family Uintatheriidae. Uintatheres were huge creatures with long narrow skulls, of which the elongated facial portion carried three pairs of bony horn-cores, probably covered with short horns in life, the hind-pair having been much the largest. The dental formula was i. 0/3, c. 1/1, p. 3/3·4, m. 3/3, the upper canines having been long sabre-like weapons, protected by a descending flange on each side of the lower front jaw.
In the basal Eocene of North America, the Amblypoda were represented by extremely primitive, five-toed, small ungulates such as "Periptychus" and "Pantolambda", each of these typifying a family. The full typical series of 44 teeth was developed in each, but whereas in the Periptychidae, the upper molars were bunodont and tritubercular, in the Pantolambdidae, they had assumed a selenodont structure. Creodont characters were displayed in the skeleton.
Current taxonomy of animals once classified in Amblypoda.
Few authorities recognize Amblypoda in modern classifications. The following mammals were once considered part of this group:

</doc>
<doc id="3251" url="https://en.wikipedia.org/wiki?curid=3251" title="Amblygonite">
Amblygonite

Amblygonite is a fluorophosphate mineral, (Li,Na)AlPO(F,OH), composed of lithium, sodium, aluminium, phosphate, fluoride and hydroxide. The mineral occurs in pegmatite deposits and is easily mistaken for albite and other feldspars. Its density, cleavage and flame test for lithium are diagnostic. Amblygonite forms a series with "montebrasite", the low fluorine endmember. Geologic occurrence is in granite pegmatites, high-temperature tin veins, and greisens. Amblygonite occurs with spodumene, apatite, lepidolite, tourmaline, and other lithium-bearing minerals in pegmatite veins. It contains about 10% lithium, and has been utilized as a source of lithium. The chief commercial sources have historically been the deposits of California and France.
History.
The mineral was first discovered in Saxony by August Breithaupt in 1817, and named by him from the Greek "amblus", blunt, and "gonia", angle, because of the obtuse angle between the cleavages. Later it was found at Montebras, Creuse, France, and at Hebron in Maine; and because of slight differences in optical character and chemical composition the names montebrasite and hebronite have been applied to the mineral from these localities. It has been discovered in considerable quantity at Pala in San Diego county, California; Caceres, Spain; and the Black Hills of South Dakota. The largest documented single crystal of amblygonite measured 7.62×2.44×1.83 m and weighed ~102 tons.
Gemology.
Transparent amblygonite has been faceted and used as a gemstone. As a gemstone set into jewelry it is vulnerable to breakage and abrasion from general wear, as its hardness and toughness are poor. The main sources for gem material are Brazil and the United States. Australia, France, Germany, Namibia, Norway, and Spain have also produced gem quality amblygonite.

</doc>
<doc id="3252" url="https://en.wikipedia.org/wiki?curid=3252" title="Amygdalin">
Amygdalin

Amygdalin (from Ancient Greek: "" "almond"), is a poisonous cyanogenic glycoside found in many plants, but most notably in the seeds (kernels) of apricot (known as bitter almonds ), peach, and plum.
Since the early 1950s, both amygdalin and a modified form named laetrile have been promoted as alternative cancer treatments, often using the misnomer Vitamin B . But studies have found them to be clinically ineffective in the treatment of cancer, as well as potentially toxic or lethal when taken by mouth, due to cyanide poisoning. Neither amygdalin nor laetrile are vitamins.
The promotion of laetrile to treat cancer has been described in the medical literature as a canonical example of quackery, and as "the slickest, most sophisticated, and certainly the most remunerative cancer quack promotion in medical history."
Chemistry.
Amygdalin is a cyanogenic glycoside derived from the aromatic amino acid phenylalanine. Amygdalin and prunasin are very common among plants of the Rosaceae, particularly the Prunus genus, Poaceae (grasses), Fabaceae (legumes), and in other food plants, including linseed and manioc. Sambunigrin, obtained from leaves of the elder tree (Sambucus nigra), is isomeric to prunasin.
Amygdalin is contained in fruit kernels, such as apricot (8%), peach (6%), bitter almond (5%), and plum (2.5%). The stones are taken out of the fruit and cracked to obtain the kernels, which are dried in the sun or in ovens. The kernels are boiled in ethanol; on evaporation of the solution and the addition of diethyl ether, amygdalin is precipitated as white minute crystals. Natural amygdalin has the R configuration at the chiral phenyl center. Under mild basic conditions, this stereogenic center isomerizes; the S enantiomer is called neoamygdalin.
Amygdalin is hydrolyzed by intestinal β-glucosidase, emulsin, and amygdalase to gentiobiose and L-mandelonitrile. Gentiobiose is further hydrolyzed to glucose, whereas mandelonitrile is hydrolyzed to benzaldehyde and hydrogen cyanide. Hydrogen cyanide in sufficient quantities (allowable daily intake: ~0.6 mg) causes cyanide poisoning (fatal oral dose: 0.6-1.5 mg/kg). Apricot pits contain 89-2,170 mg/kg hydrogen cyanide (wet weight).
In small quantities these glycosides do exhibit expectorant, sedative and digestive properties. Wild cherry bark (Prunus serotina) is an excellent cough remedy and tonic, as well as a flavouring agent used in cough syrups. It is of benefit as a tea for bronchitis. The main antitussive principle is prunasin. In Chinese medicine, apricot seeds (杏仁, xìngrén) are used against cough and constipation (4.5-9 g).
Laetrile.
Laetrile (patented 1961) is a simpler semisynthetic version of amygdalin. It is synthesized from amygdalin by hydrolysis. The usual commercial source is from apricot kernels (Prunus armeniaca). A 500 mg laetrile tablet may contain between 5–51 mg of hydrogen cyanide per gram.
Like amygdalin, laetrile is hydrolyzed in the duodenum (alkaline) and in the intestine (enzymatically) to D-glucuronic acid and L-mandelonitrile; the latter hydrolyzes to benzaldehyde and hydrogen cyanide, which causes cyanide poisoning. Intravenous laetrile does not result in cyanide exposure.
Claims for laetrile were based on three different theories:
Ernst T. Krebs falsely branded laetrile as a vitamin in order to have it classified as a nutritional supplement rather than as a pharmaceutical. He would also capitalise on the public fad for vitamins at that time.
History.
Amygdalin was first isolated in 1830 from bitter almond seeds (Prunus dulcis) by Pierre-Jean Robiquet and Antoine Boutron-Charlard. Liebig and Wöhler found three hydrolysis products of amygdalin: sugar, benzaldehyde, and prussic acid (hydrogen cyanide). Later research showed that sulfuric acid hydrolyzes it into D-glucose, benzaldehyde, and prussic acid; while hydrochloric acid gives mandelic acid, D-glucose, and ammonia.
In 1845 amygdalin was used as a cancer treatment in Russia, and in the 1920s in the United States, but it was considered too poisonous. In the 1950s, a purportedly non-toxic, synthetic form was patented for use as a meat preservative, and later marketed as laetrile for cancer treatment.
The U.S. Food and Drug Administration prohibited the interstate shipment of amygdalin and laetrile in 1977. Thereafter, 27 U.S. states legalized the use of amygdalin within those states.
In 1972, Memorial Sloan-Kettering Cancer Center (MSKCC) board member Benno C. Schmidt, Sr. convinced the hospital to test laetrile. Kanematsu Sugiura, the scientist who performed the tests, found that laetrile inhibited secondary tumors in mice, though it did not destroy the primary tumors. He repeated the experiment several times with the same results. However, three other researchers were unable to confirm Sugiura's results. Sugiura's results were leaked to laetrile advocates, resulting in significant public attention. In a controlled, blinded follow-up experiment, laetrile showed no more activity than placebo.
Subsequently, laetrile was tested on 14 tumor systems without evidence of effectiveness. MSKCC concluded that "laetrile showed no beneficial effects." Mistakes in the MSKCC press release were highlighted by a group of laetrile proponents led by Ralph Moss, former public affairs official of MSKCC who was fired following his appearance at a press conference accusing the hospital of covering up the benefits of laetrile. These mistakes were considered scientifically inconsequential, but Nicholas Wade in "Science" stated that "even the appearance of a departure from strict objectivity is unfortunate." The results from these studies were published all together.
A 2011 systematic review from the Cochrane Collaboration found: 
The authors also recommended, on ethical grounds, that no further clinical research into laetrile or amygdalin be conducted.
Given the lack of evidence, laetrile has not been approved by the U.S. Food and Drug Administration.
The U.S. National Institutes of Health evaluated the evidence separately and concluded that clinical trials of amygdalin showed little or no effect against cancer. For example, a 1982 trial by the Mayo Clinic of 175 patients found that tumor size had increased in all but one patient. The authors reported that "the hazards of amygdalin therapy were evidenced in several patients by symptoms of cyanide toxicity or by blood cyanide levels approaching the lethal range."
The study concluded "Patients exposed to this agent should be instructed about the danger of cyanide poisoning, and their blood cyanide levels should be carefully monitored. Amygdalin (Laetrile) is a toxic drug that is not effective as a cancer treatment".
Additionally, "No controlled clinical trials (trials that compare groups of patients who receive the new treatment to groups who do not) of laetrile have been reported." 
The side effects of laetrile treatment are the symptoms of cyanide poisoning. These symptoms include: nausea and vomiting, headache, dizziness, cherry red skin color, liver damage, abnormally low blood pressure, droopy upper eyelid, trouble walking due to damaged nerves, fever, mental confusion, coma, and death.
Advocacy and legality.
Advocates for laetrile assert that there is a conspiracy between the U.S. Food and Drug Administration, the pharmaceutical industry and the medical community, including the American Medical Association and the American Cancer Society, to exploit the American people, and especially cancer patients. Advocates of the use of laetrile have also changed the rationale for its use, first as a treatment of cancer, then as a vitamin, then as part of a "holistic" nutritional regimen, or as treatment for cancer pain, among others, none of which have any significant evidence supporting its use. Despite the lack of evidence for its use, laetrile developed a significant following due to its wide promotion as a "pain-free" treatment of cancer as an alternative to surgery and chemotherapy that have significant side effects. The use of laetrile led to a number of deaths.
The FDA and AMA crackdown, begun in the 1970s, effectively escalated prices on the black market, played into the conspiracy narrative and enabled unscrupulous profiteers foster multimillion-dollar smuggling empires.
Some North American cancer patients have traveled to Mexico for treatment with the substance, for example at the Oasis of Hope Hospital in Tijuana. The actor Steve McQueen died in Mexico following surgery to remove a stomach tumor having previously undergone extended treatment for pleural mesothelioma (a cancer associated with asbestos exposure) under the care of William D. Kelley, a de-licensed dentist and orthodontist who claimed to have devised a cancer treatment involving pancreatic enzymes, 50 daily vitamins and minerals, frequent body shampoos, enemas, and a specific diet as well as laetrile.
Laetrile advocates in the United States include Dean Burk, a former chief chemist of the National Cancer Institute cytochemistry laboratory, and national arm wrestling champion Jason Vale, who claimed that his kidney and pancreatic cancers were cured by eating apricot seeds. Vale was convicted in 2004 for, among other things, fraudulently marketing laetrile as a cancer cure. The court also found that Vale had made at least $500,000 from his fraudulent sales of laetrile.
The US Food and Drug Administration continues to seek jail sentences for vendors marketing laetrile for cancer treatment, calling it a "highly toxic product that has not shown any effect on treating cancer."

</doc>
<doc id="3253" url="https://en.wikipedia.org/wiki?curid=3253" title="Running amok">
Running amok

Running amok, sometimes referred to as simply amok, also spelled amuk, from the Malay language, is "an episode of sudden mass assault against people or objects usually by a single individual following a period of brooding that has traditionally been regarded as occurring especially in Malay culture but is now increasingly viewed as psychopathological behavior occurring worldwide in numerous countries and cultures". The syndrome of "Amok" is found in the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV TR). The phrase is often used in a less serious manner when describing something that is wildly out of control or causing a frenzy (e.g., a dog tearing up the living room furniture might be termed as "running amok.")
Malay/Indonesian origin.
Amok originated from the Malay/Indonesian word "mengamuk", which when roughly defined means “to make a furious and desperate charge”. According to Malay/Indonesian culture, amok was rooted in a deep spiritual belief. They believed that amok was caused by the "hantu belian", which was an evil tiger spirit that entered one’s body and caused the heinous act. As a result of the belief, those in Indonesian culture tolerated amok and dealt with the after-effects with no ill will towards the assailant.
Although commonly used in a colloquial and less-violent sense, the phrase is particularly associated with a specific sociopathic culture-bound syndrome in Malaysian culture. In a typical case of "running amok", an individual (often male), having shown no previous sign of anger or any inclination to violence, will acquire a weapon (traditionally a sword or dagger, but presently any of a variety of weapons) and in a sudden frenzy, will attempt to kill or seriously injure anyone he encounters and himself. Amok typically takes place in a well populated or crowded area. Amok episodes of this kind normally end with the attacker being killed by bystanders or committing suicide, eliciting theories that amok may be a form of intentional suicide in cultures where suicide is heavily stigmatized. Those who do not commit suicide and are not killed typically lose consciousness, and upon regaining consciousness, claim amnesia.
An early Western description of the practice appears in the journals of Captain James Cook, a British explorer, who encountered amok firsthand in 1770 during a voyage around the world. Cook writes of individuals behaving in a reckless, violent manner, without cause and "indiscriminately killing and maiming villagers and animals in a frenzied attack." 
A widely accepted explanation links amok with male honor (amok by women is virtually unknown). 
Running amok would thus be both a way of escaping the world (since perpetrators were normally killed) and re-establishing one's reputation as a man to be feared and respected.
Some observers have related this explanation to Islam's ban on suicide, which, it is suggested, drove Malay/Indonesian men to create circumstances in which others would kill them.
Contemporary syndrome.
"Running amok" is used to refer to the behavior of someone who, in the grip of strong emotion, obtains a weapon and begins attacking people indiscriminately, often with multiple fatalities. An episode of amok may be triggered by a period of depression or highly aggressive behavior. The slang terms "going postal" or "going ballistic" are similar in scope.
Police describe such an event as a killing spree. If the individual is seeking death an alternate method is often "suicide by cop".
Amok is often described as a culture-bound (or culture-specific) syndrome, which is a psychological condition whose manifestation is strongly shaped by cultural factors. Other reported culture-bound syndromes are latah and koro. Amok is also sometimes considered one of the subcategories of dissociative disorders (cross-cultural variant).
Officially classified as a psychiatric condition.
In 1849, amok was officially classified as a psychiatric condition based on numerous reports and case studies that showed the majority of individuals who committed amok were, in some sense, mentally ill. However, DSM-IV does now break amok down into two official categories; beramok and amok. Beramok is considered to be the more common of the two and is associated with the depression and sadness resulting from a loss and the subsequent brooding process. Loss includes, but is not limited to, the death of a spouse or loved one, divorce, loss of a job, money, power, etc. Beramok is associated with mental issues of severe depression or other mood disorders. Amok, the rarer form, is believed to stem from rage, insult, or a vendetta against a person, society, or object for a wide variety of reasons. Amok has been more closely associated with psychosis, personality disorders, bipolar disorder, and delusions.
Historical and cross-cultural comparisons.
Early travelers in Asia sometimes describe a kind of military amok, in which soldiers apparently facing inevitable defeat suddenly burst into a frenzy of violence which so startled their enemies that it either delivered victory or at least ensured what the soldier in that culture considered an honourable death. This form of amok appears to resemble the Germanic "Berserker", the "cafard" or "cathard" (Polynesia), "mal de pelea" (Puerto Rico), "iich'aa" (Navaho), Laos, and Papua New Guinea.
In contemporary Indonesia, the term "amok" ("amuk") generally refers not to individual violence, but to frenzied violence by mobs. Indonesians now commonly use the term 'gelap mata' (literally 'darkened eyes') to refer to individual amok. Laurens van der Post experienced the phenomenon in the East Indies and wrote in 1955:
In the Philippines, "amok" also means unreasoning murderous rage by an individual. In 1876, the Spanish governor-general of the Philippines José Malcampo coined the term "juramentado" for the behavior (from "juramentar" - "to take an oath"), surviving into modern Filipino languages as "huramentado". It has historically been linked with the Moro people of Mindanao, particularly in the island of Jolo in connection with societal and cultural pressures.
Norse Berserkers and the Zulu battle trance are two other examples of the tendency of certain groups to work themselves up into a killing frenzy. The 1911 "Webster Encyclopedia" comments:

</doc>
<doc id="3255" url="https://en.wikipedia.org/wiki?curid=3255" title="Apostles' Creed">
Apostles' Creed

The Apostles' Creed (Latin: "Symbolum Apostolorum" or "Symbolum Apostolicum"), sometimes titled Symbol of the Apostles, is an early statement of Christian belief—a creed or "symbol". It is widely used by a number of Christian denominations for both liturgical and catechetical purposes, most visibly by liturgical Churches of Western tradition, including the Roman Catholic Church, Lutheranism and Anglicanism. It is also used by Presbyterians, Methodists and Congregationalists.
The Apostles' Creed was based on Christian theological understanding of the Canonical gospels, the letters of the New Testament and to a lesser extent the Old Testament. Its basis appears to be the old Roman Creed known also as the Old Roman Symbol. Because of the early origin of its original form, it does not address some Christological issues defined in the Nicene and other Christian Creeds. It thus says nothing explicitly about the divinity of either Jesus or of the Holy Spirit. This makes it acceptable to many Arians and Unitarians. Nor does it address many other theological questions that became objects of dispute centuries later.
The first mention of the expression "Apostles’ Creed" occurs in a letter of 390 from a synod in Milan and may have been associated with the belief, widely accepted in the 4th century, that, under the inspiration of the Holy Spirit, each of the Twelve Apostles contributed an article of a creed.
Origins.
The title "Symbolum Apostolicum" (Symbol or Creed of the Apostles) appears for the first time in a letter, probably written by Ambrose, from a Council in Milan to Pope Siricius in about 390: "Let them give credit to the Creed of the Apostles, which the Roman Church has always kept and preserved undefiled". But what existed at that time was not what is now known as the Apostles' Creed but a shorter statement of belief that, for instance, did not include the phrase "maker of heaven and earth", a phrase that may have been inserted only in the 7th century.
The account of the origin of this creed, the forerunner and principal source of the Apostles' Creed, as having been jointly created by the Apostles under the inspiration of the Holy Spirit, with each of the twelve contributing one of the articles, was already current at that time.
The earlier text evolved from simpler texts based on , part of the Great Commission, and it has been argued that it was already in written form by the late 2nd century (c. 180).
While the individual statements of belief that are included in the Apostles' Creed – even those not found in the Old Roman Symbol – are found in various writings by Irenaeus, Tertullian, Novatian, Marcellus, Rufinus, Ambrose, Augustine, Nicetas, and Eusebius Gallus, the earliest appearance of what we know as the Apostles' Creed was in the "De singulis libris canonicis scarapsus" ("Excerpt from Individual Canonical Books") of St. Pirminius (Migne, "Patrologia Latina" 89, 1029 ff.), written between 710 and 714. Bettenson and Maunder state that it is first from "Dicta Abbatis Pirminii de singulis libris canonicis scarapsus" ("idem quod excarpsus", excerpt), c. 750. This longer Creed seems to have arisen in what is now France and Spain. Charlemagne imposed it throughout his dominions, and it was finally accepted in Rome, where the Old Roman Symbol or similar formulas had survived for centuries. It has been argued nonetheless that it dates from the second half of the 5th century, though no earlier.
Some have suggested that the Apostles' Creed was spliced together with phrases from the New Testament. For instance, the phrase "descendit ad inferos" ("he descended into hell") echoes , "κατέβη εἰς τὰ κατώτερα μέρη τῆς γῆς" ("he descended into the lower, earthly regions"). It is of interest that this phrase first appeared in one of the two versions of Rufinus in A.D. 390 and then did not appear again in any version of the creed until A.D. 650.
This phrase and that on the communion of saints are articles found in the Apostles' Creed, but not in the Old Roman Symbol nor in the Nicene Creed.
Musical settings.
Musical settings of the Symbolum Apostolorum as a motet are rare. The French composer Le Brung published one Latin setting in 1540, the Spanish composer Fernando de las Infantas published two in 1578.
More recently, in 1979 John Michael Talbot, a Third Order Franciscan, composed and recorded "Creed" on his album, "The Lord’s Supper". In 1986 Graham Kendrick published the popular "We believe in God the Father", closely based on the Apostles' Creed. Rich Mullins and Beaker also composed a musical setting titled "Creed", released on Mullins‘ 1993 album "A Liturgy, a Legacy, & a Ragamuffin Band". The song "Creed" on Petra’s 1990 album "Beyond Belief" is loosely based on the Apostles' Creed.
In 1991, GIA published a hymn text directly based on the Apostles’ Creed, called "I Believe in God Almighty." It has been sung to hymn tunes from Wales, the Netherlands, and Ireland.
In 2014 Hillsong released a version of the Apostles' Creed under the title "This I Believe (The Creed)" on their album No Other Name.
Text in Latin.
<poem>Credo in Deum Patrem omnipotentem, Creatorem caeli et terrae,
et in Iesum Christum, Filium Eius unicum, Dominum nostrum,
qui conceptus est de Spiritu Sancto, natus ex Maria Virgine,
passus sub Pontio Pilato, crucifixus, mortuus, et sepultus,
descendit ad inferos, tertia die resurrexit a mortuis,
ascendit ad caelos, sedet ad dexteram Patris omnipotentis,
inde venturus est iudicare vivos et mortuos.
Credo in Spiritum Sanctum,
sanctam Ecclesiam catholicam, sanctorum communionem,
remissionem peccatorum,
carnis resurrectionem,
vitam aeternam.
Amen.</poem>
Text in Greek.
Πιστεύω εἰς θεòν πατέρα παντοκράτορα, ποιητὴν οὐρανοῦ καὶ γῆς.
Καὶ εἰς Ἰησοῦν Χριστòν, υἱὸν αὐτοῦ τòν μονογενῆ, τòν κύριον ἡμῶν,
τòν συλληφθέντα ἐκ πνεύματος ἁγίου, γεννηθέντα ἐκ Μαρίας τῆς παρθένου, 
παθόντα ὑπὸ Ποντίου Πιλάτου, σταυρωθέντα, θανόντα, καὶ ταφέντα, 
κατελθόντα εἰς τὰ κατώτατα, τῇ τρίτῃ ἡμέρᾳ ἀναστάντα ἀπò τῶν νεκρῶν, 
ἀνελθόντα εἰς τοὺς οὐρανούς, καθεζόμενον ἐν δεξιᾷ θεοῦ πατρὸς παντοδυνάμου, 
ἐκεῖθεν ἐρχόμενον κρῖναι ζῶντας καὶ νεκρούς. 
Πιστεύω εἰς τò πνεῦμα τò ἅγιον, ἁγίαν καθολικὴν ἐκκλησίαν, ἁγίων κοινωνίαν, 
ἄφεσιν ἁμαρτιῶν, σαρκὸς ἀνάστασιν, ζωὴν αἰώνιον. 
Αμήν.
English translations.
Ecumenical version.
The English Language Liturgical Consultation (ELLC) is an international ecumenical group whose primary purpose is to provide ecumenically accepted texts for those who use English in their liturgy. In 1988 it produced a translation of the Apostles' Creed, distinguished among other things by its avoidance of the word "his" in relation to God. The text is as follows:
<poem>I believe in God, the Father almighty,
I believe in Jesus Christ, God’s only Son, our Lord,
I believe in the Holy Spirit,
Roman Catholic Church.
The "Catechism of the Catholic Church" gives the following English translation of the Apostles' Creed. In its discussion of the Creed, the Catechism maintains the traditional division into twelve articles, the numbering of which is here added to the text.
The English text used in the Mass of the Roman Rite since 2011 is:
<poem>I believe in God,
the Father almighty,
Creator of heaven and earth,
and in Jesus Christ, his only Son, our Lord,
who was conceived by the Holy Spirit,
born of the Virgin Mary,
suffered under Pontius Pilate,
was crucified, died and was buried;
he descended into hell;
on the third day he rose again from the dead;
he ascended into heaven,
and is seated at the right hand of God the Father almighty;
from there he will come to judge the living and the dead.
I believe in the Holy Spirit,
the holy catholic Church,
the communion of saints,
the forgiveness of sins,
the resurrection of the body,
and life everlasting. Amen.</poem>
Church of England.
In the Church of England there are currently two authorized forms of the creed: that of the "Book of Common Prayer" (1662) and that of "Common Worship" (2000).
Book of Common Prayer, 1662
<poem>I believe in God the Father Almighty,
Maker of heaven and earth:
And in Jesus Christ his only Son our Lord,
Who was conceived by the Holy Ghost,
Born of the Virgin Mary,
Suffered under Pontius Pilate,
Was crucified, dead, and buried:
He descended into hell;
The third day he rose again from the dead;
He ascended into heaven,
And sitteth on the right hand of God the Father Almighty;
From thence he shall come to judge the quick and the dead.
I believe in the Holy Ghost;
The holy Catholick Church;
The Communion of Saints;
The Forgiveness of sins;
The Resurrection of the body,
And the Life everlasting.
Amen.</poem>
Common Worship
Lutheran Church.
"Evangelical Lutheran Worship".
The publication "Evangelical Lutheran Worship" gives the ELLC ecumenical version, footnoting the phrase "he descended to the dead" to indicate the alternative reading: "or ‘he descended into hell,’ another translation of this text in widespread use".
"Lutheran Service Book".
The "Lutheran Service Book" has the following text:
<poem>I believe in God, the Father Almighty,
And in Jesus Christ, His only Son, our Lord,
I believe in the Holy Spirit,
The creed is footnoted in the LSB for the word "Christian": ""Christian:" the ancient text reads "catholic," meaning the whole Church as it confesses the wholeness of Christian doctrine."
Church of Denmark.
The Church of Denmark still uses the phrase "We renounce the devil and all his doings and all his beings" as the beginning of this creed, before the line "We believe in God etc." This is mostly due to the influence of Grundtvig. See .
United Methodist Church.
The United Methodists commonly incorporate the Apostles' Creed into their worship services. The version which is most often used is located at #881 in the "United Methodist Hymnal", one of their most popular hymnals and one with a heritage to John Wesley, founder of Methodism. It is notable for omitting the line "he descended into hell", but is otherwise very similar to the Book of Common Prayer version. The 1989 Hymnal has both the traditional version and the 1988 ecumenical version, which includes "he descended to the dead."
The "United Methodist Hymnal" also contains (at #882) what it terms the "Ecumenical Version" of this creed which is the ecumenically accepted modern translation of the International Committee on English Texts (1975) as amended by the subsequent successor body, the English Language Liturgical Consultation (1987). This form of the Apostles' Creed can be found incorporated into the Eucharistic and Baptismal Liturgies in the Hymnal and in "The United Methodist Book of Worship", and hence it is growing in popularity and use. The word "catholic" is intentionally left lowercase in the sense that the word catholic applies to the universal and ecumenical Christian church.
Liturgical use in Western Christianity.
The liturgical communities in western Christianity that derive their rituals from the Roman Missal, including those particular communities which use the Roman Missal itself (Roman Catholics), the "Book of Common Prayer" (Anglicans / Episcopalians), "Evangelical Lutheran Worship" (ELCA Lutherans), "Lutheran Service Book" (Missouri Synod Lutherans), and "The United Methodist Book of Worship" (The United Methodist Church) use the Apostles' Creed and interrogative forms of it in their rites of Baptism, which they consider to be the first sacrament of initiation into the Church.
Roman Catholic Church.
Rite of Baptism.
An interrogative form of the Apostles' Creed is used in the Rite of Baptism (for both children and adults). The minister of baptism asks the following questions (ICEL, 1974):
To each question, the catechumen, or, in the case of an infant, the parents and sponsor(s) (godparent(s)) in his or her place, answers "I do." Then the celebrant says:
And all respond: Amen.
Profession of faith at Mass.
Since the 2002 edition, the Apostles' Creed is included in the Roman Missal with the indication, "Instead of the Niceno-Constantinopolitan Creed, especially during Lent and Easter time, the baptismal Symbol of the Roman Church, known as the Apostles’ Creed, may be used." Previously the Nicene Creed was the only profession of faith that the Missal gave for use at Mass, except in Masses for children; but in some countries use of the Apostles’ Creed was already permitted.
Anglican Communion.
The Apostles' Creed is used in the non-Eucharistic services of Matins and Evening Prayer (Evensong). It is invoked after the recitation or singing of the Canticles, and it is the only part of the services in which the congregation traditionally turns to face the altar, if they are seated transversely in the quire.
Episcopal Church (United States).
The Episcopal Church uses the Apostles' Creed as a Baptismal Covenant for those who are to receive the Rite of Baptism. Regardless of age, candidates are to be sponsored by parents and/or godparents. Youths able to understand the significance of the Rite may go through the ritual speaking for themselves. Younger children and infants rely on their sponsors to act upon their behalf.
1. The celebrant calls for the candidates for Baptism to be presented.
2. The catechumen or sponsors state their request for Baptism.
3a. If the catechumen is of age, the celebrant will ask him or her if he or she desires Baptism, to which the catechumen will respond: "I do."
3b. If the candidate relies on sponsors, the celebrant asks them if they will raise the child in "the Christian faith and life" (ECUSA BCP), and will raise the child through "prayers and witness to grow into the full stature of Christ" to which the parents will state to each, "I will, with God's help."
4. A series of questions is then asked, to which the reply is always "I renounce them":
5. The second half of the query is asked, to which the reply is always "I do":
6. The Apostles' Creed is then recited by candidates, sponsors and congregation, each section of the Creed being an answer to the celebrant’s question, 'Do you believe in God the Father (God the Son, God the Holy Spirit)?'
Lutheran Church.
Lutherans, like Roman Catholics, use the Apostles' Creed during the Sacrament of Baptism:
Following each question, the candidate answers by saying "Yes, I believe". If the candidate is a child, the godparents are to answer the questions.
Methodism.
Methodists use the Apostles' Creed as part of their baptismal rites in the form of an interrogatory addressed to the candidate(s) for baptism and the whole congregation as a way of professing the faith within the context of the Church’s sacramental act. For infants, it is the professing of the faith by the parents, sponsors, and congregation on behalf of the candidate(s); for confirmands, it is the professing of the faith before and among the congregation. For the congregation, it is a reaffirmation of their professed faith.

</doc>
<doc id="3259" url="https://en.wikipedia.org/wiki?curid=3259" title="Amicable numbers">
Amicable numbers

Amicable numbers are two different numbers so related that the sum of the proper divisors of each is equal to the other number. (A proper divisor of a number is a positive factor of that number other than the number itself. For example, the proper divisors of 6 are 1, 2, and 3.) A pair of amicable numbers constitutes an aliquot sequence of period 2. A related concept is that of a perfect number, which is a number that equals the sum of "its own" proper divisors, in other words a number which forms an aliquot sequence of period 1. Numbers that are members of an aliquot sequence with period greater than 2 are known as sociable numbers.
The smallest pair of amicable numbers is (220, 284). They are amicable because the proper divisors of 220 are 1, 2, 4, 5, 10, 11, 20, 22, 44, 55 and 110, of which the sum is 284; and the proper divisors of 284 are 1, 2, 4, 71 and 142, of which the sum is 220.
The first ten amicable pairs are: (220, 284), (1184, 1210), (2620, 2924), (5020, 5564), (6232, 6368), (10744, 10856), (12285, 14595), (17296, 18416), (63020, 76084), and (66928, 66992).. (Also see and )
History.
Amicable numbers were known to the Pythagoreans, who credited them with many mystical properties. A general formula by which some of these numbers could be derived was invented circa 850 by the Iraqi mathematician Thābit ibn Qurra (826–901). Other Arab mathematicians who studied amicable numbers are al-Majriti (died 1007), al-Baghdadi (980–1037), and al-Fārisī (1260–1320). The Iranian mathematician Muhammad Baqir Yazdi (16th century) discovered the pair (9363584, 9437056), though this has often been attributed to Descartes. Much of the work of Eastern mathematicians in this area has been forgotten.
Thābit ibn Qurra's formula was rediscovered by Fermat (1601–1665) and Descartes (1596–1650), to whom it is sometimes ascribed, and extended by Euler (1707–1783). It was extended further by Borho in 1972. Fermat and Descartes also rediscovered pairs of amicable numbers known to Arab mathematicians. Euler also discovered dozens of new pairs. The second smallest pair, (1184, 1210), was discovered in 1866 by a then teenage B. Nicolò I. Paganini (no to be confused with the composer and violinist), having been overlooked by earlier mathematicians.
By 1946 there were 390 known pairs, but the advent of computers has allowed the discovery of many thousands since then. Exhaustive searches have been carried out to find all pairs less than a given bound, this bound being extended from 10 in 1970, to 10 in 1986, 10 in 1993, and to 10 in 2015.
, there are 40,871,144 known amicable pairs.
Rules for generation.
While these rules do generate some pairs of amicable numbers, many other pairs are known, so these rules are by no means comprehensive.
Thābit ibn Qurra theorem.
The Thābit ibn Qurra theorem is a method for discovering amicable numbers invented in the ninth century by the Arab mathematician Thābit ibn Qurra.
It states that if
where "n" > 1 is an integer and "p", "q", and "r" are prime numbers, then 2"×p×q" and 2"×r" are a pair of amicable numbers. This formula gives the pairs (220, 284) for "n"=2, (17296, 18416) for "n"=4, and (9363584, 9437056) for "n"=7, but no other such pairs are known. Numbers of the form 3 × 2 − 1 are known as Thabit numbers. In order for Ibn Qurra's formula to produce an amicable pair, two consecutive Thabit numbers must be prime; this severely restricts the possible values of "n".
To establish the theorem, Thâbit ibn Qurra proved nine lemmas divided into two groups. The first three lemmas deal with the determination of the aliquot parts of a natural integer. The second group of lemmas deals more specifically with the formation of perfect, abundant and deficient numbers.
Euler's rule.
"Euler's rule" is a generalization of the Thâbit ibn Qurra theorem. It states that if
where "n" > "m" > 0 are integers and "p", "q", and "r" are prime numbers, then 2×p×q and 2×r are a pair of amicable numbers. Thābit ibn Qurra's theorem corresponds to the case m=n-1. Euler's rule creates additional amicable pairs for (m,n)=(1,8), (29,40) with no others being known. William Dunham in a video claims that Euler (1750) found 58 such pairs to make all the by then existing pairs 61.
Regular pairs.
Let ("m", "n") be a pair of amicable numbers with "m"<"n", and write "m=gM" and "n=gN" where "g" is the greatest common divisor of "m" and "n". If "M" and "N" are both coprime to "g" and square free then the pair ("m", "n") is said to be regular, otherwise it is called irregular or exotic. If ("m", "n") is regular and "M" and "N" have "i" and "j" prime factors respectively, then ("m", "n") is said to be of type ("i", "j").
For example, with ("m", "n") = (220, 284), the greatest common divisor is 4 and so M = 55 and N = 71. Therefore (220, 284) is regular of type (2, 1).
Other results.
In every known case, the numbers of a pair are either both even or both odd. It is not known whether an even-odd pair of amicable numbers exists, but if it does, the even number must either be a square number or twice one, and the odd number must be a square number. However, amicable numbers where the two members have different smallest prime factors do exist: there are 7 such pairs known. Also, every known pair shares at least one common factor, higher than 1. It is not known whether a pair of coprime amicable numbers exists, though if any does, the product of the two must be greater than 10. Also, a pair of coprime amicable numbers cannot be generated by Thabit's formula (above), nor by any similar formula.
In 1955, Paul Erdős showed that the density of amicable numbers, relative to the positive integers, was 0.
Generalizations.
Amicable tuples.
Amicable numbers formula_1 satisfy formula_2 and formula_3 which can be written together as formula_4. This can be generalized to larger tuples, say formula_5, where we require
For example (1980, 2016, 2556) is an amicable triple , and (3270960, 3361680, 3461040, 3834000) is an amicable quadruple .
Amicable multisets are defined analogously and generalizes this a bit further .
Sociable numbers.
Sociable numbers are a cyclic lists of numbers such that each number is the sum of the proper divisors of the preceding number. For example formula_7 are sociable numbers of order 4.
Searching for sociable numbers.
The aliquot sequence can be represented as a directed graph, formula_8, for a given integer formula_9, where formula_10 denotes the
sum of the proper divisors of formula_11.
Cycles in formula_8 represent sociable numbers within the interval formula_13. Two special cases are loops that represent perfect numbers and cycles of length two that represent amicable pairs.

</doc>
<doc id="3262" url="https://en.wikipedia.org/wiki?curid=3262" title="Agar">
Agar

Agar (pronounced , , ") or agar-agar (, , ") is a jelly-like substance, obtained from algae. It was discovered in the late 1650s or early 1660s by Mino Tarōzaemon (美濃 太郎左衛門) in Japan, where it is called "kanten" (寒天).
Agar is derived from the polysaccharide agarose, which forms the supporting structure in the cell walls of certain species of algae, and which is released on boiling. These algae are known as agarophytes and belong to the Rhodophyta (red algae) phylum. Agar is actually the resulting mixture of two components: the linear polysaccharide agarose, and a heterogeneous mixture of smaller molecules called agaropectin.
Throughout history into modern times, agar has been chiefly used as an ingredient in desserts throughout Asia and also as a solid substrate to contain culture media for microbiological work. Agar (agar-agar) can be used as a laxative, an appetite suppressant, a vegetarian substitute for gelatin, a thickener for soups, in fruit preserves, ice cream, and other desserts, as a clarifying agent in brewing, and for sizing paper and fabrics.
The gelling agent in agar is an unbranched polysaccharide obtained from the cell walls of some species of red algae, primarily from the genera "Gelidium" and "Gracilaria". For commercial purposes, it is derived primarily from "Gelidium amansii". In chemical terms, agar is a polymer made up of subunits of the sugar galactose.
Background.
Agar was discovered around 1658 in Japan (where it is called "kanten", coined from the phrase "kan-zarashi tokoroten" or “cold-exposed agar”) by Mino Tarōzaemon, an innkeeper who was said to have discarded some surplus seaweed soup and noticed that it gelled later after a winter night's freezing.
Agar was first used in microbiology in 1882 by the German microbiologist Walther Hesse, an assistant working in Robert Koch's laboratory, on the suggestion of his wife Angelina Fannie Eilshemius Hesse. He discovered that it was more useful as a solidifying agent than gelatin, due to its better solidifying temperature.
Agar was first subjected to chemical analysis in 1859 by the French chemist Anselme Payen, who had obtained agar from the marine algae "Gelidium corneum".
Agar consists of a mixture of agarose and agaropectin. Agarose, the predominant component of agar, is a linear polymer, made up of the repeating monomeric unit of agarobiose. Agarobiose is a disaccharide made up of D-galactose and 3,6-anhydro-L-galactopyranose. Agaropectin is a heterogeneous mixture of smaller molecules that occur in lesser amounts, and is made up of alternating units of D-galactose and L-galactose heavily modified with acidic side-groups, such as sulfate and pyruvate.
Agar exhibits hysteresis, melting at 85 °C (358 K, 185 °F) and solidifying from 32–40 °C (305–313 K, 90–104 °F). This property lends a suitable balance between easy melting and good gel stability at relatively high temperatures. Since many scientific applications require incubation at temperatures close to human body temperature (37 °C), agar is more appropriate than other solidifying agents that melt at this temperature, such as gelatin.
The word "agar" comes from agar-agar, the Malay/Indonesian name for red algae ("Gigartina", "Gracilaria") from which the jelly is produced., and is also an ingredient in traditional Malay and Japanese desserts. It is also known as Kanten, Japanese isinglass, Ceylon moss or Jaffna moss. "Gracilaria lichenoides" is specifically referred to as agal-agal or Ceylon agar.
Uses.
Microbiology.
An agar plate or Petri dish is used to provide a growth medium using a mix of agar and other nutrients in which microorganisms, including bacteria and fungi, can be cultured and observed under the microscope. Agar is indigestible for many organisms so that microbial growth does not affect the gel used and it remains stable. Agar is typically sold commercially as a powder that can be mixed with water and prepared similarly to gelatin before use as a growth medium. Other ingredients are added to the agar to meet the nutritional needs of the microbes. Many specific formulations are available, because some microbes prefer certain environmental conditions over others. Agar is often dispensed using a sterile media dispenser.
Motility assays.
As a gel, an agar or agarose medium is porous and therefore can be used to measure microorganism motility and mobility. The gel's porosity is directly related to the concentration of agarose in the medium, so various levels of effective viscosity (from the cell's "point of view") can be selected, depending on the experimental objectives.
A common identification assay involves culturing a sample of the organism deep within a block of nutrient agar. Cells will attempt to grow within the gel structure. Motile species will be able to migrate, albeit slowly, throughout the gel and infiltration rates can then be visualized, whereas non-motile species will show growth only along the now-empty path introduced by the invasive initial sample deposition.
Another setup commonly used for measuring chemotaxis and chemokinesis utilizes the under-agarose cell migration assay, whereby a layer of agarose gel is placed between a cell population and a chemoattractant. As a concentration gradient develops from the diffusion of the chemoattractant into the gel, various cell populations requiring different stimulation levels to migrate can then be visualized over time using microphotography as they tunnel upward through the gel against gravity along the gradient.
Plant biology.
Research grade agar is used extensively in plant biology as it is supplemented with a nutrient and vitamin mixture that allows for seedling germination in Petri dishes under sterile conditions (given that the seeds are sterilized as well). Nutrient and vitamin supplementation for "Arabidopsis thaliana" is standard across most experimental conditions. Murashige & Skoog (MS) nutrient mix and Gamborg's B5 vitamin mix in general are used. A 1.0% agar/0.44% MS+vitamin dHO solution is suitable for growth media between normal growth temps.
The solidification of the agar within any growth media (GM) is pH-dependent, with an optimal range between 5.4-5.7. Usually, the application of KOH is needed to increase the pH to this range. A general guideline is about 600 µl 0.1M KOH per 250 ml GM. This entire mixture can be sterilized using the liquid cycle of an autoclave.
This medium nicely lends itself to the application of specific concentrations of phytohormones etc. to induce specific growth patterns in that one can easily prepare a solution containing the desired amount of hormone, add it to the known volume of GM, and autoclave to both sterilize and evaporate off any solvent that may have been used to dissolve the often-polar hormones. This hormone/GM solution can be spread across the surface of Petri dishes sown with germinated and/or etiolated seedlings.
Experiments with the moss "Physcomitrella patens", however, have shown that choice of the gelling agent — agar or Gelrite - does influence phytohormone sensitivity of the plant cell culture.
Culinary.
Agar-agar is a natural vegetable gelatin counterpart. White and semi-translucent, it is sold in packages as washed and dried strips or in powdered form. It can be used to make jellies, puddings, and custards. For making jelly, it is boiled in water until the solids dissolve. Sweetener, flavouring, colouring, fruit or vegetables are then added and the liquid is poured into molds to be served as desserts and vegetable aspics, or incorporated with other desserts, such as a jelly layer in a cake.
Agar-agar is approximately 80% fiber, so it can serve as an intestinal regulator. Its bulk quality is behind one of the latest fad diets in Asia, the "kanten" (the Japanese word for agar-agar) diet. Once ingested, "kanten" triples in size and absorbs water. This results in the consumers feeling fuller. This diet has recently received some press coverage in the United States as well. The diet has shown promise in obesity studies.
One use of agar in Japanese cuisine (Wagashi) is "anmitsu", a dessert made of small cubes of agar jelly and served in a bowl with various fruits or other ingredients. It is also the main ingredient in "mizu yōkan", another popular Japanese food.
In Philippine cuisine, it is used to make the jelly bars in the various gulaman refreshments or desserts such as "sago gulaman", "buko pandan", "agar flan", "halo-halo", and the black and red "gulaman" used in various fruit salads.
In Vietnamese cuisine, jellies made of flavored layers of agar agar, called "thạch", are a popular dessert, and are often made in ornate molds for special occasions. In Indian cuisine, agar agar is known as "China grass" and is used for making desserts. In Burmese cuisine, a sweet jelly known as "kyauk kyaw" ) ) is made from agar.
In Russia, it is used in addition or as a replacement to pectin in jams and marmalades, as a substitute to gelatin for its superior gelling properties, and as a strengthening ingredient in souffles and custards. Another use of agar-agar is in "ptich'ye moloko" (bird's milk), a rich jellified custard (or soft meringue) used as a cake filling or chocolate-glazed as individual sweets. Agar-agar may also be used as the gelling agent in gel clarification, a culinary technique used to clarify stocks, sauces, and other liquids.
Mexico has traditional candies made out of Agar gelatin, most of them in colorful, half-circle shapes that resemble a melon or watermelon fruit slice, and commonly covered with sugar. They are known in Spanish as "Dulce de Agar" (Agar sweets)
Agar-agar is an allowed nonorganic/nonsynthetic additive used as a thickener, gelling agent, texturizer, moisturizer, emulsifier, flavor enhancer, and absorbent in certified organic foods.
Other uses.
Agar is used:
Gelidium agar is used primarily for bacteriological plates. Gracilaria agar is used mainly in food applications.

</doc>
<doc id="3263" url="https://en.wikipedia.org/wiki?curid=3263" title="Acid rain">
Acid rain

Acid rain is a rain or any other form of precipitation that is unusually acidic, meaning that it possesses elevated levels of hydrogen ions (low pH). It can have harmful effects on plants, aquatic animals and infrastructure. Acid rain is caused by emissions of sulfur dioxide and nitrogen oxide, which react with the water molecules in the atmosphere to produce acids. Some Governments have made efforts since the 1970s to reduce the release of sulfur dioxide and nitrogen oxide into the atmosphere with positive results. Nitrogen oxides can also be produced naturally by lightning strikes, and sulfur dioxide is produced by volcanic eruptions. The chemicals in acid rain can cause paint to peel, corrosion of steel structures such as bridges, and weathering of stone buildings and statues.
Definition.
"Acid rain" is a popular term referring to the deposition of a mixture from wet (rain, snow, sleet, fog, cloudwater, and dew) and dry (acidifying particles and gases) acidic components. Distilled water, once carbon dioxide is removed, has a neutral pH of 7. Liquids with a pH less than 7 are acidic, and those with a pH greater than 7 are alkaline. "Clean" or unpolluted rain has an acidic pH, but usually no lower than 5.7, because carbon dioxide and water in the air react together to form carbonic acid, a weak acid according to the following reaction:
Carbonic acid then can ionize in water forming low concentrations of hydronium and carbonate ions:
However, unpolluted rain can also contain other chemicals which affect its pH (acidity level). A common example is nitric acid produced by electric discharge in the atmosphere such as lightning. Acid deposition as an environmental issue (discussed later in the article) would include additional acids to .
History.
The corrosive effect of polluted, acidic city air on limestone and marble was noted in the 17th century by John Evelyn, who remarked upon the poor condition of the Arundel marbles.
Since the Industrial Revolution, emissions of sulfur dioxide and nitrogen oxides into the atmosphere have increased. In 1852, Robert Angus Smith was the first to show the relationship between acid rain and atmospheric pollution in Manchester, England.
Though acidic rain was discovered in 1853, it was not until the late 1960s that scientists began widely observing and studying the phenomenon. The term "acid rain" was coined in 1872 by Robert Angus Smith. Canadian Harold Harvey was among the first to research a "dead" lake. Public awareness of acid rain in the U.S increased in the 1970s after The New York Times published reports from the Hubbard Brook Experimental Forest in New Hampshire of the myriad deleterious environmental effects shown to result from it.
Occasional pH readings in rain and fog water of well below 2.4 have been reported in industrialized areas. Industrial acid rain is a substantial problem in China and Russia and areas downwind from them. These areas all burn sulfur-containing coal to generate heat and electricity.
The problem of acid rain has not only increased with population and industrial growth, but has become more widespread. The use of tall smokestacks to reduce local pollution has contributed to the spread of acid rain by releasing gases into regional atmospheric circulation. Often deposition occurs a considerable distance downwind of the emissions, with mountainous regions tending to receive the greatest deposition (simply because of their higher rainfall). An example of this effect is the low pH of rain which falls in Scandinavia.
History of acid rain in the United States.
In 1980, the U.S. Congress passed an Acid Deposition Act. This Act established an 18-year assessment and research program under the direction of the National Acidic Precipitation Assessment Program (NAPAP). NAPAP looked at the entire problem from a scientific perspective. It enlarged a network of monitoring sites to determine how acidic the precipitation actually was, and to determine long-term trends, and established a network for dry deposition. It looked at the effects of acid rain and funded research on the effects of acid precipitation on freshwater and terrestrial ecosystems, historical buildings, monuments, and building materials. It also funded extensive studies on atmospheric processes and potential control programs.
From the start, policy advocates from all sides attempted to influence NAPAP activities to support their particular policy advocacy efforts, or to disparage those of their opponents. For the U.S. Government's scientific enterprise, a significant impact of NAPAP were lessons learned in the assessment process and in environmental research management to a relatively large group of scientists, program managers and the public.
In 1991, DENR provided its first assessment of acid rain in the United States. It reported that 5% of New England Lakes were acidic, with sulfates being the most common problem. They noted that 2% of the lakes could no longer support Brook Trout, and 6% of the lakes were unsuitable for the survival of many species of minnow. Subsequent Reports to Congress have documented chemical changes in soil and freshwater ecosystems, nitrogen saturation, decreases in amounts of nutrients in soil, episodic acidification, regional haze, and damage to historical monuments.
Meanwhile, in 1989, the U.S. Congress passed a series of amendments to the Clean Air Act. Title IV of these amendments established the Acid Rain Program, a cap and trade system designed to control emissions of sulfur dioxide and nitrogen oxides. Title IV called for a total reduction of about 10 million tons of SO emissions from power plants. It was implemented in two phases. Phase I began in 1995, and limited sulfur dioxide emissions from 110 of the largest power plants to a combined total of 8.7 million tons of sulfur dioxide. One power plant in New England (Merrimack) was in Phase I. Four other plants (Newington, Mount Tom, Brayton Point, and Salem Harbor) were added under other provisions of the program. Phase II began in 2000, and affects most of the power plants in the country.
During the 1990s, research continued. On March 10, 2005, EPA issued the Clean Air Interstate Rule (CAIR). This rule provides states with a solution to the problem of power plant pollution that drifts from one state to another. CAIR will permanently cap emissions of SO and NO in the eastern United States. When fully implemented, CAIR will reduce SO emissions in 28 eastern states and the District of Columbia by over 70% and NO emissions by over 60% from 2003 levels.
Overall, the program's cap and trade program has been successful in achieving its goals. Since the 1990s, SO emissions have dropped 40%, and according to the Pacific Research Institute, acid rain levels have dropped 65% since 1976. Conventional regulation was used in the European Union, which saw a decrease of over 70% in SO emissions during the same time period.
In 2007, total SO emissions were 8.9 million tons, achieving the program's long-term goal ahead of the 2010 statutory deadline.
In 2007 the EPA estimated that by 2010, the overall costs of complying with the program for businesses and consumers would be $1 billion to $2 billion a year, only one fourth of what was originally predicted. Forbes says: "In 2010, by which time the cap and trade system had been augmented by the George W. Bush administration’s Clean Air Interstate Rule, SO2 emissions had fallen to 5.1 million tons.
Emissions of chemicals leading to acidification.
The most important gas which leads to acidification is sulfur dioxide. Emissions of nitrogen oxides which are oxidized to form nitric acid are of increasing importance due to stricter controls on emissions of sulfur containing compounds. 70 Tg(S) per year in the form of SO comes from fossil fuel combustion and industry, 2.8 Tg(S) from wildfires and 7–8 Tg(S) per year from volcanoes.
Natural phenomena.
The principal natural phenomena that contribute acid-producing gases to the atmosphere are emissions from volcanoes. Thus, for example, fumaroles from the Laguna Caliente crater of Poás Volcano create extremely high amounts of acid rain and fog, with acidity as high as a pH of 2, clearing an area of any vegetation and frequently causing irritation to the eyes and lungs of inhabitants in nearby settlements.
Acid-producing gasses are also created by biological processes that occur on the land, in wetlands, and in the oceans. The major biological source of sulfur containing compounds is dimethyl sulfide.
Nitric acid in rainwater is an important source of fixed nitrogen for plant life, and is also produced by electrical activity in the atmosphere such as lightning.
Acidic deposits have been detected in glacial ice thousands of years old in remote parts of the globe.
Soils of coniferous forests are naturally very acidic due to the shedding of needles, and the results of this phenomenon should not be confused with acid rain.
Human activity.
The principal cause of acid rain is sulfur and nitrogen compounds from human sources, such as electricity generation, factories, and motor vehicles. Electrical power generation using coal is among the greatest contributors to gaseous pollutions that are responsible for acidic rain. The gases can be carried hundreds of kilometers in the atmosphere before they are converted to acids and deposited. In the past, factories had short funnels to let out smoke but this caused many problems locally; thus, factories now have taller smoke funnels. However, dispersal from these taller stacks causes pollutants to be carried farther, causing widespread ecological damage.
Chemical processes.
Combustion of fuels produces sulfur dioxide and nitric oxides. They are converted into sulfuric acid and nitric acid.
Gas phase chemistry.
In the gas phase sulfur dioxide is oxidized by reaction with the hydroxyl radical via an intermolecular reaction:
which is followed by:
In the presence of water, sulfur trioxide (SO) is converted rapidly to sulfuric acid:
Nitrogen dioxide reacts with OH to form nitric acid:
Chemistry in cloud droplets.
When clouds are present, the loss rate of SO is faster than can be explained by gas phase chemistry alone. This is due to reactions in the liquid water droplets.
Sulfur dioxide dissolves in water and then, like carbon dioxide, hydrolyses in a series of equilibrium reactions:
There are a large number of aqueous reactions that oxidize sulfur from S(IV) to S(VI), leading to the formation of sulfuric acid. The most important oxidation reactions are with ozone, hydrogen peroxide and oxygen (reactions with oxygen are catalyzed by iron and manganese in the cloud droplets).
Acid deposition.
Wet deposition.
Wet deposition of acids occurs when any form of precipitation (rain, snow, and so on.) removes acids from the atmosphere and delivers it to the Earth's surface. This can result from the deposition of acids produced in the raindrops (see aqueous phase chemistry above) or by the precipitation removing the acids either in clouds or below clouds. Wet removal of both gases and aerosols are both of importance for wet deposition.
Dry deposition.
Acid deposition also occurs via dry deposition in the absence of precipitation. This can be responsible for as much as 20 to 60% of total acid deposition. This occurs when particles and gases stick to the ground, plants or other surfaces.
Adverse effects.
Acid rain has been shown to have adverse impacts on forests, freshwaters and soils, killing insect and aquatic life-forms as well as causing damage to buildings and having impacts on human health.
Surface waters and aquatic animals.
Both the lower pH and higher aluminium concentrations in surface water that occur as a result of acid rain can cause damage to fish and other aquatic animals. At pHs lower than 5 most fish eggs will not hatch and lower pHs can kill adult fish. As lakes and rivers become more acidic biodiversity is reduced. Acid rain has eliminated insect life and some fish species, including the brook trout in some lakes, streams, and creeks in geographically sensitive areas, such as the Adirondack Mountains of the United States. However, the extent to which acid rain contributes directly or indirectly via runoff from the catchment to lake and river acidity (i.e., depending on characteristics of the surrounding watershed) is variable. The United States Environmental Protection Agency's (EPA) website states: "Of the lakes and streams surveyed, acid rain caused acidity in 75% of the acidic lakes and about 50% of the acidic streams".
Soils.
Soil biology and chemistry can be seriously damaged by acid rain. Some microbes are unable to tolerate changes to low pH and are killed. The enzymes of these microbes are denatured (changed in shape so they no longer function) by the acid. The hydronium ions of acid rain also mobilize toxins such as aluminium, and leach away essential nutrients and minerals such as magnesium.
Soil chemistry can be dramatically changed when base cations, such as calcium and magnesium, are leached by acid rain thereby affecting sensitive species, such as sugar maple (Acer saccharum).
Forests and other vegetation.
Adverse effects may be indirectly related to acid rain, like the acid's effects on soil (see above) or high concentration of gaseous precursors to acid rain. High altitude forests are especially vulnerable as they are often surrounded by clouds and fog which are more acidic than rain.
Other plants can also be damaged by acid rain, but the effect on food crops is minimized by the application of lime and fertilizers to replace lost nutrients. In cultivated areas, limestone may also be added to increase the ability of the soil to keep the pH stable, but this tactic is largely unusable in the case of wilderness lands. When calcium is leached from the needles of red spruce, these trees become less cold tolerant and exhibit winter injury and even death.
Ocean acidification.
Coral's limestone skeletal is sensitive to pH drop, because the calcium carbonate, core component of the limestone dissolves in acidic (low pH) solutions.
Human health effects.
Acid rain does not directly affect human health. The acid in the rainwater is too dilute to have direct adverse effects. However, the particulates responsible for acid rain (sulfur dioxide and nitrogen oxides) do have an adverse effect. Increased amounts of fine particulate matter in the air do contribute to heart and lung problems including asthma and bronchitis.
Other adverse effects.
Acid rain can damage buildings, historic monuments, and statues, especially those made of rocks, such as limestone and marble, that contain large amounts of calcium carbonate. Acids in the rain react with the calcium compounds in the stones to create gypsum, which then flakes off.
The effects of this are commonly seen on old gravestones, where acid rain can cause the inscriptions to become completely illegible. Acid rain also increases the corrosion rate of metals, in particular iron, steel, copper and bronze.
Affected areas.
Places significantly impacted by acid rain around the globe include most of eastern Europe from Poland northward into Scandinavia, the eastern third of the United States, and southeastern Canada. Other affected areas include the southeastern coast of China and Taiwan.
Prevention methods.
Technical solutions.
Many coal-firing power stations use flue-gas desulfurization (FGD) to remove sulfur-containing gases from their stack gases. For a typical coal-fired power station, FGD will remove 95% or more of the SO in the flue gases. An example of FGD is the wet scrubber which is commonly used. A wet scrubber is basically a reaction tower equipped with a fan that extracts hot smoke stack gases from a power plant into the tower. Lime or limestone in slurry form is also injected into the tower to mix with the stack gases and combine with the sulfur dioxide present. The calcium carbonate of the limestone produces pH-neutral calcium sulfate that is physically removed from the scrubber. That is, the scrubber turns sulfur pollution into industrial sulfates.
In some areas the sulfates are sold to chemical companies as gypsum when the purity of calcium sulfate is high. In others, they are placed in landfill. However, the effects of acid rain can last for generations, as the effects of pH level change can stimulate the continued leaching of undesirable chemicals into otherwise pristine water sources, killing off vulnerable insect and fish species and blocking efforts to restore native life.
Fluidized bed combustion also reduces the amount of sulfur emitted by power production.
Vehicle emissions control reduces emissions of nitrogen oxides from motor vehicles.
International treaties.
A number of international treaties on the long-range transport of atmospheric pollutants have been agreed for example, Sulphur Emissions Reduction Protocol under the Convention on Long-Range Transboundary Air Pollution. Canada and the US signed the Air Quality Agreement in 1991. Most European countries and Canada have signed the treaties.
Emissions trading.
In this regulatory scheme, every current polluting facility is given or may purchase on an open market an emissions allowance for each unit of a designated pollutant it emits. Operators can then install pollution control equipment, and sell portions of their emissions allowances they no longer need for their own operations, thereby recovering some of the capital cost of their investment in such equipment. The intention is to give operators economic incentives to install pollution controls.
The first emissions trading market was established in the United States by enactment of the Clean Air Act Amendments of 1990. The overall goal of the Acid Rain Program established by the Act is to achieve significant environmental and public health benefits through reductions in emissions of sulfur dioxide (SO) and nitrogen oxides (NO), the primary causes of acid rain. To achieve this goal at the lowest cost to society, the program employs both regulatory and market based approaches for controlling air pollution.

</doc>
<doc id="3266" url="https://en.wikipedia.org/wiki?curid=3266" title="Acephali">
Acephali

In church history, the term has been applied to several sects that supposedly had no leader. E. Cobham Brewer wrote, in "Dictionary of Phrase and Fable", that acephalites, "properly means men without a head." Jean Cooper wrote, in "Dictionary of Christianity", that it characterizes "various schismatical Christian bodies". Among them were Nestorians who rejected the Council of Ephesus condemnation of Patriarch Nestorius of Constantinople, which deposed Nestorius and declared him a heretic.
Fifth-century "acephali".
Those who refused to acknowledge the authority of the Council of Chalcedon were originally called Haesitantes; the "" developed from among them, and, according to Blunt, the earlier name – Haesitantes – seems to have been used for only a short time.
With the apparent purpose of bringing the orthodox and heretics into unity, Patriarch Peter III of Alexandria and Patriarch Acacius of Constantinople had elaborated a new creed in which they expressly condemned both Nestorius and Eutyches, a presbyter and archimandrite, but at the same time rejected the decisions of the Council of Chalcedon. This ambiguous formula, though approved by Byzantine Emperor Zeno and imposed in his "Henoticon", could only satisfy the indifferent.
The term applied to a 5th-century faction among the Eutychians, who seceded from Peter, a Monophysite or more accurately a Miaphysite, in 482, after Peter signed the "Henoticon" and was recognised by Zeno as the legitimate patriarch of Alexandria by which they were "deprived of their head".
The condemnation of Eutyches irritated the rigid Monophysites; the equivocal attitude taken towards the Council of Chalcedon appeared to them insufficient, and many of them, especially the monks, deserted Peter, preferring to be without a head, rather than remain in communion with him.
Later, they joined the adherents of the non-Chalcedonian Patriarch Severus of Antioch.
They were, according to "Oxford English Dictionary Online", a "group of extreme Monophysites" and "were absorbed by the Jacobites".
Liberatus of Carthage wrote, in ', that those at the Council of Ephesus who followed neither Patriarch Cyril I of Alexandria nor Patriarch John I of Antioch were called '.
Esaianites were one of the sects into which the Alexandrian "" separated at the end of the 5th century. They were the followers of Esaias, a deacon of Palestine, who claimed to have been consecrated to the episcopal office by the Bishop Eusebius. His opponents averred that after the bishop's death his hands had been laid upon the head of Esaias by some of his friends.
' were a sect of ' who followed Chalcedonian Patriarch Paul of Alexandria, who was deposed by a synod at Gaza, in 541, for his uncanonical consecration by the Patriarch of Constantinople, and who, after his deposition, sided with the Miaphysites.
Barsanians, later called Semidalites, were a sect of "" at the end of the 5th century. They had no succession of priests, and professed to keep up the celebration of a valid Eucharist by placing a few crumbs of some of the bread which had been consecrated by Dioscorus into a vessel of meal, and then using as fully consecrated the bread baked from it.
Other "acephali".
According to Brewer, acephalites were also certain bishops exempt from the jurisdiction and discipline of their patriarch. Cooper explains that they are "priests rejecting episcopal authority or bishops that of their metropolitans." Blunt described "" as those clergy who were ordained with a sinecure benefice and who generally obtained their orders by paying for them, that is by simony. The Council of Pavia, in 853, legislated its canons 18 and 23 against them, from which it appears, according to Blunt, that they were mostly chaplains to noblemen, that they produced much scandal in the Church, and that they disseminated many errors.
According to Brewer, acephalites were also a sect of Levellers during the reign of Henry I of England who acknowledged no leader. They were, according to "Oxford English Dictionary Online", "a group of free socagers having no feudal superior except the king." This usage is now considered obsolete.
Fabled human-like creatures in Greek mythology, analogous to Pliny the Elder's ', without heads and with facial features on their torsos, were also called '.

</doc>
<doc id="3269" url="https://en.wikipedia.org/wiki?curid=3269" title="Anthony of Saxony">
Anthony of Saxony

Anthony (Dresden, 27 December 1755 – Dresden, 6 June 1836), also known by his German name Anton (full name: "Anton Clemens Theodor Maria Joseph Johann Evangelista Johann Nepomuk Franz Xavier Aloys Januar"), was a King of Saxony (1827–1836) from the House of Wettin. He became known as "Anton der Gütige", (en: "Anthony the Kind").
He was the fifth but third surviving son of Frederick Christian, Elector of Saxony, and Maria Antonia of Bavaria.
Early life.
With few chances to take part in the politics of the Electorate of Saxony or receive any land from his older brother Frederick Augustus III, Anton lived under the shadows. No Elector of Saxony after Johann Georg I gave appananges to his younger sons.
During the first years of the reign of his older brother as Elector, Anton was the third in line, preceded only by his older brother Karl. The death of Karl (8 September 1781) make him the next in line to the Electorate as Crown Prince (de: "Kronprinz"); this was because all the pregnancies of the Electress Amalie, except for one daughter, ended in a stillbirth.
His aunt, the Dauphine of France, had wanted to engage her daughter Marie Zéphyrine of France to Anthony; Marie Zéphyrine died in 1755 abandoning plans. Another French candidate was Marie Zéphyrine's sister Marie Clothilde (later Queen of Sardinia) but again nothing happened.
In Turin on 29 September 1781 (by proxy) and again in Dresden on 24 October 1781 (in person), Anton married firstly with the Princess Caroline of Savoy (Maria Carolina Antonietta Adelaida), daughter of the King Victor Amadeus III of Sardinia and Maria Antonietta of Spain. Caroline died after only one year of marriage, on 28 December 1782 having succumbed to smallpox. They had no children.
In Florence on 8 September 1787 (by proxy) and again in Dresden on 18 October 1787 (in person), Anton married a second time with the Archduchess Maria Theresia of Austria (Maria Theresia Josephe Charlotte Johanna), daughter of the Grand Duke Leopold I of Tuscany, later Emperor Leopold II. Mozart's opera "Don Giovanni" was originally intended to be performed in honor of Anton and his wife for a visit to Prague on 14 October 1787, as they traveled between Dresden and Vienna, and librettos were printed with dedication to them. The premiere could not be arranged in time, however, so the opera "The Marriage of Figaro" was substituted on the express orders of the bride's uncle, Holy Roman Emperor Joseph II. The choice of "The Marriage of Figaro" was considered improper for a new bride by many observers, and the couple left the opera theater early without seeing the entire work performed. Mozart complained bitterly of the intrigues surrounding this incident in a letter to his friend Gottfried von Jacquin that was written in stages between 15 October and 25 October 1787. Anthony was also present in Prague in September 1791 for the first performance of Mozart's opera "La clemenza di Tito", which was written as part of the coronation ceremonies of his father-in-law, Leopold II, Holy Roman Emperor, as King of Bohemia.
The couple had four children, but none survived to the age of two:
The Electress gave birth for last time in 1799 to another stillborn child. After this Anton became, officially, the Heir to the Electorate and, from 1806, the Kingdom of Saxony.
King of Saxony.
Anton succeeded his brother Frederick August I as King of Saxony when he died, on 5 May 1827. The 71-year-old new king was completely inexperienced in government, thus he had no intention of initiating profound changes in foreign or domestic policy.
Prussian diplomats discussed granting the Prussian Rhineland (predominantly Catholic) to Anton (a Catholic) in exchange for Lutheran Saxony in 1827, but nothing came of these talks.
After the July Revolution of 1830 in France, disturbances in Saxony began in autumn. These were directed primarily against the old Constitution. Therefore, on 13 September the cabinet dismissed Count Detlev von Einsiedel, followed by Bernhard von Lindenau. Because the people wished a younger regent, Anton agreed to appoint his nephew Frederick Augustus Prince Co-Regent (de: "Prinz-Mitregenten"). As another consequence of the disturbances, a new constitution was accepted in 1831 which came into effect on 4 September of that year. With it Saxony became a Constitutional monarchy and obtained a bi-cameral legistature and a responsible ministry, which replaced the old feudal estates. The constitution was more conservative than other constitutions existing at this time in the German Union. Still the constitution served Saxony until 1918. The king kept his exclusive sovereignty but was bound by the Government Business to cooperate with the Ministers and the decisions of both Chambers of the States (de: "Kammern der Ständeversammlung") meeting. The entry of Saxony into the "Zollverein" in 1833 let trade, industry and traffic blossom farther.
Without surviving male issue, Anton was succeeded as king by his nephew, Frederick Augustus II.

</doc>
<doc id="3270" url="https://en.wikipedia.org/wiki?curid=3270" title="Albert III, Duke of Saxony">
Albert III, Duke of Saxony

Albert III () (27 January 1443 – 12 September 1500) was a Duke of Saxony. He was nicknamed Albert the Bold or Albert the Courageous and founded the "Albertine line" of the House of Wettin.
Biography.
Albert was born in Grimma as the third and youngest son (but fifth child in order of birth) of Frederick II the Gentle, Elector of Saxony, and Margarete of Austria, sister of Frederick III, Holy Roman Emperor. Later, he was a member of the Order of the Golden Fleece.
After escaping from the hands of Kunz von Kaufungen, who had abducted him together with his brother Ernest, he spent some time at the court of the emperor Frederick III in Vienna.
In Eger (Cheb) on 11 November 1464 Albert married Zdenka (Sidonie), daughter of George of Podebrady, King of Bohemia; but failed to obtain the Bohemian Crown on the death of George in 1471.
After the death of his father in 1464, Albert and Ernest ruled their lands together, but in 1485 a division was made by the Treaty of Leipzig, and Albert received the Meissen, together with some adjoining districts, and founded the Albertine branch of the House of Wettin.
Regarded as a capable soldier by the emperor, Albert (in 1475) took a prominent part in the campaign against Charles the Bold, duke of Burgundy, and in 1487 led an expedition against Matthias Corvinus, King of Hungary, which failed owing to lack of support on the part of the emperor.
In 1488 he was appointed Governor of the Netherlands (until 1493) and marched with the imperial forces to free the Roman king Maximilian from his imprisonment at Bruges, and when, in 1489, the King returned to Germany, Albert was left as his representative to prosecute the war against the rebels. He was successful in restoring the authority of Maximilian in Holland, Flanders, and Brabant, but failed to obtain any repayment of the large sums of money which he had spent in these campaigns.
His services were rewarded in 1498 when Maximilian bestowed upon him the title of Hereditary Governor ("potestat") of Friesland, but he had to make good his claim by force of arms. He had to a great extent succeeded, and was paying a visit to Saxony, when he was recalled by news of a fresh rising. Groningen was captured, but soon afterwards the duke died at Emden. He was buried at Meissen.
Albert, who was a man of great strength and considerable skill in feats of arms, delighted in tournaments and knightly exercises. His loyalty to the emperor Frederick, and the expenses incurred in this connection, aroused some irritation among his subjects, but his rule was a period of prosperity in Saxony.
Family and children.
With his wife Sidonie, Albrecht had nine children:

</doc>
<doc id="3273" url="https://en.wikipedia.org/wiki?curid=3273" title="Arlo Guthrie">
Arlo Guthrie

Arlo Davy Guthrie (born July 10, 1947) is an American folk singer-songwriter. Like his father, Woody Guthrie, Arlo is known for singing songs of protest against social injustice. Guthrie's best-known work was his debut piece "Alice's Restaurant Massacree", a satirical talking blues song about 18 minutes in length that has since become a Thanksgiving anthem, and his lone top-40 hit was a cover of Steve Goodman's "City of New Orleans." His song "Massachusetts" was named the official folk song of the state in which he has lived most of his adult life. Guthrie has also made several acting appearances over the course of his life, and he has also fathered four children who have likewise gone on to careers as musicians.
Early life.
Arlo Guthrie was born in Brooklyn, New York, the son of folk singer and composer Woody Guthrie and his wife Marjorie Mazia Guthrie. His sister is record producer Nora Guthrie. His mother was a one-time professional dancer with the Martha Graham Company and founder of the Committee to Combat Huntington's disease, the disease that took Woody's life in 1967. His father was from a Protestant family and his mother was Jewish. His maternal grandmother was renowned Yiddish poet Aliza Greenblatt.
Guthrie received religious training for his bar mitzvah from Rabbi Meir Kahane, who would go on to form the Jewish Defense League. "Rabbi Kahane was a really nice, patient teacher," Guthrie later recalled, "but shortly after he started giving me my lessons, he started going haywire. Maybe I was responsible." Guthrie converted to Catholicism in 1977, before embracing interfaith beliefs later in his life.
Guthrie attended Woodward School in Clinton Hill, Brooklyn 1st through 8th grades and later graduated from the Stockbridge School, in Stockbridge, Massachusetts, in 1965, and briefly attended Rocky Mountain College in Billings, Montana. He received an Honorary Doctorate from Siena College in 1981 and from Westfield State College, in 2008.
As a singer, songwriter and lifelong political activist, Guthrie carries on the legacy of his legendary father. He was awarded the Peace Abbey Courage of Conscience award on September 26, 1992.
"Alice's Restaurant".
His most famous work is "Alice's Restaurant Massacree", a talking blues song that lasts 18 minutes and 34 seconds in its original recorded version. Guthrie has pointed out that this was also the exact length of one of the famous gaps in Richard Nixon's Watergate tapes. The Alice in the song is Alice Brock, who had been a librarian at Arlo's boarding school in town before opening her restaurant, and who now owns an art studio in Provincetown, Massachusetts.
The song lampoons the Vietnam War draft. However, Guthrie has stated in multiple interviews that the song is more an "anti-stupidity" song than an anti-war song, adding that it is based on a true incident. In the song, Guthrie is called up for a draft examination, and rejected as unfit for military service as a result of a criminal record consisting in its entirety of a single arrest, court appearance, fine, and clean-up order for littering on Thanksgiving Day in 1965, when Arlo was 18 years old. Alice's restaurant is the subject of the recurrent refrain, but is not mentioned in the story (early drafts of the song explained that the restaurant was a place to hide from the police). On the DVD commentary for the 1969 movie, Guthrie states that the events presented in the song all actually happened (others, such as arresting officer William Obanhein, disputed this, and Guthrie now notes that he did embellish some minor details).
"Alice's Restaurant" was the song that earned Guthrie his first recording contract, after counterculture radio host Bob Fass began playing a tape recording of one of Guthrie's live performances of the song repeatedly one night in 1967. For a short period after its release in 1967, "Alice's Restaurant" was heavily played on U.S. college and counterculture radio stations. It became a symbol of the late 1960s and for many it defined an attitude and lifestyle that were lived out across the country in the ensuing years. Its leisurely, sassy finger-picking acoustic guitar and rambling lyrics were widely memorized and played by irreverent youth. Many stations across the States have made playing "Alice's Restaurant" a Thanksgiving Day tradition.
A 1969 film, directed and co-written by Arthur Penn, was based on the true story told in the song, but with the addition of a large number of fictional scenes. This film, also called "Alice's Restaurant", featured Arlo and several other figures in the song portraying themselves. The part of his father Woody Guthrie, who had died in 1967, was played by an actor, Joseph Boley; Alice, who made a cameo appearance as an extra, was also recast, with actress Pat Quinn in the title role.
Despite its popularity, the song "Alice's Restaurant Massacree" is not always featured on the set list of any given Guthrie performance. He performs the song every ten years, stating in a 2014 interview that the Vietnam War had ended by the 1970s and that everyone who was attending his concerts had likely already heard the song anyway, so (after a brief period in the late 1960s and early 1970s when he replaced the monologue with a fictional one involving "multicolored rainbow roaches") he decided only to do it on special occasions from that point forward.
Musical career and critical reception.
The "Alice's Restaurant" song was one of a few very long songs to become popular just when albums began replacing hit singles as young people's main music listening. But in 1972 Guthrie had a highly successful single too, Steve Goodman's song "City of New Orleans", a wistful paean to long-distance passenger rail travel. Guthrie's first trip on that train was in December 2005 (when his family joined other musicians on a train trip across the country to raise money for musicians financially devastated by Hurricane Katrina and Hurricane Rita, in the South of the United States). He also had a minor hit with his song "Coming into Los Angeles", which was played at the 1969 Woodstock Festival, and success with a live version of "The Motorcycle Song" (one of the songs on the B-side of the "Alice's Restaurant Album").
In the fall of 1975 during a benefit concert in Massachusetts, Arlo Guthrie performed with his band Shenandoah in public for the first time. They continued to tour and record throughout the 1970s until the early 1990s. Although the band received good reviews, it never gained the popularity that Guthrie did while playing solo. This band is not to be confused with the popular country music group Shenandoah, an entirely different group that had musical hits from 1986 to 2006. Arlo Guthrie's band Shenandoah consisted (after 1976) of David Grover, Steve Ide, Carol Ide, Terry A La Berry and Dan Velika.
Guthrie's 1976 album "Amigo" received a 5-star (highest rating) from "Rolling Stone", and may be his best-received work. However, that album, like Guthrie's earlier Warner Bros. Records albums, is rarely heard today even though each contains strong folk and folk rock music accompanied by widely regarded musicians such as Ry Cooder.
A number of musicians from a variety of genres have joined Guthrie onstage, including Pete Seeger, David Bromberg, Cyril Neville, Emmylou Harris, Willie Nelson, Judy Collins, John Prine, Wesley W Gray, Josh Ritter, and others.
Acting.
Though Guthrie is best known for being a musician, singer, and composer, throughout the years he has also appeared as an actor in films and on television. The film "Alice's Restaurant" (1969) is his best known role, but he has had small parts in several films and even co-starred in a television drama, "Byrds of Paradise".
Guthrie has had minor roles in several movies and television series. Usually, he has appeared as himself, often performing music and/or being interviewed about the 1960s, folk music and various social causes. His television appearances have included a broad range of programs from "The Muppet Show" (1979) to "Politically Incorrect" (1998). A rare dramatic film part was in the 1992 movie "Roadside Prophets". Guthrie's memorable appearance at the 1969 Woodstock Festival was documented in the Michael Wadleigh film "Woodstock".
Guthrie also made a pilot for a TV variety show called "The Arlo Guthrie Show" in February 1987. The hour-long program included story telling and musical performances and was filmed in Austin, Texas. It was broadcast nationally on PBS. Special guests were Pete Seeger, Bonnie Raitt, David Bromberg and Jerry Jeff Walker.
Politics.
In earlier years, at least from the 1960s to the 1980s, Guthrie had taken a decidedly leftist approach to American politics. In his often lengthy comments during concerts his expressed positions were consistently anti-war, anti-Nixon, pro-drugs and in favor of making nuclear power illegal. However, he apparently regarded himself as more an individualist than the major youth culture spokesperson he had been regarded as by the media, as evidenced by the lyrics in his 1979 song "Prologue": "I can remember all of your smiles during the demonstrations, ... and together we sang our victory songs though we were worlds apart."
In 1984, he was the featured celebrity in George McGovern's campaign for the Democratic presidential nomination in Guthrie's home state of Massachusetts, performing at rallies and receptions.
Guthrie has since become a registered Republican. He endorsed Texas Congressman Ron Paul for the 2008 Republican Party nomination, and said, "I love this guy. Dr. Paul is the only candidate I know of who would have signed the Constitution of the United States had he been there. I'm with him, because he seems to be the only candidate who actually believes it has as much relevance today as it did a couple of hundred years ago. I look forward to the day when we can work out the differences we have with the same revolutionary vision and enthusiasm that is our American legacy." He told "The New York Times Magazine" that he is a Republican because, "We had enough good Democrats. We needed a few more good Republicans. We needed a loyal opposition." Commenting on the upcoming 2016 election, Guthrie expressed disappointment at both political parties.
About once a month, Guthrie posts short writings to the Announcements area of www.arlo.net, often expounding libertarian themes.
Legacy.
Like his father, Woody Guthrie, Guthrie often sings songs of protest against social injustice. He collaborated with poet Adrian Mitchell to tell the story of Chilean folk singer and activist Víctor Jara in song. He regularly performed with folk musician Pete Seeger, one of his father's longtime partners. Ramblin' Jack Elliott, who had lived for two years in the Guthries' home before Arlo left for boarding school, had absorbed Woody's style perhaps better than anyone; Arlo has been said to have credited Elliott for passing it along to him. 
In 1991, Guthrie bought the church that had served as Alice and Ray Brock's former home in Great Barrington, Massachusetts, and converted it to the Guthrie Center, an interfaith meeting place that serves people of all religions. The center provides weekly free lunches in the community and support for families living with HIV/AIDS as well as other life-threatening illnesses. It also hosts a summertime concert series and Guthrie does six or seven fund raising shows there every year. There are several annual events such as the Walk-A-Thon to Cure Huntington's Disease and a "Thanksgiving Dinner That Can't Be Beat" for families, friends, doctors and scientists who live and work with Huntington's disease.
Family.
Guthrie resides in the town of Washington, Massachusetts, where he and Jackie Hyde, his wife of 43 years, were long time residents. Jackie died on October 14, 2012, after a brief battle with liver cancer. He also has a home in Sebastian, Florida.
Guthrie's son Abe Guthrie and his daughters Annie, Sarah Lee Guthrie, and Cathy Guthrie have also become musicians. Annie Guthrie writes songs and performs, and also takes care of family touring details. Sarah Lee performs and records with her husband Johnny Irion. Cathy plays ukulele in Folk Uke, a group she formed with Amy Nelson, the daughter of Willie Nelson. Abe Guthrie was formerly in a folk-rock band called Xavier, and now tours with his father. Abe Guthrie's son, Krishna, is a drummer and toured with Arlo Guthrie on his European tour in 2006 and played guitar for the 2009–2010 Tour. Krishna plays drums in Modest Me and aspires to be the lead of his own band some day. Arlo Guthrie is a grandfather of Abe's son Krishna and daughter Serena, Annie's son Shiva Das (Mo) and daughter Jacklyn, Sarah Lee's daughters Olivia Nora and Sophia Irion and Cathy's daughter Marjorie Maybelle Midwood.

</doc>
<doc id="3275" url="https://en.wikipedia.org/wiki?curid=3275" title="Book of Alma">
Book of Alma

The Book of Alma () is one of the books that make up the Book of Mormon. The full title is The Book of Alma: The Son of Alma. The title refers to Alma the Younger, a prophet and "chief judge" of the Nephites.
Content.
Historical outline.
The Book of Alma is the longest of all the books of the Book of Mormon, consisting of 63 chapters. The book records the first 39 years of what the Nephites termed "the reign of the judges", a period in which the Nephite nation adopted a constitutional theocratic government in which the judicial and executive branches of the government were combined.
The history of the book is outlined as follows:
Challenges to the beginning of the republic.
The first four chapters, describe the rebellions of followers of Nehor and Amlici. Contrary to the dominant lay ministry that existed in the Nephite culture, Nehor established a church in which priests were given a separate social status and were paid for their ministry. After killing a religious leader during a theological argument, Nehor was tried and executed for his crimes. The followers of Amlici resented the dominant political and religious parties and sought to reestablish the monarchy that the reign of the judges replaced. Alma, who was chief judge, governor, and high priest over the people of Nephi, led an army against Amlici and his followers and drove the rebellion out of the land.
Ministry of Alma among the Nephites.
Towards the end of chapter four, Alma realizes that the affairs of the Church require his entire concentration. He resigns from his political office and appoints Nephihah as chief judge and governor of the land. Chapters 5-16 record sermons and missionary travels of Alma between 83 and 78 BC. Alma and one of his converted followers, Amulek, provide important teachings about the atonement of Christ, overcoming pride and the natural man, retaining conversion, the resurrection of all men, and judgment day. Later, their teachings about faith and worship in Alma 32-34 are important sources of instruction and insight.
Ministry of the sons of Mosiah among the Lamanites.
Chapters 17 to 27 describe the missionary labors of the sons of King Mosiah II who was the last king over the people of Nephi prior to the peaceful transition of the nation from a monarchy to a republican form of government. The sons of Mosiah, named Ammon, Aaron, Omner and Himni, chose to devote themselves to missionary labors preaching to the people of the Lamanite nation, which periodically went to war against the Nephite nation. They lived and taught among the Lamanites between the years 91 and 77 BC.
Ministry of Alma among the Zoramites.
Chapters 28 to 35 relate the account of a rebellion of a subgroup of the Nephite nation who called themselves Zoramites. The Zoramites believed in a form of predestination and taught that all others except their people would be damned. Their apostasy from the Church was conjoined with plans to rebel against the Nephite government. Alma took two of his sons, the sons of Mosiah, Amulek, and Zeezrom on a mission among the Zoramites in an attempt to restore their loyalty to both the Church and the state. Alma and his companions had some success among the poor class of Zoramites who were then exiled from the Zoramite community by the governing rich class of Zoramites. The wealthier Zoramites eventually defected and united with the Lamanites.
Commandments of Alma to his children.
Chapters 36 to 42 record the teachings of Alma to his sons, Helaman, Shiblon, and Corianton. These teachings discuss the ministry and atonement of Jesus, the laws of justice and mercy, the need for repentance, and the resurrection and judgment of all people.
Period of war.
Chapters 43 to 62 record the struggles of the Nephite people during a war against the attacking Lamanite nation between the years of 74 and 57 BC. The Chief Captain (senior military commander) of the Nephites during this time was Captain Moroni. The Nephites were ultimately successful in their defense against the Lamanites.
Conclusion.
Chapter 63 includes concluding historical notes covering the years 56 to 53 BC. This is largely a period of post-war reconstruction and exploration in the Nephite nation.
Simple outline.
This outline is based on "main sections" and "antagonist characters" in the Book of Alma. There are two main features in this history, chapters 1 - 42 deal with Missionary Work, and chapters 43 - 63 contain the Wars. The history of the Zoramites provides a transition from Missionary Work to the War chapters of the Book of Alma. The two main sections also mirror the first two antagonist characters, Nehor ("religious agenda") and Amlici ("political agenda").
Doctrine.
50 questions of Alma.
In , Alma the Younger speaks to the people of Zarahemla in which he asks 50 rhetorical questions, which are widely cited in the LDS church.
Faith as a seed.
Alma's sermon on faith to the Zoramites in is widely used to explain the process of developing faith. Investigators are invited to try a similar experiment of faith in order to come to develop a testimony. It is worth noting that Alma doesn't actually compare faith to a seed, he compares the word to a seed (), although this is a common misconception.
Nephite temple ceremony.
According to John W. Welch, based on the appearance of the following elements in Alma 12-13, the Nephite temple ceremony utilized familiar temple motifs, including:

</doc>
<doc id="3277" url="https://en.wikipedia.org/wiki?curid=3277" title="Antioxidant">
Antioxidant

An antioxidant is a molecule that inhibits the oxidation of other molecules. Oxidation is a chemical reaction that can produce free radicals, leading to chain reactions that may damage cells. Antioxidants such as thiols or ascorbic acid (vitamin C) terminate these chain reactions.
To balance the oxidative state, plants and animals maintain complex systems of overlapping antioxidants, such as glutathione and enzymes (e.g., catalase and superoxide dismutase) produced internally or vitamin C, vitamin A and vitamin E obtained by ingestion.
Diets containing foods high in antioxidants have been shown to improve health. However, in supplement form, the prevention of diseases such as cancer or coronary heart disease and the general promotion of health has not been confirmed experimentally. Trials including supplements of beta-carotene, vitamin A, and vitamin E singly or in different combinations found no effect on mortality or might increase it. Randomized clinical trials of taking antioxidants including beta-carotene, vitamin E, vitamin C and selenium have shown no effect on cancer risk or have increased cancer risk. Supplementation with selenium or vitamin E does not reduce the risk of cardiovascular disease. Oxidative stress can be considered as either a cause or consequence of some diseases, stimulating drug development for potential antioxidant compounds for use as treatments.
Antioxidants have many industrial uses, such as preservatives in food and cosmetics and to prevent the degradation of rubber and gasoline.
Health effects.
Relation to diet.
Although some levels of antioxidant vitamins in the diet are required for good health, there is considerable doubt as to whether antioxidant supplements have anti-disease activity; and if they are actually beneficial, which antioxidant(s) are needed and in what amounts. Indeed, some authors argue that the hypothesis that antioxidants could prevent chronic diseases has now been disproved and that the idea was misguided from the beginning. Rather, dietary polyphenols may have non-antioxidant roles in minute concentrations that affect cell-to-cell signaling, receptor sensitivity, inflammatory enzyme activity or gene regulation.
For overall life expectancy, it has even been suggested that moderate levels of oxidative stress may increase lifespan in the worm "Caenorhabditis elegans", by inducing a protective response to increased levels of reactive oxygen species. The suggestion that increased life expectancy comes from increased oxidative stress conflicts with results seen in the yeast "Saccharomyces cerevisiae", and the situation in mammals is even less clear. Nevertheless, antioxidant supplements do not appear to increase life expectancy in humans.
Although antioxidants have been investigated for potential effects on neurodegenerative diseases such as Alzheimer's disease, Parkinson's disease, and amyotrophic lateral sclerosis, these studies have been inconclusive.
Medications.
Tirilazad mesylate is an anti-oxidant steroid derivative that inhibits the lipid peroxidation that is believed to play a key in neuronal death in stroke and head injury. It demonstrated activity in animal models of stroke. Human trials demonstrated no effect on mortality or other outcomes in subarachnoid haemorrhage, and worsened results in ischemic stroke.
Similarly, the designed antioxidant NXY-059 exhibited efficacy in animal models, but failed to improve stroke outcomes in a clinical trial. As of November 2014, other antioxidants are being studied as potential neuroprotectants.
Common pharmaceuticals (and supplements) with antioxidant properties may interfere with the efficacy of certain anticancer medication and radiation.
Physical exercise.
During exercise, oxygen consumption can increase by a factor of more than 10. However, no benefits for physical performance to athletes are seen with vitamin E supplementation and 6 weeks of vitamin E supplementation had no effect on muscle damage in ultramarathon runners. Some research suggests that supplementation with amounts as high as of vitamin C inhibits recovery. Other studies indicated that antioxidant supplementation may attenuate the cardiovascular benefits of exercise.
Adverse effects.
Relatively strong reducing acids can have antinutrient effects by binding to dietary minerals such as iron and zinc in the gastrointestinal tract and preventing them from being absorbed. Notable examples are oxalic acid, tannins and phytic acid, which are high in plant-based diets. Calcium and iron deficiencies are not uncommon in diets in developing countries where less meat is eaten and there is high consumption of phytic acid from beans and unleavened whole grain bread.
Nonpolar antioxidants such as eugenol—a major component of oil of cloves—have toxicity limits that can be exceeded with the misuse of undiluted essential oils. Toxicity associated with high doses of water-soluble antioxidants such as ascorbic acid are less of a concern, as these compounds can be excreted rapidly in urine. More seriously, very high doses of some antioxidants may have harmful long-term effects. The beta-carotene and Retinol Efficacy Trial (CARET) study of lung cancer patients found that smokers given supplements containing beta-carotene and vitamin A had increased rates of lung cancer. Subsequent studies confirmed these adverse effects.
These harmful effects may also be seen in non-smokers, as a recent meta-analysis including data from approximately 230,000 patients showed that β-carotene, vitamin A or vitamin E supplementation is associated with increased mortality but saw no significant effect from vitamin C. No health risk was seen when all the randomized controlled studies were examined together, but an increase in mortality was detected when only high-quality and low-bias risk trials were examined separately. As the majority of these low-bias trials dealt with either elderly people, or people with disease, these results may not apply to the general population. This meta-analysis was later repeated and extended by the same authors, with the new analysis published by the Cochrane Collaboration; confirming the previous results. These two publications are consistent with some previous meta-analyzes that also suggested that Vitamin E supplementation increased mortality, and that antioxidant supplements increased the risk of colon cancer. Beta-carotene may also increase lung cancer. Overall, the large number of clinical trials carried out on antioxidant supplements suggest that either these products have no effect on health, or that they cause a small increase in mortality in elderly or vulnerable populations.
While antioxidant supplementation is widely used in attempts to prevent the development of cancer, antioxidants may interfere with cancer treatments, since the environment of cancer cells causes high levels of oxidative stress, making these cells more susceptible to the further oxidative stress induced by treatments. As a result, by reducing the redox stress in cancer cells, antioxidant supplements (and pharmaceuticals) could decrease the effectiveness of radiotherapy and chemotherapy. On the other hand, other reviews have suggested that antioxidants could reduce side effects or increase survival times.
Oxidative challenge in biology.
A paradox in metabolism is that, while the vast majority of complex life on Earth requires oxygen for its existence, oxygen is a highly reactive molecule that damages living organisms by producing reactive oxygen species. Consequently, organisms contain a complex network of antioxidant metabolites and enzymes that work together to prevent oxidative damage to cellular components such as DNA, proteins and lipids. In general, antioxidant systems either prevent these reactive species from being formed, or remove them before they can damage vital components of the cell. However, reactive oxygen species also have useful cellular functions, such as redox signaling. Thus, the function of antioxidant systems is not to remove oxidants entirely, but instead to keep them at an optimum level.
The reactive oxygen species produced in cells include hydrogen peroxide (HO), hypochlorous acid (HClO), and free radicals such as the hydroxyl radical (·OH) and the superoxide anion (O). The hydroxyl radical is particularly unstable and will react rapidly and non-specifically with most biological molecules. This species is produced from hydrogen peroxide in metal-catalyzed redox reactions such as the Fenton reaction. These oxidants can damage cells by starting chemical chain reactions such as lipid peroxidation, or by oxidizing DNA or proteins. Damage to DNA can cause mutations and possibly cancer, if not reversed by DNA repair mechanisms, while damage to proteins causes enzyme inhibition, denaturation and protein degradation.
The use of oxygen as part of the process for generating metabolic energy produces reactive oxygen species. In this process, the superoxide anion is produced as a by-product of several steps in the electron transport chain. Particularly important is the reduction of coenzyme Q in complex III, since a highly reactive free radical is formed as an intermediate (Q·). This unstable intermediate can lead to electron "leakage", when electrons jump directly to oxygen and form the superoxide anion, instead of moving through the normal series of well-controlled reactions of the electron transport chain. Peroxide is also produced from the oxidation of reduced flavoproteins, such as complex I. However, although these enzymes can produce oxidants, the relative importance of the electron transfer chain to other processes that generate peroxide is unclear. In plants, algae, and cyanobacteria, reactive oxygen species are also produced during photosynthesis, particularly under conditions of high light intensity. This effect is partly offset by the involvement of carotenoids in photoinhibition, and in algae and cyanobacteria, by large amount of iodide and selenium, which involves these antioxidants reacting with over-reduced forms of the photosynthetic reaction centres to prevent the production of reactive oxygen species.
Metabolites.
Antioxidants are classified into two broad divisions, depending on whether they are soluble in water (hydrophilic) or in lipids (lipophilic). In general, water-soluble antioxidants react with oxidants in the cell cytosol and the blood plasma, while lipid-soluble antioxidants protect cell membranes from lipid peroxidation. These compounds may be synthesized in the body or obtained from the diet. The different antioxidants are present at a wide range of concentrations in body fluids and tissues, with some such as glutathione or ubiquinone mostly present within cells, while others such as uric acid are more evenly distributed (see table below). Some antioxidants are only found in a few organisms and these compounds can be important in pathogens and can be virulence factors.
The relative importance and interactions between these different antioxidants is a very complex question, with the various metabolites and enzyme systems having synergistic and interdependent effects on one another. The action of one antioxidant may therefore depend on the proper function of other members of the antioxidant system. The amount of protection provided by any one antioxidant will also depend on its concentration, its reactivity towards the particular reactive oxygen species being considered, and the status of the antioxidants with which it interacts.
Some compounds contribute to antioxidant defense by chelating transition metals and preventing them from catalyzing the production of free radicals in the cell. Particularly important is the ability to sequester iron, which is the function of iron-binding proteins such as transferrin and ferritin. Selenium and zinc are commonly referred to as "antioxidant nutrients", but these chemical elements have no antioxidant action themselves and are instead required for the activity of some antioxidant enzymes, as is discussed below.
Uric acid.
Uric acid is by far the highest concentration antioxidant in human blood. Uric acid (UA) is an antioxidant oxypurine produced from xanthine by the enzyme xanthine oxidase, and is an intermediate product of purine metabolism. In almost all land animals, urate oxidase further catalyzes the oxidation of uric acid to allantoin, but in humans and most higher primates, the urate oxidase gene is nonfunctional, so that UA is not further broken down. The evolutionary reasons for this loss of urate conversion to allantoin remain the topic of active speculation. The antioxidant effects of uric acid have led researchers to suggest this mutation was beneficial to early primates and humans. Studies of high altitude acclimatization support the hypothesis that urate acts as an antioxidant by mitigating the oxidative stress caused by high-altitude hypoxia. In animal studies that investigate diseases facilitated by oxidative stress, introduction of UA both prevents the disease or reduces it, leading researchers to propose this is due to UA's antioxidant properties. Studies of UA's antioxidant mechanism support this proposal.
With respect to multiple sclerosis, Gwen Scott explains the significance of uric acid as an antioxidant by proposing that "Serum UA levels are inversely associated with the incidence of MS in humans because MS patients have low serum UA levels and individuals with hyperuricemia (gout) rarely develop the disease. Moreover, the administration of UA is therapeutic in experimental allergic encephalomyelitis (EAE), an animal model of MS." In sum, while the mechanism of UA as an antioxidant is well-supported, the claim that its levels affect MS risk is still controversial, and requires more research.
Likewise, UA has the highest concentration of any blood antioxidant and provides over half of the total antioxidant capacity of human serum. Uric acid's antioxidant activities are also complex, given that it does not react with some oxidants, such as superoxide, but does act against peroxynitrite, peroxides, and hypochlorous acid. Concerns over elevated UA's contribution to gout must be considered as one of many risk factors. By itself, UA-related risk of gout at high levels (415–530 μmol/L) is only 0.5% per year with an increase to 4.5% per year at UA supersaturation levels (535+ μmol/L). Many of these aforementioned studies determined UA's antioxidant actions within normal physiological levels, and some found antioxidant activity at levels as high as 285 μmol/L.
Vitamin C.
Ascorbic acid or "vitamin C" is a monosaccharide oxidation-reduction (redox) catalyst found in both animals and plants. As one of the enzymes needed to make ascorbic acid has been lost by mutation during primate evolution, humans must obtain it from the diet; it is therefore a vitamin. Most other animals are able to produce this compound in their bodies and do not require it in their diets. Ascorbic acid is required for the conversion of the procollagen to collagen by oxidizing proline residues to hydroxyproline. In other cells, it is maintained in its reduced form by reaction with glutathione, which can be catalysed by protein disulfide isomerase and glutaredoxins. Ascorbic acid is a redox catalyst which can reduce, and thereby neutralize, reactive oxygen species such as hydrogen peroxide. In addition to its direct antioxidant effects, ascorbic acid is also a substrate for the redox enzyme ascorbate peroxidase, a function that is particularly important in stress resistance in plants. Ascorbic acid is present at high levels in all parts of plants and can reach concentrations of 20 millimolar in chloroplasts.
Glutathione.
Glutathione is a cysteine-containing peptide found in most forms of aerobic life. It is not required in the diet and is instead synthesized in cells from its constituent amino acids. Glutathione has antioxidant properties since the thiol group in its cysteine moiety is a reducing agent and can be reversibly oxidized and reduced. In cells, glutathione is maintained in the reduced form by the enzyme glutathione reductase and in turn reduces other metabolites and enzyme systems, such as ascorbate in the glutathione-ascorbate cycle, glutathione peroxidases and glutaredoxins, as well as reacting directly with oxidants. Due to its high concentration and its central role in maintaining the cell's redox state, glutathione is one of the most important cellular antioxidants. In some organisms glutathione is replaced by other thiols, such as by mycothiol in the Actinomycetes, bacillithiol in some Gram-positive bacteria, or by trypanothione in the Kinetoplastids.
Melatonin.
Melatonin is a powerful antioxidant. Melatonin easily crosses cell membranes and the blood–brain barrier. Unlike other antioxidants, melatonin does not undergo redox cycling, which is the ability of a molecule to undergo repeated reduction and oxidation. Redox cycling may allow other antioxidants (such as vitamin C) to act as pro-oxidants and promote free radical formation. Melatonin, once oxidized, cannot be reduced to its former state because it forms several stable end-products upon reacting with free radicals. Therefore, it has been referred to as a terminal (or suicidal) antioxidant.
Vitamin E.
Vitamin E is the collective name for a set of eight related tocopherols and tocotrienols, which are fat-soluble vitamins with antioxidant properties. Of these, α-tocopherol has been most studied as it has the highest bioavailability, with the body preferentially absorbing and metabolising this form.
It has been claimed that the α-tocopherol form is the most important lipid-soluble antioxidant, and that it protects membranes from oxidation by reacting with lipid radicals produced in the lipid peroxidation chain reaction. This removes the free radical intermediates and prevents the propagation reaction from continuing. This reaction produces oxidised α-tocopheroxyl radicals that can be recycled back to the active reduced form through reduction by other antioxidants, such as ascorbate, retinol or ubiquinol. This is in line with findings showing that α-tocopherol, but not water-soluble antioxidants, efficiently protects glutathione peroxidase 4 (GPX4)-deficient cells from cell death. GPx4 is the only known enzyme that efficiently reduces lipid-hydroperoxides within biological membranes.
However, the roles and importance of the various forms of vitamin E are presently unclear, and it has even been suggested that the most important function of α-tocopherol is as a signaling molecule, with this molecule having no significant role in antioxidant metabolism. The functions of the other forms of vitamin E are even less well-understood, although γ-tocopherol is a nucleophile that may react with electrophilic mutagens, and tocotrienols may be important in protecting neurons from damage.
Pro-oxidant activities.
Antioxidants that are reducing agents can also act as pro-oxidants. For example, vitamin C has antioxidant activity when it reduces oxidizing substances such as hydrogen peroxide, however, it will also reduce metal ions that generate free radicals through the Fenton reaction.
The relative importance of the antioxidant and pro-oxidant activities of antioxidants is an area of current research, but vitamin C, which exerts its effects as a vitamin by oxidizing polypeptides, appears to have a mostly antioxidant action in the human body. However, less data is available for other dietary antioxidants, such as vitamin E, or the polyphenols. Likewise, the pathogenesis of diseases involving hyperuricemia likely involve uric acid's direct and indirect pro-oxidant properties.
That is, paradoxically, agents which are normally considered antioxidants can act as conditional pro-oxidants and actually increase oxidative stress. Besides ascorbate, medically important conditional pro-oxidants include uric acid and sulfhydryl amino acids such as homocysteine. Typically, this involves some transition-series metal such as copper or iron as catalyst. The potential role of the pro-oxidant role of uric acid in (e.g.) atherosclerosis and ischemic stroke is considered above. Another example is the postulated role of homocysteine in atherosclerosis.
Negative health effects.
Some antioxidant supplements may promote disease and increase mortality in humans under certain conditions. Hypothetically, free radicals induce an endogenous response that protects against exogenous radicals (and possibly other toxic compounds). Free radicals may increase life span. This increase may be prevented by antioxidants, providing direct evidence that toxic radicals may mitohormetically exert life extending and health promoting effects.
Enzyme systems.
As with the chemical antioxidants, cells are protected against oxidative stress by an interacting network of antioxidant enzymes. Here, the superoxide released by processes such as oxidative phosphorylation is first converted to hydrogen peroxide and then further reduced to give water. This detoxification pathway is the result of multiple enzymes, with superoxide dismutases catalysing the first step and then catalases and various peroxidases removing hydrogen peroxide. As with antioxidant metabolites, the contributions of these enzymes to antioxidant defenses can be hard to separate from one another, but the generation of transgenic mice lacking just one antioxidant enzyme can be informative.
Superoxide dismutase, catalase and peroxiredoxins.
Superoxide dismutases (SODs) are a class of closely related enzymes that catalyze the breakdown of the superoxide anion into oxygen and hydrogen peroxide. SOD enzymes are present in almost all aerobic cells and in extracellular fluids. Superoxide dismutase enzymes contain metal ion cofactors that, depending on the isozyme, can be copper, zinc, manganese or iron. In humans, the copper/zinc SOD is present in the cytosol, while manganese SOD is present in the mitochondrion. There also exists a third form of SOD in extracellular fluids, which contains copper and zinc in its active sites. The mitochondrial isozyme seems to be the most biologically important of these three, since mice lacking this enzyme die soon after birth. In contrast, the mice lacking copper/zinc SOD (Sod1) are viable but have numerous pathologies and a reduced lifespan (see article on superoxide), while mice without the extracellular SOD have minimal defects (sensitive to hyperoxia). In plants, SOD isozymes are present in the cytosol and mitochondria, with an iron SOD found in chloroplasts that is absent from vertebrates and yeast.
Catalases are enzymes that catalyse the conversion of hydrogen peroxide to water and oxygen, using either an iron or manganese cofactor. This protein is localized to peroxisomes in most eukaryotic cells. Catalase is an unusual enzyme since, although hydrogen peroxide is its only substrate, it follows a ping-pong mechanism. Here, its cofactor is oxidised by one molecule of hydrogen peroxide and then regenerated by transferring the bound oxygen to a second molecule of substrate. Despite its apparent importance in hydrogen peroxide removal, humans with genetic deficiency of catalase — "acatalasemia" — or mice genetically engineered to lack catalase completely, suffer few ill effects.
Peroxiredoxins are peroxidases that catalyze the reduction of hydrogen peroxide, organic hydroperoxides, as well as peroxynitrite. They are divided into three classes: typical 2-cysteine peroxiredoxins; atypical 2-cysteine peroxiredoxins; and 1-cysteine peroxiredoxins. These enzymes share the same basic catalytic mechanism, in which a redox-active cysteine (the peroxidatic cysteine) in the active site is oxidized to a sulfenic acid by the peroxide substrate. Over-oxidation of this cysteine residue in peroxiredoxins inactivates these enzymes, but this can be reversed by the action of sulfiredoxin. Peroxiredoxins seem to be important in antioxidant metabolism, as mice lacking peroxiredoxin 1 or 2 have shortened lifespan and suffer from hemolytic anaemia, while plants use peroxiredoxins to remove hydrogen peroxide generated in chloroplasts.
Thioredoxin and glutathione systems.
The thioredoxin system contains the 12-kDa protein thioredoxin and its companion thioredoxin reductase. Proteins related to thioredoxin are present in all sequenced organisms. Plants, such as "Arabidopsis thaliana," have a particularly great diversity of isoforms. The active site of thioredoxin consists of two neighboring cysteines, as part of a highly conserved CXXC motif, that can cycle between an active dithiol form (reduced) and an oxidized disulfide form. In its active state, thioredoxin acts as an efficient reducing agent, scavenging reactive oxygen species and maintaining other proteins in their reduced state. After being oxidized, the active thioredoxin is regenerated by the action of thioredoxin reductase, using NADPH as an electron donor.
The glutathione system includes glutathione, glutathione reductase, glutathione peroxidases and glutathione "S"-transferases. This system is found in animals, plants and microorganisms. Glutathione peroxidase is an enzyme containing four selenium-cofactors that catalyzes the breakdown of hydrogen peroxide and organic hydroperoxides. There are at least four different glutathione peroxidase isozymes in animals. Glutathione peroxidase 1 is the most abundant and is a very efficient scavenger of hydrogen peroxide, while glutathione peroxidase 4 is most active with lipid hydroperoxides. Surprisingly, glutathione peroxidase 1 is dispensable, as mice lacking this enzyme have normal lifespans, but they are hypersensitive to induced oxidative stress. In addition, the glutathione "S"-transferases show high activity with lipid peroxides. These enzymes are at particularly high levels in the liver and also serve in detoxification metabolism.
Oxidative stress in disease.
Oxidative stress is thought to contribute to the development of a wide range of diseases including Alzheimer's disease, Parkinson's disease, the pathologies caused by diabetes, rheumatoid arthritis, and neurodegeneration in motor neuron diseases. In many of these cases, it is unclear if oxidants trigger the disease, or if they are produced as a secondary consequence of the disease and from general tissue damage; One case in which this link is particularly well-understood is the role of oxidative stress in cardiovascular disease. Here, low density lipoprotein (LDL) oxidation appears to trigger the process of atherogenesis, which results in atherosclerosis, and finally cardiovascular disease.
Oxidative damage in DNA can cause cancer. Several antioxidant enzymes such as superoxide dismutase, catalase, glutathione peroxidase, glutathione reductase, glutathione S-transferase etc. protect DNA from oxidative stress. It has been proposed that polymorphisms in these enzymes are associated with DNA damage and subsequently the individual's risk of cancer susceptibility.
A low calorie diet extends median and maximum lifespan in many animals. This effect may involve a reduction in oxidative stress. While there is some evidence to support the role of oxidative stress in aging in model organisms such as "Drosophila melanogaster" and "Caenorhabditis elegans", the evidence in mammals is less clear. Indeed, a 2009 review of experiments in mice concluded that almost all manipulations of antioxidant systems had no effect on aging. Diets high in fruit and vegetables, which are high in antioxidants, promote health and reduce the effects of aging; antioxidant vitamin supplementation has no detectable effect on the aging process, so the effects of fruit and vegetables may be unrelated to their antioxidant contents. One reason for this might be the fact that consuming antioxidant molecules such as polyphenols and vitamin E will produce changes in other parts of metabolism, and it may be these other effects that are the real reason these compounds are important in human nutrition.
Uses in technology.
Food preservatives.
Antioxidants are used as food additives to help guard against food deterioration. Exposure to oxygen and sunlight are the two main factors in the oxidation of food, so food is preserved by keeping in the dark and sealing it in containers or even coating it in wax, as with cucumbers. However, as oxygen is also important for plant respiration, storing plant materials in anaerobic conditions produces unpleasant flavors and unappealing colors. Consequently, packaging of fresh fruits and vegetables contains an ~8% oxygen atmosphere. Antioxidants are an especially important class of preservatives as, unlike bacterial or fungal spoilage, oxidation reactions still occur relatively rapidly in frozen or refrigerated food. These preservatives include natural antioxidants such as ascorbic acid (AA, E300) and tocopherols (E306), as well as synthetic antioxidants such as propyl gallate (PG, E310), tertiary butylhydroquinone (TBHQ), butylated hydroxyanisole (BHA, E320) and butylated hydroxytoluene (BHT, E321).
The most common molecules attacked by oxidation are unsaturated fats; oxidation causes them to turn rancid. Since oxidized lipids are often discolored and usually have unpleasant tastes such as metallic or sulfurous flavors, it is important to avoid oxidation in fat-rich foods. Thus, these foods are rarely preserved by drying; instead, they are preserved by smoking, salting or fermenting. Even less fatty foods such as fruits are sprayed with sulfurous antioxidants prior to air drying. Oxidation is often catalyzed by metals, which is why fats such as butter should never be wrapped in aluminium foil or kept in metal containers. Some fatty foods such as olive oil are partially protected from oxidation by their natural content of antioxidants, but remain sensitive to photooxidation. Antioxidant preservatives are also added to fat based cosmetics such as lipstick and moisturizers to prevent rancidity.
Industrial uses.
Antioxidants are frequently added to industrial products. A common use is as stabilizers in fuels and lubricants to prevent oxidation, and in gasolines to prevent the polymerization that leads to the formation of engine-fouling residues. In 2007, the worldwide market for industrial antioxidants had a total volume of around 0.88 million tons. This created a revenue of circa 3.7 billion US-dollars (2.4 billion Euros).
They are widely used to prevent the oxidative degradation of polymers such as rubbers, plastics and adhesives that causes a loss of strength and flexibility in these materials. Polymers containing double bonds in their main chains, such as natural rubber and polybutadiene, are especially susceptible to oxidation and ozonolysis. They can be protected by antiozonants. Solid polymer products start to crack on exposed surfaces as the material degrades and the chains break. The mode of cracking varies between oxygen and ozone attack, the former causing a "crazy paving" effect, while ozone attack produces deeper cracks aligned at right angles to the tensile strain in the product. Oxidation and UV degradation are also frequently linked, mainly because UV radiation creates free radicals by bond breakage. The free radicals then react with oxygen to produce peroxy radicals which cause yet further damage, often in a chain reaction. Other polymers susceptible to oxidation include polypropylene and polyethylene. The former is more sensitive owing to the presence of secondary carbon atoms present in every repeat unit. Attack occurs at this point because the free radical formed is more stable than one formed on a primary carbon atom. Oxidation of polyethylene tends to occur at weak links in the chain, such as branch points in low density polyethylene.
Measurement and levels in food.
Antioxidant vitamins are found in vegetables, fruits, eggs, legumes and nuts. Vitamins A, C or E can be destroyed by long-term storage or prolonged cooking. The effects of cooking and food processing are complex, as these processes can also increase the bioavailability of antioxidants, such as some carotenoids in vegetables. Processed food contains fewer antioxidant vitamins than fresh and uncooked foods, as preparation exposes food to heat and oxygen.
Other antioxidants are not vitamins and are instead made in the body. For example, ubiquinol (coenzyme Q) is poorly absorbed from the gut and is made in humans through the mevalonate pathway. Another example is glutathione, which is made from amino acids. As any glutathione in the gut is broken down to free cysteine, glycine and glutamic acid before being absorbed, even large oral doses have little effect on the concentration of glutathione in the body. Although large amounts of sulfur-containing amino acids such as acetylcysteine can increase glutathione, no evidence exists that eating high levels of these glutathione precursors is beneficial for healthy adults. Supplying more of these precursors may be useful as part of the treatment of some diseases, such as acute respiratory distress syndrome, protein-energy malnutrition, or preventing the liver damage produced by paracetamol overdose.
Other compounds in the diet can alter the levels of antioxidants by acting as pro-oxidants whereby consuming the compound may cause oxidative stress, possibly resulting in higher levels of antioxidant enzymes.
Invalidation of ORAC.
Measurement of antioxidant content in food is not a straightforward process, as this is a diverse group of compounds with different reactivities to various reactive oxygen species. In food science, the oxygen radical absorbance capacity (ORAC) used to be the industry standard for antioxidant strength of whole foods, juices and food additives. However, the United States Department of Agriculture (USDA) withdrew these ratings in 2012 as biologically invalid, stating that no physiological proof "in vivo" existed to support the free-radical theory, especially for polyphenols. Consequently, the ORAC method, derived only from "in vitro" experiments, is no longer considered relevant to human diets or biology.
Alternative "in vitro" measurements include the Folin-Ciocalteu reagent, and the Trolox equivalent antioxidant capacity assay.
History.
As part of their adaptation from marine life, terrestrial plants began producing non-marine antioxidants such as ascorbic acid (vitamin C), polyphenols and tocopherols. The evolution of angiosperm plants between 50 and 200 million years ago resulted in the development of many antioxidant pigments – particularly during the Jurassic period – as chemical defences against reactive oxygen species that are byproducts of photosynthesis. Originally, the term antioxidant specifically referred to a chemical that prevented the consumption of oxygen. In the late 19th and early 20th centuries, extensive study concentrated on the use of antioxidants in important industrial processes, such as the prevention of metal corrosion, the vulcanization of rubber, and the polymerization of fuels in the fouling of internal combustion engines.
Early research on the role of antioxidants in biology focused on their use in preventing the oxidation of unsaturated fats, which is the cause of rancidity. Antioxidant activity could be measured simply by placing the fat in a closed container with oxygen and measuring the rate of oxygen consumption. However, it was the identification of vitamins A, C, and E as antioxidants that revolutionized the field and led to the realization of the importance of antioxidants in the biochemistry of living organisms. The possible mechanisms of action of antioxidants were first explored when it was recognized that a substance with anti-oxidative activity is likely to be one that is itself readily oxidized. Research into how vitamin E prevents the process of lipid peroxidation led to the identification of antioxidants as reducing agents that prevent oxidative reactions, often by scavenging reactive oxygen species before they can damage cells.

</doc>
<doc id="3292" url="https://en.wikipedia.org/wiki?curid=3292" title="Brass">
Brass

Brass is a metal alloy made of copper and zinc; the proportions of zinc and copper can be varied to create a range of brasses with varying properties. It is a substitutional alloy: atoms of the two constituents may replace each other within the same crystal structure.
By comparison, bronze is principally an alloy of copper and tin. However, bronze and brass may also include small proportions of a range of other elements including arsenic, phosphorus, aluminium, manganese, and silicon. The term is also applied to a variety of brasses, and the distinction is largely historical. Modern practice in museums and archaeology increasingly avoids both terms for historical objects in favour of the all-embracing "copper alloy".
Brass is used for decoration for its bright gold-like appearance; for applications where low friction is required such as locks, gears, bearings, doorknobs, ammunition casings and valves; for plumbing and electrical applications; and extensively in brass musical instruments such as horns and bells where a combination of high workability (historically with hand tools) and durability is desired. It is also used in zippers. Brass is often used in situations in which it is important that sparks not be struck, such as in fittings and tools around explosive gases.
Properties.
Brass has higher malleability than bronze or zinc. The relatively low melting point of brass (900 to 940 °C, 1652 to 1724 °F, depending on composition) and its flow characteristics make it a relatively easy material to cast. By varying the proportions of copper and zinc, the properties of the brass can be changed, allowing hard and soft brasses. The density of brass is approximately .303 lb/cubic inch, 8.4 to 8.73 grams per cubic centimetre.
Today, almost 90% of all brass alloys are recycled. Because brass is not ferromagnetic, it can be separated from ferrous scrap by passing the scrap near a powerful magnet. Brass scrap is collected and transported to the foundry where it is melted and recast into billets. Billets are heated and extruded into the desired form and size.
Aluminium makes brass stronger and more corrosion-resistant. Aluminium also causes a highly beneficial hard layer of aluminium oxide (AlO) to be formed on the surface that is thin, transparent and self-healing. Tin has a similar effect and finds its use especially in seawater applications (naval brasses). Combinations of iron, aluminium, silicon and manganese make brass wear and tear resistant.
Lead content.
To enhance the machinability of brass, lead is often added in concentrations of around 2%. Since lead has a lower melting point than the other constituents of the brass, it tends to migrate towards the grain boundaries in the form of globules as it cools from casting. The pattern the globules form on the surface of the brass increases the available lead surface area which in turn affects the degree of leaching. In addition, cutting operations can smear the lead globules over the surface. These effects can lead to significant lead leaching from brasses of comparatively low lead content.
Silicon is an alternative to lead; however, when silicon is used in a brass alloy, the scrap must never be mixed with leaded brass scrap because of contamination and safety problems.
In October 1999 the California State Attorney General sued 13 key manufacturers and distributors over lead content. In laboratory tests, state researchers found the average brass key, new or old, exceeded the California Proposition 65 limits by an average factor of 19, assuming handling twice a day. In April 2001 manufacturers agreed to reduce lead content to 1.5%, or face a requirement to warn consumers about lead content. Keys plated with other metals are not affected by the settlement, and may continue to use brass alloys with higher percentage of lead content.
Also in California, lead-free materials must be used for "each component that comes into contact with the wetted surface of pipes and pipe fittings, plumbing fittings and fixtures." On January 1, 2010, the maximum amount of lead in "lead-free brass" in California was reduced from 4% to 0.25% lead. The common practice of using pipes for electrical grounding is discouraged, as it accelerates lead corrosion.
Corrosion-resistant brass for harsh environments.
 The so-called dezincification resistant (DZR or DR) brasses, sometimes referred to as CR (corrosion resistant) brasses, are used where there is a large corrosion risk and where normal brasses do not meet the standards. Applications with high water temperatures, chlorides present, or deviating water qualities (soft water) play a role. DZR-brass is excellent in water boiler systems. This brass alloy must be produced with great care, with special attention placed on a balanced composition and proper production temperatures and parameters to avoid long-term failures.
Use in musical instruments.
The malleability and traditionally attributed acoustic properties of brass have made it the metal of choice for musical instruments such as the trombone, tuba, trumpet, cornet, baritone horn, euphonium, tenor horn, and French horn which are collectively known as brass instruments. Even though the saxophone is classified as a woodwind instrument and the harmonica is a free reed aerophone, both are also often made from brass. In organ pipes of the reed family, brass strips (called tongues) are used as the reeds, which beat against the shallot (or beat "through" the shallot in the case of a "free" reed). Although not part of the brass section, snare drums are also sometimes made of brass. Some parts on electric guitars are also made from brass, especially inertia blocks on tremolo systems for its tonal properties, and for string nuts and saddles for both tonal properties and its low friction.
Germicidal and antimicrobial applications.
The copper in brass makes brass germicidal. Depending upon the type and concentration of pathogens and the medium they are in, brass kills these microorganisms within a few minutes to hours of contact.
The bactericidal properties of brass have been observed for centuries and were confirmed in the laboratory in 1983. Subsequent experiments by research groups around the world reconfirmed the antimicrobial efficacy of brass, as well as copper and other copper alloys (see Antimicrobial copper-alloy touch surfaces). Extensive structural membrane damage to bacteria was noted after being exposed to copper.
In 2007, U.S. Department of Defense’s Telemedicine and Advanced Technology Research Center (TATRC) began to study the antimicrobial properties of copper alloys, including four brasses (C87610, C69300, C26000, C46400) in a multi-site clinical hospital trial conducted at the Memorial Sloan-Kettering Cancer Center (New York City), the Medical University of South Carolina, and the Ralph H. Johnson VA Medical Center (South Carolina). Commonly touched items, such as bed rails, over-the-bed tray tables, chair arms, nurse's call buttons, IV poles, etc. were retrofitted with antimicrobial copper alloys in certain patient rooms (i.e., the "coppered" rooms) in the Intensive Care Unit (ICU). Early results disclosed in 2011 indicate that the coppered rooms demonstrated a 97% reduction in surface pathogens versus the non-coppered rooms. This reduction is the same level achieved by "terminal" cleaning regimens conducted after patients vacate their rooms. Furthermore, of critical importance to health care professionals, the preliminary results indicated that patients in the coppered ICU rooms had a 40.4% lower risk of contracting a hospital acquired infection versus patients in non-coppered ICU rooms. The U.S. Department of Defense investigation contract, which is ongoing, will also evaluate the effectiveness of copper alloy touch surfaces to prevent the transfer of microbes to patients and the transfer of microbes from patients to touch surfaces, as well as the potential efficacy of copper-alloy based components to improve indoor air quality.
In the U.S., the Environmental Protection Agency regulates the registration of antimicrobial products. After extensive antimicrobial testing according to the Agency’s stringent test protocols, 355 copper alloys, including many brasses, were found to kill more than 99.9% of methicillin-resistant "Staphylococcus aureus" (MRSA), "E. coli" O157:H7, "Pseudomonas aeruginosa", "Staphylococcus aureus", "Enterobacter aerogenes", and vancomycin-resistant "Enterococci" (VRE) within two hours of contact. Normal tarnishing was found not to impair antimicrobial effectiveness.
Antimicrobial tests have also revealed significant reductions of MRSA as well as two strains of epidemic MRSA (EMRSA-1 and EMRSA-16) on brass (C24000 with 80% Cu) at room temperature (22 °C) within three hours. Complete kills of the pathogens were observed within hours. These tests were performed under wet exposure conditions. The kill timeframes, while impressive, are nevertheless longer than for pure copper, where kill timeframes ranged between 45 to 90 minutes.
A novel assay that mimics dry bacterial exposure to touch surfaces was developed because this test method is thought to more closely replicate real world touch surface exposure conditions. In these conditions, copper alloy surfaces were found to kill several million Colony Forming Units of "Escherichia coli" within minutes. This observation, and the fact that kill timeframes shorten as the percentage of copper in an alloy increases, is proof that copper is the ingredient in brass and other copper alloys that kills the microbes.
The mechanisms of antimicrobial action by copper and its alloys, including brass, is a subject of intense and ongoing investigation. It is believed that the mechanisms are multifaceted and include the following: 1) Potassium or glutamate leakage through the outer membrane of bacteria; 2) Osmotic balance disturbances; 3) Binding to proteins that do not require or utilize copper; 4) Oxidative stress by hydrogen peroxide generation.
Research is being conducted at this time to determine whether brass, copper, and other copper alloys can help to reduce cross contamination in public facilities and reduce the incidence of nosocomial infections (hospital acquired infections) in healthcare facilities.
Also, owing to its antimicrobial/algaecidal properties that prevent biofouling, in conjunction with its strong structural and corrosion-resistant benefits for marine environments, brass alloy netting cages are currently being deployed in commercial-scale aquaculture operations in Asia, South America, and the USA.
Season cracking.
Brass is susceptible to stress corrosion cracking, especially from ammonia or substances containing or releasing ammonia. The problem is sometimes known as season cracking after it was first discovered in brass cartridge cases used for rifle ammunition during the 1920s in the British Indian Army. The problem was caused by high residual stresses from cold forming of the cases during manufacture, together with chemical attack from traces of ammonia in the atmosphere. The cartridges were stored in stables and the ammonia concentration rose during the hot summer months, thus initiating brittle cracks. The problem was resolved by annealing the cases, and storing the cartridges elsewhere.
History.
Although forms of brass have been in use since prehistory, its true nature as a copper-zinc alloy was not understood until the post medieval period because the zinc vapor which reacted with copper to make brass was not recognised as a metal. The King James Bible makes many references to "brass". The Shakespearean English form of the word 'brass' can mean any bronze alloy, or copper, rather than the strict modern definition of brass. The earliest brasses may have been natural alloys made by smelting zinc-rich copper ores. By the Roman period brass was being deliberately produced from metallic copper and zinc minerals using the cementation process and variations on this method continued until the mid-19th century. It was eventually replaced by speltering, the direct alloying of copper and zinc metal which was introduced to Europe in the 16th century.
Early copper zinc alloys.
In West Asia and the Eastern Mediterranean early copper zinc alloys are now known in small numbers from a number of third millennium BC sites in the Aegean, Iraq, the United Arab Emirates, Kalmykia, Turkmenistan and Georgia and from 2nd Millennium BC sites in West India, Uzbekistan, Iran, Syria, Iraq and Israel. However, isolated examples of copper-zinc alloys are known in China from as early as the 5th Millennium BC.
The compositions of these early "brass" objects are highly variable and most have zinc contents of between 5% and 15% wt which is lower than in brass produced by cementation. These may be "natural alloys" manufactured by smelting zinc rich copper ores in redox conditions. Many have similar tin contents to contemporary bronze artefacts and it is possible that some copper-zinc alloys were accidental and perhaps not even distinguished from copper. However the large number of copper-zinc alloys now known suggests that at least some were deliberately manufactured and many have zinc contents of more than 12% wt which would have resulted in a distinctive golden color.
By the 8th–7th century BC Assyrian cuneiform tablets mention the exploitation of the "copper of the mountains" and this may refer to "natural" brass. "Oreikhalkon" (mountain copper), the Ancient Greek translation of this term, was later adapted to the Latin "aurichalcum" meaning "golden copper" which became the standard term for brass. In the 4th century BC Plato knew "orichalkos" as rare and nearly as valuable as gold and Pliny describes how "aurichalcum" had come from Cypriot ore deposits which had been exhausted by the 1st century AD. X-ray fluorescence analysis of 39 orichalcum ingots recovered from a 2,600-year-old shipwreck off Sicily found them to be an alloy made with 75-80 percent copper, 15-20 percent zinc and small percentages of nickel, lead and iron.
Brass making in the Roman World.
During the later part of first millennium BC the use of brass spread across a wide geographical area from Britain and Spain in the west to Iran, and India in the east. This seems to have been encouraged by exports and influence from the Middle East and eastern Mediterranean where deliberate production of brass from metallic copper and zinc ores had been introduced. The 4th century BC writer Theopompus, quoted by Strabo, describes how heating earth from Andeira in Turkey produced "droplets of false silver", probably metallic zinc, which could be used to turn copper into oreichalkos. In the 1st century BC the Greek Dioscorides seems to have recognised a link between zinc minerals and brass describing how Cadmia (zinc oxide) was found on the walls of furnaces used to heat either zinc ore or copper and explaining that it can then be used to make brass.
By the first century BC brass was available in sufficient supply to use as coinage in Phrygia and Bithynia, and after the Augustan currency reform of 23 BC it was also used to make Roman "dupondii" and "sestertii". The uniform use of brass for coinage and military equipment across the Roman world may indicate a degree of state involvement in the industry, and brass even seems to have been deliberately boycotted by Jewish communities in Palestine because of its association with Roman authority.
Brass was produced by the cementation process where copper and zinc ore are heated together until zinc vapor is produced which reacts with the copper. There is good archaeological evidence for this process and crucibles used to produce brass by cementation have been found on Roman period sites including Xanten and Nidda in Germany, Lyon in France and at a number of sites in Britain. They vary in size from tiny acorn sized to large amphorae like vessels but all have elevated levels of zinc on the interior and are lidded. They show no signs of slag or metal prills suggesting that zinc minerals were heated to produce zinc vapor which reacted with metallic copper in a solid state reaction. The fabric of these crucibles is porous, probably designed to prevent a buildup of pressure, and many have small holes in the lids which may be designed to release pressure or to add additional zinc minerals near the end of the process. Dioscorides mentioned that zinc minerals were used for both the working and finishing of brass, perhaps suggesting secondary additions.
Brass made during the early Roman period seems to have varied between 20% to 28% wt zinc. The high content of zinc in coinage and brass objects declined after the first century AD and it has been suggested that this reflects zinc loss during recycling and thus an interruption in the production of new brass. However it is now thought this was probably a deliberate change in composition and overall the use of brass increases over this period making up around 40% of all copper alloys used in the Roman world by the 4th century AD.
Brass making in the medieval period.
Little is known about the production of brass during the centuries immediately after the collapse of the Roman Empire. Disruption in the trade of tin for bronze from Western Europe may have contributed to the increasing popularity of brass in the east and by the 6th–7th centuries AD over 90% of copper alloy artefacts from Egypt were made of brass. However other alloys such as low tin bronze were also used and they vary depending on local cultural attitudes, the purpose of the metal and access to zinc, especially between the Islamic and Byzantine world. Conversely the use of true brass seems to have declined in Western Europe during this period in favour of gunmetals and other mixed alloys but by about 1000 brass artefacts are found in Scandinavian graves in Scotland, brass was being used in the manufacture of coins in Northumbria and there is archaeological and historical evidence for the production of brass in Germany and The Low Countries, areas rich in calamine ore.
These places would remain important centres of brass making throughout the medieval period, especially Dinant. Brass objects are still collectively known as "dinanterie" in French. The baptismal font at St Bartholomew's Church, Liège in modern Belgium (before 1117) is an outstanding masterpiece of Romanesque brass casting, though also often described as bronze. The metal of the early 12th-century Gloucester Candlestick is unusual even by medieval standards in being a mixture of copper, zinc, tin, lead, nickel, iron, antimony and arsenic with an unusually large amount of silver, ranging from 22.5% in the base to 5.76% in the pan below the candle. The proportions of this mixture may suggest that the candlestick was made from a hoard of old coins, probably Late Roman. Latten is a term for decorative borders and similar objects cut from sheet metal, whether of brass or bronze. Aquamaniles were typically made in brass in both the European and Islamic worlds.
The cementation process continued to be used but literary sources from both Europe and the Islamic world seem to describe variants of a higher temperature liquid process which took place in open-topped crucibles. Islamic cementation seems to have used zinc oxide known as "tutiya" or tutty rather than zinc ores for brass-making, resulting in a metal with lower iron impurities. A number of Islamic writers and the 13th century Italian Marco Polo describe how this was obtained by sublimation from zinc ores and condensed onto clay or iron bars, archaeological examples of which have been identified at Kush in Iran. It could then be used for brass making or medicinal purposes. In 10th century Yemen al-Hamdani described how spreading al-iglimiya, probably zinc oxide, onto the surface of molten copper produced tutiya vapor which then reacted with the metal. The 13th century Iranian writer al-Kashani describes a more complex process whereby "tutiya" was mixed with raisins and gently roasted before being added to the surface of the molten metal. A temporary lid was added at this point presumably to minimise the escape of zinc vapor.
In Europe a similar liquid process in open-topped crucibles took place which was probably less efficient than the Roman process and the use of the term tutty by Albertus Magnus in the 13th century suggests influence from Islamic technology. The 12th century German monk Theophilus described how preheated crucibles were one sixth filled with powdered calamine and charcoal then topped up with copper and charcoal before being melted, stirred then filled again. The final product was cast, then again melted with calamine. It has been suggested that this second melting may have taken place at a lower temperature to allow more zinc to be absorbed. Albertus Magnus noted that the "power" of both calamine and tutty could evaporate and described how the addition of powdered glass could create a film to bind it to the metal. 
German brass making crucibles are known from Dortmund dating to the 10th century AD and from Soest and Schwerte in Westphalia dating to around the 13th century confirm Theophilus' account, as they are open-topped, although ceramic discs from Soest may have served as loose lids which may have been used to reduce zinc evaporation, and have slag on the interior resulting from a liquid process.
Brass in Africa.
Some of the most famous objects in African art are the lost wax castings of West Africa, mostly from what is now Nigeria, produced first by the Kingdom of Ife and then the Benin Empire. Though normally described as "bronzes", the Benin Bronze plaques, now mostly in the British Museum and other Western collections, and the large portrait heads such as the Ife Head of "heavily leaded zinc-brass" and the Bronze Head of Queen Idia, both also British Museum, are better described as brass, though of variable compositions. Work in brass or bronze continued to be important in Benin art and other West African traditions such as Akan goldweights, where the metal was regarded as a more valuable material than in Europe.
Brass making in Renaissance and post-medieval Europe.
The Renaissance saw important changes to both the theory and practice of brassmaking in Europe. By the 15th century there is evidence for the renewed use of lidded cementation crucibles at Zwickau in Germany. These large crucibles were capable of producing c.20 kg of brass. There are traces of slag and pieces of metal on the interior. Their irregular composition suggesting that this was a lower temperature not entirely liquid process. The crucible lids had small holes which were blocked with clay plugs near the end of the process presumably to maximise zinc absorption in the final stages. Triangular crucibles were then used to melt the brass for casting.
16th-century technical writers such as Biringuccio, Ercker and Agricola described a variety of cementation brass making techniques and came closer to understanding the true nature of the process noting that copper became heavier as it changed to brass and that it became more golden as additional calamine was added. Zinc metal was also becoming more commonplace By 1513 metallic zinc ingots from India and China were arriving in London and pellets of zinc condensed in furnace flues at the Rammelsberg in Germany were exploited for cementation brass making from around 1550.
Eventually it was discovered that metallic zinc could be alloyed with copper to make brass; a process known as speltering and by 1657 the German chemist Johann Glauber had recognised that calamine was "nothing else but unmeltable zinc" and that zinc was a "half ripe metal." However some earlier high zinc, low iron brasses such as the 1530 Wightman brass memorial plaque from England may have been made by alloying copper with "zinc" and include traces of cadmium similar those found in some zinc ingots from China.
However the cementation process was not abandoned and as late as the early 19th century there are descriptions of solid-state cementation in a domed furnace at around 900–950 °C and lasting up to 10 hours. The European brass industry continued to flourish into the post medieval period buoyed by innovations such as the 16th century introduction of water powered hammers for the production of battery wares. By 1559 the Germany city of Aachen alone was capable of producing 300,000 cwt of brass per year. After several false starts during the 16th and 17th centuries the brass industry was also established in England taking advantage of abundant supplies of cheap copper smelted in the new coal fired reverberatory furnace. In 1723 Bristol brass maker Nehemiah Champion patented the use of granulated copper, produced by pouring molten metal into cold water. This increased the surface area of the copper helping it react and zinc contents of up to 33% wt were reported using this new technique.
In 1738 Nehemiah's son William Champion patented a technique for the first industrial scale distillation of metallic zinc known as "distillation per descencum" or "the English process." This local zinc was used in speltering and allowed greater control over the zinc content of brass and the production of high-zinc copper alloys which would have been difficult or impossible to produce using cementation, for use in expensive objects such as scientific instruments, clocks, brass buttons and costume jewellery. However Champion continued to use the cheaper calamine cementation method to produce lower-zinc brass and the archaeological remains of bee-hive shaped cementation furnaces have been identified at his works at Warmley. By the mid-to-late 18th century developments in cheaper zinc distillation such as John-Jaques Dony's horizontal furnaces in Belgium and the reduction of tariffs on zinc as well as demand for corrosion-resistant high zinc alloys increased the popularity of speltering and as a result cementation was largely abandoned by the mid-19th century.

</doc>
<doc id="3295" url="https://en.wikipedia.org/wiki?curid=3295" title="Bonn">
Bonn

The Federal City of Bonn (; ) is a city on the banks of the Rhine and northwest of the
Siebengebirge (Seven Mountains) in the German state of North Rhine-Westphalia, with a population of 311,287 within its administrative limits. Bonn serves alongside the capital Berlin as the seat of government of Germany. The city is the second official seat and second official residence of the President of Germany, the Chancellor of Germany, the Bundesrat, and the first official seat and first official residence of six German federal ministries. Bonn is located in the southernmost part of the Rhine-Ruhr region, the largest metropolitan area of Germany, with over 11 million inhabitants.
Founded in the first century BC as a Roman settlement, Bonn is one of Germany's oldest cities. From 1597 to 1794, Bonn was the capital of the Electorate of Cologne and residence of the Archbishops and Prince-electors of Cologne. In 1949, the Parliamentary Council drafted and adopted the German constitution, the Basic Law for the Federal Republic of Germany in Bonn. Though Berlin was symbolically named the "de jure" capital, from 1949 to 1990 Bonn was the seat of government and "de facto" capital of West Germany. In recognition of its former status as German capital, it holds the name of Federal City ("Bundesstadt").
The two DAX-listed corporations Deutsche Post DHL and Deutsche Telekom have headquarters in Bonn. The city is also the location of 19 United Nations institutions and the University of Bonn. Bonn is the birthplace of Ludwig van Beethoven (born 1770).
Climate.
Bonn has an oceanic climate ("Cfb"). Located in the south of the Cologne lowland in the Rhine valley, Bonn is in one of Germany's warmest regions.
History.
History before 1945.
The history of the city dates back to Roman times. In about 11 BC, the Roman army appears to have stationed a small unit in what is presently the historical centre of the city. Even earlier, the army had resettled members of a Germanic tribal group allied with Rome, the Ubii, in Bonn. The Latin name for that settlement, "Bonna", may stem from the original population of this and many other settlements in the area, the Eburoni. The Eburoni were members of a large tribal coalition effectively wiped out during the final phase of Caesar's War in Gaul. After several decades, the army gave up the small camp linked to the Ubii-settlement. During the 1st century AD, the army then chose a site to the north of the emerging town in what is now the section of Bonn-Castell to build a large military installation dubbed Castra Bonnensis, i.e., literally, "Fort Bonn". Initially built from wood, the fort was eventually rebuilt in stone. With additions, changes and new construction, the fort remained in use by the army into the waning days of the Western Roman Empire, possibly the mid-5th century. The structures themselves remained standing well into the Middle Ages, when they were called the Bonnburg. They were used by Frankish kings until they fell into disuse. Eventually, much of the building materials seem to have been re-used in the construction of Bonn's 13th-century city wall. The Sterntor ("star gate") in the city center is a reconstruction using the last remnants of the medieval city wall.
To date, Bonn's Roman fort remains the largest fort of its type known from the ancient world, i.e. a fort built to accommodate a full-strength Imperial Legion and its auxiliaries. The fort covered an area of approximately . Between its walls it contained a dense grid of streets and a multitude of buildings, ranging from spacious headquarters and large officers' quarters to barracks, stables and a military jail. Among the legions stationed in Bonn, the "1st", i.e. the Prima Legio Minervia, seems to have served here the longest. Units of the Bonn legion were deployed to theatres of war ranging from modern-day Algeria to what is now the Russian republic of Chechnya.
The chief Roman road linking the provincial capitals of Cologne and Mainz cut right through the fort where it joined the fort's main road (now, Römerstraße). Once past the South Gate, the Cologne–Mainz road continued along what are now streets named Belderberg, Adenauerallee et al. On both sides of the road, the local settlement, "Bonna", grew into a sizeable Roman town.
In late antiquity, much of the town seems to have been destroyed by marauding invaders. The remaining civilian population then took refuge inside the fort along with the remnants of the troops stationed here. During the final decades of Imperial rule, the troops were supplied by Franci chieftains employed by the Roman administration. When the end came, these troops simply shifted their allegiances to the new barbarian rulers, the Kingdom of the Franks. From the fort, the Bonnburg, as well as from a new medieval settlement to the South centered around what later became the minster, grew the medieval city of Bonn. Local legends arose from this period that the name of the village came from Saint Boniface via Vulgar Latin "*Bonnifatia", but this proved to be a myth.
Between the 11th and 13th centuries, the Romanesque style Bonn Minster was built, and in 1597 Bonn became the seat of the Archdiocese of Cologne. The city gained more influence and grew considerably. The city was subject to a major bombardment during the Siege of Bonn in 1689. The elector Clemens August (ruled 1723–1761) ordered the construction of a series of Baroque buildings which still give the city its character. Another memorable ruler was Max Franz (ruled 1784–1794), who founded the university and the spa quarter of Bad Godesberg. In addition he was a patron of the young Ludwig van Beethoven, who was born in Bonn in 1770; the elector financed the composer's first journey to Vienna.
In 1794, the city was seized by French troops, becoming a part of the First French Empire. In 1815 following the Napoleonic Wars, Bonn became part of the Kingdom of Prussia. Administered within the Prussian Rhine Province, the city became part of the German Empire in 1871 during the Prussian-led unification of Germany. Bonn was of little relevance in these years.
History since 1945.
During World War II, Bonn acquired military significance because of its strategic location on the Rhine River, which formed a natural barrier to easy penetration into the German heartland from the west. The Allied ground advance into Germany reached Bonn on 7 March 1945, and the US 1st Infantry Division captured the city during the battle of 8–9 March 1945.
Following World War II, Bonn was in the British zone of occupation, and in 1949 became the "de facto" capital of the newly formed Federal Republic of Germany (the "de jure" capital of the Federal Republic throughout the years of the Cold War division of Germany was always Berlin). Such "provisional" capital cities have been common in history; for example, the "official" capital of the Republic of China is still Nanjing on mainland China, with Taipei considered the provisional capital. The choice of Bonn was made mainly due to the advocacy of West Germany's first chancellor, Konrad Adenauer, a former Cologne Mayor and a native of that area. This was despite the fact that Frankfurt already had most of the required facilities and using Bonn was estimated to be 95 million DM more expensive than using Frankfurt. However, Adenauer and other prominent politicians intended to make Berlin the capital of the reunified Germany, and felt that locating the capital in a major city like Frankfurt or Hamburg would imply a permanent capital and weaken support in West Germany for reunification.
Because of its relatively small size for a capital city, Bonn was sometimes referred to, jokingly, as the Bundeshauptstadt ohne nennenswertes Nachtleben" (Federal capital without noteworthy nightlife) or the Bundesdorf" (Federal Village). At one point in the post-WWII/Cold War era, the U.S. Embassy in Bonn was America's largest, "comparable, with its thousands of staff, to the .S Baghdad embassy today".
German reunification in 1990 made Berlin the nominal capital of Germany again. This decision did not mandate that the republic's political institutions would also move. While some argued for the seat of government to move to Berlin, others advocated leaving it in Bonn—a situation roughly analogous to that of the Netherlands, where Amsterdam is the capital but The Hague is the seat of government. Berlin's previous history as united Germany's capital was strongly connected with Imperial Germany, the Weimar Republic and more ominously with Nazi Germany. It was felt that a new peacefully united Germany should not be governed from a city connected to such overtones of war. Additionally, Bonn was closer to Brussels, headquarters of the EU.
The heated debate that resulted was settled by the "Bundestag" (Germany's parliament) only on 20 June 1991. By a vote of 338–320, the Bundestag voted to move the seat of government to Berlin. The vote broke largely along regional lines, with legislators from the south and west favouring Bonn and legislators from the north and east voting for Berlin. It also broke along generational lines as well; older legislators with memories of Berlin's past glory favoured Berlin, while younger legislators favoured Bonn. Ultimately, the votes of the "Ossi" legislators tipped the balance in favour of Berlin.
While the government and parliament moved to Berlin, as a compromise, some of the ministries (such as Defence and Agriculture) largely remained in Bonn, with only the top officials based in Berlin. There was no plan to move these departments, and so Bonn remained a second, unofficial capital with the new title "Federal City" (Bundesstadt). Because of the necessary construction work, the move took until 1999 to complete. Over 8,000 of the 18,000 federal officials remain in Bonn.
At present, the private sector plays a major role in Bonn's economy. With five stock listed companies, Bonn has the fourth highest market capitalisation among German cities. With headquarters of DHL, T-Mobile and other renowned companies, managers have replaced the public sector.
Main sites.
Beethoven's birthplace is located in Bonngasse near the market place. Next to the market place is the Old City Hall, built in 1737 in Rococo style, under the rule of Clemens August of Bavaria. It is used for receptions of guests of the city, and as an office for the mayor. Nearby is the "Kurfürstliches Schloss", built as a residence for the prince-elector and now the main building of the University of Bonn.
The "Poppelsdorfer Allee" is an avenue flanked by chestnut trees which had the first horsecar of the city. It connects the "Kurfürstliches Schloss" with the "Poppelsdorfer Schloss", a palace that was built as a resort for the prince-electors in the first half of the 18th century, and whose grounds are now a botanical garden (the Botanischer Garten Bonn). This axis is interrupted by a railway line and Bonn Hauptbahnhof, a building erected in 1883/84.
The Beethoven Monument stands on the Münsterplatz, which is flanked by the Bonn Minster, one of Germany's oldest churches.
The three highest buildings in the city are the radio mast of WDR in Bonn-Venusberg (180 m), the headquarters of the Deutsche Post called "Post Tower" (162.5 m) and the former building for the German members of parliament "Langer Eugen" (114.7 m) now the new location of the UN Campus.
Education.
The Rheinische Friedrich Wilhelms Universität Bonn (University of Bonn) is one of the largest universities in Germany. It is also the location of the German research institute Deutsche Forschungsgemeinschaft (DFG) offices and of the German Academic Exchange Service ("Deutscher Akademischer Austauschdienst" - DAAD).
Districts.
In 1969, the independent towns of Bad Godesberg and Beuel as well as several villages were incorporated into Bonn, resulting in a city more than twice as large as before. Bad Godesberg and Beuel became districts ("Stadtbezirke") of Bonn with some independence and populations of about 70,000 each.
Each district has its own quarters:
Transport.
Bonn is connected to three autobahns (federal motorways) and the German rail network. Some InterCityExpress and most InterCity trains call at Bonn Hauptbahnhof whilst the Siegburg/Bonn railway station is situated on the Cologne–Frankfurt high-speed rail line outside of Bonn and serviced by InterCityExpress trains. Local transport is provided by the Bonn Stadtbahn, which also features two lines to Cologne.
Bonn's international airport is Cologne Bonn Airport.
Demographics.
As of 2011, Bonn had a population of 327,913. About 70% of the population was entirely of German origin, while about 100,000 people, equating to roughly 30%, were at least partly of non-German origin. The city is one of the fastest-growing municipalities in Germany and the 18th most populous city in the country. Bonn's population is predicted to surpass the populations of Wuppertal and Bochum before the year 2030.
The following list shows the largest groups of foreign residents in Bonn as of 2014 by nationalities.
Economy.
The head offices of Deutsche Telekom, its subsidiary T-Mobile, Deutsche Post, Haribo, German Academic Exchange Service, and SolarWorld are in Bonn.
Sports.
Bonn is home of the Telekom Baskets Bonn, the only basketball club in Germany that owns its arena, the Telekom Dome. The club is a regular participant at international competitions such as the Eurocup.
The city also has an amateur football team Bonner SC which was formed in 1965 through the merger of "Bonner FV" and "Tura Bonn".
International relations.
Since 1983, the City of Bonn has established friendship relations with the City of Tel Aviv, Israel, and since 1988 Bonn, in former times the residence of the Princes Electors of Cologne, and Potsdam, Germany, the formerly most important residential city of the Prussian rulers, have established a city-to-city partnership.
Central Bonn is surrounded by a number of traditional towns and villages which were independent up to several decades ago. As many of those communities had already established their own contacts and partnerships before the regional and local reorganisation in 1969, the Federal City of Bonn now has a dense network of city district partnerships with European partner towns.
The city district of Bonn is a partner of the English university city of Oxford, England, UK (since 1947), of Budafok, District XXII of Budapest, Hungary (since 1991) and of Opole, Poland (officially since 1997; contacts were established 1954).
The district of Bad Godesberg has established partnerships with Saint-Cloud in France, Frascati in Italy, Windsor and Maidenhead in England, UK and Kortrijk in Belgium; a friendship agreement has been signed with the town of Yalova, Turkey.
The district of Beuel on the right bank of the Rhine and the city district of Hardtberg foster partnerships with towns in France: Mirecourt and Villemomble.
Moreover, the city of Bonn has developed a concept of international co-operation and maintains sustainability oriented project partnerships in addition to traditional city twinning, among others with Minsk in Belarus, Ulaanbaatar in Mongolia, Bukhara in Uzbekistan, Chengdu in China and La Paz in Bolivia.
Twin towns—Sister cities.
The city Bonn is twinned with:
The city district Bonn has partnerships with:
Further, the city Bonn has subject-specific project partnerships with:

</doc>
<doc id="3332" url="https://en.wikipedia.org/wiki?curid=3332" title="Ballroom dance">
Ballroom dance

Ballroom dance is a set of partner dances, which are enjoyed both socially and competitively around the world. Because of its performance and entertainment aspects, ballroom dance is also widely enjoyed on stage, film, and television.
"Ballroom dance" may refer, at its widest definition, to almost any type of partner dancing as recreation. However, with the emergence of dancesport in modern times, the term has become narrower in scope, and traditionally refers to the five International Standard and five International Latin style dances (see dance categories below). The two styles, while differing in technique, rhythm and costumes, exemplify core elements of ballroom dancing such as control and cohesiveness. Developed in England, the two styles are now regulated by the World Dance Council (WDC) and the world dancesport federation. (Wdsf). In the United States, two additional variations are popular: "American Smooth" and "American Rhythm", which combine elements of both traditional Latin and Ballroom dances.
There are also a number of historical dances, and local or national dances, which may be danced in ballrooms or salons. Sequence dancing, in pairs or other formations, is still a popular style of ballroom dance.
Definitions and history.
The term 'ballroom dancing' is derived from the word "ball" which in turn originates from the Latin word "ballare" which means 'to dance' (a ball-room being a large room specially designed for such dances). In times past, ballroom dancing was social dancing for the privileged, leaving folk dancing for the lower classes. These boundaries have since become blurred, and it should be noted even in times long gone, many ballroom dances were really elevated folk dances. The definition of ballroom dance also depends on the era: balls have featured popular dances of the day such as the Minuet, Quadrille, Polonaise, Polka, Mazurka, and others, which are now considered to be historical dances.
Early Modern Age.
The first authoritative knowledge of the earliest ballroom dances was recorded toward the end of the 16th century, when Jehan Tabourot, under the pen name "Thoinot-Arbeau", published in 1588 his "Orchésographie", a study of late 16th-century French renaissance social dance. Among the dances described were the solemn basse danse, the livelier branle, pavane, and the galliarde which Shakespeare called the "cinq pace" as it was made of five steps.
In 1650 the Minuet, originally a peasant dance of Poitou, was introduced into Paris and set to music by Jean-Baptiste Lully and danced by the King Louis XIV in public, and would continue to dominate ballroom from that time until the close of the 18th century.
Toward the latter half of the 17th century, Louis XIV founded his 'Académie Royale de Musique et de Danse', where specific rules for the execution of every dance and the "five positions" of the feet were formulated for the first time by members of the Académie. Eventually, the first definite cleavage between ballet and ballroom came when professional dancers appeared in the ballets, and the ballets left the Court and went to the stage. Ballet technique such as the turned out positions of the feet, however, lingered for over two centuries and past the end of the Victoria era.
19th century.
The waltz with its modern hold took root in England in about 1812; in 1819 Carl Maria von Weber wrote "Invitation to the Dance", which marked the adoption of the waltz form into the sphere of absolute music. The dance was initially met with tremendous opposition due to the semblance of impropriety associated with the closed hold, though the stance gradually softened. In the 1840s several new dances made their appearance in the ballroom, including the Polka, Mazurka, and the Schottische. In the meantime a strong tendency emerged to drop all 'decorative' steps such as "entrechats" and "ronds de jambes" that had found a place in the Quadrilles and other dances.
Early 20th century.
Modern ballroom dance has its roots early in the 20th century, when several different things happened more or less at the same time. The first was a movement away from the sequence dances towards dances where the couples moved independently. This had been pre-figured by the waltz, which had already made this transition. The second was a wave of popular music, such as jazz, much of which was based on the ideas of black musicians in the USA. Since dance is to a large extent tied to music, this led to a burst of newly invented dances. There were many dance crazes in the period 1910–1930.
The third event was a concerted effort to transform some of the dance crazes into dances which could be taught to a wider dance public in the US and Europe. Here Vernon and Irene Castle were important, and so was a generation of English dancers in the 1920s, including Josephine Bradley and Victor Silvester. These professionals analysed, codified, published and taught a number of standard dances. It was essential, if popular dance was to flourish, for dancers to have some basic movements they could confidently perform with any partner they might meet. Here the huge Arthur Murray organisation in America, and the dance societies in England, such as the Imperial Society of Teachers of Dancing, were highly influential. Finally, much of this happened during and after a period of World War, and the effect of such a conflict in dissolving older social customs was considerable.
Later, in the 1930s, the on-screen dance pairing of Fred Astaire and Ginger Rogers influenced all forms of dance in the USA and elsewhere. Although both actors had separate careers, their filmed dance sequences together, which included portrayals of the Castles, have reached iconic status. Much of Astaire and Rogers' work portrayed social dancing, although the performances were highly choreographed (often by Astaire or Hermes Pan), and meticulously staged and rehearsed.
Competitive dancing.
Competitions, sometimes referred to as Dancesport, range from world championships, regulated by the World Dance Council (WDC), to less advanced dancers at various proficiency levels. Most competitions are divided into professional and amateur, though in the USA pro-am competitions typically accompany professional competitions. The International Olympic Committee now recognizes competitive ballroom dance. It has recognized another body, the World DanceSport Federation (WDSF), as the sole representative body for dancesport in the Olympic Games. However, it seems doubtful that dance will be included in the Olympic Games, especially in light of efforts to reduce the number of participating sports.
Ballroom dance competitions are regulated by each country in its own way. There are about 30 countries which compete regularly in international competitions. There are another 20 or so countries which have membership of the WDC and/or the WDSF, but whose dancers rarely appear in international competitions. In Britain there is the British Dance Council, which grants national and regional championship titles, such as the British Ballroom Championships, the British Sequence Championships and the United Kingdom Championships. In the United States, amateur dance proficiency levels are defined by USA Dance (formerly United States Amateur Ballroom Dance Association, USABDA).
Ballroom dancing competitions in the former USSR also included the Soviet Ballroom dances, or "Soviet Programme". Australian New Vogue is danced both competitively and socially. In competition there are 15 recognised New Vogue dances, which are performed by the competitors in sequence. These dance forms are not recognised internationally, neither are the US variations such as American Smooth, and Rhythm. Such variations in dance and competition methods are attempts to meets perceived needs in the local market-place.
Internationally, the Blackpool Dance Festival, hosted annually at Blackpool, England, is considered the most prestigious event a dancesport competitor can attend.
Formation dance is another style of competitive dance recognised by the IDSF. In this style, multiple dancers (usually in couples and typically up to 16 dancers at one time) compete on the same team, moving in and out of various formations while dancing.
Elements of competition.
In competition ballroom, dancers are judged by diverse criteria such as poise, the hold or frame, posture, musicality and expression, timing, body alignment and shape, floor craft, foot and leg action, and presentation. Judging in a performance-oriented sport is inevitably subjective in nature, and controversy and complaints by competitors over judging placements are not uncommon. The scorekeepers—called scrutineers—will tally the total number recalls accumulated by each couple through each round until the finals, when the Skating system is used to place each couple by ordinals, typically 1–6, though the number of couples in the final may vary. Sometimes, up to 7 couples may be present on the floor during the finals.
≤≠″°—and bronze the lowest. In these levels, moves are restricted to those written in syllabus, and illegal moves can lead to disqualification. Each level, bronze, silver, and gold, has different moves on their syllabus, increasing in difficulty. At these levels, the elaborate costumes are not allowed, as there are very strict clothing restrictions. Jewels on costumes or hair can lead to disqualification. Open levels are reserved for higher-skilled dancers, usually taking time to get to that caliber of dancing. There are three levels in the open category; novice, pre-champ, and champ in increasing order of skill. At those levels, dancers no longer have restrictions on clothing, so gowns covered in jewels for example, are allowed in the smooth and standard dances, and fringe dresses with huge cutouts and elaborate designs are now allowed in the rhythm and Latin categories. Women also tend to wear extremely intricate hairstyles and bright makeup, often with jewels glued on in patterns.
Medal tests.
Medal examinations for amateurs enable dancers' individual abilities to be recognized according to conventional standards. In medal exams, which are run by bodies such as the Imperial Society of Teachers of Dancing (ISTD) and the United Kingdom Alliance (UKA), each dancer performs two or more dances in a certain genre in front of a judge. Genres such as Modern Ballroom or Latin are the most popular. Societies such as the ISTD and UKA also offer medal tests on other dance styles (such as Country & Western, Rock 'n Roll or Tap). In some North American examinations, levels include Newcomer, Bronze, Silver, Gold, Novice, Pre-championship, and Championship; each level may be further subdivided into either two or four separate sections.
Collegiate Ballroom.
There is a part of the ballroom world dedicated to college students. These chapters are typically clubs or teams that have an interest in ballroom dancing. Teams hold fundraisers, social events, and ballroom dance lessons. Ballroom dance team’s goals are to have fun and learn to dance well. There is a strong focus on finding a compatible dance partner and bonding with teammates. There is also a competitive side to collegiate ballroom.
In competitive collegiate ballroom, competitors go to competitions at different schools or events, such as Arnold Dancesport Classic and MIT Open Ballroom Dance Competition. Dancers can compete in four different categories. The categories are American Rhythm, International Latin, American Smooth, and International Standard. Competitors dance at different level based on their abilities. The levels of dance, in order of difficultly, are newcomer, bronze, silver, gold, novice, pre-championship, and championship. Bronze through gold is considered syllabus. Novice through Championship is considered open. Individuals and teams as a whole compete against each other.
Dances.
"Ballroom dance" refers most often to the ten dances of International Ballroom (or Standard) and International Latin, though the term is also often used interchangeably with the five International Ballroom dances. Sequence dancing, which is danced predominantly in the United Kingdom, and its development New Vogue in Australia and New Zealand, are also sometimes included as a type of Ballroom dancing.
In the United States and Canada, the American Style (American Smooth and American Rhythm) also exists. The dance technique used for both International and American styles is similar, but International Ballroom allows only closed dance positions, whereas American Smooth allows closed, open and separated dance movements. In addition, different sets of dance figures are usually taught for the two styles. International Latin and American Rhythm have different styling, and have different dance figures in their respective syllabi.
Other dances sometimes placed under the umbrella "ballroom dance" include Nightclub Dances such as Lindy Hop, West Coast Swing, Nightclub Two Step, Hustle, Salsa, and Merengue.
The categorization of dances as "ballroom dances" has always been fluid, with new dances or folk dances being added to or removed from the ballroom repertoire from time to time, so no list of subcategories or dances is any more than a description of current practices. There are other dances historically accepted as ballroom dances, and are revived via the Vintage dance movement.
In Europe, Latin Swing dances include Argentine Tango, Mambo, Lindy Hop, Swing Boogie (sometimes also known as Nostalgic Boogie), and Disco Fox. One example of this is the subcategory of Cajun dances that originated in Acadiana, with branches reaching both coasts of the United States.
Ballroom/Smooth dances are normally danced to Western music (often from the mid-twentieth century), and couples dance counter-clockwise around a rectangular floor following the line of dance. In competitions, competitors are costumed as would be appropriate for a white tie affair, with full gowns for the ladies and bow tie and tail coats for the men; though in American Smooth it is now conventional for the men to abandon the tailsuit in favor of shorter tuxedos, vests, and other creative outfits.
Latin/Rhythm dances are commonly danced to contemporary Latin American music and (in case of Jive) Western music. With the exception of a few traveling dances like Samba and Paso Doble, couples do not follow the line of dance but perform their routines more or less in one spot. In competitions, the women are often dressed in short-skirted latin outfits while the men are outfitted in tight-fitting shirts and pants, the goal being to emphasize the dancers' leg action and body movements.
Dance style classification.
International Style competition dances.
According to World Dance Council. 
Standard.
Waltz:
28 bars per minute, 3/4 time, also known as "Slow Waltz" or "English Waltz" depending on locality
Tango:
32 bars per minute, 2/4 time
Viennese Waltz:
60 bars per minute, 3/4 time
In some countries (for example, Austria) Viennese is known as the Waltz, while Waltz is recognized as "Slow Waltz".
Foxtrot:
28 bars per minute, 4/4 time
Quickstep:
50 bars per minute, 4/4 time
Latin.
Samba:
48 bars per minute, 4/4 time
Cha-cha-cha:
30 bars per minute, 4/4 time
Rumba:
24 bars per minute, 4/4 time
Paso Doble:
56 bars per minute, 2/4 time
Jive:
42 bars per minute, 4/4 time
American Style competition dances (only in the U.S. & Canada).
Smooth.
Waltz:
28–30 bars per minute
30–32 bars per minute for Bronze
Tango:
30 bars per minute
30–32 bars per minute for Bronze
Foxtrot:
30 bars per minute
32–34 bars per minute for Bronze
Viennese Waltz:
53–54 bars per minute
54 bars per minute for Bronze
Rhythm.
Cha Cha:
30 bars per minute
Rumba:
30–32 bars per minute
32–36 bars per minute for Bronze
East Coast Swing:
36 bars per minute
34–36 bars per minute for Bronze
Bolero:
24 bars per minute
24–26 bars per minute for Bronze
Mambo:
47 bars per minute
48–51 bars per minute for Bronze
Others.
Historical/Vintage Ballroom dance:
Other dances occasionally categorized as ballroom:

</doc>
<doc id="3333" url="https://en.wikipedia.org/wiki?curid=3333" title="The Birth of a Nation">
The Birth of a Nation

The Birth of a Nation (originally called "The Clansman") is a 1915 American silent epic drama film directed by D. W. Griffith and starring Lillian Gish. The screenplay is adapted from the novel and play "The Clansman", both by Thomas Dixon, Jr. Griffith co-wrote the screenplay (with Frank E. Woods), and co-produced the film (with Harry Aitken). It was released on February 8, 1915. Over two hours long, the film was originally presented in two parts separated by an intermission; it was the first 12-reel film in America.
The film chronicles the relationship of two families in the American Civil War and Reconstruction era: the pro-Union Northern Stonemans and the pro-Confederacy Southern Camerons over the course of several years. The assassination of President Abraham Lincoln by John Wilkes Booth is dramatized.
The film was a commercial success, though it was highly controversial owing to its portrayal of black men (some played by white actors in blackface) as unintelligent and sexually aggressive towards white women, and the portrayal of the Ku Klux Klan (whose original founding is dramatized) as a heroic force. There were widespread African-American protests against "The Birth of a Nation", such as in Boston, while thousands of white Bostonians flocked to see the film. The NAACP spearheaded an unsuccessful campaign to ban the film. Griffith's indignation at efforts to censor or ban the film motivated him to produce "Intolerance" the following year.
The film is also credited as one of the events that inspired the formation of the "second era" Ku Klux Klan at Stone Mountain, Georgia, in the same year. "The Birth of a Nation", along with the trial and lynching of Leo Frank for the 1913 murder of Mary Phagan in Atlanta, was used as a recruiting tool for the KKK. Under President Woodrow Wilson it was the first American motion picture to be screened at the White House, although in 1914 the Italian film "Cabiria" had been shown on the White House lawn.
Griffith's innovative techniques and storytelling power have made "The Birth of a Nation" one of the landmarks of film history. In 1992, the United States Library of Congress deemed the film "culturally, historically, or aesthetically significant" and selected it for preservation in the National Film Registry.
Plot.
Part 1: Civil War of United States.
The film follows two juxtaposed families: the Northern Stonemans—abolitionist Congressman Austin Stoneman, based on the Reconstruction-era Congressman Thaddeus Stevens, his two sons and his daughter Elsie—and the Southern Camerons, a family including two daughters, Margaret and Flora, and three sons, most notably Ben.
The Stoneman brothers visit the Camerons at their South Carolina estate, representing the Old South. Phil, the elder Stoneman son, falls in love with Margaret Cameron, while young Ben Cameron idolizes a picture of Elsie Stoneman. When the Civil War begins, these young men enlist in their respective armies.
A black militia acting under a white leader ransacks the Cameron house; the Cameron women are rescued by Confederate soldiers who rout the militia. Meanwhile, the younger Stoneman and two of the Cameron brothers are killed in the war. Ben Cameron is wounded after a heroic charge at the Siege of Petersburg; as a result, he earns the nickname "the Little Colonel." He is taken to a Northern hospital in Washington, D.C., where he at last meets the Elsie Stoneman of the picture he has been carrying; she is working there as a nurse. While recovering, Cameron is told that he will be hanged for being a Confederate guerrilla. Elsie takes Cameron's mother, who had traveled to Washington to tend her son, to see Abraham Lincoln, and the mother persuades the president to issue a pardon to Ben Cameron.
When Lincoln is assassinated at Ford's Theater, his conciliatory postwar policy expires with him. In the wake of the president's death, and with a power vacuum having opened up, Austin Stoneman and his fellow radical congressmen are determined to carry out their desire to punish the South, employing harsh measures that Griffith depicts as having been typical of the Reconstruction era.
Part 2: Reconstruction.
Stoneman and his protégé Silas Lynch, a mulatto exhibiting psychopathic characteristics, travel to South Carolina to observe the implementation of Reconstruction policies firsthand. Black occupation soldiers are seen parading through the streets and pushing white residents aside on the sidewalks. During the election, in which Lynch is elected lieutenant governor, whites are seen being prevented from voting while blacks are observed stuffing the ballot boxes. The newly elected, mostly black members of the South Carolina legislature are shown at their desks displaying inappropriate behavior, such as one member taking off his shoe and putting his feet up on his desk, and others drinking liquor and feasting on stereotypically African American fare such as fried chicken. The legislature passes laws requiring white civilians to salute black soldiers and allowing mixed-race marriages.
Meanwhile, inspired by observing white children pretending to be ghosts to scare black children, Ben fights back by forming the Ku Klux Klan. As a result, Elsie, out of loyalty to her father, breaks off her relationship with Ben. Later, Flora Cameron goes off alone into the woods to fetch water and is followed by Gus, a freedman and soldier who is now a captain. He confronts Flora and tells her that he desires to get married. Frightened, she flees into the forest, pursued by Gus. Trapped on a precipice, Flora warns Gus she will jump if he comes any closer. When he does, she leaps to her death. Having run through the forest looking for her, Ben has seen her jump; he holds her as she dies, then carries her body back to the Cameron home. In response, the Klan hunts down Gus, tries him, finds him guilty, lynches him, and delivers his corpse to Lt. Gov. Lynch's doorstep.
Lynch then orders a crackdown on the Klan. Dr. Cameron, Ben's father, is arrested for possessing Ben's Klan costume, now considered a crime punishable by death. His faithful black servants rescue him with help from Phil Stoneman. Together they flee, along with Margaret Cameron. When their wagon breaks down, they make their way through the woods to a small hut that is home to two sympathetic former Union soldiers who agree to hide them. As an intertitle states, "The former enemies of North and South are united again in defense of their Aryan birthright."
Congressman Stoneman leaves to avoid being connected with Lt. Gov. Lynch's crackdown. Elsie, learning of Dr. Cameron's arrest, goes to Lynch to plead for his release. Lynch, who had been lusting after Elsie, tries to force her to marry him, which causes her to faint. Stoneman returns, causing Elsie to be placed in another room. At first, Stoneman is happy when Lynch tells him he wants to marry a white woman, but is then angered when Lynch tells him that it is Stoneman's daughter. Undercover Klansmen spies discover Elsie's plight when she breaks a window and cries out for help, and the Klansmen go to get help. Elsie falls unconscious again, and revives while gagged and being bound. The Klan, gathered together at full strength and with Ben leading them, rides in to regain control of the town. When news about Elsie reaches Ben, he and others go to her rescue. Elsie frees her mouth and screams for help. Lynch is captured. Victorious, the Klansmen celebrate in the streets. Meanwhile, Lynch's militia surrounds and attacks the hut where the Camerons are hiding. The Klansmen, with Ben at their head, race in to save them just in time.
The next election day, blacks find a line of mounted and armed Klansmen just outside their homes, and are intimidated into not voting. The film concludes with a double wedding as Margaret Cameron marries Phil Stoneman and Elsie Stoneman marries Ben Cameron. The masses are shown oppressed by a giant warlike figure who gradually fades away. The scene shifts to another group finding peace under the image of Jesus Christ. The penultimate title rhetorically asks: "Dare we dream of a golden day when the bestial War shall rule no more? But instead — the gentle Prince in the Hall of Brotherly Love in the City of Peace."
Uncredited:
Production.
"The Birth of a Nation" began filming in 1914 and pioneered such camera techniques as the use of panoramic long shots, the iris effects, still-shots, night photography, panning camera shots, and a carefully staged battle sequence with hundreds of extras made to look like thousands. It also contains many new artistic techniques, such as color tinting for dramatic purposes, building up the plot to an exciting climax, dramatizing history alongside fiction, and featuring its own musical score written for an orchestra.
When the film was released, it shattered both box office and film-length records, running three hours and ten minutes. In 1998, it was voted one of the "Top 100 American Films" (#44) by the American Film Institute.
The film was based on Thomas Dixon, Jr.'s novels "The Clansman" and "The Leopard's Spots". It was originally to have been shot in Kinemacolor but D. W. Griffith took over the Hollywood studio of Kinemacolor and Kinemacolor's plans to film Dixon's novel. Griffith, whose father served as a colonel in the Confederate Army, agreed to pay Thomas Dixon $10,000 (equal to $ today) for the rights to his play "The Clansman". Since he ran out of money and could afford only $2,500 of the original option, Griffith offered Dixon 25 percent interest in the picture. Dixon reluctantly agreed, and the unprecedented success of the film made him rich. Dixon's proceeds were the largest sum any author had received for a motion picture story and amounted to several million dollars.
Griffith's budget started at US$40,000 (equal to $ today) but rose to over $100,000 (the equivalent of $ in constant dollars).
West Point engineers provided technical advice on the Civil War battle scenes. They provided Griffith with the artillery used in the film. Some scenes from the movie were filmed on the porches and lawns of Homewood Plantation in Natchez, Mississippi.
The film premiered on February 8, 1915, at Clune's Auditorium in downtown Los Angeles. At its premiere the film was entitled "The Clansman," but the title was later changed to "The Birth of a Nation" to reflect Griffith's belief that the United States emerged from the American Civil War and Reconstruction as a unified nation.
The film is in the public domain.
Score.
Although "The Birth of a Nation" is commonly regarded as a landmark for its dramatic and visual innovations, its use of music was arguably no less revolutionary. Though film was still silent at the time, it was common practice to distribute musical cue sheets, or less commonly, full scores (usually for organ or piano accompaniment) along with each print of a film.
For "The Birth of a Nation", composer Joseph Carl Breil created a three-hour-long musical score that combined all three types of music in use at the time: adaptations of existing works by classical composers, new arrangements of well-known melodies, and original composed music. Though it had been specifically composed for the film, Breil's score was not used for the Los Angeles première of the film at Clune's Auditorium; rather, a score compiled by Carli Elinor was performed in its stead, and this score was used exclusively in West Coast showings. Breil's score was not used until the film debuted in New York at the Liberty Theatre, and was the score utilized in all showings save those on the West Coast.
Outside of original compositions, Breil adapted classical music for use in the film, including passages from "Der Freischütz" by Carl Maria von Weber, "Leichte Kavallerie" by Franz von Suppé, Symphony No. 6 by Ludwig van Beethoven, and "Ride of the Valkyries" by Richard Wagner, the latter used as a leitmotif during the ride of the KKK. Breil also arranged several traditional and popular tunes that would have been recognizable to audiences at the time, including many Southern melodies; among these songs were "Maryland, My Maryland", "Dixie", "Old Folks at Home", "The Star-Spangled Banner", "America the Beautiful", "The Battle Hymn of the Republic", "Auld Lang Syne", and "Where Did You Get That Hat?".
In his original compositions for the film, Breil wrote numerous leitmotifs to accompany the appearance of specific characters. The principal love theme that was created for the romance between Elsie Stoneman and Ben Cameron was published as "The Perfect Song" and is regarded as the first marketed "theme song" from a film; it was later even used as the theme song for the popular radio and television sitcom "Amos 'n' Andy".
Responses and reception.
The National Association for the Advancement of Colored People (NAACP), founded in 1909, protested premieres of the film in numerous cities. According to the historian David Copeland, "by the time of the movie's March 3 91 premiere in New York City, its subject matter had embroiled the film in charges of racism, protests, and calls for censorship, which began after the Los Angeles branch of the NAACP requested the city's film board ban the movie. Since film boards were composed almost entirely of whites, few review boards initially banned Griffith's picture". The NAACP also conducted a public education campaign, publishing articles protesting the film's fabrications and inaccuracies, organizing petitions against it, and conducting education on the facts of the war and Reconstruction.
Because of the lack of success in NAACP's actions to ban the film, on April 17, 1915, NAACP secretary Mary Childs Nerney wrote to NAACP Executive Committee member George Packard: "I am utterly disgusted with the situation in regard to "The Birth of a Nation" ... kindly remember that we have put six weeks of constant effort of this thing and have gotten nowhere."
Jane Addams, an American social worker and social reformer, and the founder of Hull House, voiced her reaction to the film in an interview published by the "New York Post" on March 13, 1915, just ten days after the film was released. She stated that "One of the most unfortunate things about this film is that it appeals to race prejudice upon the basis of conditions of half a century ago, which have nothing to do with the facts we have to consider to-day. Even then it does not tell the whole truth. It is claimed that the play is historical: but history is easy to misuse."
When the film was released, riots broke out in Boston, Philadelphia and other major cities in the United States. The film's inflammatory nature was a catalyst for gangs of whites to attack blacks. On 24 April 1916, the Chicago American reported that a white man murdered a black teenager in Lafayette, Indiana after seeing the film, although there has been some controversy as to whether the murderer had actually seen "The Birth of a Nation". The mayor of Cedar Rapids, Iowa was the first of twelve mayors to ban the film in 1915 out of concern that it would promote race prejudice, after meeting with a delegation of black citizens. The NAACP set up a precedent-setting national boycott of the film, likely seen as the most successful effort. Additionally, they organised a mass demonstration when the film was screened in Boston, and it was banned in three states and several cities.
Thomas Dixon, Jr., author of "The Birth of a Nation"s source play and novel "The Clansman", was a former classmate of then-president Woodrow Wilson at Johns Hopkins University. Dixon managed to arrange a screening of "The Birth of a Nation" at the White House for Wilson, members of his cabinet, and their families, in what was at the time one of the firsts ever screenings at the White House. Wilson was falsely reported to have said about the film, "It is like writing history with lightning. And my only regret is that it is all so terribly true". Wilson's aide, Joseph Tumulty, denied the claims and said that "the President was entirely unaware of the nature of the play before it was presented and at no time has expressed his approbation of it." Historians believe the quote attributed to Wilson originated with Dixon, who was relentless in publicizing the film. After controversy over the film had grown, Wilson wrote that he disapproved of the "unfortunate production."
Griffith, indignant at the film's negative critical reception, wrote letters to newspapers, and published a pamphlet in which he accused his critics of censoring unpopular opinions. When Sherwin Lewis for the New York Globe wrote a critical piece that expressed criticism towards the distorted portrayal of the history and that it was not worth being constitutionally protecting because it was to make a few "dirty dollars", Griffith responded that "the public should not be afraid to accept the truth, even though it might not like it". He also added to say that the man who wrote the editorial was "damaging my reputation as a producer" and "a liar and a coward". He conceived his next film, "Intolerance" (1916), as a response to those who had censored his film.
Despite the film's controversy, "The Birth of a Nation" was critically well-received and very popular. At over three hours in length (including intermissions), the film was ground-breaking in its production value, budget and ambition. At the time, the film was unlike anything the American audiences had ever seen before.
Box office performance.
The box office gross of "The Birth of a Nation" is not known, and was long subject to exaggeration. At the end of 1917 Epoch reported to its shareholders cumulative receipts of $4.8 million, and Griffith's own records put Epoch's worldwide earnings from the film at $5.2 million as of 1919, although the distributor's share of the revenue at this time was much lower than the exhibition gross. In the biggest cities, Epoch negotiated with individual theater owners for a percentage of the box office; elsewhere the producer sold all rights in a particular state to a single distributor (an arrangement known as "state's rights" distribution). The film historian Richard Schickel says that under the state's rights contracts, Epoch typically received about 10% of the box office gross—which theater owners often underreported—and concludes that ""Birth" certainly generated more than $60 million in box-office business in its first run". By 1940 "Time" magazine estimated the film's cumulative gross rental (the distributor's earnings) at approximately $15 million. For years "Variety" had the gross rental listed as $50 million, but in 1977 repudiated the claim and revised its estimate down to $5 million. It is not known for sure how much the film has earned in total, but producer Harry Aitken put its estimated earnings at $15–18 million in a letter to a prospective investor in a proposed sound version; it is likely the film earned over $20 million for its backers, and generated $50–100 million in box office receipts.
The film played at the Liberty Theater in New York City for 44 weeks and tickets were priced at $2.20 ($51.50 in 2015 dollars).
Sequel, appropriations, and spin-offs.
D. W. Griffith made a film in 1916, called "Intolerance", partly in response to the criticism that "Birth Of A Nation" received. Griffith has made clear within numerous interviews that the film's title and main themes were chosen in response to those who Griffith felt had been intolerant to his "Birth Of A Nation".
A sequel called "The Fall of a Nation" was released in 1916. It was the first sequel in film history. The film was directed by Thomas Dixon, Jr., who adapted it from his own novel of the same name. The film has three acts and a prologue. Despite its success in the foreign market, the film was not a success among the American audiences. It is believed that it is now a lost film.
In 1918, an American silent drama film directed by John W. Noble called "The Birth of a Race" was released as a direct response to "The Birth of a Nation". The film was an ambitious project by producer Emmett Jay Scott to challenge Griffith's film and tell another side of the story, but was ultimately unsuccessful.
In 1919, the director/producer/writer Oscar Micheaux released "Within Our Gates", a response from the African-American community. Notably, he reversed a key scene of Griffith's film by depicting a white man assaulting a black woman.
The film was remixed in 2004 as "Rebirth of a Nation", a live cinema experience by DJ Spooky at Lincoln Center, and has toured at many venues around the world including The Acropolis as a live cinema "remix". The remix version was also presented at Paula Cooper Gallery in New York.
In 2016, Nate Parker produced and directed the film The Birth of a Nation (2016 film), a story of a slave boy who becomes a leader through education and preaching. Parker states: " I've reclaimed this title and re-purposed it as a tool to challenge racism and white supremacy in America, to inspire a riotous disposition toward any and all injustice in this country (and abroad) and to promote the kind of honest confrontation that will galvanize our society toward healing and sustained systemic change." 
Ideology and accuracy.
The film remains controversial due to its interpretation of American history. University of Houston historian Steven Mintz summarizes its message as follows: Reconstruction was a disaster, blacks could never be integrated into white society as equals, and the violent actions of the Ku Klux Klan were justified to reestablish honest government. The South is portrayed as a victim. The first overt mentioning of the war is the scene in which Abraham Lincoln signs the call for the first 75,000 volunteers. However, the first aggression in the Civil War, made when the Confederate troops fired on Fort Sumter in 1861, is not mentioned in the film. The film suggested that the Ku Klux Klan restored order to the postwar South, which was depicted as endangered by abolitionists, freedmen, and carpetbagging Republican politicians from the North. This reflects the so-called Dunning School of historiography. The film portrays President Abraham Lincoln as a friend of the Confederacy, and refers to him as "the Great Heart". The two romances depicted in the film, Phil Stoneman with Margaret Cameron and Ben Cameron with Elsie Stoneman, reflect Griffith's retelling of history. The couples are used as a metaphor, representing the film's broader message of the need for the reconciliation of the North and South to defend white supremacy. Among both couples, there is an attraction that forms before the war, stemming from the friendship between their families. With the war, though, both families are split apart, and their losses culminate in the end of the war with the defense of white supremacy. One of the intertitles clearly sums up the message of unity, stating, "The former enemies of North and South are united again in defense of their Aryan birthright." 
Some historians, such as E. Merton Coulter in his "The South Under Reconstruction" (1947), maintained the Dunning School view after World War II. Today, the Dunning School position is largely seen as a product of anti-black racism of the early 20th century, by which many Americans held that black Americans were unequal as citizens.
Veteran film reviewer Roger Ebert wrote,
Despite some similarities between the Congressman Stoneman character and Rep. Thaddeus Stevens of Pennsylvania, Rep. Stevens did not have the family members described and did not move to South Carolina during Reconstruction. He died in Washington, D.C. in 1868. However, Stevens was widely rumored to keep a biracial mistress-housekeeper, who was generously provided for in his will.
The depictions of mass Klan paramilitary actions do not seem to have historical equivalents, although there were incidents in 1871 where Klan groups traveled from other areas in fairly large numbers to aid localities in disarming local companies of the all-black portion of the state militia under various justifications, prior to the eventual Federal troop intervention, and the organized Klan's continued activities as small groups of "night riders."
The Civil Rights Movement and other social movements created a new generation of historians, such as scholar Eric Foner, who led a reassessment of Reconstruction. Building on W.E.B. DuBois' work but also adding new sources, they focused on achievements of the African-American and white Republican coalitions, such as establishment of universal public education and charitable institutions in the South and extension of suffrage to black men. In response, the Southern-dominated Democratic Party and its affiliated white militias had used extensive terrorism, intimidation and outright assassinations to suppress African-American leaders and voting in the 1870s and to regain power.
Significance.
Released in 1915, "The Birth of a Nation" has been credited as groundbreaking among its contemporaries for its innovative application of the medium of film. According to the film historian Kevin Brownlow, the film was "astounding in its time" and initiated "so many advances in film-making technique that it was rendered obsolete within a few years." The content of the work, however, has received widespread criticism for its blatantly racist and fantastical depictions of scenes that are presented onscreen as if in documentary form. Film critic Roger Ebert writes, "Certainly "The Birth of a Nation" (1915) presents a challenge for modern audiences. Unaccustomed to silent films and uninterested in film history, they find it quaint and not to their taste. Those evolved enough to understand what they are looking at find the early and wartime scenes brilliant, but cringe during the postwar and Reconstruction scenes, which are racist in the ham-handed way of an old minstrel show or a vile comic pamphlet." ""Birth of a Nation" was the first picture that really made people take the motion picture industry seriously," said Mary Pickford.
The film held the mantle of the highest grossing film until it was overtaken by "Gone with the Wind".
In 1992, the United States Library of Congress deemed the film "culturally, historically, or aesthetically significant" and selected it for preservation in the National Film Registry. Despite its controversial story, the film has been praised by film critics such as Roger Ebert, who said: ""The Birth of a Nation" is not a bad film because it argues for evil. Like Riefenstahl's "Triumph of the Will", it is a great film that argues for evil. To understand how it does so is to learn a great deal about film, and even something about evil." The website "Rotten Tomatoes", which compiles reviews from various sources, indicates the film has a 100% approval rating.
According to a 2002 article in the "Los Angeles Times", the film facilitated the refounding of the Ku Klux Klan in the 1920s. As late as the 1970s, the Ku Klux Klan continued to use the film as a recruitment tool.
American Film Institute recognition
New opening titles on re-release.
One famous part of the film was added by Griffith only on the second run of the film and is missing from most online versions of the film (presumably taken from first run prints.)
These are the second and third of three opening title cards which defend the film. The added titles read:
A PLEA FOR THE ART OF THE MOTION PICTURE:
We do not fear censorship, for we have no wish to offend with improprieties or obscenities, but we do demand, as a right, the liberty to show the dark side of wrong, that we may illuminate the bright side of virtue – the same liberty that is conceded to the art of the written word – that art to which we owe the Bible and the works of Shakespeare
and
If in this work we have conveyed to the mind the ravages of war to the end that war may be held in abhorrence, this effort will not have been in vain.
Various film historians have expressed a range of views about these titles. To Nicholas Andrew Miller, this shows that "Griffith's greatest achievement in "The Birth of a Nation" was that he brought the cinema's capacity for spectacle... under the rein of an outdated, but comfortably literary form of historical narrative. Griffith's models... are not the pioneers of film spectacle... but the giants of literary narrative." On the other hand, S. Kittrell Rushing complains about Griffith's "didactic" title-cards, while Stanley Corkin complains that Griffith "masks his idea of fact in the rhetoric of high art and free expression" and creates film which "erodes the very ideal" of "liberty" which he asserts.
Home media and restorations.
"Birth of a Nation," even more than other films in the public domain, has been poorly represented in later releases. The problem, in part, is that Griffith and others have reworked the film, leaving no definitive version. According to the silent film website "Brenton Film", "there are a multitude of poor quality DVDs with different edits, scores, running speeds and usually in "definitely unoriginal" black and white."
There are exceptions. Among them is film preservationist David Shepard's 1992 transfer of a 16mm print for VHS and laserdisc release via Image Entertainment. A short documentary, "The Making of The Birth of a Nation", newly produced and narrated by Shepard, was also included. Both were released on DVD by Image in 1998 and the UK's Eureka Entertainment in 2000.
In the UK, Photoplay Productions restored the Museum of Modern Art's 35mm print that was the source of Shepard's 16mm print, though they also augmented it with extra material from the British Film Institute. It was also given a full orchestral recording of the original Breil score. Though broadcast on Channel 4 television and theatrically screened many times, Photoplay's 1993 version was never released on home video.
Shepard's transfer and documentary were reissued in the US by Kino Video in 2002, this time in a 2-DVD set with added extras on the second disc. These included several Civil War shorts also directed by D.W. Griffith.
In 2011 Kino prepared a HD transfer of a 35mm negative from the Paul Killiam Collection. They added some material from the Library of Congress and gave it a new compilation score. This version was released on Blu-ray by Kino in the US, Eureka in the UK (as part of their "Masters of Cinema" collection) and Divisa Home Video in Spain.
In 2015, the year of the film's centenary, Photoplay Productions' Patrick Stanbury, in conjunction with the British Film Institute, carried out the first full restoration. It mostly used new 4K scans of the LoC's original camera negative, along with other early generation material. It too was given the original Breil score and featured the film's original tinting for the first time since its 1915 release. The restoration was released on a 2-Blu-ray set by the BFI, alongside a host of extras, including many other newly restored Civil War related films from the period.
References.
Bibliography

</doc>
<doc id="3335" url="https://en.wikipedia.org/wiki?curid=3335" title="Baltic Sea">
Baltic Sea

The Baltic Sea (; ; ; ; ; ; ; ; ) is a sea of the Atlantic Ocean, enclosed by Scandinavia, Finland, the Baltic countries, and the North European Plain. It includes the Gulf of Bothnia, the Bay of Bothnia, the Gulf of Finland, the Gulf of Riga, and the Bay of Gdańsk. The sea stretches from 53°N to 66°N latitude and from 10°E to 30°E longitude. A mediterranean sea of the Atlantic, with limited water exchange between the two bodies, the Baltic Sea drains through the Danish islands into the Kattegat by way of the straits of Øresund, the Great Belt, and the Little Belt.
The Baltic Proper is bordered on its northern edge, at the latitude 60°N, by the Åland islands and the Gulf of Bothnia, on its northeastern edge by the Gulf of Finland, on its eastern edge by the Gulf of Riga, and in the West by the South-Swedish part of the Scandinavian Peninsula.
The Baltic Sea is connected by artificial waterways to the White Sea via the White Sea Canal and to the German Bight of the North Sea via the Kiel Canal.
Definitions.
Administration:
The Helsinki Convention on the Protection of the Marine Environment of the Baltic Sea Area includes the Baltic Sea and the Kattegat, without calling Kattegat a part of the Baltic Sea, "For the purposes of this Convention the "Baltic Sea Area" shall be the Baltic Sea and the Entrance to the Baltic Sea, bounded by the parallel of the Skaw in the Skagerrak at 57°44.43'N."
Traffic history:
Historically, the Kingdom of Denmark collected Sound Dues from ships at the border between the ocean and the land-locked Baltic Sea. They were collected in the Øresund at Kronborg castle near Helsingør, in the Great Belt at Nyborg. In the Little Belt, the site of intake was moved to Fredericia, after that stronghold had been built. The narrowest part of Little Belt is the "Middelfart Sund" near Middelfart.
Oceanography:
Geographers widely agree that the preferred physical border of the Baltic is a line drawn through the southern Danish islands, Drogden-Sill and Langeland. The Drogden Sill is situated north of Køge Bugt and connects Dragør in the south of Copenhagen to Malmö; it is used by the Øresund Bridge, including the "Drogden Tunnel". By this definition, the Danish Straits are part of the entrance, but the Bay of Mecklenburg and the Bay of Kiel are parts of the Baltic Sea.
Hydrography and biology:
Drogden Sill (depth of ) sets a limit to Øresund and Darss Sill (depth of ), and a limit to the Belt Sea. The shallow sills are obstacles to the flow of heavy salt water from the Kattegat into the basins around Bornholm and Gotland.
The Kattegat and the southwestern Baltic Sea are well oxygenated and have a rich biology. The remainder of the Sea is brackish, poor in oxygen and in species. Thus, statistically, the more of the entrance that is included in its definition, the healthier the Baltic appears; conversely, the more narrowly it is defined, the more endangered its biology appears.
Etymology.
While Tacitus called it "Mare Suebicum" after the Germanic people called the Suebi, the first to name it the "Baltic Sea" ("Mare Balticum") was the eleventh-century German chronicler Adam of Bremen. The origin of the latter name is speculative. It might be connected to the Germanic word "belt", a name used for two of the Danish straits, the Belts, while others claim it to be derived from Latin "balteus" (belt). Adam of Bremen himself compared the sea with a belt, stating that it is so named because it stretches through the land as a belt ("Balticus, eo quod in modum baltei longo tractu per Scithicas regiones tendatur usque in Greciam"). He might also have been influenced by the name of a legendary island mentioned in the "Natural History" of Pliny the Elder. Pliny mentions an island named Baltia (or "Balcia") with reference to accounts of Pytheas and Xenophon. It is possible that Pliny refers to an island named "Basilia" ("kingdom" or "royal") in "On the Ocean" by Pytheas. "Baltia" also might be derived from "belt" and mean "near belt of sea (strait)." Meanwhile, others have concluded that the name of the island originates from the Indo-European root *"bhel" meaning "white, fair". This root and its basic meaning were retained in both Lithuanian (as "baltas") and Latvian (as "balts"). On this basis, a related hypothesis holds that the name originated from this Indo-European root via a Baltic language such as Lithuanian. Another explanation is that, while derived from the aforementioned root, the name of the sea is related to names for various forms of water and related substances in several European languages, that might have been originally associated with colors found in swamps. Yet another explanation is that the name originally meant "enclosed sea, bay" as opposed to open sea.
Some Swedish historians believe the name derives from the god Balder of Nordic mythology.
In the Middle Ages the sea was known by variety of names. The name "Baltic Sea" became dominant only after 1600. Usage of "Baltic" and similar terms to denote the region east of the sea started only in 19th century.
Name in other languages.
The Baltic Sea was known in ancient sources as "Mare Suebicum" or "Mare Germanicum". It is also known by the equivalents of "East Sea", "West Sea", or "Baltic Sea" in different languages:
History.
The Classical world.
At the time of the Roman Empire, the Baltic Sea was known as the "Mare Suebicum" or "Mare Sarmaticum". Tacitus in his AD 98 "Agricola" and "Germania" described the Mare Suebicum, named for the Suebi tribe, during the spring months, as a brackish sea where the ice broke apart and chunks floated about. The Suebi eventually migrated south west to reside for a while in the Rhineland area of modern Germany, where their name survives in the historic region known as Swabia. Jordanes called it the "Germanic Sea" in his work, the "Getica".
The Middle Ages.
In the early Middle Ages, Norse (Scandinavian) merchants built a trade empire all around the Baltic. Later, the Norse fought for control of the Baltic against Wendish tribes dwelling on the southern shore. The Norse also used the rivers of Russia for trade routes, finding their way eventually to the Black Sea and southern Russia. This Norse-dominated period is referred to as the Viking Age.
Since the Viking age, the Scandinavians have referred to the Baltic Sea as "Austmarr" ("Eastern Lake"). "Eastern Sea", appears in the "Heimskringla" and "Eystra salt" appears in "Sörla þáttr". Saxo Grammaticus recorded in "Gesta Danorum" an older name, "Gandvik", "-vik" being Old Norse for "bay", which implies that the Vikings correctly regarded it as an inlet of the sea. Another form of the name, "Grandvik", attested in at least one English translation of "Gesta Danorum", is likely to be a misspelling.)
In addition to fish the sea also provides amber, especially from its southern shores. The bordering countries have traditionally exported lumber, wood tar, flax, hemp and furs by ship across the Baltic. Sweden had from early medieval times exported iron and silver mined there, while Poland had and still has extensive salt mines. Thus the Baltic Sea has long been crossed by much merchant shipping.
The lands on the Baltic's eastern shore were among the last in Europe to be converted to Christianity. This finally happened during the Northern Crusades: Finland in the twelfth century by Swedes, and what are now Estonia and Latvia in the early thirteenth century by Danes and Germans (Livonian Brothers of the Sword). The Teutonic Order gained control over parts of the southern and eastern shore of the Baltic Sea, where they set up their monastic state. Lithuania was the last European state to convert to Christianity.
An arena of conflict.
In the period between the 8th and 14th centuries, there was much piracy in the Baltic from the coasts of Pomerania and Prussia, and the Victual Brothers even held Gotland.
Starting in the 11th century, the southern and eastern shores of the Baltic were settled by migrants mainly from Germany, a movement called the "Ostsiedlung" ("east settling"). Other settlers were from the Netherlands, Denmark, and Scotland. The Polabian Slavs were gradually assimilated by the Germans. Denmark gradually gained control over most of the Baltic coast, until she lost much of her possessions after being defeated in the 1227 Battle of Bornhöved.
In the 13th to 17th centuries, the strongest economic force in Northern Europe was the Hanseatic League, a federation of merchant cities around the Baltic Sea and the North Sea. In the sixteenth and early seventeenth centuries, Poland, Denmark, and Sweden fought wars for "Dominium maris baltici" ("Lordship over the Baltic Sea"). Eventually, it was Sweden that virtually encompassed the Baltic Sea. In Sweden the sea was then referred to as "Mare Nostrum Balticum" ("Our Baltic Sea"). The goal of Swedish warfare during the 17th century was to make the Baltic Sea an all-Swedish sea ("Ett Svenskt innanhav"). Something that was accomplishes except the rout between Riga in Latvia and Szczecin in Poland.
However, it was the Dutch who dominated Baltic trade in the seventeenth century.
In the eighteenth century, Russia and Prussia became the leading powers over the sea. Sweden's defeat in the Great Northern War brought Russia to the eastern coast. Russia became and remained a dominating power in the Baltic. Russia's Peter the Great saw the strategic importance of the Baltic and decided to found his new capital, Saint Petersburg, at the mouth of the Neva river at the east end of the Gulf of Finland. There was much trading not just within the Baltic region but also with the North Sea region, especially eastern England and the Netherlands: their fleets needed the Baltic timber, tar, flax and hemp.
During the Crimean War, a joint British and French fleet attacked the Russian fortresses in the Baltic. They bombarded Sveaborg, which guards Helsinki; and Kronstadt, which guards Saint Petersburg; and they destroyed Bomarsund in the Åland Islands. After the unification of Germany in 1871, the whole southern coast became German. World War I was partly fought in the Baltic Sea. After 1920 Poland was connected to the Baltic Sea by the Polish Corridor and enlarged the port of Gdynia in rivalry with the port of the Free City of Danzig.
During World War II, Germany reclaimed all of the southern and much of the eastern shore by occupying Poland and the Baltic states. In 1945, the Baltic Sea became a mass grave for retreating soldiers and refugees on torpedoed troop transports. The sinking of the "Wilhelm Gustloff" remains the worst maritime disaster in history, killing (very roughly) 9,000 people. In 2005, a Russian group of scientists found over five thousand airplane wrecks, sunken warships, and other material, mainly from World War II, on the bottom of the sea.
Since World War II.
Since the end of World War II, various nations, including the Soviet Union, the United Kingdom and the United States, have disposed of chemical weapons in the Baltic Sea, raising concerns of environmental contamination. Even now fishermen accidentally retrieve some of these materials: the most recent available report from the Helsinki Commission notes that four small scale catches of chemical munitions representing approximately of material were reported in 2005. This is a reduction from the 25 incidents representing of material in 2003. Until now, the U.S. Government refuses to disclose the exact coordinates of the wreck sites. Rotting bottles leak Lost and other substances, thus slowly poisoning a substantial part of the Baltic Sea.
After 1945, the German population was expelled from all areas east of the Oder-Neisse line, making room for displaced Poles and Russians. Poland gained most of the southern shore. The Soviet Union gained another access to the Baltic with the Kaliningrad Oblast. The Baltic states on the eastern shore were annexed by the Soviet Union. The Baltic then separated opposing military blocs: NATO and the Warsaw Pact. Had war broken out, the Polish navy was prepared to invade the Danish isles. This border status restricted trade and travel. It ended only after the collapse of the Communist regimes in Central and Eastern Europe in the late 1980s.
Since May 2004, with the accession of the Baltic states and Poland, the Baltic Sea has been almost entirely surrounded by countries of the European Union (EU). The only remaining non-EU shore areas are Russian: the Saint Petersburg area and the exclave of the Kaliningrad Oblast.
Winter storms begin arriving in the region during October. These have caused numerous shipwrecks, and contributed to the extreme difficulties of rescuing passengers of the ferry "M/S Estonia" en route from Tallinn, Estonia, to Stockholm, Sweden, in September 1994, which claimed the lives of 852 people. Older, wood-based shipwrecks such as the "Vasa" tend to remain well-preserved, as the Baltic's cold and brackish water does not suit the shipworm.
Storm floods.
Storm surge floodings are generally taken to occur when the water level is more than one metre above normal. In Warnemünde about 110 floods occurred from 1950 to 2000, an average of just over two per year.
Historic flood events were the All Saints' Flood of 1304 and other floods in the years 1320, 1449, 1625, 1694, 1784 and 1825. Little is known of their extent. From 1872, there exist regular and reliable records of water levels in the Baltic Sea. The highest was the flood of 1872 when the water was an average of above sea level at Warnemünde and a maximum of above sea level in Warnemünde. In the last very heavy floods the average water levels reached above sea level in 1904, in 1913, in January 1954, on 2–4 November 1995 and on 21 February 2002.
Geography.
Geophysical data.
An arm of the North Atlantic Ocean, the Baltic Sea is enclosed by Scandinavia to the northwest, Finland to the northeast, the Baltic countries to the southeast, and the North European Plain to the southwest.
It is about long, an average of wide, and an average of deep. The maximum depth is which is on the Swedish side of the center. The surface area is about and the volume is about . The periphery amounts to about of coastline.
The Baltic Sea is one of the largest brackish inland seas by area, and occupies a basin (a "zungenbecken") formed by glacial erosion during the last few ice ages.
Physical characteristics of the Baltic Sea, its main sub-regions, and the transition zone to the Skagerrak/North Sea area
Extent.
The International Hydrographic Organization defines the limits of the Baltic Sea as follows:
Subdivisions.
The northern part of the Baltic Sea is known as the Gulf of Bothnia, of which the northernmost part is the Bay of Bothnia or Bothnian Bay. The more rounded southern basin of the gulf is called Bothnian Sea and immediately to the south of it lies the Sea of Åland. The Gulf of Finland connects the Baltic Sea with Saint Petersburg. The Gulf of Riga lies between the Latvian capital city of Riga and the Estonian island of Saaremaa.
The Northern Baltic Sea lies between the Stockholm area, southwestern Finland and Estonia. The Western and Eastern Gotland Basins form the major parts of the Central Baltic Sea or Baltic proper. The Bornholm Basin is the area east of Bornholm, and the shallower Arkona Basin extends from Bornholm to the Danish isles of Falster and Zealand.
In the south, the Bay of Gdańsk lies east of the Hel Peninsula on the Polish coast and west of the Sambia Peninsula in Kaliningrad Oblast. The Bay of Pomerania lies north of the islands of Usedom and Wolin, east of Rügen. Between Falster and the German coast lie the Bay of Mecklenburg and Bay of Lübeck. The westernmost part of the Baltic Sea is the Bay of Kiel. The three Danish straits, the Great Belt, the Little Belt and The Sound ("Öresund"/"Øresund"), connect the Baltic Sea with the Kattegat and Skagerrak strait in the North Sea.
The ice.
On the long-term average, the Baltic Sea is ice-covered at the annual maximum for about 45% of its surface area. The ice-covered area during such a typical winter includes the Gulf of Bothnia, the Gulf of Finland, the Gulf of Riga, the archipelago west of Estonia, the Stockholm archipelago, and the Archipelago Sea southwest of Finland. The remainder of the Baltic does not freeze during a normal winter, with the exception of sheltered bays and shallow lagoons such as the Curonian Lagoon. The ice reaches its maximum extent in February or March; typical ice thickness in the northernmost areas in the Bothnian Bay, the northern basin of the Gulf of Bothnia, is about for landfast sea ice. The thickness decreases farther south.
Freezing begins in the northern extremities of Gulf of Bothnia typically in the middle of November, reaching the open waters of the Bothnian Bay in early January. The Bothnian Sea, the basin south of Kvarken, freezes on average in late February. The Gulf of Finland and the Gulf of Riga freeze typically in late January. In 2011, the Gulf of Finland was completely frozen on 15 February.
The ice extent depends on whether the winter is mild, moderate, or severe. Severe winters can lead to ice formation around southern Sweden and even in the Danish straits. According to the 18th-century natural historian William Derham, during the severe winters of 1703 and 1708, the ice cover reached as far as the Danish straits. Frequently, parts of the Gulf of Bothnia and Gulf of Finland are frozen, in addition to coastal fringes in more southerly locations such as the Gulf of Riga. This description meant that the whole of the Baltic Sea was covered with ice.
It is known that since 1720, the Baltic Sea has frozen over entirely a total of 20 times. The most recent case was in early 1987, which was the most severe winter in Scandinavia since that date. The ice then covered . During the winter of 2010–11, which was quite severe compared to those of the last decades, the maximum ice cover was , which was reached on 25 February 2011. The ice then extended from the north down to the northern tip of Gotland, with small ice-free areas on either side, and the east coast of the Baltic Sea was covered by an ice sheet about wide all the way to Gdańsk. This was brought about by a stagnant high-pressure area that lingered over central and northern Scandinavia from around 10 to 24 February. After this, strong southern winds pushed the ice further into the north, and much of the waters north of Gotland were again free of ice, which had then packed against the shores of southern Finland. The effects of the afore-mentioned high-pressure area did not reach the southern parts of the Baltic Sea, and thus the entire sea did not freeze over. However, floating ice was additionally observed near Świnoujście harbour in January 2010.
In recent years prior to 2011, the Bothnian Bay and the Bothnian Sea were frozen with solid ice near the Baltic coast and dense floating ice far from it. In 2008, there was almost no ice formation except for a short period in March.
During winter, fast ice, which is attached to the shoreline, develops first, rendering ports unusable without the services of icebreakers. Level ice, ice sludge, pancake ice, and rafter ice form in the more open regions. The gleaming expanse of ice is similar to the Arctic, with wind-driven pack ice and ridges up to . Offshore of the landfast ice, the ice remains very dynamic all year, and it is relatively easily moved around by winds and therefore forms pack ice, made up of large piles and ridges pushed against the landfast ice and shores.
In spring, the Gulf of Finland and the Gulf of Bothnia normally thaw in late April, with some ice ridges persisting until May in the eastern extremities of the Gulf of Finland. In the northernmost reaches of the Bothnian Bay, ice usually stays until late May; by early June it is practically always gone.
The ice cover is the main habitat for two large mammals, the grey seal ("Halichoerus grypus") and the Baltic ringed seal ("Pusa hispida botnica"), both of which feed underneath the ice and breed on its surface. Of these two seals, only the Baltic ringed seal suffers when there is not adequate ice in the Baltic Sea, as it feeds its young only on ice. The grey seal is adapted to reproducing also with no ice in the sea. The sea ice also harbours several species of algae that live in the bottom and inside unfrozen brine pockets in the ice.
Hydrography.
The Baltic Sea flows out through the Danish straits; however, the flow is complex. A surface layer of brackish water discharges per year into the North Sea. Due to the difference in salinity, by salinity permeation principle, a sub-surface layer of more saline water moving in the opposite direction brings in per year. It mixes very slowly with the upper waters, resulting in a salinity gradient from top to bottom, with most of the salt water remaining below deep. The general circulation is counter-clockwise: northwards along its eastern boundary, and south along the western one .
The difference between the outflow and the inflow comes entirely from fresh water. More than 250 streams drain a basin of about , contributing a volume of per year to the Baltic. They include the major rivers of north Europe, such as the Oder, the Vistula, the Neman, the Daugava and the Neva. Additional fresh water comes from the difference of precipitation less evaporation, which is positive.
An important source of salty water are infrequent inflows of North Sea water into the Baltic. Such inflows, important to the Baltic ecosystem because of the oxygen they transport into the Baltic deeps, used to happen on average every four to five years until the 1980s. In recent decades they have become less frequent. The latest four occurred in 1983, 1993, 2003 and 2014 suggesting a new inter-inflow period of about ten years.
The water level is generally far more dependent on the regional wind situation than on tidal effects. However, tidal currents occur in narrow passages in the western parts of the Baltic Sea.
The significant wave height is generally much lower than that of the North Sea. Violent and sudden storms often sweep the surface, due to large transient temperature differences and a long reach of wind. Seasonal winds also cause small changes in sea level, of the order of .
Salinity.
The Baltic Sea's salinity is much lower than that of ocean water (which averages 3.5%), as a result of abundant freshwater runoff from the surrounding land, combined with the shallowness of the sea itself; indeed, runoff contributes roughly one-fortieth its total volume per year, as the volume of the basin is about and yearly runoff is about . The open surface waters of the central basin have salinity of 0.5% to 0.8%, which makes the basin border-line or, nearly Freshwater. Drinking the water as a means of survival would actually hydrate the body instead of dehydrating, like that of ocean water. At the semi-enclosed bays with major freshwater inflows, such as head of Finnish Gulf with Neva mouth and head of Bothnian gulf with close mouths of Lule, Tornio and Kemi, the salinity is considerably lower. Below , the salinity is between 1.0% and 1.5% in the open Baltic Sea, and more than this near Danish Straits, but this is still less than half that of ocean water.
The flow of fresh water into the sea from approximately two-hundred rivers and the introduction of salt from the South builds up a gradient of salinity in the Baltic Sea. Near the Danish straits the salinity is close to that of the Kattegat, but still not fully oceanic, because the saltiest water that passes the straits is still already mixed with considerable amounts of outflow water. The salinity steadily decreases towards North and East. At the northern part of the Gulf of Bothnia the water is no longer salty and many fresh water species live in the sea. The salinity gradient is paralleled by a temperature gradient. These two factors limit many species of animals and plants to a relatively narrow region of Baltic Sea.
The most saline water is vertically stratified in the water column to the north, creating a barrier to the exchange of oxygen and nutrients, and fostering completely separate maritime environments.
Major tributaries.
The rating of mean discharges differs from the ranking of hydrological lengths (from the most distant source to the sea) and the rating of the nominal lengths. Göta älv, a tributary of the Kattegat, is not listed, as due to the northward upper low-salinity-flow in the sea, its water hardly reaches the Baltic proper:
Coastal countries.
Countries that border on the sea:
Countries that are in the drainage basin but do not border on the sea:
The Baltic sea drainage basin is roughly four times the surface area of the sea itself. About 48% of the region is forested, with Sweden and Finland containing the majority of the forest, especially around the Gulfs of Bothnia and Finland.
About 20% of the land is used for agriculture and pasture, mainly in Poland and around the edge of the Baltic Proper, in Germany, Denmark and Sweden. About 17% of the basin is unused open land with another 8% of wetlands. Most of the latter are in the Gulfs of Bothnia and Finland.
The rest of the land is heavily populated. About 85 million people live in the Baltic drainage basin, 15 million within of the coast and 29 million within of the coast. Around 22 million live in population centers of over 250,000. 90% of these are concentrated in the band around the coast. Of the nations containing all or part of the basin, Poland includes 45% of the 85 million, Russia 12%, Sweden 10% and the others less than 6% each.
Cities.
The biggest coastal cities (by population):
Important ports (though not big cities):
"Estonia:"
"Finland:"
"Germany:"
"Latvia:"
"Lithuania:"
"Poland:"
"Russia:"
"Sweden:"
Geology.
The Baltic Sea somewhat resembles a riverbed, with two tributaries, the Gulf of Finland and Gulf of Bothnia. Geological surveys show that before the Pleistocene, instead of the Baltic Sea, there was a wide plain around a great river paleontologists call the Eridanos. Several Pleistocene glacial episodes scooped out the river bed into the sea basin. By the time of the last, or Eemian Stage (MIS 5e), the Eemian Sea was in place. Instead of a true sea, the Baltic can even today also be understood as the common estuary of all rivers flowing into it.
From that time the waters underwent a geologic history summarized under the names listed below. Many of the stages are named after marine animals (e.g. the Littorina mollusk) that are clear markers of changing water temperatures and salinity.
The factors that determined the sea's characteristics were the submergence or emergence of the region due to the weight of ice and subsequent isostatic readjustment, and the connecting channels it found to the North Sea-Atlantic, either through the straits of Denmark or at what are now the large lakes of Sweden, and the White Sea-Arctic Sea.
The land is still emerging isostatically from its depressed state, which was caused by the weight of ice during the last glaciation. The phenomenon is known as post-glacial rebound. Consequently, the surface area and the depth of the sea are diminishing. The uplift is about eight millimetres per year on the Finnish coast of the northernmost Gulf of Bothnia. In the area, the former seabed is only gently sloping, leading to large areas of land being reclaimed in what are, geologically speaking, relatively short periods (decades and centuries).
Anomalous object formation.
The Baltic Sea anomaly is a 60-metre (200 ft) diameter circular rock-like formation on the floor of the northern Baltic Sea at the center of the Bothnian Sea, discovered by Peter Lindberg, Dennis Åsberg and their Swedish "Ocean X" diving team in June 2011. The team reported that the formation rests on a pillar and includes a structure similar in appearance to a staircase, leading to a dark hole.
According to Ocean X, the formation has an appearance of "rough granite", is round, thick and approximately in diameter, stands on an tall pillar-like feature, and is located at a depth of . There is also another smaller object not far away. The object is at the end of what resembles a "runway".
The Ocean X team has published one additional close-up sonar scan on their Web site and nine additional close-up sonar scans on their YouTube page that appear to show a 90-degree angle and other features of the object.
On their second expedition, they reported that they found something that looks like a staircase and a round black hole that goes directly into the structure.
Biology.
Fauna.
The fauna of the Baltic sea is a mixture of marine and freshwater species. Among marine fishes are cod, herring, hake, plaice, flounder, shorthorn sculpin, stickleback and turbot, and examples of freshwater species include perch, pike, whitefish and roach.
There is a decrease in faunal species from the Belts to the Gulf of Bothnia. The decreasing salinity along this path causes restrictions in both physiology and habitats. The lack of tides has affected the marine species as compared with the Atlantic.
Since the Baltic Sea is so young there are only a few endemic species. The mostly asexually reproducing brown alga "Fucus radicans" seems to have evolved in the basin. Another endemic is the Copenhagen cockle "Parvicardium hauniense". However, several marine species have populations in the Baltic Sea adapted to the low salinity, such as the Baltic Sea herring which is smaller than the Atlantic herring.
A peculiar feature of the fauna is that it contains a number of glacial relict species, isolated populations of arctic species which have remained in the Baltic Sea since the last glaciation, such as the large isopod "Saduria entomon", the Baltic subspecies of ringed seal, and the fourhorn sculpin. Some of these relicts are derived from glacial lakes, such as "Monoporeia affinis", which is a main element in the benthic fauna of the low-salinity Bothnian Bay.
Cetaceans in Baltic Sea have been monitored by the ASCOBANS. Critically endangered populations of Atlantic white-sided dolphins and harbor porpoises inhabit the sea where white-colored porpoises have been recorded, and occasionally oceanic species such as bottlenose dolphins, orcas, and beaked whales visit the waters. In recent years, very small, but with an increasing rate, humpback whales migrate into Baltic sea including mother and calf pair. Now extinct Atlantic grey whales and eastern population of North Atlantic right whales that is facing functional extinction once migrated into Baltic Sea.
Strandings of Leatherback turtles have been recorded in Baltic Sea, too. Other notable megafauna include the basking sharks.
Environmental status.
Satellite images taken in July 2010 revealed a massive algal bloom covering in the Baltic Sea. The area of the bloom extended from Germany and Poland to Finland. Researchers of the phenomenon have indicated that algal blooms have occurred every summer for decades. Fertilizer runoff from surrounding agricultural land has exacerbated the problem and led to increased eutrophication.
Approximately of the Baltic's seafloor (a quarter of its total area) is a variable dead zone. The more saline (and therefore denser) water remains on the bottom, isolating it from surface waters and the atmosphere. This leads to decreased oxygen concentrations within the zone. It is mainly bacteria that grow in it, digesting organic material and releasing hydrogen sulfide. Because of this large anaerobic zone, the seafloor ecology differs from that of the neighbouring Atlantic.
Plans to artificially oxygenate areas of the Baltic that have experienced eutrophication have been proposed by the University of Gothenburg and Inocean AB. The proposal intends to use wind-driven pumps to inject oxygen (air) into waters at, or around, 130m below sea level.
Economy.
Construction of the Great Belt Bridge in Denmark (completed 1997) and the Øresund Bridge-Tunnel (completed 1999), linking Denmark with Sweden, provided a highway and railroad connection between Sweden and the Danish mainland (the Jutland Peninsula). The undersea tunnel of the Øresund Bridge-Tunnel provides for navigation of large ships into and out of the Baltic Sea. The Baltic Sea is the main trade route for export of Russian petroleum. Many of the countries neighboring the Baltic Sea have been concerned about this, since a major oil leak in a seagoing tanker would be disastrous for the Baltic—given the slow exchange of water. The tourism industry surrounding the Baltic Sea is naturally concerned about oil pollution.
Much shipbuilding is carried out in the shipyards around the Baltic Sea. The largest shipyards are at Gdańsk, Gdynia, and Szczecin, Poland; Kiel, Germany; Karlskrona and Malmö, Sweden; Rauma, Turku, and Helsinki, Finland; Riga, Ventspils, and Liepāja, Latvia; Klaipėda, Lithuania; and Saint Petersburg, Russia.
There are several cargo and passenger ferries that operate on the Baltic Sea, such as Scandlines, Silja Line, Polferries, the Viking Line, Tallink, and Superfast Ferries.
Tourism.
European Route of Brick Gothic.
European Route of Brick Gothic is a touristic route connecting cities with Brick Gothic architecture in three countries along the Baltic Sea: Denmark, Germany and Poland.
Resort towns.
Examples:
The Helsinki Convention.
1974 Convention.
For the first time ever, all the sources of pollution around an entire sea were made subject to a single convention, signed in 1974 by the then seven Baltic coastal states. The 1974 Convention entered into force on 3 May 1980.
1992 Convention.
In the light of political changes and developments in international environmental and maritime law, a new convention was signed in 1992 by all the states bordering on the Baltic Sea, and the European Community. After ratification the Convention entered into force on 17 January 2000. The Convention covers the whole of the Baltic Sea area, including inland waters and the water of the sea itself, as well as the seabed. Measures are also taken in the whole catchment area of the Baltic Sea to reduce land-based pollution. The Convention on the Protection of the Marine Environment of the Baltic Sea Area, 1992, entered into force on 17 January 2000.
The governing body of the Convention is the Helsinki Commission, also known as HELCOM, or Baltic Marine Environment Protection Commission. The present contracting parties are Denmark, Estonia, the European Community, Finland, Germany, Latvia, Lithuania, Poland, Russia and Sweden.
The ratification instruments were deposited by the European Community, Germany, Latvia and Sweden in 1994, by Estonia and Finland in 1995, by Denmark in 1996, by Lithuania in 1997 and by Poland and Russia in November 1999.

</doc>
<doc id="3336" url="https://en.wikipedia.org/wiki?curid=3336" title="Brackish water">
Brackish water

Brackish water or briny water is water that has more salinity than fresh water, but not as much as seawater. It may result from mixing of seawater with fresh water, as in estuaries, or it may occur in brackish fossil aquifers. The word comes from the Middle Dutch root "brak". Certain human activities can produce brackish water, in particular civil engineering projects such as dikes and the flooding of coastal marshland to produce brackish water pools for freshwater prawn farming. Brackish water is also the primary waste product of the salinity gradient power process. Because brackish water is hostile to the growth of most terrestrial plant species, without appropriate management it is damaging to the environment (see article on shrimp farms).
Technically, brackish water contains between 0.5 and 30 grams of salt per litre—more often expressed as 0.5 to 30 parts per thousand (ppt or ‰), which is a specific gravity of between 1.005 and 1.010. Thus, "brackish" covers a range of salinity regimes and is not considered a precisely defined condition. It is characteristic of many brackish surface waters that their salinity can vary considerably over space and/or time.
Brackish water habitats.
Estuaries.
Brackish water condition commonly occurs when fresh water meets seawater. In fact, the most extensive brackish water habitats worldwide are estuaries, where a river meets the sea.
The River Thames flowing through London is a classic river estuary. The town of Teddington a few miles west of London marks the boundary between the tidal and non-tidal parts of the Thames, although it is still considered a freshwater river about as far east as Battersea insofar as the average salinity is very low and the fish fauna consists predominantly of freshwater species such as roach, dace, carp, perch, and pike. The Thames Estuary becomes brackish between Battersea and Gravesend, and the diversity of freshwater fish species present is smaller, primarily roach and dace; euryhaline marine species such as flounder, European seabass, mullet, and smelt become much more common. Further east, the salinity increases and the freshwater fish species are completely replaced by euryhaline marine ones, until the river reaches Gravesend, at which point conditions become fully marine and the fish fauna resembles that of the adjacent North Sea and includes both euryhaline and stenohaline marine species. A similar pattern of replacement can be observed with the aquatic plants and invertebrates living in the river.
This type of ecological succession from a freshwater to marine ecosystem is typical of river estuaries. River estuaries form important staging points during the migration of anadromous and catadromous fish species, such as salmon, shad, and eels, giving them time to form social groups and to adjust to the changes in salinity. Salmon are anadromous, meaning they live in the sea but ascend rivers to spawn; eels are catadromous, living in rivers and streams, but returning to the sea to breed. Besides the species that migrate through estuaries, there are many other fish that use them as "nursery grounds" for spawning or as places young fish can feed and grow before moving elsewhere. Herring and plaice are two commercially important species that use the Thames Estuary for this purpose.
Estuaries are also commonly used as fishing grounds, and as places for fish farming or ranching. For example, Atlantic salmon farms are often located in estuaries, although this has caused controversy, because in doing so, fish farmers expose migrating wild fish to large numbers of external parasites such as sea lice that escape from the pens the farmed fish are kept in.
Mangroves.
Another important brackish water habitat is the mangrove swamp or mangal. Many, though not all, mangrove swamps fringe estuaries and lagoons where the salinity changes with each tide. Among the most specialised residents of mangrove forests are mudskippers, fish that forage for food on land, and archer fish, perch-like fish that "spit" at insects and other small animals living in the trees, knocking them into the water where they can be eaten. Like estuaries, mangrove swamps are extremely important breeding grounds for many fish, with species such as snappers, halfbeaks, and tarpon spawning or maturing among them. Besides fish, numerous other animals use mangroves, including such specialists as the saltwater crocodile, American crocodile, proboscis monkey, diamondback terrapin, and the crab-eating frog, "Fejervarya cancrivora" (formerly "Rana cancrivora"). Mangroves represent important nesting site for numerous birds groups such as herons, storks, spoonbills, ibises, kingfishers, shorebirds and seabirds.
Although often plagued with mosquitoes and other insects that make them unpleasant for humans, mangrove swamps are very important buffer zones between land and sea, and are a natural defense against hurricane and tsunami damage in particular.
The Sundarbans and Bhitarkanika Mangroves are two of the large mangrove forests in the world, both on the coast of the Bay of Bengal.
Brackish seas and lakes.
Some seas and lakes are brackish. The Baltic Sea is a brackish sea adjoining the North Sea. Originally the confluence of two major river systems prior to the Pleistocene, since then it has been flooded by the North Sea but still receives so much freshwater from the adjacent lands that the water is brackish. Because the salt water coming in from the sea is denser than freshwater, the water in the Baltic is stratified, with salt water at the bottom and freshwater at the top. Limited mixing occurs because of the lack of tides and storms, with the result that the fish fauna at the surface is freshwater in composition while that lower down is more marine. Cod are an example of a species only found in deep water in the Baltic, while pike are confined to the less saline surface waters.
The Caspian Sea is the world's largest lake and contains brackish water with a salinity about one-third that of normal seawater. The Caspian is famous for its peculiar animal fauna, including one of the few non-marine seals (the Caspian seal) and the great sturgeons, a major source of caviar.
In the Black Sea the surface water is brackish with an average salinity of about 17-18 parts per thousand compared to 30 to 40 for the oceans. The deep, anoxic water of the Black Sea originates from warm, salty water of the Mediterranean.
Brackish marsh.
A brackish marsh may occur where a freshwater flow enters a salt marsh.
Notable brackish bodies of water (by type, in alphabetical order).
Brackish seas
Brackish water lakes
Lochs (Scottish)
Coastal lagoons, marshes, and deltas
Estuaries

</doc>
